title,authors,published,summary,cleaned_summary,word_list
"Integrating AI Planning with Natural Language Processing: A Combination
  of Explicit and Tacit Knowledge","Kebing Jin, Hankz Hankui Zhuo",2022-02-15T02:19:09Z,"  Natural language processing (NLP) aims at investigating the interactions
between agents and humans, processing and analyzing large amounts of natural
language data. Large-scale language models play an important role in current
natural language processing. However, the challenges of explainability and
complexity come along with the developments of language models. One way is to
introduce logical relations and rules into natural language processing models,
such as making use of Automated Planning. Automated planning (AI planning)
focuses on building symbolic domain models and synthesizing plans to transit
initial states to goals based on domain models. Recently, there have been
plenty of works related to these two fields, which have the abilities to
generate explicit knowledge, e.g., preconditions and effects of action models,
and learn from tacit knowledge, e.g., neural models, respectively. Integrating
AI planning and natural language processing effectively improves the
communication between human and intelligent agents. This paper outlines the
commons and relations between AI planning and natural language processing,
argues that each of them can effectively impact on the other one by five areas:
(1) planning-based text understanding, (2) planning-based natural language
processing, (3) planning-based explainability, (4) text-based human-robot
interaction, and (5) applications. We also explore some potential future issues
between AI planning and natural language processing. To the best of our
knowledge, this survey is the first work that addresses the deep connections
between AI planning and Natural language processing.
","['natural', 'language', 'processing', '(', 'nlp', ')', 'aims', 'investigating', 'interactions', 'agents', 'humans', ',', 'processing', 'analyzing', 'large', 'amounts', 'natural', 'language', 'data', '.', 'large-scale', 'language', 'models', 'play', 'important', 'role', 'current', 'natural', 'language', 'processing', '.', 'however', ',', 'challenges', 'explainability', 'complexity', 'come', 'along', 'developments', 'language', 'models', '.', 'one', 'way', 'introduce', 'logical', 'relations', 'rules', 'natural', 'language', 'processing', 'models', ',', 'making', 'use', 'automated', 'planning', '.', 'automated', 'planning', '(', 'ai', 'planning', ')', 'focuses', 'building', 'symbolic', 'domain', 'models', 'synthesizing', 'plans', 'transit', 'initial', 'states', 'goals', 'based', 'domain', 'models', '.', 'recently', ',', 'plenty', 'works', 'related', 'two', 'fields', ',', 'abilities', 'generate', 'explicit', 'knowledge', ',', 'e.g.', ',', 'preconditions', 'effects', 'action', 'models', ',', 'learn', 'tacit', 'knowledge', ',', 'e.g.', ',', 'neural', 'models', ',', 'respectively', '.', 'integrating', 'ai', 'planning', 'natural', 'language', 'processing', 'effectively', 'improves', 'communication', 'human', 'intelligent', 'agents', '.', 'paper', 'outlines', 'commons', 'relations', 'ai', 'planning', 'natural', 'language', 'processing', ',', 'argues', 'effectively', 'impact', 'one', 'five', 'areas', ':', '(', '1', ')', 'planning-based', 'text', 'understanding', ',', '(', '2', ')', 'planning-based', 'natural', 'language', 'processing', ',', '(', '3', ')', 'planning-based', 'explainability', ',', '(', '4', ')', 'text-based', 'human-robot', 'interaction', ',', '(', '5', ')', 'applications', '.', 'also', 'explore', 'potential', 'future', 'issues', 'ai', 'planning', 'natural', 'language', 'processing', '.', 'best', 'knowledge', ',', 'survey', 'first', 'work', 'addresses', 'deep', 'connections', 'ai', 'planning', 'natural', 'language', 'processing', '.']","natural, language, processing, (, nlp, ), aims, investigating, interactions, agents, humans, ,, processing, analyzing, large, amounts, natural, language, data, ., large-scale, language, models, play, important, role, current, natural, language, processing, ., however, ,, challenges, explainability, complexity, come, along, developments, language, models, ., one, way, introduce, logical, relations, rules, natural, language, processing, models, ,, making, use, automated, planning, ., automated, planning, (, ai, planning, ), focuses, building, symbolic, domain, models, synthesizing, plans, transit, initial, states, goals, based, domain, models, ., recently, ,, plenty, works, related, two, fields, ,, abilities, generate, explicit, knowledge, ,, e.g., ,, preconditions, effects, action, models, ,, learn, tacit, knowledge, ,, e.g., ,, neural, models, ,, respectively, ., integrating, ai, planning, natural, language, processing, effectively, improves, communication, human, intelligent, agents, ., paper, outlines, commons, relations, ai, planning, natural, language, processing, ,, argues, effectively, impact, one, five, areas, :, (, 1, ), planning-based, text, understanding, ,, (, 2, ), planning-based, natural, language, processing, ,, (, 3, ), planning-based, explainability, ,, (, 4, ), text-based, human-robot, interaction, ,, (, 5, ), applications, ., also, explore, potential, future, issues, ai, planning, natural, language, processing, ., best, knowledge, ,, survey, first, work, addresses, deep, connections, ai, planning, natural, language, processing, ."
Towards the Study of Morphological Processing of the Tangkhul Language,"Mirinso Shadang, Navanath Saharia, Thoudam Doren Singh",2020-06-29T17:24:09Z,"  There is no or little work on natural language processing of Tangkhul
language. The current work is a humble beginning of morphological processing of
this language using an unsupervised approach. We use a small corpus collected
from different sources of text books, short stories and articles of other
topics. Based on the experiments carried out, the morpheme identification task
using morphessor gives reasonable and interesting output despite using a small
corpus.
","['little', 'work', 'natural', 'language', 'processing', 'tangkhul', 'language', '.', 'current', 'work', 'humble', 'beginning', 'morphological', 'processing', 'language', 'using', 'unsupervised', 'approach', '.', 'use', 'small', 'corpus', 'collected', 'different', 'sources', 'text', 'books', ',', 'short', 'stories', 'articles', 'topics', '.', 'based', 'experiments', 'carried', ',', 'morpheme', 'identification', 'task', 'using', 'morphessor', 'gives', 'reasonable', 'interesting', 'output', 'despite', 'using', 'small', 'corpus', '.']","little, work, natural, language, processing, tangkhul, language, ., current, work, humble, beginning, morphological, processing, language, using, unsupervised, approach, ., use, small, corpus, collected, different, sources, text, books, ,, short, stories, articles, topics, ., based, experiments, carried, ,, morpheme, identification, task, using, morphessor, gives, reasonable, interesting, output, despite, using, small, corpus, ."
Deploying Technology to Save Endangered Languages,"Hilaria Cruz, Joseph Waring",2019-08-23T18:31:35Z,"  Computer scientists working on natural language processing, native speakers
of endangered languages, and field linguists to discuss ways to harness
Automatic Speech Recognition, especially neural networks, to automate
annotation, speech tagging, and text parsing on endangered languages.
","['computer', 'scientists', 'working', 'natural', 'language', 'processing', ',', 'native', 'speakers', 'endangered', 'languages', ',', 'field', 'linguists', 'discuss', 'ways', 'harness', 'automatic', 'speech', 'recognition', ',', 'especially', 'neural', 'networks', ',', 'automate', 'annotation', ',', 'speech', 'tagging', ',', 'text', 'parsing', 'endangered', 'languages', '.']","computer, scientists, working, natural, language, processing, ,, native, speakers, endangered, languages, ,, field, linguists, discuss, ways, harness, automatic, speech, recognition, ,, especially, neural, networks, ,, automate, annotation, ,, speech, tagging, ,, text, parsing, endangered, languages, ."
A Precis of Language Models are not Models of Language,Csaba Veres,2022-05-16T12:50:58Z,"  Natural Language Processing is one of the leading application areas in the
current resurgence of Artificial Intelligence, spearheaded by Artificial Neural
Networks. We show that despite their many successes at performing linguistic
tasks, Large Neural Language Models are ill-suited as comprehensive models of
natural language. The wider implication is that, in spite of the often
overbearing optimism about AI, modern neural models do not represent a
revolution in our understanding of cognition.
","['natural', 'language', 'processing', 'one', 'leading', 'application', 'areas', 'current', 'resurgence', 'artificial', 'intelligence', ',', 'spearheaded', 'artificial', 'neural', 'networks', '.', 'show', 'despite', 'many', 'successes', 'performing', 'linguistic', 'tasks', ',', 'large', 'neural', 'language', 'models', 'ill-suited', 'comprehensive', 'models', 'natural', 'language', '.', 'wider', 'implication', ',', 'spite', 'often', 'overbearing', 'optimism', 'ai', ',', 'modern', 'neural', 'models', 'represent', 'revolution', 'understanding', 'cognition', '.']","natural, language, processing, one, leading, application, areas, current, resurgence, artificial, intelligence, ,, spearheaded, artificial, neural, networks, ., show, despite, many, successes, performing, linguistic, tasks, ,, large, neural, language, models, ill-suited, comprehensive, models, natural, language, ., wider, implication, ,, spite, often, overbearing, optimism, ai, ,, modern, neural, models, represent, revolution, understanding, cognition, ."
Multilingual Text Classification for Dravidian Languages,"Xiaotian Lin, Nankai Lin, Kanoksak Wattanachote, Shengyi Jiang, Lianxi Wang",2021-12-03T04:26:49Z,"  As the fourth largest language family in the world, the Dravidian languages
have become a research hotspot in natural language processing (NLP). Although
the Dravidian languages contain a large number of languages, there are
relatively few public available resources. Besides, text classification task,
as a basic task of natural language processing, how to combine it to multiple
languages in the Dravidian languages, is still a major difficulty in Dravidian
Natural Language Processing. Hence, to address these problems, we proposed a
multilingual text classification framework for the Dravidian languages. On the
one hand, the framework used the LaBSE pre-trained model as the base model.
Aiming at the problem of text information bias in multi-task learning, we
propose to use the MLM strategy to select language-specific words, and used
adversarial training to perturb them. On the other hand, in view of the problem
that the model cannot well recognize and utilize the correlation among
languages, we further proposed a language-specific representation module to
enrich semantic information for the model. The experimental results
demonstrated that the framework we proposed has a significant performance in
multilingual text classification tasks with each strategy achieving certain
improvements.
","['fourth', 'largest', 'language', 'family', 'world', ',', 'dravidian', 'languages', 'become', 'research', 'hotspot', 'natural', 'language', 'processing', '(', 'nlp', ')', '.', 'although', 'dravidian', 'languages', 'contain', 'large', 'number', 'languages', ',', 'relatively', 'public', 'available', 'resources', '.', 'besides', ',', 'text', 'classification', 'task', ',', 'basic', 'task', 'natural', 'language', 'processing', ',', 'combine', 'multiple', 'languages', 'dravidian', 'languages', ',', 'still', 'major', 'difficulty', 'dravidian', 'natural', 'language', 'processing', '.', 'hence', ',', 'address', 'problems', ',', 'proposed', 'multilingual', 'text', 'classification', 'framework', 'dravidian', 'languages', '.', 'one', 'hand', ',', 'framework', 'used', 'labse', 'pre-trained', 'model', 'base', 'model', '.', 'aiming', 'problem', 'text', 'information', 'bias', 'multi-task', 'learning', ',', 'propose', 'use', 'mlm', 'strategy', 'select', 'language-specific', 'words', ',', 'used', 'adversarial', 'training', 'perturb', '.', 'hand', ',', 'view', 'problem', 'model', 'well', 'recognize', 'utilize', 'correlation', 'among', 'languages', ',', 'proposed', 'language-specific', 'representation', 'module', 'enrich', 'semantic', 'information', 'model', '.', 'experimental', 'results', 'demonstrated', 'framework', 'proposed', 'significant', 'performance', 'multilingual', 'text', 'classification', 'tasks', 'strategy', 'achieving', 'certain', 'improvements', '.']","fourth, largest, language, family, world, ,, dravidian, languages, become, research, hotspot, natural, language, processing, (, nlp, ), ., although, dravidian, languages, contain, large, number, languages, ,, relatively, public, available, resources, ., besides, ,, text, classification, task, ,, basic, task, natural, language, processing, ,, combine, multiple, languages, dravidian, languages, ,, still, major, difficulty, dravidian, natural, language, processing, ., hence, ,, address, problems, ,, proposed, multilingual, text, classification, framework, dravidian, languages, ., one, hand, ,, framework, used, labse, pre-trained, model, base, model, ., aiming, problem, text, information, bias, multi-task, learning, ,, propose, use, mlm, strategy, select, language-specific, words, ,, used, adversarial, training, perturb, ., hand, ,, view, problem, model, well, recognize, utilize, correlation, among, languages, ,, proposed, language-specific, representation, module, enrich, semantic, information, model, ., experimental, results, demonstrated, framework, proposed, significant, performance, multilingual, text, classification, tasks, strategy, achieving, certain, improvements, ."
Self-move and Other-move: Quantum Categorical Foundations of Japanese,Ryder Dale Walton,2022-10-10T06:26:59Z,"  The purpose of this work is to contribute toward the larger goal of creating
a Quantum Natural Language Processing (QNLP) translator program. This work
contributes original diagrammatic representations of the Japanese language
based on prior work that accomplished on the English language based on category
theory. The germane differences between the English and Japanese languages are
emphasized to help address English language bias in the current body of
research. Additionally, topological principles of these diagrams and many
potential avenues for further research are proposed. Why is this endeavor
important? Hundreds of languages have developed over the course of millennia
coinciding with the evolution of human interaction across time and geographic
location. These languages are foundational to human survival, experience,
flourishing, and living the good life. They are also, however, the strongest
barrier between people groups. Over the last several decades, advancements in
Natural Language Processing (NLP) have made it easier to bridge the gap between
individuals who do not share a common language or culture. Tools like Google
Translate and DeepL make it easier than ever before to share our experiences
with people globally. Nevertheless, these tools are still inadequate as they
fail to convey our ideas across the language barrier fluently, leaving people
feeling anxious and embarrassed. This is particularly true of languages born
out of substantially different cultures, such as English and Japanese. Quantum
computers offer the best chance to achieve translation fluency in that they are
better suited to simulating the natural world and natural phenomenon such as
natural speech.
  Keywords: category theory, DisCoCat, DisCoCirc, Japanese grammar, English
grammar, translation, topology, Quantum Natural Language Processing, Natural
Language Processing
","['purpose', 'work', 'contribute', 'toward', 'larger', 'goal', 'creating', 'quantum', 'natural', 'language', 'processing', '(', 'qnlp', ')', 'translator', 'program', '.', 'work', 'contributes', 'original', 'diagrammatic', 'representations', 'japanese', 'language', 'based', 'prior', 'work', 'accomplished', 'english', 'language', 'based', 'category', 'theory', '.', 'germane', 'differences', 'english', 'japanese', 'languages', 'emphasized', 'help', 'address', 'english', 'language', 'bias', 'current', 'body', 'research', '.', 'additionally', ',', 'topological', 'principles', 'diagrams', 'many', 'potential', 'avenues', 'research', 'proposed', '.', 'endeavor', 'important', '?', 'hundreds', 'languages', 'developed', 'course', 'millennia', 'coinciding', 'evolution', 'human', 'interaction', 'across', 'time', 'geographic', 'location', '.', 'languages', 'foundational', 'human', 'survival', ',', 'experience', ',', 'flourishing', ',', 'living', 'good', 'life', '.', 'also', ',', 'however', ',', 'strongest', 'barrier', 'people', 'groups', '.', 'last', 'several', 'decades', ',', 'advancements', 'natural', 'language', 'processing', '(', 'nlp', ')', 'made', 'easier', 'bridge', 'gap', 'individuals', 'share', 'common', 'language', 'culture', '.', 'tools', 'like', 'google', 'translate', 'deepl', 'make', 'easier', 'ever', 'share', 'experiences', 'people', 'globally', '.', 'nevertheless', ',', 'tools', 'still', 'inadequate', 'fail', 'convey', 'ideas', 'across', 'language', 'barrier', 'fluently', ',', 'leaving', 'people', 'feeling', 'anxious', 'embarrassed', '.', 'particularly', 'true', 'languages', 'born', 'substantially', 'different', 'cultures', ',', 'english', 'japanese', '.', 'quantum', 'computers', 'offer', 'best', 'chance', 'achieve', 'translation', 'fluency', 'better', 'suited', 'simulating', 'natural', 'world', 'natural', 'phenomenon', 'natural', 'speech', '.', 'keywords', ':', 'category', 'theory', ',', 'discocat', ',', 'discocirc', ',', 'japanese', 'grammar', ',', 'english', 'grammar', ',', 'translation', ',', 'topology', ',', 'quantum', 'natural', 'language', 'processing', ',', 'natural', 'language', 'processing']","purpose, work, contribute, toward, larger, goal, creating, quantum, natural, language, processing, (, qnlp, ), translator, program, ., work, contributes, original, diagrammatic, representations, japanese, language, based, prior, work, accomplished, english, language, based, category, theory, ., germane, differences, english, japanese, languages, emphasized, help, address, english, language, bias, current, body, research, ., additionally, ,, topological, principles, diagrams, many, potential, avenues, research, proposed, ., endeavor, important, ?, hundreds, languages, developed, course, millennia, coinciding, evolution, human, interaction, across, time, geographic, location, ., languages, foundational, human, survival, ,, experience, ,, flourishing, ,, living, good, life, ., also, ,, however, ,, strongest, barrier, people, groups, ., last, several, decades, ,, advancements, natural, language, processing, (, nlp, ), made, easier, bridge, gap, individuals, share, common, language, culture, ., tools, like, google, translate, deepl, make, easier, ever, share, experiences, people, globally, ., nevertheless, ,, tools, still, inadequate, fail, convey, ideas, across, language, barrier, fluently, ,, leaving, people, feeling, anxious, embarrassed, ., particularly, true, languages, born, substantially, different, cultures, ,, english, japanese, ., quantum, computers, offer, best, chance, achieve, translation, fluency, better, suited, simulating, natural, world, natural, phenomenon, natural, speech, ., keywords, :, category, theory, ,, discocat, ,, discocirc, ,, japanese, grammar, ,, english, grammar, ,, translation, ,, topology, ,, quantum, natural, language, processing, ,, natural, language, processing"
PersianLLaMA: Towards Building First Persian Large Language Model,"Mohammad Amin Abbasi, Arash Ghafouri, Mahdi Firouzmandi, Hassan Naderi, Behrouz Minaei Bidgoli",2023-12-25T12:48:55Z,"  Despite the widespread use of the Persian language by millions globally,
limited efforts have been made in natural language processing for this
language. The use of large language models as effective tools in various
natural language processing tasks typically requires extensive textual data and
robust hardware resources. Consequently, the scarcity of Persian textual data
and the unavailability of powerful hardware resources have hindered the
development of large language models for Persian. This paper introduces the
first large Persian language model, named PersianLLaMA, trained on a collection
of Persian texts and datasets. This foundational model comes in two versions,
with 7 and 13 billion parameters, trained on formal and colloquial Persian
texts using two different approaches. PersianLLaMA has been evaluated for
natural language generation tasks based on the latest evaluation methods,
namely using larger language models, and for natural language understanding
tasks based on automated machine metrics. The results indicate that
PersianLLaMA significantly outperforms its competitors in both understanding
and generating Persian text. PersianLLaMA marks an important step in the
development of Persian natural language processing and can be a valuable
resource for the Persian-speaking community. This large language model can be
used for various natural language processing tasks, especially text generation
like chatbots, question-answering, machine translation, and text summarization
","['despite', 'widespread', 'use', 'persian', 'language', 'millions', 'globally', ',', 'limited', 'efforts', 'made', 'natural', 'language', 'processing', 'language', '.', 'use', 'large', 'language', 'models', 'effective', 'tools', 'various', 'natural', 'language', 'processing', 'tasks', 'typically', 'requires', 'extensive', 'textual', 'data', 'robust', 'hardware', 'resources', '.', 'consequently', ',', 'scarcity', 'persian', 'textual', 'data', 'unavailability', 'powerful', 'hardware', 'resources', 'hindered', 'development', 'large', 'language', 'models', 'persian', '.', 'paper', 'introduces', 'first', 'large', 'persian', 'language', 'model', ',', 'named', 'persianllama', ',', 'trained', 'collection', 'persian', 'texts', 'datasets', '.', 'foundational', 'model', 'comes', 'two', 'versions', ',', '7', '13', 'billion', 'parameters', ',', 'trained', 'formal', 'colloquial', 'persian', 'texts', 'using', 'two', 'different', 'approaches', '.', 'persianllama', 'evaluated', 'natural', 'language', 'generation', 'tasks', 'based', 'latest', 'evaluation', 'methods', ',', 'namely', 'using', 'larger', 'language', 'models', ',', 'natural', 'language', 'understanding', 'tasks', 'based', 'automated', 'machine', 'metrics', '.', 'results', 'indicate', 'persianllama', 'significantly', 'outperforms', 'competitors', 'understanding', 'generating', 'persian', 'text', '.', 'persianllama', 'marks', 'important', 'step', 'development', 'persian', 'natural', 'language', 'processing', 'valuable', 'resource', 'persian-speaking', 'community', '.', 'large', 'language', 'model', 'used', 'various', 'natural', 'language', 'processing', 'tasks', ',', 'especially', 'text', 'generation', 'like', 'chatbots', ',', 'question-answering', ',', 'machine', 'translation', ',', 'text', 'summarization']","despite, widespread, use, persian, language, millions, globally, ,, limited, efforts, made, natural, language, processing, language, ., use, large, language, models, effective, tools, various, natural, language, processing, tasks, typically, requires, extensive, textual, data, robust, hardware, resources, ., consequently, ,, scarcity, persian, textual, data, unavailability, powerful, hardware, resources, hindered, development, large, language, models, persian, ., paper, introduces, first, large, persian, language, model, ,, named, persianllama, ,, trained, collection, persian, texts, datasets, ., foundational, model, comes, two, versions, ,, 7, 13, billion, parameters, ,, trained, formal, colloquial, persian, texts, using, two, different, approaches, ., persianllama, evaluated, natural, language, generation, tasks, based, latest, evaluation, methods, ,, namely, using, larger, language, models, ,, natural, language, understanding, tasks, based, automated, machine, metrics, ., results, indicate, persianllama, significantly, outperforms, competitors, understanding, generating, persian, text, ., persianllama, marks, important, step, development, persian, natural, language, processing, valuable, resource, persian-speaking, community, ., large, language, model, used, various, natural, language, processing, tasks, ,, especially, text, generation, like, chatbots, ,, question-answering, ,, machine, translation, ,, text, summarization"
ANGLEr: A Next-Generation Natural Language Exploratory Framework,"Timotej Knez, Marko Bajec, Slavko Žitnik",2022-05-10T13:32:13Z,"  Natural language processing is used for solving a wide variety of problems.
Some scholars and interest groups working with language resources are not well
versed in programming, so there is a need for a good graphical framework that
allows users to quickly design and test natural language processing pipelines
without the need for programming. The existing frameworks do not satisfy all
the requirements for such a tool. We, therefore, propose a new framework that
provides a simple way for its users to build language processing pipelines. It
also allows a simple programming language agnostic way for adding new modules,
which will help the adoption by natural language processing developers and
researchers. The main parts of the proposed framework consist of (a) a
pluggable Docker-based architecture, (b) a general data model, and (c) APIs
description along with the graphical user interface. The proposed design is
being used for implementation of a new natural language processing framework,
called ANGLEr.
","['natural', 'language', 'processing', 'used', 'solving', 'wide', 'variety', 'problems', '.', 'scholars', 'interest', 'groups', 'working', 'language', 'resources', 'well', 'versed', 'programming', ',', 'need', 'good', 'graphical', 'framework', 'allows', 'users', 'quickly', 'design', 'test', 'natural', 'language', 'processing', 'pipelines', 'without', 'need', 'programming', '.', 'existing', 'frameworks', 'satisfy', 'requirements', 'tool', '.', ',', 'therefore', ',', 'propose', 'new', 'framework', 'provides', 'simple', 'way', 'users', 'build', 'language', 'processing', 'pipelines', '.', 'also', 'allows', 'simple', 'programming', 'language', 'agnostic', 'way', 'adding', 'new', 'modules', ',', 'help', 'adoption', 'natural', 'language', 'processing', 'developers', 'researchers', '.', 'main', 'parts', 'proposed', 'framework', 'consist', '(', ')', 'pluggable', 'docker-based', 'architecture', ',', '(', 'b', ')', 'general', 'data', 'model', ',', '(', 'c', ')', 'apis', 'description', 'along', 'graphical', 'user', 'interface', '.', 'proposed', 'design', 'used', 'implementation', 'new', 'natural', 'language', 'processing', 'framework', ',', 'called', 'angler', '.']","natural, language, processing, used, solving, wide, variety, problems, ., scholars, interest, groups, working, language, resources, well, versed, programming, ,, need, good, graphical, framework, allows, users, quickly, design, test, natural, language, processing, pipelines, without, need, programming, ., existing, frameworks, satisfy, requirements, tool, ., ,, therefore, ,, propose, new, framework, provides, simple, way, users, build, language, processing, pipelines, ., also, allows, simple, programming, language, agnostic, way, adding, new, modules, ,, help, adoption, natural, language, processing, developers, researchers, ., main, parts, proposed, framework, consist, (, ), pluggable, docker-based, architecture, ,, (, b, ), general, data, model, ,, (, c, ), apis, description, along, graphical, user, interface, ., proposed, design, used, implementation, new, natural, language, processing, framework, ,, called, angler, ."
"Thoth: Improved Rapid Serial Visual Presentation using Natural Language
  Processing",David Awad,2019-08-05T15:45:39Z,"  Thoth is a tool designed to combine many different types of speed reading
technology. The largest insight is using natural language parsing for more
optimal rapid serial visual presentation and more effective reading
information.
","['thoth', 'tool', 'designed', 'combine', 'many', 'different', 'types', 'speed', 'reading', 'technology', '.', 'largest', 'insight', 'using', 'natural', 'language', 'parsing', 'optimal', 'rapid', 'serial', 'visual', 'presentation', 'effective', 'reading', 'information', '.']","thoth, tool, designed, combine, many, different, types, speed, reading, technology, ., largest, insight, using, natural, language, parsing, optimal, rapid, serial, visual, presentation, effective, reading, information, ."
"A Survey of Resources and Methods for Natural Language Processing of
  Serbian Language","Ulfeta A. Marovac, Aldina R. Avdić, Nikola Lj. Milošević",2023-04-11T19:33:41Z,"  The Serbian language is a Slavic language spoken by over 12 million speakers
and well understood by over 15 million people. In the area of natural language
processing, it can be considered a low-resourced language. Also, Serbian is
considered a high-inflectional language. The combination of many word
inflections and low availability of language resources makes natural language
processing of Serbian challenging. Nevertheless, over the past three decades,
there have been a number of initiatives to develop resources and methods for
natural language processing of Serbian, ranging from developing a corpus of
free text from books and the internet, annotated corpora for classification and
named entity recognition tasks to various methods and models performing these
tasks. In this paper, we review the initiatives, resources, methods, and their
availability.
","['serbian', 'language', 'slavic', 'language', 'spoken', '12', 'million', 'speakers', 'well', 'understood', '15', 'million', 'people', '.', 'area', 'natural', 'language', 'processing', ',', 'considered', 'low-resourced', 'language', '.', 'also', ',', 'serbian', 'considered', 'high-inflectional', 'language', '.', 'combination', 'many', 'word', 'inflections', 'low', 'availability', 'language', 'resources', 'makes', 'natural', 'language', 'processing', 'serbian', 'challenging', '.', 'nevertheless', ',', 'past', 'three', 'decades', ',', 'number', 'initiatives', 'develop', 'resources', 'methods', 'natural', 'language', 'processing', 'serbian', ',', 'ranging', 'developing', 'corpus', 'free', 'text', 'books', 'internet', ',', 'annotated', 'corpora', 'classification', 'named', 'entity', 'recognition', 'tasks', 'various', 'methods', 'models', 'performing', 'tasks', '.', 'paper', ',', 'review', 'initiatives', ',', 'resources', ',', 'methods', ',', 'availability', '.']","serbian, language, slavic, language, spoken, 12, million, speakers, well, understood, 15, million, people, ., area, natural, language, processing, ,, considered, low-resourced, language, ., also, ,, serbian, considered, high-inflectional, language, ., combination, many, word, inflections, low, availability, language, resources, makes, natural, language, processing, serbian, challenging, ., nevertheless, ,, past, three, decades, ,, number, initiatives, develop, resources, methods, natural, language, processing, serbian, ,, ranging, developing, corpus, free, text, books, internet, ,, annotated, corpora, classification, named, entity, recognition, tasks, various, methods, models, performing, tasks, ., paper, ,, review, initiatives, ,, resources, ,, methods, ,, availability, ."
Challenges Encountered in Turkish Natural Language Processing Studies,"Kadir Tohma, Yakup Kutlu",2021-01-21T08:30:33Z,"  Natural language processing is a branch of computer science that combines
artificial intelligence with linguistics. It aims to analyze a language element
such as writing or speaking with software and convert it into information.
Considering that each language has its own grammatical rules and vocabulary
diversity, the complexity of the studies in this field is somewhat
understandable. For instance, Turkish is a very interesting language in many
ways. Examples of this are agglutinative word structure, consonant/vowel
harmony, a large number of productive derivational morphemes (practically
infinite vocabulary), derivation and syntactic relations, a complex emphasis on
vocabulary and phonological rules. In this study, the interesting features of
Turkish in terms of natural language processing are mentioned. In addition,
summary info about natural language processing techniques, systems and various
sources developed for Turkish are given.
","['natural', 'language', 'processing', 'branch', 'computer', 'science', 'combines', 'artificial', 'intelligence', 'linguistics', '.', 'aims', 'analyze', 'language', 'element', 'writing', 'speaking', 'software', 'convert', 'information', '.', 'considering', 'language', 'grammatical', 'rules', 'vocabulary', 'diversity', ',', 'complexity', 'studies', 'field', 'somewhat', 'understandable', '.', 'instance', ',', 'turkish', 'interesting', 'language', 'many', 'ways', '.', 'examples', 'agglutinative', 'word', 'structure', ',', 'consonant/vowel', 'harmony', ',', 'large', 'number', 'productive', 'derivational', 'morphemes', '(', 'practically', 'infinite', 'vocabulary', ')', ',', 'derivation', 'syntactic', 'relations', ',', 'complex', 'emphasis', 'vocabulary', 'phonological', 'rules', '.', 'study', ',', 'interesting', 'features', 'turkish', 'terms', 'natural', 'language', 'processing', 'mentioned', '.', 'addition', ',', 'summary', 'info', 'natural', 'language', 'processing', 'techniques', ',', 'systems', 'various', 'sources', 'developed', 'turkish', 'given', '.']","natural, language, processing, branch, computer, science, combines, artificial, intelligence, linguistics, ., aims, analyze, language, element, writing, speaking, software, convert, information, ., considering, language, grammatical, rules, vocabulary, diversity, ,, complexity, studies, field, somewhat, understandable, ., instance, ,, turkish, interesting, language, many, ways, ., examples, agglutinative, word, structure, ,, consonant/vowel, harmony, ,, large, number, productive, derivational, morphemes, (, practically, infinite, vocabulary, ), ,, derivation, syntactic, relations, ,, complex, emphasis, vocabulary, phonological, rules, ., study, ,, interesting, features, turkish, terms, natural, language, processing, mentioned, ., addition, ,, summary, info, natural, language, processing, techniques, ,, systems, various, sources, developed, turkish, given, ."
Categorical Tools for Natural Language Processing,Giovanni de Felice,2022-12-13T15:12:37Z,"  This thesis develops the translation between category theory and
computational linguistics as a foundation for natural language processing. The
three chapters deal with syntax, semantics and pragmatics. First, string
diagrams provide a unified model of syntactic structures in formal grammars.
Second, functors compute semantics by turning diagrams into logical, tensor,
neural or quantum computation. Third, the resulting functorial models can be
composed to form games where equilibria are the solutions of language
processing tasks. This framework is implemented as part of DisCoPy, the Python
library for computing with string diagrams. We describe the correspondence
between categorical, linguistic and computational structures, and demonstrate
their applications in compositional natural language processing.
","['thesis', 'develops', 'translation', 'category', 'theory', 'computational', 'linguistics', 'foundation', 'natural', 'language', 'processing', '.', 'three', 'chapters', 'deal', 'syntax', ',', 'semantics', 'pragmatics', '.', 'first', ',', 'string', 'diagrams', 'provide', 'unified', 'model', 'syntactic', 'structures', 'formal', 'grammars', '.', 'second', ',', 'functors', 'compute', 'semantics', 'turning', 'diagrams', 'logical', ',', 'tensor', ',', 'neural', 'quantum', 'computation', '.', 'third', ',', 'resulting', 'functorial', 'models', 'composed', 'form', 'games', 'equilibria', 'solutions', 'language', 'processing', 'tasks', '.', 'framework', 'implemented', 'part', 'discopy', ',', 'python', 'library', 'computing', 'string', 'diagrams', '.', 'describe', 'correspondence', 'categorical', ',', 'linguistic', 'computational', 'structures', ',', 'demonstrate', 'applications', 'compositional', 'natural', 'language', 'processing', '.']","thesis, develops, translation, category, theory, computational, linguistics, foundation, natural, language, processing, ., three, chapters, deal, syntax, ,, semantics, pragmatics, ., first, ,, string, diagrams, provide, unified, model, syntactic, structures, formal, grammars, ., second, ,, functors, compute, semantics, turning, diagrams, logical, ,, tensor, ,, neural, quantum, computation, ., third, ,, resulting, functorial, models, composed, form, games, equilibria, solutions, language, processing, tasks, ., framework, implemented, part, discopy, ,, python, library, computing, string, diagrams, ., describe, correspondence, categorical, ,, linguistic, computational, structures, ,, demonstrate, applications, compositional, natural, language, processing, ."
"Natural Language Reasoning, A Survey","Fei Yu, Hongbo Zhang, Prayag Tiwari, Benyou Wang",2023-03-26T13:44:18Z,"  This survey paper proposes a clearer view of natural language reasoning in
the field of Natural Language Processing (NLP), both conceptually and
practically. Conceptually, we provide a distinct definition for natural
language reasoning in NLP, based on both philosophy and NLP scenarios, discuss
what types of tasks require reasoning, and introduce a taxonomy of reasoning.
Practically, we conduct a comprehensive literature review on natural language
reasoning in NLP, mainly covering classical logical reasoning, natural language
inference, multi-hop question answering, and commonsense reasoning. The paper
also identifies and views backward reasoning, a powerful paradigm for
multi-step reasoning, and introduces defeasible reasoning as one of the most
important future directions in natural language reasoning research. We focus on
single-modality unstructured natural language text, excluding neuro-symbolic
techniques and mathematical reasoning.
","['survey', 'paper', 'proposes', 'clearer', 'view', 'natural', 'language', 'reasoning', 'field', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'conceptually', 'practically', '.', 'conceptually', ',', 'provide', 'distinct', 'definition', 'natural', 'language', 'reasoning', 'nlp', ',', 'based', 'philosophy', 'nlp', 'scenarios', ',', 'discuss', 'types', 'tasks', 'require', 'reasoning', ',', 'introduce', 'taxonomy', 'reasoning', '.', 'practically', ',', 'conduct', 'comprehensive', 'literature', 'review', 'natural', 'language', 'reasoning', 'nlp', ',', 'mainly', 'covering', 'classical', 'logical', 'reasoning', ',', 'natural', 'language', 'inference', ',', 'multi-hop', 'question', 'answering', ',', 'commonsense', 'reasoning', '.', 'paper', 'also', 'identifies', 'views', 'backward', 'reasoning', ',', 'powerful', 'paradigm', 'multi-step', 'reasoning', ',', 'introduces', 'defeasible', 'reasoning', 'one', 'important', 'future', 'directions', 'natural', 'language', 'reasoning', 'research', '.', 'focus', 'single-modality', 'unstructured', 'natural', 'language', 'text', ',', 'excluding', 'neuro-symbolic', 'techniques', 'mathematical', 'reasoning', '.']","survey, paper, proposes, clearer, view, natural, language, reasoning, field, natural, language, processing, (, nlp, ), ,, conceptually, practically, ., conceptually, ,, provide, distinct, definition, natural, language, reasoning, nlp, ,, based, philosophy, nlp, scenarios, ,, discuss, types, tasks, require, reasoning, ,, introduce, taxonomy, reasoning, ., practically, ,, conduct, comprehensive, literature, review, natural, language, reasoning, nlp, ,, mainly, covering, classical, logical, reasoning, ,, natural, language, inference, ,, multi-hop, question, answering, ,, commonsense, reasoning, ., paper, also, identifies, views, backward, reasoning, ,, powerful, paradigm, multi-step, reasoning, ,, introduces, defeasible, reasoning, one, important, future, directions, natural, language, reasoning, research, ., focus, single-modality, unstructured, natural, language, text, ,, excluding, neuro-symbolic, techniques, mathematical, reasoning, ."
"Language Tasks and Language Games: On Methodology in Current Natural
  Language Processing Research",David Schlangen,2019-08-28T14:29:13Z,"  ""This paper introduces a new task and a new dataset"", ""we improve the state
of the art in X by Y"" -- it is rare to find a current natural language
processing paper (or AI paper more generally) that does not contain such
statements. What is mostly left implicit, however, is the assumption that this
necessarily constitutes progress, and what it constitutes progress towards.
Here, we make more precise the normally impressionistically used notions of
language task and language game and ask how a research programme built on these
might make progress towards the goal of modelling general language competence.
","['``', 'paper', 'introduces', 'new', 'task', 'new', 'dataset', ""''"", ',', '``', 'improve', 'state', 'art', 'x', ""''"", '--', 'rare', 'find', 'current', 'natural', 'language', 'processing', 'paper', '(', 'ai', 'paper', 'generally', ')', 'contain', 'statements', '.', 'mostly', 'left', 'implicit', ',', 'however', ',', 'assumption', 'necessarily', 'constitutes', 'progress', ',', 'constitutes', 'progress', 'towards', '.', ',', 'make', 'precise', 'normally', 'impressionistically', 'used', 'notions', 'language', 'task', 'language', 'game', 'ask', 'research', 'programme', 'built', 'might', 'make', 'progress', 'towards', 'goal', 'modelling', 'general', 'language', 'competence', '.']","``, paper, introduces, new, task, new, dataset, '', ,, ``, improve, state, art, x, '', --, rare, find, current, natural, language, processing, paper, (, ai, paper, generally, ), contain, statements, ., mostly, left, implicit, ,, however, ,, assumption, necessarily, constitutes, progress, ,, constitutes, progress, towards, ., ,, make, precise, normally, impressionistically, used, notions, language, task, language, game, ask, research, programme, built, might, make, progress, towards, goal, modelling, general, language, competence, ."
"Pretraining with Artificial Language: Studying Transferable Knowledge in
  Language Models","Ryokan Ri, Yoshimasa Tsuruoka",2022-03-19T13:29:48Z,"  We investigate what kind of structural knowledge learned in neural network
encoders is transferable to processing natural language. We design artificial
languages with structural properties that mimic natural language, pretrain
encoders on the data, and see how much performance the encoder exhibits on
downstream tasks in natural language. Our experimental results show that
pretraining with an artificial language with a nesting dependency structure
provides some knowledge transferable to natural language. A follow-up probing
analysis indicates that its success in the transfer is related to the amount of
encoded contextual information and what is transferred is the knowledge of
position-aware context dependence of language. Our results provide insights
into how neural network encoders process human languages and the source of
cross-lingual transferability of recent multilingual language models.
","['investigate', 'kind', 'structural', 'knowledge', 'learned', 'neural', 'network', 'encoders', 'transferable', 'processing', 'natural', 'language', '.', 'design', 'artificial', 'languages', 'structural', 'properties', 'mimic', 'natural', 'language', ',', 'pretrain', 'encoders', 'data', ',', 'see', 'much', 'performance', 'encoder', 'exhibits', 'downstream', 'tasks', 'natural', 'language', '.', 'experimental', 'results', 'show', 'pretraining', 'artificial', 'language', 'nesting', 'dependency', 'structure', 'provides', 'knowledge', 'transferable', 'natural', 'language', '.', 'follow-up', 'probing', 'analysis', 'indicates', 'success', 'transfer', 'related', 'amount', 'encoded', 'contextual', 'information', 'transferred', 'knowledge', 'position-aware', 'context', 'dependence', 'language', '.', 'results', 'provide', 'insights', 'neural', 'network', 'encoders', 'process', 'human', 'languages', 'source', 'cross-lingual', 'transferability', 'recent', 'multilingual', 'language', 'models', '.']","investigate, kind, structural, knowledge, learned, neural, network, encoders, transferable, processing, natural, language, ., design, artificial, languages, structural, properties, mimic, natural, language, ,, pretrain, encoders, data, ,, see, much, performance, encoder, exhibits, downstream, tasks, natural, language, ., experimental, results, show, pretraining, artificial, language, nesting, dependency, structure, provides, knowledge, transferable, natural, language, ., follow-up, probing, analysis, indicates, success, transfer, related, amount, encoded, contextual, information, transferred, knowledge, position-aware, context, dependence, language, ., results, provide, insights, neural, network, encoders, process, human, languages, source, cross-lingual, transferability, recent, multilingual, language, models, ."
"Incrementalizing RASA's Open-Source Natural Language Understanding
  Pipeline","Andrew Rafla, Casey Kennington",2019-07-11T17:35:20Z,"  As spoken dialogue systems and chatbots are gaining more widespread adoption,
commercial and open-sourced services for natural language understanding are
emerging. In this paper, we explain how we altered the open-source RASA natural
language understanding pipeline to process incrementally (i.e., word-by-word),
following the incremental unit framework proposed by Schlangen and Skantze. To
do so, we altered existing RASA components to process incrementally, and added
an update-incremental intent recognition model as a component to RASA. Our
evaluations on the Snips dataset show that our changes allow RASA to function
as an effective incremental natural language understanding service.
","['spoken', 'dialogue', 'systems', 'chatbots', 'gaining', 'widespread', 'adoption', ',', 'commercial', 'open-sourced', 'services', 'natural', 'language', 'understanding', 'emerging', '.', 'paper', ',', 'explain', 'altered', 'open-source', 'rasa', 'natural', 'language', 'understanding', 'pipeline', 'process', 'incrementally', '(', 'i.e.', ',', 'word-by-word', ')', ',', 'following', 'incremental', 'unit', 'framework', 'proposed', 'schlangen', 'skantze', '.', ',', 'altered', 'existing', 'rasa', 'components', 'process', 'incrementally', ',', 'added', 'update-incremental', 'intent', 'recognition', 'model', 'component', 'rasa', '.', 'evaluations', 'snips', 'dataset', 'show', 'changes', 'allow', 'rasa', 'function', 'effective', 'incremental', 'natural', 'language', 'understanding', 'service', '.']","spoken, dialogue, systems, chatbots, gaining, widespread, adoption, ,, commercial, open-sourced, services, natural, language, understanding, emerging, ., paper, ,, explain, altered, open-source, rasa, natural, language, understanding, pipeline, process, incrementally, (, i.e., ,, word-by-word, ), ,, following, incremental, unit, framework, proposed, schlangen, skantze, ., ,, altered, existing, rasa, components, process, incrementally, ,, added, update-incremental, intent, recognition, model, component, rasa, ., evaluations, snips, dataset, show, changes, allow, rasa, function, effective, incremental, natural, language, understanding, service, ."
Curriculum learning for language modeling,Daniel Campos,2021-08-04T16:53:43Z,"  Language Models like ELMo and BERT have provided robust representations of
natural language, which serve as the language understanding component for a
diverse range of downstream tasks.Curriculum learning is a method that employs
a structured training regime instead, which has been leveraged in computer
vision and machine translation to improve model training speed and model
performance. While language models have proven transformational for the natural
language processing community, these models have proven expensive,
energy-intensive, and challenging to train. In this work, we explore the effect
of curriculum learning on language model pretraining using various
linguistically motivated curricula and evaluate transfer performance on the
GLUE Benchmark. Despite a broad variety of training methodologies and
experiments we do not find compelling evidence that curriculum learning methods
improve language model training.
","['language', 'models', 'like', 'elmo', 'bert', 'provided', 'robust', 'representations', 'natural', 'language', ',', 'serve', 'language', 'understanding', 'component', 'diverse', 'range', 'downstream', 'tasks.curriculum', 'learning', 'method', 'employs', 'structured', 'training', 'regime', 'instead', ',', 'leveraged', 'computer', 'vision', 'machine', 'translation', 'improve', 'model', 'training', 'speed', 'model', 'performance', '.', 'language', 'models', 'proven', 'transformational', 'natural', 'language', 'processing', 'community', ',', 'models', 'proven', 'expensive', ',', 'energy-intensive', ',', 'challenging', 'train', '.', 'work', ',', 'explore', 'effect', 'curriculum', 'learning', 'language', 'model', 'pretraining', 'using', 'various', 'linguistically', 'motivated', 'curricula', 'evaluate', 'transfer', 'performance', 'glue', 'benchmark', '.', 'despite', 'broad', 'variety', 'training', 'methodologies', 'experiments', 'find', 'compelling', 'evidence', 'curriculum', 'learning', 'methods', 'improve', 'language', 'model', 'training', '.']","language, models, like, elmo, bert, provided, robust, representations, natural, language, ,, serve, language, understanding, component, diverse, range, downstream, tasks.curriculum, learning, method, employs, structured, training, regime, instead, ,, leveraged, computer, vision, machine, translation, improve, model, training, speed, model, performance, ., language, models, proven, transformational, natural, language, processing, community, ,, models, proven, expensive, ,, energy-intensive, ,, challenging, train, ., work, ,, explore, effect, curriculum, learning, language, model, pretraining, using, various, linguistically, motivated, curricula, evaluate, transfer, performance, glue, benchmark, ., despite, broad, variety, training, methodologies, experiments, find, compelling, evidence, curriculum, learning, methods, improve, language, model, training, ."
Natural Language Specifications in Proof Assistants,"Colin S. Gordon, Sergey Matskevich",2022-05-16T17:05:45Z,"  Interactive proof assistants are computer programs carefully constructed to
check a human-designed proof of a mathematical claim with high confidence in
the implementation. However, this only validates truth of a formal claim, which
may have been mistranslated from a claim made in natural language. This is
especially problematic when using proof assistants to formally verify the
correctness of software with respect to a natural language specification. The
translation from informal to formal remains a challenging, time-consuming
process that is difficult to audit for correctness. This paper argues that it
is possible to build support for natural language specifications within
existing proof assistants, in a way that complements the principles used to
establish trust and auditability in proof assistants themselves.
","['interactive', 'proof', 'assistants', 'computer', 'programs', 'carefully', 'constructed', 'check', 'human-designed', 'proof', 'mathematical', 'claim', 'high', 'confidence', 'implementation', '.', 'however', ',', 'validates', 'truth', 'formal', 'claim', ',', 'may', 'mistranslated', 'claim', 'made', 'natural', 'language', '.', 'especially', 'problematic', 'using', 'proof', 'assistants', 'formally', 'verify', 'correctness', 'software', 'respect', 'natural', 'language', 'specification', '.', 'translation', 'informal', 'formal', 'remains', 'challenging', ',', 'time-consuming', 'process', 'difficult', 'audit', 'correctness', '.', 'paper', 'argues', 'possible', 'build', 'support', 'natural', 'language', 'specifications', 'within', 'existing', 'proof', 'assistants', ',', 'way', 'complements', 'principles', 'used', 'establish', 'trust', 'auditability', 'proof', 'assistants', '.']","interactive, proof, assistants, computer, programs, carefully, constructed, check, human-designed, proof, mathematical, claim, high, confidence, implementation, ., however, ,, validates, truth, formal, claim, ,, may, mistranslated, claim, made, natural, language, ., especially, problematic, using, proof, assistants, formally, verify, correctness, software, respect, natural, language, specification, ., translation, informal, formal, remains, challenging, ,, time-consuming, process, difficult, audit, correctness, ., paper, argues, possible, build, support, natural, language, specifications, within, existing, proof, assistants, ,, way, complements, principles, used, establish, trust, auditability, proof, assistants, ."
Can Transformers Reason in Fragments of Natural Language?,"Viktor Schlegel, Kamen V. Pavlov, Ian Pratt-Hartmann",2022-11-10T08:46:53Z,"  State-of-the-art deep-learning-based approaches to Natural Language
Processing (NLP) are credited with various capabilities that involve reasoning
with natural language texts. In this paper we carry out a large-scale empirical
study investigating the detection of formally valid inferences in controlled
fragments of natural language for which the satisfiability problem becomes
increasingly complex. We find that, while transformer-based language models
perform surprisingly well in these scenarios, a deeper analysis re-veals that
they appear to overfit to superficial patterns in the data rather than
acquiring the logical principles governing the reasoning in these fragments.
","['state-of-the-art', 'deep-learning-based', 'approaches', 'natural', 'language', 'processing', '(', 'nlp', ')', 'credited', 'various', 'capabilities', 'involve', 'reasoning', 'natural', 'language', 'texts', '.', 'paper', 'carry', 'large-scale', 'empirical', 'study', 'investigating', 'detection', 'formally', 'valid', 'inferences', 'controlled', 'fragments', 'natural', 'language', 'satisfiability', 'problem', 'becomes', 'increasingly', 'complex', '.', 'find', ',', 'transformer-based', 'language', 'models', 'perform', 'surprisingly', 'well', 'scenarios', ',', 'deeper', 'analysis', 're-veals', 'appear', 'overfit', 'superficial', 'patterns', 'data', 'rather', 'acquiring', 'logical', 'principles', 'governing', 'reasoning', 'fragments', '.']","state-of-the-art, deep-learning-based, approaches, natural, language, processing, (, nlp, ), credited, various, capabilities, involve, reasoning, natural, language, texts, ., paper, carry, large-scale, empirical, study, investigating, detection, formally, valid, inferences, controlled, fragments, natural, language, satisfiability, problem, becomes, increasingly, complex, ., find, ,, transformer-based, language, models, perform, surprisingly, well, scenarios, ,, deeper, analysis, re-veals, appear, overfit, superficial, patterns, data, rather, acquiring, logical, principles, governing, reasoning, fragments, ."
"GANCoder: An Automatic Natural Language-to-Programming Language
  Translation Approach based on GAN","Yabing Zhu, Yanfeng Zhang, Huili Yang, Fangjing Wang",2019-12-02T07:41:25Z,"  We propose GANCoder, an automatic programming approach based on Generative
Adversarial Networks (GAN), which can generate the same functional and logical
programming language codes conditioned on the given natural language
utterances. The adversarial training between generator and discriminator helps
generator learn distribution of dataset and improve code generation quality.
Our experimental results show that GANCoder can achieve comparable accuracy
with the state-of-the-art methods and is more stable when programming
languages.
","['propose', 'gancoder', ',', 'automatic', 'programming', 'approach', 'based', 'generative', 'adversarial', 'networks', '(', 'gan', ')', ',', 'generate', 'functional', 'logical', 'programming', 'language', 'codes', 'conditioned', 'given', 'natural', 'language', 'utterances', '.', 'adversarial', 'training', 'generator', 'discriminator', 'helps', 'generator', 'learn', 'distribution', 'dataset', 'improve', 'code', 'generation', 'quality', '.', 'experimental', 'results', 'show', 'gancoder', 'achieve', 'comparable', 'accuracy', 'state-of-the-art', 'methods', 'stable', 'programming', 'languages', '.']","propose, gancoder, ,, automatic, programming, approach, based, generative, adversarial, networks, (, gan, ), ,, generate, functional, logical, programming, language, codes, conditioned, given, natural, language, utterances, ., adversarial, training, generator, discriminator, helps, generator, learn, distribution, dataset, improve, code, generation, quality, ., experimental, results, show, gancoder, achieve, comparable, accuracy, state-of-the-art, methods, stable, programming, languages, ."
"Fuzzy Temporal Protoforms for the Quantitative Description of Processes
  in Natural Language","Yago Fontenla-Seco, Alberto Bugarín-Diz, Manuel Lama",2023-05-16T14:59:38Z,"  In this paper, we propose a series of fuzzy temporal protoforms in the
framework of the automatic generation of quantitative and qualitative natural
language descriptions of processes. The model includes temporal and causal
information from processes and attributes, quantifies attributes in time during
the process life-span and recalls causal relations and temporal distances
between events, among other features. Through integrating process mining
techniques and fuzzy sets within the usual Data-to-Text architecture, our
framework is able to extract relevant quantitative temporal as well as
structural information from a process and describe it in natural language
involving uncertain terms. A real use-case in the cardiology domain is
presented, showing the potential of our model for providing natural language
explanations addressed to domain experts.
","['paper', ',', 'propose', 'series', 'fuzzy', 'temporal', 'protoforms', 'framework', 'automatic', 'generation', 'quantitative', 'qualitative', 'natural', 'language', 'descriptions', 'processes', '.', 'model', 'includes', 'temporal', 'causal', 'information', 'processes', 'attributes', ',', 'quantifies', 'attributes', 'time', 'process', 'life-span', 'recalls', 'causal', 'relations', 'temporal', 'distances', 'events', ',', 'among', 'features', '.', 'integrating', 'process', 'mining', 'techniques', 'fuzzy', 'sets', 'within', 'usual', 'data-to-text', 'architecture', ',', 'framework', 'able', 'extract', 'relevant', 'quantitative', 'temporal', 'well', 'structural', 'information', 'process', 'describe', 'natural', 'language', 'involving', 'uncertain', 'terms', '.', 'real', 'use-case', 'cardiology', 'domain', 'presented', ',', 'showing', 'potential', 'model', 'providing', 'natural', 'language', 'explanations', 'addressed', 'domain', 'experts', '.']","paper, ,, propose, series, fuzzy, temporal, protoforms, framework, automatic, generation, quantitative, qualitative, natural, language, descriptions, processes, ., model, includes, temporal, causal, information, processes, attributes, ,, quantifies, attributes, time, process, life-span, recalls, causal, relations, temporal, distances, events, ,, among, features, ., integrating, process, mining, techniques, fuzzy, sets, within, usual, data-to-text, architecture, ,, framework, able, extract, relevant, quantitative, temporal, well, structural, information, process, describe, natural, language, involving, uncertain, terms, ., real, use-case, cardiology, domain, presented, ,, showing, potential, model, providing, natural, language, explanations, addressed, domain, experts, ."
"Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human
  Narrative Processing","Zhengqi He, Taro Toyoizumi",2023-11-17T10:09:12Z,"  Understanding how humans process natural language has long been a vital
research direction. The field of natural language processing (NLP) has recently
experienced a surge in the development of powerful language models. These
models have proven to be invaluable tools for studying another complex system
known to process human language: the brain. Previous studies have demonstrated
that the features of language models can be mapped to fMRI brain activity. This
raises the question: is there a commonality between information processing in
language models and the human brain? To estimate information flow patterns in a
language model, we examined the causal relationships between different layers.
Drawing inspiration from the workspace framework for consciousness, we
hypothesized that features integrating more information would more accurately
predict higher hierarchical brain activity. To validate this hypothesis, we
classified language model features into two categories based on causal network
measures: 'low in-degree' and 'high in-degree'. We subsequently compared the
brain prediction accuracy maps for these two groups. Our results reveal that
the difference in prediction accuracy follows a hierarchical pattern,
consistent with the cortical hierarchy map revealed by activity time constants.
This finding suggests a parallel between how language models and the human
brain process linguistic information.
","['understanding', 'humans', 'process', 'natural', 'language', 'long', 'vital', 'research', 'direction', '.', 'field', 'natural', 'language', 'processing', '(', 'nlp', ')', 'recently', 'experienced', 'surge', 'development', 'powerful', 'language', 'models', '.', 'models', 'proven', 'invaluable', 'tools', 'studying', 'another', 'complex', 'system', 'known', 'process', 'human', 'language', ':', 'brain', '.', 'previous', 'studies', 'demonstrated', 'features', 'language', 'models', 'mapped', 'fmri', 'brain', 'activity', '.', 'raises', 'question', ':', 'commonality', 'information', 'processing', 'language', 'models', 'human', 'brain', '?', 'estimate', 'information', 'flow', 'patterns', 'language', 'model', ',', 'examined', 'causal', 'relationships', 'different', 'layers', '.', 'drawing', 'inspiration', 'workspace', 'framework', 'consciousness', ',', 'hypothesized', 'features', 'integrating', 'information', 'would', 'accurately', 'predict', 'higher', 'hierarchical', 'brain', 'activity', '.', 'validate', 'hypothesis', ',', 'classified', 'language', 'model', 'features', 'two', 'categories', 'based', 'causal', 'network', 'measures', ':', ""'low"", 'in-degree', ""'"", ""'high"", 'in-degree', ""'"", '.', 'subsequently', 'compared', 'brain', 'prediction', 'accuracy', 'maps', 'two', 'groups', '.', 'results', 'reveal', 'difference', 'prediction', 'accuracy', 'follows', 'hierarchical', 'pattern', ',', 'consistent', 'cortical', 'hierarchy', 'map', 'revealed', 'activity', 'time', 'constants', '.', 'finding', 'suggests', 'parallel', 'language', 'models', 'human', 'brain', 'process', 'linguistic', 'information', '.']","understanding, humans, process, natural, language, long, vital, research, direction, ., field, natural, language, processing, (, nlp, ), recently, experienced, surge, development, powerful, language, models, ., models, proven, invaluable, tools, studying, another, complex, system, known, process, human, language, :, brain, ., previous, studies, demonstrated, features, language, models, mapped, fmri, brain, activity, ., raises, question, :, commonality, information, processing, language, models, human, brain, ?, estimate, information, flow, patterns, language, model, ,, examined, causal, relationships, different, layers, ., drawing, inspiration, workspace, framework, consciousness, ,, hypothesized, features, integrating, information, would, accurately, predict, higher, hierarchical, brain, activity, ., validate, hypothesis, ,, classified, language, model, features, two, categories, based, causal, network, measures, :, 'low, in-degree, ', 'high, in-degree, ', ., subsequently, compared, brain, prediction, accuracy, maps, two, groups, ., results, reveal, difference, prediction, accuracy, follows, hierarchical, pattern, ,, consistent, cortical, hierarchy, map, revealed, activity, time, constants, ., finding, suggests, parallel, language, models, human, brain, process, linguistic, information, ."
Putting Natural in Natural Language Processing,Grzegorz Chrupała,2023-05-08T09:29:31Z,"  Human language is firstly spoken and only secondarily written. Text, however,
is a very convenient and efficient representation of language, and modern
civilization has made it ubiquitous. Thus the field of NLP has overwhelmingly
focused on processing written rather than spoken language. Work on spoken
language, on the other hand, has been siloed off within the largely separate
speech processing community which has been inordinately preoccupied with
transcribing speech into text. Recent advances in deep learning have led to a
fortuitous convergence in methods between speech processing and mainstream NLP.
Arguably, the time is ripe for a unification of these two fields, and for
starting to take spoken language seriously as the primary mode of human
communication. Truly natural language processing could lead to better
integration with the rest of language science and could lead to systems which
are more data-efficient and more human-like, and which can communicate beyond
the textual modality.
","['human', 'language', 'firstly', 'spoken', 'secondarily', 'written', '.', 'text', ',', 'however', ',', 'convenient', 'efficient', 'representation', 'language', ',', 'modern', 'civilization', 'made', 'ubiquitous', '.', 'thus', 'field', 'nlp', 'overwhelmingly', 'focused', 'processing', 'written', 'rather', 'spoken', 'language', '.', 'work', 'spoken', 'language', ',', 'hand', ',', 'siloed', 'within', 'largely', 'separate', 'speech', 'processing', 'community', 'inordinately', 'preoccupied', 'transcribing', 'speech', 'text', '.', 'recent', 'advances', 'deep', 'learning', 'led', 'fortuitous', 'convergence', 'methods', 'speech', 'processing', 'mainstream', 'nlp', '.', 'arguably', ',', 'time', 'ripe', 'unification', 'two', 'fields', ',', 'starting', 'take', 'spoken', 'language', 'seriously', 'primary', 'mode', 'human', 'communication', '.', 'truly', 'natural', 'language', 'processing', 'could', 'lead', 'better', 'integration', 'rest', 'language', 'science', 'could', 'lead', 'systems', 'data-efficient', 'human-like', ',', 'communicate', 'beyond', 'textual', 'modality', '.']","human, language, firstly, spoken, secondarily, written, ., text, ,, however, ,, convenient, efficient, representation, language, ,, modern, civilization, made, ubiquitous, ., thus, field, nlp, overwhelmingly, focused, processing, written, rather, spoken, language, ., work, spoken, language, ,, hand, ,, siloed, within, largely, separate, speech, processing, community, inordinately, preoccupied, transcribing, speech, text, ., recent, advances, deep, learning, led, fortuitous, convergence, methods, speech, processing, mainstream, nlp, ., arguably, ,, time, ripe, unification, two, fields, ,, starting, take, spoken, language, seriously, primary, mode, human, communication, ., truly, natural, language, processing, could, lead, better, integration, rest, language, science, could, lead, systems, data-efficient, human-like, ,, communicate, beyond, textual, modality, ."
PyThaiNLP: Thai Natural Language Processing in Python,"Wannaphong Phatthiyaphaibun, Korakot Chaovavanich, Charin Polpanumas, Arthit Suriyawongkul, Lalita Lowphansirikul, Pattarawat Chormai, Peerat Limkonchotiwat, Thanathip Suntorntip, Can Udomcharoenchaikit",2023-12-07T19:19:43Z,"  We present PyThaiNLP, a free and open-source natural language processing
(NLP) library for Thai language implemented in Python. It provides a wide range
of software, models, and datasets for Thai language. We first provide a brief
historical context of tools for Thai language prior to the development of
PyThaiNLP. We then outline the functionalities it provided as well as datasets
and pre-trained language models. We later summarize its development milestones
and discuss our experience during its development. We conclude by demonstrating
how industrial and research communities utilize PyThaiNLP in their work. The
library is freely available at https://github.com/pythainlp/pythainlp.
","['present', 'pythainlp', ',', 'free', 'open-source', 'natural', 'language', 'processing', '(', 'nlp', ')', 'library', 'thai', 'language', 'implemented', 'python', '.', 'provides', 'wide', 'range', 'software', ',', 'models', ',', 'datasets', 'thai', 'language', '.', 'first', 'provide', 'brief', 'historical', 'context', 'tools', 'thai', 'language', 'prior', 'development', 'pythainlp', '.', 'outline', 'functionalities', 'provided', 'well', 'datasets', 'pre-trained', 'language', 'models', '.', 'later', 'summarize', 'development', 'milestones', 'discuss', 'experience', 'development', '.', 'conclude', 'demonstrating', 'industrial', 'research', 'communities', 'utilize', 'pythainlp', 'work', '.', 'library', 'freely', 'available', 'https', ':', '//github.com/pythainlp/pythainlp', '.']","present, pythainlp, ,, free, open-source, natural, language, processing, (, nlp, ), library, thai, language, implemented, python, ., provides, wide, range, software, ,, models, ,, datasets, thai, language, ., first, provide, brief, historical, context, tools, thai, language, prior, development, pythainlp, ., outline, functionalities, provided, well, datasets, pre-trained, language, models, ., later, summarize, development, milestones, discuss, experience, development, ., conclude, demonstrating, industrial, research, communities, utilize, pythainlp, work, ., library, freely, available, https, :, //github.com/pythainlp/pythainlp, ."
JamPatoisNLI: A Jamaican Patois Natural Language Inference Dataset,"Ruth-Ann Armstrong, John Hewitt, Christopher Manning",2022-12-07T03:07:02Z,"  JamPatoisNLI provides the first dataset for natural language inference in a
creole language, Jamaican Patois. Many of the most-spoken low-resource
languages are creoles. These languages commonly have a lexicon derived from a
major world language and a distinctive grammar reflecting the languages of the
original speakers and the process of language birth by creolization. This gives
them a distinctive place in exploring the effectiveness of transfer from large
monolingual or multilingual pretrained models. While our work, along with
previous work, shows that transfer from these models to low-resource languages
that are unrelated to languages in their training set is not very effective, we
would expect stronger results from transfer to creoles. Indeed, our experiments
show considerably better results from few-shot learning of JamPatoisNLI than
for such unrelated languages, and help us begin to understand how the unique
relationship between creoles and their high-resource base languages affect
cross-lingual transfer. JamPatoisNLI, which consists of naturally-occurring
premises and expert-written hypotheses, is a step towards steering research
into a traditionally underserved language and a useful benchmark for
understanding cross-lingual NLP.
","['jampatoisnli', 'provides', 'first', 'dataset', 'natural', 'language', 'inference', 'creole', 'language', ',', 'jamaican', 'patois', '.', 'many', 'most-spoken', 'low-resource', 'languages', 'creoles', '.', 'languages', 'commonly', 'lexicon', 'derived', 'major', 'world', 'language', 'distinctive', 'grammar', 'reflecting', 'languages', 'original', 'speakers', 'process', 'language', 'birth', 'creolization', '.', 'gives', 'distinctive', 'place', 'exploring', 'effectiveness', 'transfer', 'large', 'monolingual', 'multilingual', 'pretrained', 'models', '.', 'work', ',', 'along', 'previous', 'work', ',', 'shows', 'transfer', 'models', 'low-resource', 'languages', 'unrelated', 'languages', 'training', 'set', 'effective', ',', 'would', 'expect', 'stronger', 'results', 'transfer', 'creoles', '.', 'indeed', ',', 'experiments', 'show', 'considerably', 'better', 'results', 'few-shot', 'learning', 'jampatoisnli', 'unrelated', 'languages', ',', 'help', 'us', 'begin', 'understand', 'unique', 'relationship', 'creoles', 'high-resource', 'base', 'languages', 'affect', 'cross-lingual', 'transfer', '.', 'jampatoisnli', ',', 'consists', 'naturally-occurring', 'premises', 'expert-written', 'hypotheses', ',', 'step', 'towards', 'steering', 'research', 'traditionally', 'underserved', 'language', 'useful', 'benchmark', 'understanding', 'cross-lingual', 'nlp', '.']","jampatoisnli, provides, first, dataset, natural, language, inference, creole, language, ,, jamaican, patois, ., many, most-spoken, low-resource, languages, creoles, ., languages, commonly, lexicon, derived, major, world, language, distinctive, grammar, reflecting, languages, original, speakers, process, language, birth, creolization, ., gives, distinctive, place, exploring, effectiveness, transfer, large, monolingual, multilingual, pretrained, models, ., work, ,, along, previous, work, ,, shows, transfer, models, low-resource, languages, unrelated, languages, training, set, effective, ,, would, expect, stronger, results, transfer, creoles, ., indeed, ,, experiments, show, considerably, better, results, few-shot, learning, jampatoisnli, unrelated, languages, ,, help, us, begin, understand, unique, relationship, creoles, high-resource, base, languages, affect, cross-lingual, transfer, ., jampatoisnli, ,, consists, naturally-occurring, premises, expert-written, hypotheses, ,, step, towards, steering, research, traditionally, underserved, language, useful, benchmark, understanding, cross-lingual, nlp, ."
NLP for The Greek Language: A Longer Survey,"Katerina Papantoniou, Yannis Tzitzikas",2024-08-20T15:57:18Z,"  English language is in the spotlight of the Natural Language Processing (NLP)
community with other languages, like Greek, lagging behind in terms of offered
methods, tools and resources. Due to the increasing interest in NLP, in this
paper we try to condense research efforts for the automatic processing of Greek
language covering the last three decades. In particular, we list and briefly
discuss related works, resources and tools, categorized according to various
processing layers and contexts. We are not restricted to the modern form of
Greek language but also cover Ancient Greek and various Greek dialects. This
survey can be useful for researchers and students interested in NLP tasks,
Information Retrieval and Knowledge Management for the Greek language.
","['english', 'language', 'spotlight', 'natural', 'language', 'processing', '(', 'nlp', ')', 'community', 'languages', ',', 'like', 'greek', ',', 'lagging', 'behind', 'terms', 'offered', 'methods', ',', 'tools', 'resources', '.', 'due', 'increasing', 'interest', 'nlp', ',', 'paper', 'try', 'condense', 'research', 'efforts', 'automatic', 'processing', 'greek', 'language', 'covering', 'last', 'three', 'decades', '.', 'particular', ',', 'list', 'briefly', 'discuss', 'related', 'works', ',', 'resources', 'tools', ',', 'categorized', 'according', 'various', 'processing', 'layers', 'contexts', '.', 'restricted', 'modern', 'form', 'greek', 'language', 'also', 'cover', 'ancient', 'greek', 'various', 'greek', 'dialects', '.', 'survey', 'useful', 'researchers', 'students', 'interested', 'nlp', 'tasks', ',', 'information', 'retrieval', 'knowledge', 'management', 'greek', 'language', '.']","english, language, spotlight, natural, language, processing, (, nlp, ), community, languages, ,, like, greek, ,, lagging, behind, terms, offered, methods, ,, tools, resources, ., due, increasing, interest, nlp, ,, paper, try, condense, research, efforts, automatic, processing, greek, language, covering, last, three, decades, ., particular, ,, list, briefly, discuss, related, works, ,, resources, tools, ,, categorized, according, various, processing, layers, contexts, ., restricted, modern, form, greek, language, also, cover, ancient, greek, various, greek, dialects, ., survey, useful, researchers, students, interested, nlp, tasks, ,, information, retrieval, knowledge, management, greek, language, ."
Benchmarking Language Models for Code Syntax Understanding,"Da Shen, Xinyun Chen, Chenguang Wang, Koushik Sen, Dawn Song",2022-10-26T04:47:18Z,"  Pre-trained language models have demonstrated impressive performance in both
natural language processing and program understanding, which represent the
input as a token sequence without explicitly modeling its structure. Some prior
works show that pre-trained language models can capture the syntactic rules of
natural languages without finetuning on syntax understanding tasks. However,
there is limited understanding of how well pre-trained models understand the
code structure so far. In this work, we perform the first thorough benchmarking
of the state-of-the-art pre-trained models for identifying the syntactic
structures of programs. Specifically, we introduce CodeSyntax, a large-scale
dataset of programs annotated with the syntactic relationships in their
corresponding abstract syntax trees. Our key observation is that existing
language models pretrained on code still lack the understanding of code syntax.
In fact, these pre-trained programming language models fail to match the
performance of simple baselines based on positional offsets and keywords. We
also present a natural language benchmark to highlight the differences between
natural languages and programming languages in terms of syntactic structure
understanding. Our findings point out key limitations of existing pre-training
methods for programming languages, and suggest the importance of modeling code
syntactic structures.
","['pre-trained', 'language', 'models', 'demonstrated', 'impressive', 'performance', 'natural', 'language', 'processing', 'program', 'understanding', ',', 'represent', 'input', 'token', 'sequence', 'without', 'explicitly', 'modeling', 'structure', '.', 'prior', 'works', 'show', 'pre-trained', 'language', 'models', 'capture', 'syntactic', 'rules', 'natural', 'languages', 'without', 'finetuning', 'syntax', 'understanding', 'tasks', '.', 'however', ',', 'limited', 'understanding', 'well', 'pre-trained', 'models', 'understand', 'code', 'structure', 'far', '.', 'work', ',', 'perform', 'first', 'thorough', 'benchmarking', 'state-of-the-art', 'pre-trained', 'models', 'identifying', 'syntactic', 'structures', 'programs', '.', 'specifically', ',', 'introduce', 'codesyntax', ',', 'large-scale', 'dataset', 'programs', 'annotated', 'syntactic', 'relationships', 'corresponding', 'abstract', 'syntax', 'trees', '.', 'key', 'observation', 'existing', 'language', 'models', 'pretrained', 'code', 'still', 'lack', 'understanding', 'code', 'syntax', '.', 'fact', ',', 'pre-trained', 'programming', 'language', 'models', 'fail', 'match', 'performance', 'simple', 'baselines', 'based', 'positional', 'offsets', 'keywords', '.', 'also', 'present', 'natural', 'language', 'benchmark', 'highlight', 'differences', 'natural', 'languages', 'programming', 'languages', 'terms', 'syntactic', 'structure', 'understanding', '.', 'findings', 'point', 'key', 'limitations', 'existing', 'pre-training', 'methods', 'programming', 'languages', ',', 'suggest', 'importance', 'modeling', 'code', 'syntactic', 'structures', '.']","pre-trained, language, models, demonstrated, impressive, performance, natural, language, processing, program, understanding, ,, represent, input, token, sequence, without, explicitly, modeling, structure, ., prior, works, show, pre-trained, language, models, capture, syntactic, rules, natural, languages, without, finetuning, syntax, understanding, tasks, ., however, ,, limited, understanding, well, pre-trained, models, understand, code, structure, far, ., work, ,, perform, first, thorough, benchmarking, state-of-the-art, pre-trained, models, identifying, syntactic, structures, programs, ., specifically, ,, introduce, codesyntax, ,, large-scale, dataset, programs, annotated, syntactic, relationships, corresponding, abstract, syntax, trees, ., key, observation, existing, language, models, pretrained, code, still, lack, understanding, code, syntax, ., fact, ,, pre-trained, programming, language, models, fail, match, performance, simple, baselines, based, positional, offsets, keywords, ., also, present, natural, language, benchmark, highlight, differences, natural, languages, programming, languages, terms, syntactic, structure, understanding, ., findings, point, key, limitations, existing, pre-training, methods, programming, languages, ,, suggest, importance, modeling, code, syntactic, structures, ."
"Natural Language Interfaces for Tabular Data Querying and Visualization:
  A Survey","Weixu Zhang, Yifei Wang, Yuanfeng Song, Victor Junqiu Wei, Yuxing Tian, Yiyan Qi, Jonathan H. Chan, Raymond Chi-Wing Wong, Haiqin Yang",2023-10-27T05:01:20Z,"  The emergence of natural language processing has revolutionized the way users
interact with tabular data, enabling a shift from traditional query languages
and manual plotting to more intuitive, language-based interfaces. The rise of
large language models (LLMs) such as ChatGPT and its successors has further
advanced this field, opening new avenues for natural language processing
techniques. This survey presents a comprehensive overview of natural language
interfaces for tabular data querying and visualization, which allow users to
interact with data using natural language queries. We introduce the fundamental
concepts and techniques underlying these interfaces with a particular emphasis
on semantic parsing, the key technology facilitating the translation from
natural language to SQL queries or data visualization commands. We then delve
into the recent advancements in Text-to-SQL and Text-to-Vis problems from the
perspectives of datasets, methodologies, metrics, and system designs. This
includes a deep dive into the influence of LLMs, highlighting their strengths,
limitations, and potential for future improvements. Through this survey, we aim
to provide a roadmap for researchers and practitioners interested in developing
and applying natural language interfaces for data interaction in the era of
large language models.
","['emergence', 'natural', 'language', 'processing', 'revolutionized', 'way', 'users', 'interact', 'tabular', 'data', ',', 'enabling', 'shift', 'traditional', 'query', 'languages', 'manual', 'plotting', 'intuitive', ',', 'language-based', 'interfaces', '.', 'rise', 'large', 'language', 'models', '(', 'llms', ')', 'chatgpt', 'successors', 'advanced', 'field', ',', 'opening', 'new', 'avenues', 'natural', 'language', 'processing', 'techniques', '.', 'survey', 'presents', 'comprehensive', 'overview', 'natural', 'language', 'interfaces', 'tabular', 'data', 'querying', 'visualization', ',', 'allow', 'users', 'interact', 'data', 'using', 'natural', 'language', 'queries', '.', 'introduce', 'fundamental', 'concepts', 'techniques', 'underlying', 'interfaces', 'particular', 'emphasis', 'semantic', 'parsing', ',', 'key', 'technology', 'facilitating', 'translation', 'natural', 'language', 'sql', 'queries', 'data', 'visualization', 'commands', '.', 'delve', 'recent', 'advancements', 'text-to-sql', 'text-to-vis', 'problems', 'perspectives', 'datasets', ',', 'methodologies', ',', 'metrics', ',', 'system', 'designs', '.', 'includes', 'deep', 'dive', 'influence', 'llms', ',', 'highlighting', 'strengths', ',', 'limitations', ',', 'potential', 'future', 'improvements', '.', 'survey', ',', 'aim', 'provide', 'roadmap', 'researchers', 'practitioners', 'interested', 'developing', 'applying', 'natural', 'language', 'interfaces', 'data', 'interaction', 'era', 'large', 'language', 'models', '.']","emergence, natural, language, processing, revolutionized, way, users, interact, tabular, data, ,, enabling, shift, traditional, query, languages, manual, plotting, intuitive, ,, language-based, interfaces, ., rise, large, language, models, (, llms, ), chatgpt, successors, advanced, field, ,, opening, new, avenues, natural, language, processing, techniques, ., survey, presents, comprehensive, overview, natural, language, interfaces, tabular, data, querying, visualization, ,, allow, users, interact, data, using, natural, language, queries, ., introduce, fundamental, concepts, techniques, underlying, interfaces, particular, emphasis, semantic, parsing, ,, key, technology, facilitating, translation, natural, language, sql, queries, data, visualization, commands, ., delve, recent, advancements, text-to-sql, text-to-vis, problems, perspectives, datasets, ,, methodologies, ,, metrics, ,, system, designs, ., includes, deep, dive, influence, llms, ,, highlighting, strengths, ,, limitations, ,, potential, future, improvements, ., survey, ,, aim, provide, roadmap, researchers, practitioners, interested, developing, applying, natural, language, interfaces, data, interaction, era, large, language, models, ."
Integrating Linguistic Theory and Neural Language Models,Bai Li,2022-07-20T04:20:46Z,"  Transformer-based language models have recently achieved remarkable results
in many natural language tasks. However, performance on leaderboards is
generally achieved by leveraging massive amounts of training data, and rarely
by encoding explicit linguistic knowledge into neural models. This has led many
to question the relevance of linguistics for modern natural language
processing. In this dissertation, I present several case studies to illustrate
how theoretical linguistics and neural language models are still relevant to
each other. First, language models are useful to linguists by providing an
objective tool to measure semantic distance, which is difficult to do using
traditional methods. On the other hand, linguistic theory contributes to
language modelling research by providing frameworks and sources of data to
probe our language models for specific aspects of language understanding.
  This thesis contributes three studies that explore different aspects of the
syntax-semantics interface in language models. In the first part of my thesis,
I apply language models to the problem of word class flexibility. Using mBERT
as a source of semantic distance measurements, I present evidence in favour of
analyzing word class flexibility as a directional process. In the second part
of my thesis, I propose a method to measure surprisal at intermediate layers of
language models. My experiments show that sentences containing morphosyntactic
anomalies trigger surprisals earlier in language models than semantic and
commonsense anomalies. Finally, in the third part of my thesis, I adapt several
psycholinguistic studies to show that language models contain knowledge of
argument structure constructions. In summary, my thesis develops new
connections between natural language processing, linguistic theory, and
psycholinguistics to provide fresh perspectives for the interpretation of
language models.
","['transformer-based', 'language', 'models', 'recently', 'achieved', 'remarkable', 'results', 'many', 'natural', 'language', 'tasks', '.', 'however', ',', 'performance', 'leaderboards', 'generally', 'achieved', 'leveraging', 'massive', 'amounts', 'training', 'data', ',', 'rarely', 'encoding', 'explicit', 'linguistic', 'knowledge', 'neural', 'models', '.', 'led', 'many', 'question', 'relevance', 'linguistics', 'modern', 'natural', 'language', 'processing', '.', 'dissertation', ',', 'present', 'several', 'case', 'studies', 'illustrate', 'theoretical', 'linguistics', 'neural', 'language', 'models', 'still', 'relevant', '.', 'first', ',', 'language', 'models', 'useful', 'linguists', 'providing', 'objective', 'tool', 'measure', 'semantic', 'distance', ',', 'difficult', 'using', 'traditional', 'methods', '.', 'hand', ',', 'linguistic', 'theory', 'contributes', 'language', 'modelling', 'research', 'providing', 'frameworks', 'sources', 'data', 'probe', 'language', 'models', 'specific', 'aspects', 'language', 'understanding', '.', 'thesis', 'contributes', 'three', 'studies', 'explore', 'different', 'aspects', 'syntax-semantics', 'interface', 'language', 'models', '.', 'first', 'part', 'thesis', ',', 'apply', 'language', 'models', 'problem', 'word', 'class', 'flexibility', '.', 'using', 'mbert', 'source', 'semantic', 'distance', 'measurements', ',', 'present', 'evidence', 'favour', 'analyzing', 'word', 'class', 'flexibility', 'directional', 'process', '.', 'second', 'part', 'thesis', ',', 'propose', 'method', 'measure', 'surprisal', 'intermediate', 'layers', 'language', 'models', '.', 'experiments', 'show', 'sentences', 'containing', 'morphosyntactic', 'anomalies', 'trigger', 'surprisals', 'earlier', 'language', 'models', 'semantic', 'commonsense', 'anomalies', '.', 'finally', ',', 'third', 'part', 'thesis', ',', 'adapt', 'several', 'psycholinguistic', 'studies', 'show', 'language', 'models', 'contain', 'knowledge', 'argument', 'structure', 'constructions', '.', 'summary', ',', 'thesis', 'develops', 'new', 'connections', 'natural', 'language', 'processing', ',', 'linguistic', 'theory', ',', 'psycholinguistics', 'provide', 'fresh', 'perspectives', 'interpretation', 'language', 'models', '.']","transformer-based, language, models, recently, achieved, remarkable, results, many, natural, language, tasks, ., however, ,, performance, leaderboards, generally, achieved, leveraging, massive, amounts, training, data, ,, rarely, encoding, explicit, linguistic, knowledge, neural, models, ., led, many, question, relevance, linguistics, modern, natural, language, processing, ., dissertation, ,, present, several, case, studies, illustrate, theoretical, linguistics, neural, language, models, still, relevant, ., first, ,, language, models, useful, linguists, providing, objective, tool, measure, semantic, distance, ,, difficult, using, traditional, methods, ., hand, ,, linguistic, theory, contributes, language, modelling, research, providing, frameworks, sources, data, probe, language, models, specific, aspects, language, understanding, ., thesis, contributes, three, studies, explore, different, aspects, syntax-semantics, interface, language, models, ., first, part, thesis, ,, apply, language, models, problem, word, class, flexibility, ., using, mbert, source, semantic, distance, measurements, ,, present, evidence, favour, analyzing, word, class, flexibility, directional, process, ., second, part, thesis, ,, propose, method, measure, surprisal, intermediate, layers, language, models, ., experiments, show, sentences, containing, morphosyntactic, anomalies, trigger, surprisals, earlier, language, models, semantic, commonsense, anomalies, ., finally, ,, third, part, thesis, ,, adapt, several, psycholinguistic, studies, show, language, models, contain, knowledge, argument, structure, constructions, ., summary, ,, thesis, develops, new, connections, natural, language, processing, ,, linguistic, theory, ,, psycholinguistics, provide, fresh, perspectives, interpretation, language, models, ."
"Logical Semantics, Dialogical Argumentation, and Textual Entailment","Davide Catta, Richard Moot, Christian Retoré",2020-08-17T08:04:11Z,"  In this chapter, we introduce a new dialogical system for first order
classical logic which is close to natural language argumentation, and we prove
its completeness with respect to usual classical validity. We combine our
dialogical system with the Grail syntactic and semantic parser developed by the
second author in order to address automated textual entailment, that is, we use
it for deciding whether or not a sentence is a consequence of a short text.
This work-which connects natural language semantics and argumentation with
dialogical logic-can be viewed as a step towards an inferentialist view of
natural language semantics.
","['chapter', ',', 'introduce', 'new', 'dialogical', 'system', 'first', 'order', 'classical', 'logic', 'close', 'natural', 'language', 'argumentation', ',', 'prove', 'completeness', 'respect', 'usual', 'classical', 'validity', '.', 'combine', 'dialogical', 'system', 'grail', 'syntactic', 'semantic', 'parser', 'developed', 'second', 'author', 'order', 'address', 'automated', 'textual', 'entailment', ',', ',', 'use', 'deciding', 'whether', 'sentence', 'consequence', 'short', 'text', '.', 'work-which', 'connects', 'natural', 'language', 'semantics', 'argumentation', 'dialogical', 'logic-can', 'viewed', 'step', 'towards', 'inferentialist', 'view', 'natural', 'language', 'semantics', '.']","chapter, ,, introduce, new, dialogical, system, first, order, classical, logic, close, natural, language, argumentation, ,, prove, completeness, respect, usual, classical, validity, ., combine, dialogical, system, grail, syntactic, semantic, parser, developed, second, author, order, address, automated, textual, entailment, ,, ,, use, deciding, whether, sentence, consequence, short, text, ., work-which, connects, natural, language, semantics, argumentation, dialogical, logic-can, viewed, step, towards, inferentialist, view, natural, language, semantics, ."
Cedille: A large autoregressive French language model,"Martin Müller, Florian Laurent",2022-02-07T17:40:43Z,"  Scaling up the size and training of autoregressive language models has
enabled novel ways of solving Natural Language Processing tasks using zero-shot
and few-shot learning. While extreme-scale language models such as GPT-3 offer
multilingual capabilities, zero-shot learning for languages other than English
remain largely unexplored. Here, we introduce Cedille, a large open source
auto-regressive language model, specifically trained for the French language.
Our results show that Cedille outperforms existing French language models and
is competitive with GPT-3 on a range of French zero-shot benchmarks.
Furthermore, we provide an in-depth comparison of the toxicity exhibited by
these models, showing that Cedille marks an improvement in language model
safety thanks to dataset filtering.
","['scaling', 'size', 'training', 'autoregressive', 'language', 'models', 'enabled', 'novel', 'ways', 'solving', 'natural', 'language', 'processing', 'tasks', 'using', 'zero-shot', 'few-shot', 'learning', '.', 'extreme-scale', 'language', 'models', 'gpt-3', 'offer', 'multilingual', 'capabilities', ',', 'zero-shot', 'learning', 'languages', 'english', 'remain', 'largely', 'unexplored', '.', ',', 'introduce', 'cedille', ',', 'large', 'open', 'source', 'auto-regressive', 'language', 'model', ',', 'specifically', 'trained', 'french', 'language', '.', 'results', 'show', 'cedille', 'outperforms', 'existing', 'french', 'language', 'models', 'competitive', 'gpt-3', 'range', 'french', 'zero-shot', 'benchmarks', '.', 'furthermore', ',', 'provide', 'in-depth', 'comparison', 'toxicity', 'exhibited', 'models', ',', 'showing', 'cedille', 'marks', 'improvement', 'language', 'model', 'safety', 'thanks', 'dataset', 'filtering', '.']","scaling, size, training, autoregressive, language, models, enabled, novel, ways, solving, natural, language, processing, tasks, using, zero-shot, few-shot, learning, ., extreme-scale, language, models, gpt-3, offer, multilingual, capabilities, ,, zero-shot, learning, languages, english, remain, largely, unexplored, ., ,, introduce, cedille, ,, large, open, source, auto-regressive, language, model, ,, specifically, trained, french, language, ., results, show, cedille, outperforms, existing, french, language, models, competitive, gpt-3, range, french, zero-shot, benchmarks, ., furthermore, ,, provide, in-depth, comparison, toxicity, exhibited, models, ,, showing, cedille, marks, improvement, language, model, safety, thanks, dataset, filtering, ."
Spontaneous Emerging Preference in Two-tower Language Model,"Zhengqi He, Taro Toyoizumi",2022-10-13T13:55:19Z,"  The ever-growing size of the foundation language model has brought
significant performance gains in various types of downstream tasks. With the
existence of side-effects brought about by the large size of the foundation
language model such as deployment cost, availability issues, and environmental
cost, there is some interest in exploring other possible directions, such as a
divide-and-conquer scheme. In this paper, we are asking a basic question: are
language processes naturally dividable? We study this problem with a simple
two-tower language model setting, where two language models with identical
configurations are trained side-by-side cooperatively. With this setting, we
discover the spontaneous emerging preference phenomenon, where some of the
tokens are consistently better predicted by one tower while others by another
tower. This phenomenon is qualitatively stable, regardless of model
configuration and type, suggesting this as an intrinsic property of natural
language. This study suggests that interesting properties of natural language
are still waiting to be discovered, which may aid the future development of
natural language processing techniques.
","['ever-growing', 'size', 'foundation', 'language', 'model', 'brought', 'significant', 'performance', 'gains', 'various', 'types', 'downstream', 'tasks', '.', 'existence', 'side-effects', 'brought', 'large', 'size', 'foundation', 'language', 'model', 'deployment', 'cost', ',', 'availability', 'issues', ',', 'environmental', 'cost', ',', 'interest', 'exploring', 'possible', 'directions', ',', 'divide-and-conquer', 'scheme', '.', 'paper', ',', 'asking', 'basic', 'question', ':', 'language', 'processes', 'naturally', 'dividable', '?', 'study', 'problem', 'simple', 'two-tower', 'language', 'model', 'setting', ',', 'two', 'language', 'models', 'identical', 'configurations', 'trained', 'side-by-side', 'cooperatively', '.', 'setting', ',', 'discover', 'spontaneous', 'emerging', 'preference', 'phenomenon', ',', 'tokens', 'consistently', 'better', 'predicted', 'one', 'tower', 'others', 'another', 'tower', '.', 'phenomenon', 'qualitatively', 'stable', ',', 'regardless', 'model', 'configuration', 'type', ',', 'suggesting', 'intrinsic', 'property', 'natural', 'language', '.', 'study', 'suggests', 'interesting', 'properties', 'natural', 'language', 'still', 'waiting', 'discovered', ',', 'may', 'aid', 'future', 'development', 'natural', 'language', 'processing', 'techniques', '.']","ever-growing, size, foundation, language, model, brought, significant, performance, gains, various, types, downstream, tasks, ., existence, side-effects, brought, large, size, foundation, language, model, deployment, cost, ,, availability, issues, ,, environmental, cost, ,, interest, exploring, possible, directions, ,, divide-and-conquer, scheme, ., paper, ,, asking, basic, question, :, language, processes, naturally, dividable, ?, study, problem, simple, two-tower, language, model, setting, ,, two, language, models, identical, configurations, trained, side-by-side, cooperatively, ., setting, ,, discover, spontaneous, emerging, preference, phenomenon, ,, tokens, consistently, better, predicted, one, tower, others, another, tower, ., phenomenon, qualitatively, stable, ,, regardless, model, configuration, type, ,, suggesting, intrinsic, property, natural, language, ., study, suggests, interesting, properties, natural, language, still, waiting, discovered, ,, may, aid, future, development, natural, language, processing, techniques, ."
LangPro: Natural Language Theorem Prover,Lasha Abzianidze,2017-08-30T18:22:28Z,"  LangPro is an automated theorem prover for natural language
(https://github.com/kovvalsky/LangPro). Given a set of premises and a
hypothesis, it is able to prove semantic relations between them. The prover is
based on a version of analytic tableau method specially designed for natural
logic. The proof procedure operates on logical forms that preserve linguistic
expressions to a large extent. %This property makes the logical forms easily
obtainable from syntactic trees. %, in particular, Combinatory Categorial
Grammar derivation trees. The nature of proofs is deductive and transparent. On
the FraCaS and SICK textual entailment datasets, the prover achieves high
results comparable to state-of-the-art.
","['langpro', 'automated', 'theorem', 'prover', 'natural', 'language', '(', 'https', ':', '//github.com/kovvalsky/langpro', ')', '.', 'given', 'set', 'premises', 'hypothesis', ',', 'able', 'prove', 'semantic', 'relations', '.', 'prover', 'based', 'version', 'analytic', 'tableau', 'method', 'specially', 'designed', 'natural', 'logic', '.', 'proof', 'procedure', 'operates', 'logical', 'forms', 'preserve', 'linguistic', 'expressions', 'large', 'extent', '.', '%', 'property', 'makes', 'logical', 'forms', 'easily', 'obtainable', 'syntactic', 'trees', '.', '%', ',', 'particular', ',', 'combinatory', 'categorial', 'grammar', 'derivation', 'trees', '.', 'nature', 'proofs', 'deductive', 'transparent', '.', 'fracas', 'sick', 'textual', 'entailment', 'datasets', ',', 'prover', 'achieves', 'high', 'results', 'comparable', 'state-of-the-art', '.']","langpro, automated, theorem, prover, natural, language, (, https, :, //github.com/kovvalsky/langpro, ), ., given, set, premises, hypothesis, ,, able, prove, semantic, relations, ., prover, based, version, analytic, tableau, method, specially, designed, natural, logic, ., proof, procedure, operates, logical, forms, preserve, linguistic, expressions, large, extent, ., %, property, makes, logical, forms, easily, obtainable, syntactic, trees, ., %, ,, particular, ,, combinatory, categorial, grammar, derivation, trees, ., nature, proofs, deductive, transparent, ., fracas, sick, textual, entailment, datasets, ,, prover, achieves, high, results, comparable, state-of-the-art, ."
"Natural Language Processing: State of The Art, Current Trends and
  Challenges","Diksha Khurana, Aditya Koli, Kiran Khatter, Sukhdev Singh",2017-08-17T06:42:03Z,"  Natural language processing (NLP) has recently gained much attention for
representing and analysing human language computationally. It has spread its
applications in various fields such as machine translation, email spam
detection, information extraction, summarization, medical, and question
answering etc. The paper distinguishes four phases by discussing different
levels of NLP and components of Natural Language Generation (NLG) followed by
presenting the history and evolution of NLP, state of the art presenting the
various applications of NLP and current trends and challenges.
","['natural', 'language', 'processing', '(', 'nlp', ')', 'recently', 'gained', 'much', 'attention', 'representing', 'analysing', 'human', 'language', 'computationally', '.', 'spread', 'applications', 'various', 'fields', 'machine', 'translation', ',', 'email', 'spam', 'detection', ',', 'information', 'extraction', ',', 'summarization', ',', 'medical', ',', 'question', 'answering', 'etc', '.', 'paper', 'distinguishes', 'four', 'phases', 'discussing', 'different', 'levels', 'nlp', 'components', 'natural', 'language', 'generation', '(', 'nlg', ')', 'followed', 'presenting', 'history', 'evolution', 'nlp', ',', 'state', 'art', 'presenting', 'various', 'applications', 'nlp', 'current', 'trends', 'challenges', '.']","natural, language, processing, (, nlp, ), recently, gained, much, attention, representing, analysing, human, language, computationally, ., spread, applications, various, fields, machine, translation, ,, email, spam, detection, ,, information, extraction, ,, summarization, ,, medical, ,, question, answering, etc, ., paper, distinguishes, four, phases, discussing, different, levels, nlp, components, natural, language, generation, (, nlg, ), followed, presenting, history, evolution, nlp, ,, state, art, presenting, various, applications, nlp, current, trends, challenges, ."
Linking Emergent and Natural Languages via Corpus Transfer,"Shunyu Yao, Mo Yu, Yang Zhang, Karthik R Narasimhan, Joshua B. Tenenbaum, Chuang Gan",2022-03-24T21:24:54Z,"  The study of language emergence aims to understand how human languages are
shaped by perceptual grounding and communicative intent. Computational
approaches to emergent communication (EC) predominantly consider referential
games in limited domains and analyze the learned protocol within the game
framework. As a result, it remains unclear how the emergent languages from
these settings connect to natural languages or provide benefits in real-world
language processing tasks, where statistical models trained on large text
corpora dominate. In this work, we propose a novel way to establish such a link
by corpus transfer, i.e. pretraining on a corpus of emergent language for
downstream natural language tasks, which is in contrast to prior work that
directly transfers speaker and listener parameters. Our approach showcases
non-trivial transfer benefits for two different tasks -- language modeling and
image captioning. For example, in a low-resource setup (modeling 2 million
natural language tokens), pre-training on an emergent language corpus with just
2 million tokens reduces model perplexity by $24.6\%$ on average across ten
natural languages. We also introduce a novel metric to predict the
transferability of an emergent language by translating emergent messages to
natural language captions grounded on the same images. We find that our
translation-based metric highly correlates with the downstream performance on
modeling natural languages (for instance $\rho=0.83$ on Hebrew), while
topographic similarity, a popular metric in previous work, shows surprisingly
low correlation ($\rho=0.003$), hinting that simple properties like attribute
disentanglement from synthetic domains might not capture the full complexities
of natural language. Our findings also indicate potential benefits of moving
language emergence forward with natural language resources and models.
","['study', 'language', 'emergence', 'aims', 'understand', 'human', 'languages', 'shaped', 'perceptual', 'grounding', 'communicative', 'intent', '.', 'computational', 'approaches', 'emergent', 'communication', '(', 'ec', ')', 'predominantly', 'consider', 'referential', 'games', 'limited', 'domains', 'analyze', 'learned', 'protocol', 'within', 'game', 'framework', '.', 'result', ',', 'remains', 'unclear', 'emergent', 'languages', 'settings', 'connect', 'natural', 'languages', 'provide', 'benefits', 'real-world', 'language', 'processing', 'tasks', ',', 'statistical', 'models', 'trained', 'large', 'text', 'corpora', 'dominate', '.', 'work', ',', 'propose', 'novel', 'way', 'establish', 'link', 'corpus', 'transfer', ',', 'i.e', '.', 'pretraining', 'corpus', 'emergent', 'language', 'downstream', 'natural', 'language', 'tasks', ',', 'contrast', 'prior', 'work', 'directly', 'transfers', 'speaker', 'listener', 'parameters', '.', 'approach', 'showcases', 'non-trivial', 'transfer', 'benefits', 'two', 'different', 'tasks', '--', 'language', 'modeling', 'image', 'captioning', '.', 'example', ',', 'low-resource', 'setup', '(', 'modeling', '2', 'million', 'natural', 'language', 'tokens', ')', ',', 'pre-training', 'emergent', 'language', 'corpus', '2', 'million', 'tokens', 'reduces', 'model', 'perplexity', '$', '24.6\\', '%', '$', 'average', 'across', 'ten', 'natural', 'languages', '.', 'also', 'introduce', 'novel', 'metric', 'predict', 'transferability', 'emergent', 'language', 'translating', 'emergent', 'messages', 'natural', 'language', 'captions', 'grounded', 'images', '.', 'find', 'translation-based', 'metric', 'highly', 'correlates', 'downstream', 'performance', 'modeling', 'natural', 'languages', '(', 'instance', '$', '\\rho=0.83', '$', 'hebrew', ')', ',', 'topographic', 'similarity', ',', 'popular', 'metric', 'previous', 'work', ',', 'shows', 'surprisingly', 'low', 'correlation', '(', '$', '\\rho=0.003', '$', ')', ',', 'hinting', 'simple', 'properties', 'like', 'attribute', 'disentanglement', 'synthetic', 'domains', 'might', 'capture', 'full', 'complexities', 'natural', 'language', '.', 'findings', 'also', 'indicate', 'potential', 'benefits', 'moving', 'language', 'emergence', 'forward', 'natural', 'language', 'resources', 'models', '.']","study, language, emergence, aims, understand, human, languages, shaped, perceptual, grounding, communicative, intent, ., computational, approaches, emergent, communication, (, ec, ), predominantly, consider, referential, games, limited, domains, analyze, learned, protocol, within, game, framework, ., result, ,, remains, unclear, emergent, languages, settings, connect, natural, languages, provide, benefits, real-world, language, processing, tasks, ,, statistical, models, trained, large, text, corpora, dominate, ., work, ,, propose, novel, way, establish, link, corpus, transfer, ,, i.e, ., pretraining, corpus, emergent, language, downstream, natural, language, tasks, ,, contrast, prior, work, directly, transfers, speaker, listener, parameters, ., approach, showcases, non-trivial, transfer, benefits, two, different, tasks, --, language, modeling, image, captioning, ., example, ,, low-resource, setup, (, modeling, 2, million, natural, language, tokens, ), ,, pre-training, emergent, language, corpus, 2, million, tokens, reduces, model, perplexity, $, 24.6\, %, $, average, across, ten, natural, languages, ., also, introduce, novel, metric, predict, transferability, emergent, language, translating, emergent, messages, natural, language, captions, grounded, images, ., find, translation-based, metric, highly, correlates, downstream, performance, modeling, natural, languages, (, instance, $, \rho=0.83, $, hebrew, ), ,, topographic, similarity, ,, popular, metric, previous, work, ,, shows, surprisingly, low, correlation, (, $, \rho=0.003, $, ), ,, hinting, simple, properties, like, attribute, disentanglement, synthetic, domains, might, capture, full, complexities, natural, language, ., findings, also, indicate, potential, benefits, moving, language, emergence, forward, natural, language, resources, models, ."
Cheetah: Natural Language Generation for 517 African Languages,"Ife Adebara, AbdelRahim Elmadany, Muhammad Abdul-Mageed",2024-01-02T06:24:13Z,"  Low-resource African languages pose unique challenges for natural language
processing (NLP) tasks, including natural language generation (NLG). In this
paper, we develop Cheetah, a massively multilingual NLG language model for
African languages. Cheetah supports 517 African languages and language
varieties, allowing us to address the scarcity of NLG resources and provide a
solution to foster linguistic diversity. We demonstrate the effectiveness of
Cheetah through comprehensive evaluations across six generation downstream
tasks. In five of the six tasks, Cheetah significantly outperforms other
models, showcasing its remarkable performance for generating coherent and
contextually appropriate text in a wide range of African languages. We
additionally conduct a detailed human evaluation to delve deeper into the
linguistic capabilities of Cheetah. The introduction of Cheetah has
far-reaching benefits for linguistic diversity. By leveraging pretrained models
and adapting them to specific languages, our approach facilitates the
development of practical NLG applications for African communities. The findings
of this study contribute to advancing NLP research in low-resource settings,
enabling greater accessibility and inclusion for African languages in a rapidly
expanding digital landscape. We publicly release our models for research.
","['low-resource', 'african', 'languages', 'pose', 'unique', 'challenges', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', ',', 'including', 'natural', 'language', 'generation', '(', 'nlg', ')', '.', 'paper', ',', 'develop', 'cheetah', ',', 'massively', 'multilingual', 'nlg', 'language', 'model', 'african', 'languages', '.', 'cheetah', 'supports', '517', 'african', 'languages', 'language', 'varieties', ',', 'allowing', 'us', 'address', 'scarcity', 'nlg', 'resources', 'provide', 'solution', 'foster', 'linguistic', 'diversity', '.', 'demonstrate', 'effectiveness', 'cheetah', 'comprehensive', 'evaluations', 'across', 'six', 'generation', 'downstream', 'tasks', '.', 'five', 'six', 'tasks', ',', 'cheetah', 'significantly', 'outperforms', 'models', ',', 'showcasing', 'remarkable', 'performance', 'generating', 'coherent', 'contextually', 'appropriate', 'text', 'wide', 'range', 'african', 'languages', '.', 'additionally', 'conduct', 'detailed', 'human', 'evaluation', 'delve', 'deeper', 'linguistic', 'capabilities', 'cheetah', '.', 'introduction', 'cheetah', 'far-reaching', 'benefits', 'linguistic', 'diversity', '.', 'leveraging', 'pretrained', 'models', 'adapting', 'specific', 'languages', ',', 'approach', 'facilitates', 'development', 'practical', 'nlg', 'applications', 'african', 'communities', '.', 'findings', 'study', 'contribute', 'advancing', 'nlp', 'research', 'low-resource', 'settings', ',', 'enabling', 'greater', 'accessibility', 'inclusion', 'african', 'languages', 'rapidly', 'expanding', 'digital', 'landscape', '.', 'publicly', 'release', 'models', 'research', '.']","low-resource, african, languages, pose, unique, challenges, natural, language, processing, (, nlp, ), tasks, ,, including, natural, language, generation, (, nlg, ), ., paper, ,, develop, cheetah, ,, massively, multilingual, nlg, language, model, african, languages, ., cheetah, supports, 517, african, languages, language, varieties, ,, allowing, us, address, scarcity, nlg, resources, provide, solution, foster, linguistic, diversity, ., demonstrate, effectiveness, cheetah, comprehensive, evaluations, across, six, generation, downstream, tasks, ., five, six, tasks, ,, cheetah, significantly, outperforms, models, ,, showcasing, remarkable, performance, generating, coherent, contextually, appropriate, text, wide, range, african, languages, ., additionally, conduct, detailed, human, evaluation, delve, deeper, linguistic, capabilities, cheetah, ., introduction, cheetah, far-reaching, benefits, linguistic, diversity, ., leveraging, pretrained, models, adapting, specific, languages, ,, approach, facilitates, development, practical, nlg, applications, african, communities, ., findings, study, contribute, advancing, nlp, research, low-resource, settings, ,, enabling, greater, accessibility, inclusion, african, languages, rapidly, expanding, digital, landscape, ., publicly, release, models, research, ."
Defining and Evaluating Fair Natural Language Generation,"Catherine Yeo, Alyssa Chen",2020-07-28T04:11:10Z,"  Our work focuses on the biases that emerge in the natural language generation
(NLG) task of sentence completion. In this paper, we introduce a framework of
fairness for NLG followed by an evaluation of gender biases in two
state-of-the-art language models. Our analysis provides a theoretical
formulation for biases in NLG and empirical evidence that existing language
generation models embed gender bias.
","['work', 'focuses', 'biases', 'emerge', 'natural', 'language', 'generation', '(', 'nlg', ')', 'task', 'sentence', 'completion', '.', 'paper', ',', 'introduce', 'framework', 'fairness', 'nlg', 'followed', 'evaluation', 'gender', 'biases', 'two', 'state-of-the-art', 'language', 'models', '.', 'analysis', 'provides', 'theoretical', 'formulation', 'biases', 'nlg', 'empirical', 'evidence', 'existing', 'language', 'generation', 'models', 'embed', 'gender', 'bias', '.']","work, focuses, biases, emerge, natural, language, generation, (, nlg, ), task, sentence, completion, ., paper, ,, introduce, framework, fairness, nlg, followed, evaluation, gender, biases, two, state-of-the-art, language, models, ., analysis, provides, theoretical, formulation, biases, nlg, empirical, evidence, existing, language, generation, models, embed, gender, bias, ."
Persian Natural Language Inference: A Meta-learning approach,"Heydar Soudani, Mohammad Hassan Mojab, Hamid Beigy",2022-05-18T06:51:58Z,"  Incorporating information from other languages can improve the results of
tasks in low-resource languages. A powerful method of building functional
natural language processing systems for low-resource languages is to combine
multilingual pre-trained representations with cross-lingual transfer learning.
In general, however, shared representations are learned separately, either
across tasks or across languages. This paper proposes a meta-learning approach
for inferring natural language in Persian. Alternately, meta-learning uses
different task information (such as QA in Persian) or other language
information (such as natural language inference in English). Also, we
investigate the role of task augmentation strategy for forming additional
high-quality tasks. We evaluate the proposed method using four languages and an
auxiliary task. Compared to the baseline approach, the proposed model
consistently outperforms it, improving accuracy by roughly six percent. We also
examine the effect of finding appropriate initial parameters using zero-shot
evaluation and CCA similarity.
","['incorporating', 'information', 'languages', 'improve', 'results', 'tasks', 'low-resource', 'languages', '.', 'powerful', 'method', 'building', 'functional', 'natural', 'language', 'processing', 'systems', 'low-resource', 'languages', 'combine', 'multilingual', 'pre-trained', 'representations', 'cross-lingual', 'transfer', 'learning', '.', 'general', ',', 'however', ',', 'shared', 'representations', 'learned', 'separately', ',', 'either', 'across', 'tasks', 'across', 'languages', '.', 'paper', 'proposes', 'meta-learning', 'approach', 'inferring', 'natural', 'language', 'persian', '.', 'alternately', ',', 'meta-learning', 'uses', 'different', 'task', 'information', '(', 'qa', 'persian', ')', 'language', 'information', '(', 'natural', 'language', 'inference', 'english', ')', '.', 'also', ',', 'investigate', 'role', 'task', 'augmentation', 'strategy', 'forming', 'additional', 'high-quality', 'tasks', '.', 'evaluate', 'proposed', 'method', 'using', 'four', 'languages', 'auxiliary', 'task', '.', 'compared', 'baseline', 'approach', ',', 'proposed', 'model', 'consistently', 'outperforms', ',', 'improving', 'accuracy', 'roughly', 'six', 'percent', '.', 'also', 'examine', 'effect', 'finding', 'appropriate', 'initial', 'parameters', 'using', 'zero-shot', 'evaluation', 'cca', 'similarity', '.']","incorporating, information, languages, improve, results, tasks, low-resource, languages, ., powerful, method, building, functional, natural, language, processing, systems, low-resource, languages, combine, multilingual, pre-trained, representations, cross-lingual, transfer, learning, ., general, ,, however, ,, shared, representations, learned, separately, ,, either, across, tasks, across, languages, ., paper, proposes, meta-learning, approach, inferring, natural, language, persian, ., alternately, ,, meta-learning, uses, different, task, information, (, qa, persian, ), language, information, (, natural, language, inference, english, ), ., also, ,, investigate, role, task, augmentation, strategy, forming, additional, high-quality, tasks, ., evaluate, proposed, method, using, four, languages, auxiliary, task, ., compared, baseline, approach, ,, proposed, model, consistently, outperforms, ,, improving, accuracy, roughly, six, percent, ., also, examine, effect, finding, appropriate, initial, parameters, using, zero-shot, evaluation, cca, similarity, ."
"Understanding scholarly Natural Language Processing system diagrams
  through application of the Richards-Engelhardt framework","Guy Clarke Marshall, Caroline Jay, André Freitas",2020-08-26T20:06:30Z,"  We utilise Richards-Engelhardt framework as a tool for understanding Natural
Language Processing systems diagrams. Through four examples from scholarly
proceedings, we find that the application of the framework to this ecological
and complex domain is effective for reflecting on these diagrams. We argue for
vocabulary to describe multiple-codings, semiotic variability, and
inconsistency or misuse of visual encoding principles in diagrams. Further, for
application to scholarly Natural Language Processing systems, and perhaps
systems diagrams more broadly, we propose the addition of ""Grouping by Object""
as a new visual encoding principle, and ""Emphasising"" as a new visual encoding
type.
","['utilise', 'richards-engelhardt', 'framework', 'tool', 'understanding', 'natural', 'language', 'processing', 'systems', 'diagrams', '.', 'four', 'examples', 'scholarly', 'proceedings', ',', 'find', 'application', 'framework', 'ecological', 'complex', 'domain', 'effective', 'reflecting', 'diagrams', '.', 'argue', 'vocabulary', 'describe', 'multiple-codings', ',', 'semiotic', 'variability', ',', 'inconsistency', 'misuse', 'visual', 'encoding', 'principles', 'diagrams', '.', ',', 'application', 'scholarly', 'natural', 'language', 'processing', 'systems', ',', 'perhaps', 'systems', 'diagrams', 'broadly', ',', 'propose', 'addition', '``', 'grouping', 'object', ""''"", 'new', 'visual', 'encoding', 'principle', ',', '``', 'emphasising', ""''"", 'new', 'visual', 'encoding', 'type', '.']","utilise, richards-engelhardt, framework, tool, understanding, natural, language, processing, systems, diagrams, ., four, examples, scholarly, proceedings, ,, find, application, framework, ecological, complex, domain, effective, reflecting, diagrams, ., argue, vocabulary, describe, multiple-codings, ,, semiotic, variability, ,, inconsistency, misuse, visual, encoding, principles, diagrams, ., ,, application, scholarly, natural, language, processing, systems, ,, perhaps, systems, diagrams, broadly, ,, propose, addition, ``, grouping, object, '', new, visual, encoding, principle, ,, ``, emphasising, '', new, visual, encoding, type, ."
Indian Legal NLP Benchmarks : A Survey,"Prathamesh Kalamkar, Janani Venugopalan Ph. D., Vivek Raghavan Ph. D",2021-07-13T13:10:10Z,"  Availability of challenging benchmarks is the key to advancement of AI in a
specific field.Since Legal Text is significantly different than normal English
text, there is a need to create separate Natural Language Processing benchmarks
for Indian Legal Text which are challenging and focus on tasks specific to
Legal Systems. This will spur innovation in applications of Natural language
Processing for Indian Legal Text and will benefit AI community and Legal
fraternity. We review the existing work in this area and propose ideas to
create new benchmarks for Indian Legal Natural Language Processing.
","['availability', 'challenging', 'benchmarks', 'key', 'advancement', 'ai', 'specific', 'field.since', 'legal', 'text', 'significantly', 'different', 'normal', 'english', 'text', ',', 'need', 'create', 'separate', 'natural', 'language', 'processing', 'benchmarks', 'indian', 'legal', 'text', 'challenging', 'focus', 'tasks', 'specific', 'legal', 'systems', '.', 'spur', 'innovation', 'applications', 'natural', 'language', 'processing', 'indian', 'legal', 'text', 'benefit', 'ai', 'community', 'legal', 'fraternity', '.', 'review', 'existing', 'work', 'area', 'propose', 'ideas', 'create', 'new', 'benchmarks', 'indian', 'legal', 'natural', 'language', 'processing', '.']","availability, challenging, benchmarks, key, advancement, ai, specific, field.since, legal, text, significantly, different, normal, english, text, ,, need, create, separate, natural, language, processing, benchmarks, indian, legal, text, challenging, focus, tasks, specific, legal, systems, ., spur, innovation, applications, natural, language, processing, indian, legal, text, benefit, ai, community, legal, fraternity, ., review, existing, work, area, propose, ideas, create, new, benchmarks, indian, legal, natural, language, processing, ."
Natural Language Processing for Financial Regulation,"Ixandra Achitouv, Dragos Gorduza, Antoine Jacquier",2023-11-14T20:58:21Z,"  This article provides an understanding of Natural Language Processing
techniques in the framework of financial regulation, more specifically in order
to perform semantic matching search between rules and policy when no dataset is
available for supervised learning. We outline how to outperform simple
pre-trained sentences-transformer models using freely available resources and
explain the mathematical concepts behind the key building blocks of Natural
Language Processing.
","['article', 'provides', 'understanding', 'natural', 'language', 'processing', 'techniques', 'framework', 'financial', 'regulation', ',', 'specifically', 'order', 'perform', 'semantic', 'matching', 'search', 'rules', 'policy', 'dataset', 'available', 'supervised', 'learning', '.', 'outline', 'outperform', 'simple', 'pre-trained', 'sentences-transformer', 'models', 'using', 'freely', 'available', 'resources', 'explain', 'mathematical', 'concepts', 'behind', 'key', 'building', 'blocks', 'natural', 'language', 'processing', '.']","article, provides, understanding, natural, language, processing, techniques, framework, financial, regulation, ,, specifically, order, perform, semantic, matching, search, rules, policy, dataset, available, supervised, learning, ., outline, outperform, simple, pre-trained, sentences-transformer, models, using, freely, available, resources, explain, mathematical, concepts, behind, key, building, blocks, natural, language, processing, ."
"Large Language Models on the Chessboard: A Study on ChatGPT's Formal
  Language Comprehension and Complex Reasoning Skills","Mu-Tien Kuo, Chih-Chung Hsueh, Richard Tzong-Han Tsai",2023-08-29T08:36:30Z,"  While large language models have made strides in natural language processing,
their proficiency in complex reasoning tasks requiring formal language
comprehension, such as chess, remains less investigated. This paper probes the
performance of ChatGPT, a sophisticated language model by OpenAI in tackling
such complex reasoning tasks, using chess as a case study. Through robust
metrics examining both the legality and quality of moves, we assess ChatGPT's
understanding of the chessboard, adherence to chess rules, and strategic
decision-making abilities. Our evaluation identifies limitations within
ChatGPT's attention mechanism that affect its formal language comprehension and
uncovers the model's underdeveloped self-regulation abilities. Our study also
reveals ChatGPT's propensity for a coherent strategy in its gameplay and a
noticeable uptick in decision-making assertiveness when the model is presented
with a greater volume of natural language or possesses a more lucid
understanding of the state of the chessboard. These findings contribute to the
growing exploration of language models' abilities beyond natural language
processing, providing valuable information for future research towards models
demonstrating human-like cognitive abilities.
","['large', 'language', 'models', 'made', 'strides', 'natural', 'language', 'processing', ',', 'proficiency', 'complex', 'reasoning', 'tasks', 'requiring', 'formal', 'language', 'comprehension', ',', 'chess', ',', 'remains', 'less', 'investigated', '.', 'paper', 'probes', 'performance', 'chatgpt', ',', 'sophisticated', 'language', 'model', 'openai', 'tackling', 'complex', 'reasoning', 'tasks', ',', 'using', 'chess', 'case', 'study', '.', 'robust', 'metrics', 'examining', 'legality', 'quality', 'moves', ',', 'assess', 'chatgpt', ""'s"", 'understanding', 'chessboard', ',', 'adherence', 'chess', 'rules', ',', 'strategic', 'decision-making', 'abilities', '.', 'evaluation', 'identifies', 'limitations', 'within', 'chatgpt', ""'s"", 'attention', 'mechanism', 'affect', 'formal', 'language', 'comprehension', 'uncovers', 'model', ""'s"", 'underdeveloped', 'self-regulation', 'abilities', '.', 'study', 'also', 'reveals', 'chatgpt', ""'s"", 'propensity', 'coherent', 'strategy', 'gameplay', 'noticeable', 'uptick', 'decision-making', 'assertiveness', 'model', 'presented', 'greater', 'volume', 'natural', 'language', 'possesses', 'lucid', 'understanding', 'state', 'chessboard', '.', 'findings', 'contribute', 'growing', 'exploration', 'language', 'models', ""'"", 'abilities', 'beyond', 'natural', 'language', 'processing', ',', 'providing', 'valuable', 'information', 'future', 'research', 'towards', 'models', 'demonstrating', 'human-like', 'cognitive', 'abilities', '.']","large, language, models, made, strides, natural, language, processing, ,, proficiency, complex, reasoning, tasks, requiring, formal, language, comprehension, ,, chess, ,, remains, less, investigated, ., paper, probes, performance, chatgpt, ,, sophisticated, language, model, openai, tackling, complex, reasoning, tasks, ,, using, chess, case, study, ., robust, metrics, examining, legality, quality, moves, ,, assess, chatgpt, 's, understanding, chessboard, ,, adherence, chess, rules, ,, strategic, decision-making, abilities, ., evaluation, identifies, limitations, within, chatgpt, 's, attention, mechanism, affect, formal, language, comprehension, uncovers, model, 's, underdeveloped, self-regulation, abilities, ., study, also, reveals, chatgpt, 's, propensity, coherent, strategy, gameplay, noticeable, uptick, decision-making, assertiveness, model, presented, greater, volume, natural, language, possesses, lucid, understanding, state, chessboard, ., findings, contribute, growing, exploration, language, models, ', abilities, beyond, natural, language, processing, ,, providing, valuable, information, future, research, towards, models, demonstrating, human-like, cognitive, abilities, ."
"Do Large Language Models Speak All Languages Equally? A Comparative
  Study in Low-Resource Settings","Md. Arid Hasan, Prerona Tarannum, Krishno Dey, Imran Razzak, Usman Naseem",2024-08-05T05:09:23Z,"  Large language models (LLMs) have garnered significant interest in natural
language processing (NLP), particularly their remarkable performance in various
downstream tasks in resource-rich languages. Recent studies have highlighted
the limitations of LLMs in low-resource languages, primarily focusing on binary
classification tasks and giving minimal attention to South Asian languages.
These limitations are primarily attributed to constraints such as dataset
scarcity, computational costs, and research gaps specific to low-resource
languages. To address this gap, we present datasets for sentiment and hate
speech tasks by translating from English to Bangla, Hindi, and Urdu,
facilitating research in low-resource language processing. Further, we
comprehensively examine zero-shot learning using multiple LLMs in English and
widely spoken South Asian languages. Our findings indicate that GPT-4
consistently outperforms Llama 2 and Gemini, with English consistently
demonstrating superior performance across diverse tasks compared to
low-resource languages. Furthermore, our analysis reveals that natural language
inference (NLI) exhibits the highest performance among the evaluated tasks,
with GPT-4 demonstrating superior capabilities.
","['large', 'language', 'models', '(', 'llms', ')', 'garnered', 'significant', 'interest', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'particularly', 'remarkable', 'performance', 'various', 'downstream', 'tasks', 'resource-rich', 'languages', '.', 'recent', 'studies', 'highlighted', 'limitations', 'llms', 'low-resource', 'languages', ',', 'primarily', 'focusing', 'binary', 'classification', 'tasks', 'giving', 'minimal', 'attention', 'south', 'asian', 'languages', '.', 'limitations', 'primarily', 'attributed', 'constraints', 'dataset', 'scarcity', ',', 'computational', 'costs', ',', 'research', 'gaps', 'specific', 'low-resource', 'languages', '.', 'address', 'gap', ',', 'present', 'datasets', 'sentiment', 'hate', 'speech', 'tasks', 'translating', 'english', 'bangla', ',', 'hindi', ',', 'urdu', ',', 'facilitating', 'research', 'low-resource', 'language', 'processing', '.', ',', 'comprehensively', 'examine', 'zero-shot', 'learning', 'using', 'multiple', 'llms', 'english', 'widely', 'spoken', 'south', 'asian', 'languages', '.', 'findings', 'indicate', 'gpt-4', 'consistently', 'outperforms', 'llama', '2', 'gemini', ',', 'english', 'consistently', 'demonstrating', 'superior', 'performance', 'across', 'diverse', 'tasks', 'compared', 'low-resource', 'languages', '.', 'furthermore', ',', 'analysis', 'reveals', 'natural', 'language', 'inference', '(', 'nli', ')', 'exhibits', 'highest', 'performance', 'among', 'evaluated', 'tasks', ',', 'gpt-4', 'demonstrating', 'superior', 'capabilities', '.']","large, language, models, (, llms, ), garnered, significant, interest, natural, language, processing, (, nlp, ), ,, particularly, remarkable, performance, various, downstream, tasks, resource-rich, languages, ., recent, studies, highlighted, limitations, llms, low-resource, languages, ,, primarily, focusing, binary, classification, tasks, giving, minimal, attention, south, asian, languages, ., limitations, primarily, attributed, constraints, dataset, scarcity, ,, computational, costs, ,, research, gaps, specific, low-resource, languages, ., address, gap, ,, present, datasets, sentiment, hate, speech, tasks, translating, english, bangla, ,, hindi, ,, urdu, ,, facilitating, research, low-resource, language, processing, ., ,, comprehensively, examine, zero-shot, learning, using, multiple, llms, english, widely, spoken, south, asian, languages, ., findings, indicate, gpt-4, consistently, outperforms, llama, 2, gemini, ,, english, consistently, demonstrating, superior, performance, across, diverse, tasks, compared, low-resource, languages, ., furthermore, ,, analysis, reveals, natural, language, inference, (, nli, ), exhibits, highest, performance, among, evaluated, tasks, ,, gpt-4, demonstrating, superior, capabilities, ."
Syntax Representation in Word Embeddings and Neural Networks -- A Survey,"Tomasz Limisiewicz, David Mareček",2020-10-02T15:44:58Z,"  Neural networks trained on natural language processing tasks capture syntax
even though it is not provided as a supervision signal. This indicates that
syntactic analysis is essential to the understating of language in artificial
intelligence systems. This overview paper covers approaches of evaluating the
amount of syntactic information included in the representations of words for
different neural network architectures. We mainly summarize re-search on
English monolingual data on language modeling tasks and multilingual data for
neural machine translation systems and multilingual language models. We
describe which pre-trained models and representations of language are best
suited for transfer to syntactic tasks.
","['neural', 'networks', 'trained', 'natural', 'language', 'processing', 'tasks', 'capture', 'syntax', 'even', 'though', 'provided', 'supervision', 'signal', '.', 'indicates', 'syntactic', 'analysis', 'essential', 'understating', 'language', 'artificial', 'intelligence', 'systems', '.', 'overview', 'paper', 'covers', 'approaches', 'evaluating', 'amount', 'syntactic', 'information', 'included', 'representations', 'words', 'different', 'neural', 'network', 'architectures', '.', 'mainly', 'summarize', 're-search', 'english', 'monolingual', 'data', 'language', 'modeling', 'tasks', 'multilingual', 'data', 'neural', 'machine', 'translation', 'systems', 'multilingual', 'language', 'models', '.', 'describe', 'pre-trained', 'models', 'representations', 'language', 'best', 'suited', 'transfer', 'syntactic', 'tasks', '.']","neural, networks, trained, natural, language, processing, tasks, capture, syntax, even, though, provided, supervision, signal, ., indicates, syntactic, analysis, essential, understating, language, artificial, intelligence, systems, ., overview, paper, covers, approaches, evaluating, amount, syntactic, information, included, representations, words, different, neural, network, architectures, ., mainly, summarize, re-search, english, monolingual, data, language, modeling, tasks, multilingual, data, neural, machine, translation, systems, multilingual, language, models, ., describe, pre-trained, models, representations, language, best, suited, transfer, syntactic, tasks, ."
"Exploring Chemical Space using Natural Language Processing Methodologies
  for Drug Discovery","Hakime Öztürk, Arzucan Özgür, Philippe Schwaller, Teodoro Laino, Elif Ozkirimli",2020-02-10T21:02:05Z,"  Text-based representations of chemicals and proteins can be thought of as
unstructured languages codified by humans to describe domain-specific
knowledge. Advances in natural language processing (NLP) methodologies in the
processing of spoken languages accelerated the application of NLP to elucidate
hidden knowledge in textual representations of these biochemical entities and
then use it to construct models to predict molecular properties or to design
novel molecules. This review outlines the impact made by these advances on drug
discovery and aims to further the dialogue between medicinal chemists and
computer scientists.
","['text-based', 'representations', 'chemicals', 'proteins', 'thought', 'unstructured', 'languages', 'codified', 'humans', 'describe', 'domain-specific', 'knowledge', '.', 'advances', 'natural', 'language', 'processing', '(', 'nlp', ')', 'methodologies', 'processing', 'spoken', 'languages', 'accelerated', 'application', 'nlp', 'elucidate', 'hidden', 'knowledge', 'textual', 'representations', 'biochemical', 'entities', 'use', 'construct', 'models', 'predict', 'molecular', 'properties', 'design', 'novel', 'molecules', '.', 'review', 'outlines', 'impact', 'made', 'advances', 'drug', 'discovery', 'aims', 'dialogue', 'medicinal', 'chemists', 'computer', 'scientists', '.']","text-based, representations, chemicals, proteins, thought, unstructured, languages, codified, humans, describe, domain-specific, knowledge, ., advances, natural, language, processing, (, nlp, ), methodologies, processing, spoken, languages, accelerated, application, nlp, elucidate, hidden, knowledge, textual, representations, biochemical, entities, use, construct, models, predict, molecular, properties, design, novel, molecules, ., review, outlines, impact, made, advances, drug, discovery, aims, dialogue, medicinal, chemists, computer, scientists, ."
"Large Language Models are not Models of Natural Language: they are
  Corpus Models",Csaba Veres,2021-12-13T22:39:46Z,"  Natural Language Processing (NLP) has become one of the leading application
areas in the current Artificial Intelligence boom. Transfer learning has
enabled large deep learning neural networks trained on the language modeling
task to vastly improve performance in almost all downstream language tasks.
Interestingly, when the language models are trained with data that includes
software code, they demonstrate remarkable abilities in generating functioning
computer code from natural language specifications. We argue that this creates
a conundrum for the claim that eliminative neural models are a radical
restructuring in our understanding of cognition in that they eliminate the need
for symbolic abstractions like generative phrase structure grammars. Because
the syntax of programming languages is by design determined by phrase structure
grammars, neural models that produce syntactic code are apparently
uninformative about the theoretical foundations of programming languages. The
demonstration that neural models perform well on tasks that involve clearly
symbolic systems, proves that they cannot be used as an argument that language
and other cognitive systems are not symbolic. Finally, we argue as a corollary
that the term language model is misleading and propose the adoption of the
working term corpus model instead, which better reflects the genesis and
contents of the model.
","['natural', 'language', 'processing', '(', 'nlp', ')', 'become', 'one', 'leading', 'application', 'areas', 'current', 'artificial', 'intelligence', 'boom', '.', 'transfer', 'learning', 'enabled', 'large', 'deep', 'learning', 'neural', 'networks', 'trained', 'language', 'modeling', 'task', 'vastly', 'improve', 'performance', 'almost', 'downstream', 'language', 'tasks', '.', 'interestingly', ',', 'language', 'models', 'trained', 'data', 'includes', 'software', 'code', ',', 'demonstrate', 'remarkable', 'abilities', 'generating', 'functioning', 'computer', 'code', 'natural', 'language', 'specifications', '.', 'argue', 'creates', 'conundrum', 'claim', 'eliminative', 'neural', 'models', 'radical', 'restructuring', 'understanding', 'cognition', 'eliminate', 'need', 'symbolic', 'abstractions', 'like', 'generative', 'phrase', 'structure', 'grammars', '.', 'syntax', 'programming', 'languages', 'design', 'determined', 'phrase', 'structure', 'grammars', ',', 'neural', 'models', 'produce', 'syntactic', 'code', 'apparently', 'uninformative', 'theoretical', 'foundations', 'programming', 'languages', '.', 'demonstration', 'neural', 'models', 'perform', 'well', 'tasks', 'involve', 'clearly', 'symbolic', 'systems', ',', 'proves', 'used', 'argument', 'language', 'cognitive', 'systems', 'symbolic', '.', 'finally', ',', 'argue', 'corollary', 'term', 'language', 'model', 'misleading', 'propose', 'adoption', 'working', 'term', 'corpus', 'model', 'instead', ',', 'better', 'reflects', 'genesis', 'contents', 'model', '.']","natural, language, processing, (, nlp, ), become, one, leading, application, areas, current, artificial, intelligence, boom, ., transfer, learning, enabled, large, deep, learning, neural, networks, trained, language, modeling, task, vastly, improve, performance, almost, downstream, language, tasks, ., interestingly, ,, language, models, trained, data, includes, software, code, ,, demonstrate, remarkable, abilities, generating, functioning, computer, code, natural, language, specifications, ., argue, creates, conundrum, claim, eliminative, neural, models, radical, restructuring, understanding, cognition, eliminate, need, symbolic, abstractions, like, generative, phrase, structure, grammars, ., syntax, programming, languages, design, determined, phrase, structure, grammars, ,, neural, models, produce, syntactic, code, apparently, uninformative, theoretical, foundations, programming, languages, ., demonstration, neural, models, perform, well, tasks, involve, clearly, symbolic, systems, ,, proves, used, argument, language, cognitive, systems, symbolic, ., finally, ,, argue, corollary, term, language, model, misleading, propose, adoption, working, term, corpus, model, instead, ,, better, reflects, genesis, contents, model, ."
Comparative Analysis of Word Embeddings for Capturing Word Similarities,"Martina Toshevska, Frosina Stojanovska, Jovan Kalajdjieski",2020-05-08T01:16:03Z,"  Distributed language representation has become the most widely used technique
for language representation in various natural language processing tasks. Most
of the natural language processing models that are based on deep learning
techniques use already pre-trained distributed word representations, commonly
called word embeddings. Determining the most qualitative word embeddings is of
crucial importance for such models. However, selecting the appropriate word
embeddings is a perplexing task since the projected embedding space is not
intuitive to humans. In this paper, we explore different approaches for
creating distributed word representations. We perform an intrinsic evaluation
of several state-of-the-art word embedding methods. Their performance on
capturing word similarities is analysed with existing benchmark datasets for
word pairs similarities. The research in this paper conducts a correlation
analysis between ground truth word similarities and similarities obtained by
different word embedding methods.
","['distributed', 'language', 'representation', 'become', 'widely', 'used', 'technique', 'language', 'representation', 'various', 'natural', 'language', 'processing', 'tasks', '.', 'natural', 'language', 'processing', 'models', 'based', 'deep', 'learning', 'techniques', 'use', 'already', 'pre-trained', 'distributed', 'word', 'representations', ',', 'commonly', 'called', 'word', 'embeddings', '.', 'determining', 'qualitative', 'word', 'embeddings', 'crucial', 'importance', 'models', '.', 'however', ',', 'selecting', 'appropriate', 'word', 'embeddings', 'perplexing', 'task', 'since', 'projected', 'embedding', 'space', 'intuitive', 'humans', '.', 'paper', ',', 'explore', 'different', 'approaches', 'creating', 'distributed', 'word', 'representations', '.', 'perform', 'intrinsic', 'evaluation', 'several', 'state-of-the-art', 'word', 'embedding', 'methods', '.', 'performance', 'capturing', 'word', 'similarities', 'analysed', 'existing', 'benchmark', 'datasets', 'word', 'pairs', 'similarities', '.', 'research', 'paper', 'conducts', 'correlation', 'analysis', 'ground', 'truth', 'word', 'similarities', 'similarities', 'obtained', 'different', 'word', 'embedding', 'methods', '.']","distributed, language, representation, become, widely, used, technique, language, representation, various, natural, language, processing, tasks, ., natural, language, processing, models, based, deep, learning, techniques, use, already, pre-trained, distributed, word, representations, ,, commonly, called, word, embeddings, ., determining, qualitative, word, embeddings, crucial, importance, models, ., however, ,, selecting, appropriate, word, embeddings, perplexing, task, since, projected, embedding, space, intuitive, humans, ., paper, ,, explore, different, approaches, creating, distributed, word, representations, ., perform, intrinsic, evaluation, several, state-of-the-art, word, embedding, methods, ., performance, capturing, word, similarities, analysed, existing, benchmark, datasets, word, pairs, similarities, ., research, paper, conducts, correlation, analysis, ground, truth, word, similarities, similarities, obtained, different, word, embedding, methods, ."
Do learned speech symbols follow Zipf's law?,"Shinnosuke Takamichi, Hiroki Maeda, Joonyong Park, Daisuke Saito, Hiroshi Saruwatari",2023-09-18T11:56:10Z,"  In this study, we investigate whether speech symbols, learned through deep
learning, follow Zipf's law, akin to natural language symbols. Zipf's law is an
empirical law that delineates the frequency distribution of words, forming
fundamentals for statistical analysis in natural language processing. Natural
language symbols, which are invented by humans to symbolize speech content, are
recognized to comply with this law. On the other hand, recent breakthroughs in
spoken language processing have given rise to the development of learned speech
symbols; these are data-driven symbolizations of speech content. Our objective
is to ascertain whether these data-driven speech symbols follow Zipf's law, as
the same as natural language symbols. Through our investigation, we aim to
forge new ways for the statistical analysis of spoken language processing.
","['study', ',', 'investigate', 'whether', 'speech', 'symbols', ',', 'learned', 'deep', 'learning', ',', 'follow', 'zipf', ""'s"", 'law', ',', 'akin', 'natural', 'language', 'symbols', '.', 'zipf', ""'s"", 'law', 'empirical', 'law', 'delineates', 'frequency', 'distribution', 'words', ',', 'forming', 'fundamentals', 'statistical', 'analysis', 'natural', 'language', 'processing', '.', 'natural', 'language', 'symbols', ',', 'invented', 'humans', 'symbolize', 'speech', 'content', ',', 'recognized', 'comply', 'law', '.', 'hand', ',', 'recent', 'breakthroughs', 'spoken', 'language', 'processing', 'given', 'rise', 'development', 'learned', 'speech', 'symbols', ';', 'data-driven', 'symbolizations', 'speech', 'content', '.', 'objective', 'ascertain', 'whether', 'data-driven', 'speech', 'symbols', 'follow', 'zipf', ""'s"", 'law', ',', 'natural', 'language', 'symbols', '.', 'investigation', ',', 'aim', 'forge', 'new', 'ways', 'statistical', 'analysis', 'spoken', 'language', 'processing', '.']","study, ,, investigate, whether, speech, symbols, ,, learned, deep, learning, ,, follow, zipf, 's, law, ,, akin, natural, language, symbols, ., zipf, 's, law, empirical, law, delineates, frequency, distribution, words, ,, forming, fundamentals, statistical, analysis, natural, language, processing, ., natural, language, symbols, ,, invented, humans, symbolize, speech, content, ,, recognized, comply, law, ., hand, ,, recent, breakthroughs, spoken, language, processing, given, rise, development, learned, speech, symbols, ;, data-driven, symbolizations, speech, content, ., objective, ascertain, whether, data-driven, speech, symbols, follow, zipf, 's, law, ,, natural, language, symbols, ., investigation, ,, aim, forge, new, ways, statistical, analysis, spoken, language, processing, ."
Stopwords in Technical Language Processing,"Serhad Sarica, Jianxi Luo",2020-06-04T03:52:59Z,"  There are increasingly applications of natural language processing techniques
for information retrieval, indexing and topic modelling in the engineering
contexts. A standard component of such tasks is the removal of stopwords, which
are uninformative components of the data. While researchers use readily
available stopword lists which are derived for general English language, the
technical jargon of engineering fields contains their own highly frequent and
uninformative words and there exists no standard stopword list for technical
language processing applications. Here we address this gap by rigorously
identifying generic, insignificant, uninformative stopwords in engineering
texts beyond the stopwords in general texts, based on the synthesis of
alternative data-driven approaches, and curating a stopword list ready for
technical language processing applications.
","['increasingly', 'applications', 'natural', 'language', 'processing', 'techniques', 'information', 'retrieval', ',', 'indexing', 'topic', 'modelling', 'engineering', 'contexts', '.', 'standard', 'component', 'tasks', 'removal', 'stopwords', ',', 'uninformative', 'components', 'data', '.', 'researchers', 'use', 'readily', 'available', 'stopword', 'lists', 'derived', 'general', 'english', 'language', ',', 'technical', 'jargon', 'engineering', 'fields', 'contains', 'highly', 'frequent', 'uninformative', 'words', 'exists', 'standard', 'stopword', 'list', 'technical', 'language', 'processing', 'applications', '.', 'address', 'gap', 'rigorously', 'identifying', 'generic', ',', 'insignificant', ',', 'uninformative', 'stopwords', 'engineering', 'texts', 'beyond', 'stopwords', 'general', 'texts', ',', 'based', 'synthesis', 'alternative', 'data-driven', 'approaches', ',', 'curating', 'stopword', 'list', 'ready', 'technical', 'language', 'processing', 'applications', '.']","increasingly, applications, natural, language, processing, techniques, information, retrieval, ,, indexing, topic, modelling, engineering, contexts, ., standard, component, tasks, removal, stopwords, ,, uninformative, components, data, ., researchers, use, readily, available, stopword, lists, derived, general, english, language, ,, technical, jargon, engineering, fields, contains, highly, frequent, uninformative, words, exists, standard, stopword, list, technical, language, processing, applications, ., address, gap, rigorously, identifying, generic, ,, insignificant, ,, uninformative, stopwords, engineering, texts, beyond, stopwords, general, texts, ,, based, synthesis, alternative, data-driven, approaches, ,, curating, stopword, list, ready, technical, language, processing, applications, ."
Development of Word Embeddings for Uzbek Language,"B. Mansurov, A. Mansurov",2020-09-30T01:52:00Z,"  In this paper, we share the process of developing word embeddings for the
Cyrillic variant of the Uzbek language. The result of our work is the first
publicly available set of word vectors trained on the word2vec, GloVe, and
fastText algorithms using a high-quality web crawl corpus developed in-house.
The developed word embeddings can be used in many natural language processing
downstream tasks.
","['paper', ',', 'share', 'process', 'developing', 'word', 'embeddings', 'cyrillic', 'variant', 'uzbek', 'language', '.', 'result', 'work', 'first', 'publicly', 'available', 'set', 'word', 'vectors', 'trained', 'word2vec', ',', 'glove', ',', 'fasttext', 'algorithms', 'using', 'high-quality', 'web', 'crawl', 'corpus', 'developed', 'in-house', '.', 'developed', 'word', 'embeddings', 'used', 'many', 'natural', 'language', 'processing', 'downstream', 'tasks', '.']","paper, ,, share, process, developing, word, embeddings, cyrillic, variant, uzbek, language, ., result, work, first, publicly, available, set, word, vectors, trained, word2vec, ,, glove, ,, fasttext, algorithms, using, high-quality, web, crawl, corpus, developed, in-house, ., developed, word, embeddings, used, many, natural, language, processing, downstream, tasks, ."
Investigating Masking-based Data Generation in Language Models,Ed S. Ma,2023-06-16T16:48:27Z,"  The current era of natural language processing (NLP) has been defined by the
prominence of pre-trained language models since the advent of BERT. A feature
of BERT and models with similar architecture is the objective of masked
language modeling, in which part of the input is intentionally masked and the
model is trained to predict this piece of masked information. Data augmentation
is a data-driven technique widely used in machine learning, including research
areas like computer vision and natural language processing, to improve model
performance by artificially augmenting the training data set by designated
techniques. Masked language models (MLM), an essential training feature of
BERT, have introduced a novel approach to perform effective pre-training on
Transformer based models in natural language processing tasks. Recent studies
have utilized masked language model to generate artificially augmented data for
NLP downstream tasks. The experimental results show that Mask based data
augmentation method provides a simple but efficient approach to improve the
model performance. In this paper, we explore and discuss the broader
utilization of these data augmentation methods based on MLM.
","['current', 'era', 'natural', 'language', 'processing', '(', 'nlp', ')', 'defined', 'prominence', 'pre-trained', 'language', 'models', 'since', 'advent', 'bert', '.', 'feature', 'bert', 'models', 'similar', 'architecture', 'objective', 'masked', 'language', 'modeling', ',', 'part', 'input', 'intentionally', 'masked', 'model', 'trained', 'predict', 'piece', 'masked', 'information', '.', 'data', 'augmentation', 'data-driven', 'technique', 'widely', 'used', 'machine', 'learning', ',', 'including', 'research', 'areas', 'like', 'computer', 'vision', 'natural', 'language', 'processing', ',', 'improve', 'model', 'performance', 'artificially', 'augmenting', 'training', 'data', 'set', 'designated', 'techniques', '.', 'masked', 'language', 'models', '(', 'mlm', ')', ',', 'essential', 'training', 'feature', 'bert', ',', 'introduced', 'novel', 'approach', 'perform', 'effective', 'pre-training', 'transformer', 'based', 'models', 'natural', 'language', 'processing', 'tasks', '.', 'recent', 'studies', 'utilized', 'masked', 'language', 'model', 'generate', 'artificially', 'augmented', 'data', 'nlp', 'downstream', 'tasks', '.', 'experimental', 'results', 'show', 'mask', 'based', 'data', 'augmentation', 'method', 'provides', 'simple', 'efficient', 'approach', 'improve', 'model', 'performance', '.', 'paper', ',', 'explore', 'discuss', 'broader', 'utilization', 'data', 'augmentation', 'methods', 'based', 'mlm', '.']","current, era, natural, language, processing, (, nlp, ), defined, prominence, pre-trained, language, models, since, advent, bert, ., feature, bert, models, similar, architecture, objective, masked, language, modeling, ,, part, input, intentionally, masked, model, trained, predict, piece, masked, information, ., data, augmentation, data-driven, technique, widely, used, machine, learning, ,, including, research, areas, like, computer, vision, natural, language, processing, ,, improve, model, performance, artificially, augmenting, training, data, set, designated, techniques, ., masked, language, models, (, mlm, ), ,, essential, training, feature, bert, ,, introduced, novel, approach, perform, effective, pre-training, transformer, based, models, natural, language, processing, tasks, ., recent, studies, utilized, masked, language, model, generate, artificially, augmented, data, nlp, downstream, tasks, ., experimental, results, show, mask, based, data, augmentation, method, provides, simple, efficient, approach, improve, model, performance, ., paper, ,, explore, discuss, broader, utilization, data, augmentation, methods, based, mlm, ."
Enabling Quantum Natural Language Processing for Hindi Language,"Naman Srivastava, Gaurang Belekar, Sunil Saumya, Aswath Babu H",2023-12-02T20:19:11Z,"  Quantum Natural Language Processing (QNLP) is taking huge leaps in solving
the shortcomings of classical Natural Language Processing (NLP) techniques and
moving towards a more ""Explainable"" NLP system. The current literature around
QNLP focuses primarily on implementing QNLP techniques in sentences in the
English language. In this paper, we propose to enable the QNLP approach to
HINDI, which is the third most spoken language in South Asia. We present the
process of building the parameterized quantum circuits required to undertake
QNLP on Hindi sentences. We use the pregroup representation of Hindi and the
DisCoCat framework to draw sentence diagrams. Later, we translate these
diagrams to Parameterised Quantum Circuits based on Instantaneous Quantum
Polynomial (IQP) style ansatz. Using these parameterized quantum circuits
allows one to train grammar and topic-aware sentence classifiers for the Hindi
Language.
","['quantum', 'natural', 'language', 'processing', '(', 'qnlp', ')', 'taking', 'huge', 'leaps', 'solving', 'shortcomings', 'classical', 'natural', 'language', 'processing', '(', 'nlp', ')', 'techniques', 'moving', 'towards', '``', 'explainable', ""''"", 'nlp', 'system', '.', 'current', 'literature', 'around', 'qnlp', 'focuses', 'primarily', 'implementing', 'qnlp', 'techniques', 'sentences', 'english', 'language', '.', 'paper', ',', 'propose', 'enable', 'qnlp', 'approach', 'hindi', ',', 'third', 'spoken', 'language', 'south', 'asia', '.', 'present', 'process', 'building', 'parameterized', 'quantum', 'circuits', 'required', 'undertake', 'qnlp', 'hindi', 'sentences', '.', 'use', 'pregroup', 'representation', 'hindi', 'discocat', 'framework', 'draw', 'sentence', 'diagrams', '.', 'later', ',', 'translate', 'diagrams', 'parameterised', 'quantum', 'circuits', 'based', 'instantaneous', 'quantum', 'polynomial', '(', 'iqp', ')', 'style', 'ansatz', '.', 'using', 'parameterized', 'quantum', 'circuits', 'allows', 'one', 'train', 'grammar', 'topic-aware', 'sentence', 'classifiers', 'hindi', 'language', '.']","quantum, natural, language, processing, (, qnlp, ), taking, huge, leaps, solving, shortcomings, classical, natural, language, processing, (, nlp, ), techniques, moving, towards, ``, explainable, '', nlp, system, ., current, literature, around, qnlp, focuses, primarily, implementing, qnlp, techniques, sentences, english, language, ., paper, ,, propose, enable, qnlp, approach, hindi, ,, third, spoken, language, south, asia, ., present, process, building, parameterized, quantum, circuits, required, undertake, qnlp, hindi, sentences, ., use, pregroup, representation, hindi, discocat, framework, draw, sentence, diagrams, ., later, ,, translate, diagrams, parameterised, quantum, circuits, based, instantaneous, quantum, polynomial, (, iqp, ), style, ansatz, ., using, parameterized, quantum, circuits, allows, one, train, grammar, topic-aware, sentence, classifiers, hindi, language, ."
"LINDA: Unsupervised Learning to Interpolate in Natural Language
  Processing","Yekyung Kim, Seohyeong Jeong, Kyunghyun Cho",2021-12-28T02:56:41Z,"  Despite the success of mixup in data augmentation, its applicability to
natural language processing (NLP) tasks has been limited due to the discrete
and variable-length nature of natural languages. Recent studies have thus
relied on domain-specific heuristics and manually crafted resources, such as
dictionaries, in order to apply mixup in NLP. In this paper, we instead propose
an unsupervised learning approach to text interpolation for the purpose of data
augmentation, to which we refer as ""Learning to INterpolate for Data
Augmentation"" (LINDA), that does not require any heuristics nor manually
crafted resources but learns to interpolate between any pair of natural
language sentences over a natural language manifold. After empirically
demonstrating the LINDA's interpolation capability, we show that LINDA indeed
allows us to seamlessly apply mixup in NLP and leads to better generalization
in text classification both in-domain and out-of-domain.
","['despite', 'success', 'mixup', 'data', 'augmentation', ',', 'applicability', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', 'limited', 'due', 'discrete', 'variable-length', 'nature', 'natural', 'languages', '.', 'recent', 'studies', 'thus', 'relied', 'domain-specific', 'heuristics', 'manually', 'crafted', 'resources', ',', 'dictionaries', ',', 'order', 'apply', 'mixup', 'nlp', '.', 'paper', ',', 'instead', 'propose', 'unsupervised', 'learning', 'approach', 'text', 'interpolation', 'purpose', 'data', 'augmentation', ',', 'refer', '``', 'learning', 'interpolate', 'data', 'augmentation', ""''"", '(', 'linda', ')', ',', 'require', 'heuristics', 'manually', 'crafted', 'resources', 'learns', 'interpolate', 'pair', 'natural', 'language', 'sentences', 'natural', 'language', 'manifold', '.', 'empirically', 'demonstrating', 'linda', ""'s"", 'interpolation', 'capability', ',', 'show', 'linda', 'indeed', 'allows', 'us', 'seamlessly', 'apply', 'mixup', 'nlp', 'leads', 'better', 'generalization', 'text', 'classification', 'in-domain', 'out-of-domain', '.']","despite, success, mixup, data, augmentation, ,, applicability, natural, language, processing, (, nlp, ), tasks, limited, due, discrete, variable-length, nature, natural, languages, ., recent, studies, thus, relied, domain-specific, heuristics, manually, crafted, resources, ,, dictionaries, ,, order, apply, mixup, nlp, ., paper, ,, instead, propose, unsupervised, learning, approach, text, interpolation, purpose, data, augmentation, ,, refer, ``, learning, interpolate, data, augmentation, '', (, linda, ), ,, require, heuristics, manually, crafted, resources, learns, interpolate, pair, natural, language, sentences, natural, language, manifold, ., empirically, demonstrating, linda, 's, interpolation, capability, ,, show, linda, indeed, allows, us, seamlessly, apply, mixup, nlp, leads, better, generalization, text, classification, in-domain, out-of-domain, ."
NLP-based Relation Extraction Methods in Requirements Engineering,"Quim Motger, Xavier Franch",2024-01-22T16:14:27Z,"  In the context of requirements engineering, relation extraction is the task
of documenting the traceability between requirements artefacts. When dealing
with textual requirements (i.e., requirements expressed using natural
language), relation extraction becomes a cognitively challenging task,
especially in terms of ambiguity and required effort from domain-experts.
Hence, in highly-adaptive, large-scale environments, effective and efficient
automated relation extraction using natural language processing techniques
becomes essential. In this chapter, we present a comprehensive overview of
natural language-based relation extraction from text-based requirements. We
initially describe the fundamentals of requirements relations based on the most
relevant literature in the field, including the most common requirements
relations types. The core of the chapter is composed by two main sections: (i)
natural language techniques for the identification and categorization of
requirements relations (i.e., syntactic vs. semantic techniques), and (ii)
information extraction methods for the task of relation extraction (i.e.,
retrieval-based vs. machine learning-based methods). We complement this
analysis with the state-of-the-art challenges and the envisioned future
research directions. Overall, this chapter aims at providing a clear
perspective on the theoretical and practical fundamentals in the field of
natural language-based relation extraction.
","['context', 'requirements', 'engineering', ',', 'relation', 'extraction', 'task', 'documenting', 'traceability', 'requirements', 'artefacts', '.', 'dealing', 'textual', 'requirements', '(', 'i.e.', ',', 'requirements', 'expressed', 'using', 'natural', 'language', ')', ',', 'relation', 'extraction', 'becomes', 'cognitively', 'challenging', 'task', ',', 'especially', 'terms', 'ambiguity', 'required', 'effort', 'domain-experts', '.', 'hence', ',', 'highly-adaptive', ',', 'large-scale', 'environments', ',', 'effective', 'efficient', 'automated', 'relation', 'extraction', 'using', 'natural', 'language', 'processing', 'techniques', 'becomes', 'essential', '.', 'chapter', ',', 'present', 'comprehensive', 'overview', 'natural', 'language-based', 'relation', 'extraction', 'text-based', 'requirements', '.', 'initially', 'describe', 'fundamentals', 'requirements', 'relations', 'based', 'relevant', 'literature', 'field', ',', 'including', 'common', 'requirements', 'relations', 'types', '.', 'core', 'chapter', 'composed', 'two', 'main', 'sections', ':', '(', ')', 'natural', 'language', 'techniques', 'identification', 'categorization', 'requirements', 'relations', '(', 'i.e.', ',', 'syntactic', 'vs.', 'semantic', 'techniques', ')', ',', '(', 'ii', ')', 'information', 'extraction', 'methods', 'task', 'relation', 'extraction', '(', 'i.e.', ',', 'retrieval-based', 'vs.', 'machine', 'learning-based', 'methods', ')', '.', 'complement', 'analysis', 'state-of-the-art', 'challenges', 'envisioned', 'future', 'research', 'directions', '.', 'overall', ',', 'chapter', 'aims', 'providing', 'clear', 'perspective', 'theoretical', 'practical', 'fundamentals', 'field', 'natural', 'language-based', 'relation', 'extraction', '.']","context, requirements, engineering, ,, relation, extraction, task, documenting, traceability, requirements, artefacts, ., dealing, textual, requirements, (, i.e., ,, requirements, expressed, using, natural, language, ), ,, relation, extraction, becomes, cognitively, challenging, task, ,, especially, terms, ambiguity, required, effort, domain-experts, ., hence, ,, highly-adaptive, ,, large-scale, environments, ,, effective, efficient, automated, relation, extraction, using, natural, language, processing, techniques, becomes, essential, ., chapter, ,, present, comprehensive, overview, natural, language-based, relation, extraction, text-based, requirements, ., initially, describe, fundamentals, requirements, relations, based, relevant, literature, field, ,, including, common, requirements, relations, types, ., core, chapter, composed, two, main, sections, :, (, ), natural, language, techniques, identification, categorization, requirements, relations, (, i.e., ,, syntactic, vs., semantic, techniques, ), ,, (, ii, ), information, extraction, methods, task, relation, extraction, (, i.e., ,, retrieval-based, vs., machine, learning-based, methods, ), ., complement, analysis, state-of-the-art, challenges, envisioned, future, research, directions, ., overall, ,, chapter, aims, providing, clear, perspective, theoretical, practical, fundamentals, field, natural, language-based, relation, extraction, ."
"New Approaches for Natural Language Understanding based on the Idea that
  Natural Language encodes both Information and its Processing Procedures",Limin Zhang,2020-10-24T05:40:47Z,"  We must recognize that natural language is a way of information encoding, and
it encodes not only the information but also the procedures for how information
is processed. To understand natural language, the same as we conceive and
design computer languages, the first step is to separate information (or data)
and the processing procedures of information (or data). In natural language,
some processing procedures of data are encoded directly as the structure chunk
and the pointer chunk (this paper has reclassified lexical chunks as the data
chunk, structure chunk, and the pointer chunk); some processing procedures of
data imply in sentences structures; some requests of processing procedures are
expressed by information senders and processed by information receivers. For
the data parts, the classification encoding system of attribute information and
the information organization architecture (including constitutional structures
of information sets and the hierarchy between the information sets) were
discussed. In section 2, the theoretical part elaborated in section 2 has been
verified in examples and proofed that the studies in this paper have achieved
the goal of enabling machines to understand the information conveyed in the
dialogue. In section 4, the author summarizes the basic conditions of
""Understanding"", rethinks what ""Understanding"" is and how to proceed. The study
in this paper provides a practical, theoretical basis and research methods for
NLU. It also can be applied in large-scale and multi-type information
processing in the artificial intelligence (AI) area.
","['must', 'recognize', 'natural', 'language', 'way', 'information', 'encoding', ',', 'encodes', 'information', 'also', 'procedures', 'information', 'processed', '.', 'understand', 'natural', 'language', ',', 'conceive', 'design', 'computer', 'languages', ',', 'first', 'step', 'separate', 'information', '(', 'data', ')', 'processing', 'procedures', 'information', '(', 'data', ')', '.', 'natural', 'language', ',', 'processing', 'procedures', 'data', 'encoded', 'directly', 'structure', 'chunk', 'pointer', 'chunk', '(', 'paper', 'reclassified', 'lexical', 'chunks', 'data', 'chunk', ',', 'structure', 'chunk', ',', 'pointer', 'chunk', ')', ';', 'processing', 'procedures', 'data', 'imply', 'sentences', 'structures', ';', 'requests', 'processing', 'procedures', 'expressed', 'information', 'senders', 'processed', 'information', 'receivers', '.', 'data', 'parts', ',', 'classification', 'encoding', 'system', 'attribute', 'information', 'information', 'organization', 'architecture', '(', 'including', 'constitutional', 'structures', 'information', 'sets', 'hierarchy', 'information', 'sets', ')', 'discussed', '.', 'section', '2', ',', 'theoretical', 'part', 'elaborated', 'section', '2', 'verified', 'examples', 'proofed', 'studies', 'paper', 'achieved', 'goal', 'enabling', 'machines', 'understand', 'information', 'conveyed', 'dialogue', '.', 'section', '4', ',', 'author', 'summarizes', 'basic', 'conditions', ""''"", 'understanding', ""''"", ',', 'rethinks', '``', 'understanding', ""''"", 'proceed', '.', 'study', 'paper', 'provides', 'practical', ',', 'theoretical', 'basis', 'research', 'methods', 'nlu', '.', 'also', 'applied', 'large-scale', 'multi-type', 'information', 'processing', 'artificial', 'intelligence', '(', 'ai', ')', 'area', '.']","must, recognize, natural, language, way, information, encoding, ,, encodes, information, also, procedures, information, processed, ., understand, natural, language, ,, conceive, design, computer, languages, ,, first, step, separate, information, (, data, ), processing, procedures, information, (, data, ), ., natural, language, ,, processing, procedures, data, encoded, directly, structure, chunk, pointer, chunk, (, paper, reclassified, lexical, chunks, data, chunk, ,, structure, chunk, ,, pointer, chunk, ), ;, processing, procedures, data, imply, sentences, structures, ;, requests, processing, procedures, expressed, information, senders, processed, information, receivers, ., data, parts, ,, classification, encoding, system, attribute, information, information, organization, architecture, (, including, constitutional, structures, information, sets, hierarchy, information, sets, ), discussed, ., section, 2, ,, theoretical, part, elaborated, section, 2, verified, examples, proofed, studies, paper, achieved, goal, enabling, machines, understand, information, conveyed, dialogue, ., section, 4, ,, author, summarizes, basic, conditions, '', understanding, '', ,, rethinks, ``, understanding, '', proceed, ., study, paper, provides, practical, ,, theoretical, basis, research, methods, nlu, ., also, applied, large-scale, multi-type, information, processing, artificial, intelligence, (, ai, ), area, ."
"Comprehensive Implementation of TextCNN for Enhanced Collaboration
  between Natural Language Processing and System Recommendation","Xiaonan Xu, Zheng Xu, Zhipeng Ling, Zhengyu Jin, ShuQian Du",2024-03-12T07:25:53Z,"  Natural Language Processing (NLP) is an important branch of artificial
intelligence that studies how to enable computers to understand, process, and
generate human language. Text classification is a fundamental task in NLP,
which aims to classify text into different predefined categories. Text
classification is the most basic and classic task in natural language
processing, and most of the tasks in natural language processing can be
regarded as classification tasks. In recent years, deep learning has achieved
great success in many research fields, and today, it has also become a standard
technology in the field of NLP, which is widely integrated into text
classification tasks. Unlike numbers and images, text processing emphasizes
fine-grained processing ability. Traditional text classification methods
generally require preprocessing the input model's text data. Additionally, they
also need to obtain good sample features through manual annotation and then use
classical machine learning algorithms for classification. Therefore, this paper
analyzes the application status of deep learning in the three core tasks of NLP
(including text representation, word order modeling, and knowledge
representation). This content explores the improvement and synergy achieved
through natural language processing in the context of text classification,
while also taking into account the challenges posed by adversarial techniques
in text generation, text classification, and semantic parsing. An empirical
study on text classification tasks demonstrates the effectiveness of
interactive integration training, particularly in conjunction with TextCNN,
highlighting the significance of these advancements in text classification
augmentation and enhancement.
","['natural', 'language', 'processing', '(', 'nlp', ')', 'important', 'branch', 'artificial', 'intelligence', 'studies', 'enable', 'computers', 'understand', ',', 'process', ',', 'generate', 'human', 'language', '.', 'text', 'classification', 'fundamental', 'task', 'nlp', ',', 'aims', 'classify', 'text', 'different', 'predefined', 'categories', '.', 'text', 'classification', 'basic', 'classic', 'task', 'natural', 'language', 'processing', ',', 'tasks', 'natural', 'language', 'processing', 'regarded', 'classification', 'tasks', '.', 'recent', 'years', ',', 'deep', 'learning', 'achieved', 'great', 'success', 'many', 'research', 'fields', ',', 'today', ',', 'also', 'become', 'standard', 'technology', 'field', 'nlp', ',', 'widely', 'integrated', 'text', 'classification', 'tasks', '.', 'unlike', 'numbers', 'images', ',', 'text', 'processing', 'emphasizes', 'fine-grained', 'processing', 'ability', '.', 'traditional', 'text', 'classification', 'methods', 'generally', 'require', 'preprocessing', 'input', 'model', ""'s"", 'text', 'data', '.', 'additionally', ',', 'also', 'need', 'obtain', 'good', 'sample', 'features', 'manual', 'annotation', 'use', 'classical', 'machine', 'learning', 'algorithms', 'classification', '.', 'therefore', ',', 'paper', 'analyzes', 'application', 'status', 'deep', 'learning', 'three', 'core', 'tasks', 'nlp', '(', 'including', 'text', 'representation', ',', 'word', 'order', 'modeling', ',', 'knowledge', 'representation', ')', '.', 'content', 'explores', 'improvement', 'synergy', 'achieved', 'natural', 'language', 'processing', 'context', 'text', 'classification', ',', 'also', 'taking', 'account', 'challenges', 'posed', 'adversarial', 'techniques', 'text', 'generation', ',', 'text', 'classification', ',', 'semantic', 'parsing', '.', 'empirical', 'study', 'text', 'classification', 'tasks', 'demonstrates', 'effectiveness', 'interactive', 'integration', 'training', ',', 'particularly', 'conjunction', 'textcnn', ',', 'highlighting', 'significance', 'advancements', 'text', 'classification', 'augmentation', 'enhancement', '.']","natural, language, processing, (, nlp, ), important, branch, artificial, intelligence, studies, enable, computers, understand, ,, process, ,, generate, human, language, ., text, classification, fundamental, task, nlp, ,, aims, classify, text, different, predefined, categories, ., text, classification, basic, classic, task, natural, language, processing, ,, tasks, natural, language, processing, regarded, classification, tasks, ., recent, years, ,, deep, learning, achieved, great, success, many, research, fields, ,, today, ,, also, become, standard, technology, field, nlp, ,, widely, integrated, text, classification, tasks, ., unlike, numbers, images, ,, text, processing, emphasizes, fine-grained, processing, ability, ., traditional, text, classification, methods, generally, require, preprocessing, input, model, 's, text, data, ., additionally, ,, also, need, obtain, good, sample, features, manual, annotation, use, classical, machine, learning, algorithms, classification, ., therefore, ,, paper, analyzes, application, status, deep, learning, three, core, tasks, nlp, (, including, text, representation, ,, word, order, modeling, ,, knowledge, representation, ), ., content, explores, improvement, synergy, achieved, natural, language, processing, context, text, classification, ,, also, taking, account, challenges, posed, adversarial, techniques, text, generation, ,, text, classification, ,, semantic, parsing, ., empirical, study, text, classification, tasks, demonstrates, effectiveness, interactive, integration, training, ,, particularly, conjunction, textcnn, ,, highlighting, significance, advancements, text, classification, augmentation, enhancement, ."
"Safe Multi-agent Reinforcement Learning with Natural Language
  Constraints","Ziyan Wang, Meng Fang, Tristan Tomilin, Fei Fang, Yali Du",2024-05-30T12:57:35Z,"  The role of natural language constraints in Safe Multi-agent Reinforcement
Learning (MARL) is crucial, yet often overlooked. While Safe MARL has vast
potential, especially in fields like robotics and autonomous vehicles, its full
potential is limited by the need to define constraints in pre-designed
mathematical terms, which requires extensive domain expertise and reinforcement
learning knowledge, hindering its broader adoption. To address this limitation
and make Safe MARL more accessible and adaptable, we propose a novel approach
named Safe Multi-agent Reinforcement Learning with Natural Language constraints
(SMALL). Our method leverages fine-tuned language models to interpret and
process free-form textual constraints, converting them into semantic embeddings
that capture the essence of prohibited states and behaviours. These embeddings
are then integrated into the multi-agent policy learning process, enabling
agents to learn policies that minimize constraint violations while optimizing
rewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a
multi-task benchmark designed to assess the performance of multiple agents in
adhering to natural language constraints. Empirical evaluations across various
environments demonstrate that SMALL achieves comparable rewards and
significantly fewer constraint violations, highlighting its effectiveness in
understanding and enforcing natural language constraints.
","['role', 'natural', 'language', 'constraints', 'safe', 'multi-agent', 'reinforcement', 'learning', '(', 'marl', ')', 'crucial', ',', 'yet', 'often', 'overlooked', '.', 'safe', 'marl', 'vast', 'potential', ',', 'especially', 'fields', 'like', 'robotics', 'autonomous', 'vehicles', ',', 'full', 'potential', 'limited', 'need', 'define', 'constraints', 'pre-designed', 'mathematical', 'terms', ',', 'requires', 'extensive', 'domain', 'expertise', 'reinforcement', 'learning', 'knowledge', ',', 'hindering', 'broader', 'adoption', '.', 'address', 'limitation', 'make', 'safe', 'marl', 'accessible', 'adaptable', ',', 'propose', 'novel', 'approach', 'named', 'safe', 'multi-agent', 'reinforcement', 'learning', 'natural', 'language', 'constraints', '(', 'small', ')', '.', 'method', 'leverages', 'fine-tuned', 'language', 'models', 'interpret', 'process', 'free-form', 'textual', 'constraints', ',', 'converting', 'semantic', 'embeddings', 'capture', 'essence', 'prohibited', 'states', 'behaviours', '.', 'embeddings', 'integrated', 'multi-agent', 'policy', 'learning', 'process', ',', 'enabling', 'agents', 'learn', 'policies', 'minimize', 'constraint', 'violations', 'optimizing', 'rewards', '.', 'evaluate', 'effectiveness', 'small', ',', 'introduce', 'lamasafe', ',', 'multi-task', 'benchmark', 'designed', 'assess', 'performance', 'multiple', 'agents', 'adhering', 'natural', 'language', 'constraints', '.', 'empirical', 'evaluations', 'across', 'various', 'environments', 'demonstrate', 'small', 'achieves', 'comparable', 'rewards', 'significantly', 'fewer', 'constraint', 'violations', ',', 'highlighting', 'effectiveness', 'understanding', 'enforcing', 'natural', 'language', 'constraints', '.']","role, natural, language, constraints, safe, multi-agent, reinforcement, learning, (, marl, ), crucial, ,, yet, often, overlooked, ., safe, marl, vast, potential, ,, especially, fields, like, robotics, autonomous, vehicles, ,, full, potential, limited, need, define, constraints, pre-designed, mathematical, terms, ,, requires, extensive, domain, expertise, reinforcement, learning, knowledge, ,, hindering, broader, adoption, ., address, limitation, make, safe, marl, accessible, adaptable, ,, propose, novel, approach, named, safe, multi-agent, reinforcement, learning, natural, language, constraints, (, small, ), ., method, leverages, fine-tuned, language, models, interpret, process, free-form, textual, constraints, ,, converting, semantic, embeddings, capture, essence, prohibited, states, behaviours, ., embeddings, integrated, multi-agent, policy, learning, process, ,, enabling, agents, learn, policies, minimize, constraint, violations, optimizing, rewards, ., evaluate, effectiveness, small, ,, introduce, lamasafe, ,, multi-task, benchmark, designed, assess, performance, multiple, agents, adhering, natural, language, constraints, ., empirical, evaluations, across, various, environments, demonstrate, small, achieves, comparable, rewards, significantly, fewer, constraint, violations, ,, highlighting, effectiveness, understanding, enforcing, natural, language, constraints, ."
Reasoning about Procedures with Natural Language Processing: A Tutorial,Li Zhang,2022-05-16T05:42:00Z,"  This tutorial provides a comprehensive and in-depth view of the research on
procedures, primarily in Natural Language Processing. A procedure is a sequence
of steps intended to achieve some goal. Understanding procedures in natural
language has a long history, with recent breakthroughs made possible by
advances in technology. First, we discuss established approaches to collect
procedures, by human annotation or extraction from web resources. Then, we
examine different angles from which procedures can be reasoned about, as well
as ways to represent them. Finally, we enumerate scenarios where procedural
knowledge can be applied to the real world.
","['tutorial', 'provides', 'comprehensive', 'in-depth', 'view', 'research', 'procedures', ',', 'primarily', 'natural', 'language', 'processing', '.', 'procedure', 'sequence', 'steps', 'intended', 'achieve', 'goal', '.', 'understanding', 'procedures', 'natural', 'language', 'long', 'history', ',', 'recent', 'breakthroughs', 'made', 'possible', 'advances', 'technology', '.', 'first', ',', 'discuss', 'established', 'approaches', 'collect', 'procedures', ',', 'human', 'annotation', 'extraction', 'web', 'resources', '.', ',', 'examine', 'different', 'angles', 'procedures', 'reasoned', ',', 'well', 'ways', 'represent', '.', 'finally', ',', 'enumerate', 'scenarios', 'procedural', 'knowledge', 'applied', 'real', 'world', '.']","tutorial, provides, comprehensive, in-depth, view, research, procedures, ,, primarily, natural, language, processing, ., procedure, sequence, steps, intended, achieve, goal, ., understanding, procedures, natural, language, long, history, ,, recent, breakthroughs, made, possible, advances, technology, ., first, ,, discuss, established, approaches, collect, procedures, ,, human, annotation, extraction, web, resources, ., ,, examine, different, angles, procedures, reasoned, ,, well, ways, represent, ., finally, ,, enumerate, scenarios, procedural, knowledge, applied, real, world, ."
"XNLI 2.0: Improving XNLI dataset and performance on Cross Lingual
  Understanding (XLU)","Ankit Kumar Upadhyay, Harsit Kumar Upadhya",2023-01-16T17:24:57Z,"  Natural Language Processing systems are heavily dependent on the availability
of annotated data to train practical models. Primarily, models are trained on
English datasets. In recent times, significant advances have been made in
multilingual understanding due to the steeply increasing necessity of working
in different languages. One of the points that stands out is that since there
are now so many pre-trained multilingual models, we can utilize them for
cross-lingual understanding tasks. Using cross-lingual understanding and
Natural Language Inference, it is possible to train models whose applications
extend beyond the training language. We can leverage the power of machine
translation to skip the tiresome part of translating datasets from one language
to another. In this work, we focus on improving the original XNLI dataset by
re-translating the MNLI dataset in all of the 14 different languages present in
XNLI, including the test and dev sets of XNLI using Google Translate. We also
perform experiments by training models in all 15 languages and analyzing their
performance on the task of natural language inference. We then expand our
boundary to investigate if we could improve performance in low-resource
languages such as Swahili and Urdu by training models in languages other than
English.
","['natural', 'language', 'processing', 'systems', 'heavily', 'dependent', 'availability', 'annotated', 'data', 'train', 'practical', 'models', '.', 'primarily', ',', 'models', 'trained', 'english', 'datasets', '.', 'recent', 'times', ',', 'significant', 'advances', 'made', 'multilingual', 'understanding', 'due', 'steeply', 'increasing', 'necessity', 'working', 'different', 'languages', '.', 'one', 'points', 'stands', 'since', 'many', 'pre-trained', 'multilingual', 'models', ',', 'utilize', 'cross-lingual', 'understanding', 'tasks', '.', 'using', 'cross-lingual', 'understanding', 'natural', 'language', 'inference', ',', 'possible', 'train', 'models', 'whose', 'applications', 'extend', 'beyond', 'training', 'language', '.', 'leverage', 'power', 'machine', 'translation', 'skip', 'tiresome', 'part', 'translating', 'datasets', 'one', 'language', 'another', '.', 'work', ',', 'focus', 'improving', 'original', 'xnli', 'dataset', 're-translating', 'mnli', 'dataset', '14', 'different', 'languages', 'present', 'xnli', ',', 'including', 'test', 'dev', 'sets', 'xnli', 'using', 'google', 'translate', '.', 'also', 'perform', 'experiments', 'training', 'models', '15', 'languages', 'analyzing', 'performance', 'task', 'natural', 'language', 'inference', '.', 'expand', 'boundary', 'investigate', 'could', 'improve', 'performance', 'low-resource', 'languages', 'swahili', 'urdu', 'training', 'models', 'languages', 'english', '.']","natural, language, processing, systems, heavily, dependent, availability, annotated, data, train, practical, models, ., primarily, ,, models, trained, english, datasets, ., recent, times, ,, significant, advances, made, multilingual, understanding, due, steeply, increasing, necessity, working, different, languages, ., one, points, stands, since, many, pre-trained, multilingual, models, ,, utilize, cross-lingual, understanding, tasks, ., using, cross-lingual, understanding, natural, language, inference, ,, possible, train, models, whose, applications, extend, beyond, training, language, ., leverage, power, machine, translation, skip, tiresome, part, translating, datasets, one, language, another, ., work, ,, focus, improving, original, xnli, dataset, re-translating, mnli, dataset, 14, different, languages, present, xnli, ,, including, test, dev, sets, xnli, using, google, translate, ., also, perform, experiments, training, models, 15, languages, analyzing, performance, task, natural, language, inference, ., expand, boundary, investigate, could, improve, performance, low-resource, languages, swahili, urdu, training, models, languages, english, ."
"BioBART: Pretraining and Evaluation of A Biomedical Generative Language
  Model","Hongyi Yuan, Zheng Yuan, Ruyi Gan, Jiaxing Zhang, Yutao Xie, Sheng Yu",2022-04-08T08:07:42Z,"  Pretrained language models have served as important backbones for natural
language processing. Recently, in-domain pretraining has been shown to benefit
various domain-specific downstream tasks. In the biomedical domain, natural
language generation (NLG) tasks are of critical importance, while understudied.
Approaching natural language understanding (NLU) tasks as NLG achieves
satisfying performance in the general domain through constrained language
generation or language prompting. We emphasize the lack of in-domain generative
language models and the unsystematic generative downstream benchmarks in the
biomedical domain, hindering the development of the research community. In this
work, we introduce the generative language model BioBART that adapts BART to
the biomedical domain. We collate various biomedical language generation tasks
including dialogue, summarization, entity linking, and named entity
recognition. BioBART pretrained on PubMed abstracts has enhanced performance
compared to BART and set strong baselines on several tasks. Furthermore, we
conduct ablation studies on the pretraining tasks for BioBART and find that
sentence permutation has negative effects on downstream tasks.
","['pretrained', 'language', 'models', 'served', 'important', 'backbones', 'natural', 'language', 'processing', '.', 'recently', ',', 'in-domain', 'pretraining', 'shown', 'benefit', 'various', 'domain-specific', 'downstream', 'tasks', '.', 'biomedical', 'domain', ',', 'natural', 'language', 'generation', '(', 'nlg', ')', 'tasks', 'critical', 'importance', ',', 'understudied', '.', 'approaching', 'natural', 'language', 'understanding', '(', 'nlu', ')', 'tasks', 'nlg', 'achieves', 'satisfying', 'performance', 'general', 'domain', 'constrained', 'language', 'generation', 'language', 'prompting', '.', 'emphasize', 'lack', 'in-domain', 'generative', 'language', 'models', 'unsystematic', 'generative', 'downstream', 'benchmarks', 'biomedical', 'domain', ',', 'hindering', 'development', 'research', 'community', '.', 'work', ',', 'introduce', 'generative', 'language', 'model', 'biobart', 'adapts', 'bart', 'biomedical', 'domain', '.', 'collate', 'various', 'biomedical', 'language', 'generation', 'tasks', 'including', 'dialogue', ',', 'summarization', ',', 'entity', 'linking', ',', 'named', 'entity', 'recognition', '.', 'biobart', 'pretrained', 'pubmed', 'abstracts', 'enhanced', 'performance', 'compared', 'bart', 'set', 'strong', 'baselines', 'several', 'tasks', '.', 'furthermore', ',', 'conduct', 'ablation', 'studies', 'pretraining', 'tasks', 'biobart', 'find', 'sentence', 'permutation', 'negative', 'effects', 'downstream', 'tasks', '.']","pretrained, language, models, served, important, backbones, natural, language, processing, ., recently, ,, in-domain, pretraining, shown, benefit, various, domain-specific, downstream, tasks, ., biomedical, domain, ,, natural, language, generation, (, nlg, ), tasks, critical, importance, ,, understudied, ., approaching, natural, language, understanding, (, nlu, ), tasks, nlg, achieves, satisfying, performance, general, domain, constrained, language, generation, language, prompting, ., emphasize, lack, in-domain, generative, language, models, unsystematic, generative, downstream, benchmarks, biomedical, domain, ,, hindering, development, research, community, ., work, ,, introduce, generative, language, model, biobart, adapts, bart, biomedical, domain, ., collate, various, biomedical, language, generation, tasks, including, dialogue, ,, summarization, ,, entity, linking, ,, named, entity, recognition, ., biobart, pretrained, pubmed, abstracts, enhanced, performance, compared, bart, set, strong, baselines, several, tasks, ., furthermore, ,, conduct, ablation, studies, pretraining, tasks, biobart, find, sentence, permutation, negative, effects, downstream, tasks, ."
"Knowledge Representation for Conceptual, Motivational, and Affective
  Processes in Natural Language Communication","Seng-Beng Ho, Zhaoxia Wang, Boon-Kiat Quek, Erik Cambria",2022-09-26T01:37:50Z,"  Natural language communication is an intricate and complex process. The
speaker usually begins with an intention and motivation of what is to be
communicated, and what effects are expected from the communication, while
taking into consideration the listener's mental model to concoct an appropriate
sentence. The listener likewise has to interpret what the speaker means, and
respond accordingly, also with the speaker's mental state in mind. To do this
successfully, conceptual, motivational, and affective processes have to be
represented appropriately to drive the language generation and understanding
processes. Language processing has succeeded well with the big data approach in
applications such as chatbots and machine translation. However, in human-robot
collaborative social communication and in using natural language for delivering
precise instructions to robots, a deeper representation of the conceptual,
motivational, and affective processes is needed. This paper capitalizes on the
UGALRS (Unified General Autonomous and Language Reasoning System) framework and
the CD+ (Conceptual Representation Plus) representational scheme to illustrate
how social communication through language is supported by a knowledge
representational scheme that handles conceptual, motivational, and affective
processes in a deep and general way. Though a small set of concepts,
motivations, and emotions is treated in this paper, its main contribution is in
articulating a general framework of knowledge representation and processing to
link these aspects together in serving the purpose of natural language
communication for an intelligent system.
","['natural', 'language', 'communication', 'intricate', 'complex', 'process', '.', 'speaker', 'usually', 'begins', 'intention', 'motivation', 'communicated', ',', 'effects', 'expected', 'communication', ',', 'taking', 'consideration', 'listener', ""'s"", 'mental', 'model', 'concoct', 'appropriate', 'sentence', '.', 'listener', 'likewise', 'interpret', 'speaker', 'means', ',', 'respond', 'accordingly', ',', 'also', 'speaker', ""'s"", 'mental', 'state', 'mind', '.', 'successfully', ',', 'conceptual', ',', 'motivational', ',', 'affective', 'processes', 'represented', 'appropriately', 'drive', 'language', 'generation', 'understanding', 'processes', '.', 'language', 'processing', 'succeeded', 'well', 'big', 'data', 'approach', 'applications', 'chatbots', 'machine', 'translation', '.', 'however', ',', 'human-robot', 'collaborative', 'social', 'communication', 'using', 'natural', 'language', 'delivering', 'precise', 'instructions', 'robots', ',', 'deeper', 'representation', 'conceptual', ',', 'motivational', ',', 'affective', 'processes', 'needed', '.', 'paper', 'capitalizes', 'ugalrs', '(', 'unified', 'general', 'autonomous', 'language', 'reasoning', 'system', ')', 'framework', 'cd+', '(', 'conceptual', 'representation', 'plus', ')', 'representational', 'scheme', 'illustrate', 'social', 'communication', 'language', 'supported', 'knowledge', 'representational', 'scheme', 'handles', 'conceptual', ',', 'motivational', ',', 'affective', 'processes', 'deep', 'general', 'way', '.', 'though', 'small', 'set', 'concepts', ',', 'motivations', ',', 'emotions', 'treated', 'paper', ',', 'main', 'contribution', 'articulating', 'general', 'framework', 'knowledge', 'representation', 'processing', 'link', 'aspects', 'together', 'serving', 'purpose', 'natural', 'language', 'communication', 'intelligent', 'system', '.']","natural, language, communication, intricate, complex, process, ., speaker, usually, begins, intention, motivation, communicated, ,, effects, expected, communication, ,, taking, consideration, listener, 's, mental, model, concoct, appropriate, sentence, ., listener, likewise, interpret, speaker, means, ,, respond, accordingly, ,, also, speaker, 's, mental, state, mind, ., successfully, ,, conceptual, ,, motivational, ,, affective, processes, represented, appropriately, drive, language, generation, understanding, processes, ., language, processing, succeeded, well, big, data, approach, applications, chatbots, machine, translation, ., however, ,, human-robot, collaborative, social, communication, using, natural, language, delivering, precise, instructions, robots, ,, deeper, representation, conceptual, ,, motivational, ,, affective, processes, needed, ., paper, capitalizes, ugalrs, (, unified, general, autonomous, language, reasoning, system, ), framework, cd+, (, conceptual, representation, plus, ), representational, scheme, illustrate, social, communication, language, supported, knowledge, representational, scheme, handles, conceptual, ,, motivational, ,, affective, processes, deep, general, way, ., though, small, set, concepts, ,, motivations, ,, emotions, treated, paper, ,, main, contribution, articulating, general, framework, knowledge, representation, processing, link, aspects, together, serving, purpose, natural, language, communication, intelligent, system, ."
GreekBART: The First Pretrained Greek Sequence-to-Sequence Model,"Iakovos Evdaimon, Hadi Abdine, Christos Xypolopoulos, Stamatis Outsios, Michalis Vazirgiannis, Giorgos Stamou",2023-04-03T10:48:51Z,"  The era of transfer learning has revolutionized the fields of Computer Vision
and Natural Language Processing, bringing powerful pretrained models with
exceptional performance across a variety of tasks. Specifically, Natural
Language Processing tasks have been dominated by transformer-based language
models. In Natural Language Inference and Natural Language Generation tasks,
the BERT model and its variants, as well as the GPT model and its successors,
demonstrated exemplary performance. However, the majority of these models are
pretrained and assessed primarily for the English language or on a multilingual
corpus. In this paper, we introduce GreekBART, the first Seq2Seq model based on
BART-base architecture and pretrained on a large-scale Greek corpus. We
evaluate and compare GreekBART against BART-random, Greek-BERT, and XLM-R on a
variety of discriminative tasks. In addition, we examine its performance on two
NLG tasks from GreekSUM, a newly introduced summarization dataset for the Greek
language. The model, the code, and the new summarization dataset will be
publicly available.
","['era', 'transfer', 'learning', 'revolutionized', 'fields', 'computer', 'vision', 'natural', 'language', 'processing', ',', 'bringing', 'powerful', 'pretrained', 'models', 'exceptional', 'performance', 'across', 'variety', 'tasks', '.', 'specifically', ',', 'natural', 'language', 'processing', 'tasks', 'dominated', 'transformer-based', 'language', 'models', '.', 'natural', 'language', 'inference', 'natural', 'language', 'generation', 'tasks', ',', 'bert', 'model', 'variants', ',', 'well', 'gpt', 'model', 'successors', ',', 'demonstrated', 'exemplary', 'performance', '.', 'however', ',', 'majority', 'models', 'pretrained', 'assessed', 'primarily', 'english', 'language', 'multilingual', 'corpus', '.', 'paper', ',', 'introduce', 'greekbart', ',', 'first', 'seq2seq', 'model', 'based', 'bart-base', 'architecture', 'pretrained', 'large-scale', 'greek', 'corpus', '.', 'evaluate', 'compare', 'greekbart', 'bart-random', ',', 'greek-bert', ',', 'xlm-r', 'variety', 'discriminative', 'tasks', '.', 'addition', ',', 'examine', 'performance', 'two', 'nlg', 'tasks', 'greeksum', ',', 'newly', 'introduced', 'summarization', 'dataset', 'greek', 'language', '.', 'model', ',', 'code', ',', 'new', 'summarization', 'dataset', 'publicly', 'available', '.']","era, transfer, learning, revolutionized, fields, computer, vision, natural, language, processing, ,, bringing, powerful, pretrained, models, exceptional, performance, across, variety, tasks, ., specifically, ,, natural, language, processing, tasks, dominated, transformer-based, language, models, ., natural, language, inference, natural, language, generation, tasks, ,, bert, model, variants, ,, well, gpt, model, successors, ,, demonstrated, exemplary, performance, ., however, ,, majority, models, pretrained, assessed, primarily, english, language, multilingual, corpus, ., paper, ,, introduce, greekbart, ,, first, seq2seq, model, based, bart-base, architecture, pretrained, large-scale, greek, corpus, ., evaluate, compare, greekbart, bart-random, ,, greek-bert, ,, xlm-r, variety, discriminative, tasks, ., addition, ,, examine, performance, two, nlg, tasks, greeksum, ,, newly, introduced, summarization, dataset, greek, language, ., model, ,, code, ,, new, summarization, dataset, publicly, available, ."
Towards a Natural Language Query Processing System,"Chantal Montgomery, Haruna Isah, Farhana Zulkernine",2020-09-25T19:52:20Z,"  Tackling the information retrieval gap between non-technical database
end-users and those with the knowledge of formal query languages has been an
interesting area of data management and analytics research. The use of natural
language interfaces to query information from databases offers the opportunity
to bridge the communication challenges between end-users and systems that use
formal query languages. Previous research efforts mainly focused on developing
structured query interfaces to relational databases. However, the evolution of
unstructured big data such as text, images, and video has exposed the
limitations of traditional structured query interfaces. While the existing web
search tools prove the popularity and usability of natural language query, they
return complete documents and web pages instead of focused query responses and
are not applicable to database systems. This paper reports our study on the
design and development of a natural language query interface to a backend
relational database. The novelty in the study lies in defining a graph database
as a middle layer to store necessary metadata needed to transform a natural
language query into structured query language that can be executed on backend
databases. We implemented and evaluated our approach using a restaurant
dataset. The translation results for some sample queries yielded a 90% accuracy
rate.
","['tackling', 'information', 'retrieval', 'gap', 'non-technical', 'database', 'end-users', 'knowledge', 'formal', 'query', 'languages', 'interesting', 'area', 'data', 'management', 'analytics', 'research', '.', 'use', 'natural', 'language', 'interfaces', 'query', 'information', 'databases', 'offers', 'opportunity', 'bridge', 'communication', 'challenges', 'end-users', 'systems', 'use', 'formal', 'query', 'languages', '.', 'previous', 'research', 'efforts', 'mainly', 'focused', 'developing', 'structured', 'query', 'interfaces', 'relational', 'databases', '.', 'however', ',', 'evolution', 'unstructured', 'big', 'data', 'text', ',', 'images', ',', 'video', 'exposed', 'limitations', 'traditional', 'structured', 'query', 'interfaces', '.', 'existing', 'web', 'search', 'tools', 'prove', 'popularity', 'usability', 'natural', 'language', 'query', ',', 'return', 'complete', 'documents', 'web', 'pages', 'instead', 'focused', 'query', 'responses', 'applicable', 'database', 'systems', '.', 'paper', 'reports', 'study', 'design', 'development', 'natural', 'language', 'query', 'interface', 'backend', 'relational', 'database', '.', 'novelty', 'study', 'lies', 'defining', 'graph', 'database', 'middle', 'layer', 'store', 'necessary', 'metadata', 'needed', 'transform', 'natural', 'language', 'query', 'structured', 'query', 'language', 'executed', 'backend', 'databases', '.', 'implemented', 'evaluated', 'approach', 'using', 'restaurant', 'dataset', '.', 'translation', 'results', 'sample', 'queries', 'yielded', '90', '%', 'accuracy', 'rate', '.']","tackling, information, retrieval, gap, non-technical, database, end-users, knowledge, formal, query, languages, interesting, area, data, management, analytics, research, ., use, natural, language, interfaces, query, information, databases, offers, opportunity, bridge, communication, challenges, end-users, systems, use, formal, query, languages, ., previous, research, efforts, mainly, focused, developing, structured, query, interfaces, relational, databases, ., however, ,, evolution, unstructured, big, data, text, ,, images, ,, video, exposed, limitations, traditional, structured, query, interfaces, ., existing, web, search, tools, prove, popularity, usability, natural, language, query, ,, return, complete, documents, web, pages, instead, focused, query, responses, applicable, database, systems, ., paper, reports, study, design, development, natural, language, query, interface, backend, relational, database, ., novelty, study, lies, defining, graph, database, middle, layer, store, necessary, metadata, needed, transform, natural, language, query, structured, query, language, executed, backend, databases, ., implemented, evaluated, approach, using, restaurant, dataset, ., translation, results, sample, queries, yielded, 90, %, accuracy, rate, ."
"Natural Language Embedded Programs for Hybrid Language Symbolic
  Reasoning","Tianhua Zhang, Jiaxin Ge, Hongyin Luo, Yung-Sung Chuang, Mingye Gao, Yuan Gong, Xixin Wu, Yoon Kim, Helen Meng, James Glass",2023-09-19T17:54:21Z,"  How can we perform computations over natural language representations to
solve tasks that require symbolic and numeric reasoning? We propose natural
language embedded programs (NLEP) as a unifying framework for addressing
math/symbolic reasoning, natural language understanding, and instruction
following tasks. Our approach prompts a language model to generate full Python
programs that define functions over data structures which contain natural
language representations of structured knowledge. A Python interpreter then
executes the generated code and prints the output. Despite using a task-general
prompt, we find that this approach can improve upon strong baselines across a
range of different tasks including math and symbolic reasoning, text
classification, question answering, and instruction following. We found that
the generated programs are interpretable since they outline the exact reasoning
process followed by the program interpreter.
","['perform', 'computations', 'natural', 'language', 'representations', 'solve', 'tasks', 'require', 'symbolic', 'numeric', 'reasoning', '?', 'propose', 'natural', 'language', 'embedded', 'programs', '(', 'nlep', ')', 'unifying', 'framework', 'addressing', 'math/symbolic', 'reasoning', ',', 'natural', 'language', 'understanding', ',', 'instruction', 'following', 'tasks', '.', 'approach', 'prompts', 'language', 'model', 'generate', 'full', 'python', 'programs', 'define', 'functions', 'data', 'structures', 'contain', 'natural', 'language', 'representations', 'structured', 'knowledge', '.', 'python', 'interpreter', 'executes', 'generated', 'code', 'prints', 'output', '.', 'despite', 'using', 'task-general', 'prompt', ',', 'find', 'approach', 'improve', 'upon', 'strong', 'baselines', 'across', 'range', 'different', 'tasks', 'including', 'math', 'symbolic', 'reasoning', ',', 'text', 'classification', ',', 'question', 'answering', ',', 'instruction', 'following', '.', 'found', 'generated', 'programs', 'interpretable', 'since', 'outline', 'exact', 'reasoning', 'process', 'followed', 'program', 'interpreter', '.']","perform, computations, natural, language, representations, solve, tasks, require, symbolic, numeric, reasoning, ?, propose, natural, language, embedded, programs, (, nlep, ), unifying, framework, addressing, math/symbolic, reasoning, ,, natural, language, understanding, ,, instruction, following, tasks, ., approach, prompts, language, model, generate, full, python, programs, define, functions, data, structures, contain, natural, language, representations, structured, knowledge, ., python, interpreter, executes, generated, code, prints, output, ., despite, using, task-general, prompt, ,, find, approach, improve, upon, strong, baselines, across, range, different, tasks, including, math, symbolic, reasoning, ,, text, classification, ,, question, answering, ,, instruction, following, ., found, generated, programs, interpretable, since, outline, exact, reasoning, process, followed, program, interpreter, ."
Improving Natural Language Capability of Code Large Language Model,"Wei Li, Daoguang Zan, Bei Guan, Ailun Yu, Xiaolin Chen, Yongji Wang",2024-01-25T15:33:20Z,"  Code large language models (Code LLMs) have demonstrated remarkable
performance in code generation. Nonetheless, most existing works focus on
boosting code LLMs from the perspective of programming capabilities, while
their natural language capabilities receive less attention. To fill this gap,
we thus propose a novel framework, comprising two modules: AttentionExtractor,
which is responsible for extracting key phrases from the user's natural
language requirements, and AttentionCoder, which leverages these extracted
phrases to generate target code to solve the requirement. This framework
pioneers an innovative idea by seamlessly integrating code LLMs with
traditional natural language processing tools. To validate the effectiveness of
the framework, we craft a new code generation benchmark, called MultiNL-H,
covering five natural languages. Extensive experimental results demonstrate the
effectiveness of our proposed framework.
","['code', 'large', 'language', 'models', '(', 'code', 'llms', ')', 'demonstrated', 'remarkable', 'performance', 'code', 'generation', '.', 'nonetheless', ',', 'existing', 'works', 'focus', 'boosting', 'code', 'llms', 'perspective', 'programming', 'capabilities', ',', 'natural', 'language', 'capabilities', 'receive', 'less', 'attention', '.', 'fill', 'gap', ',', 'thus', 'propose', 'novel', 'framework', ',', 'comprising', 'two', 'modules', ':', 'attentionextractor', ',', 'responsible', 'extracting', 'key', 'phrases', 'user', ""'s"", 'natural', 'language', 'requirements', ',', 'attentioncoder', ',', 'leverages', 'extracted', 'phrases', 'generate', 'target', 'code', 'solve', 'requirement', '.', 'framework', 'pioneers', 'innovative', 'idea', 'seamlessly', 'integrating', 'code', 'llms', 'traditional', 'natural', 'language', 'processing', 'tools', '.', 'validate', 'effectiveness', 'framework', ',', 'craft', 'new', 'code', 'generation', 'benchmark', ',', 'called', 'multinl-h', ',', 'covering', 'five', 'natural', 'languages', '.', 'extensive', 'experimental', 'results', 'demonstrate', 'effectiveness', 'proposed', 'framework', '.']","code, large, language, models, (, code, llms, ), demonstrated, remarkable, performance, code, generation, ., nonetheless, ,, existing, works, focus, boosting, code, llms, perspective, programming, capabilities, ,, natural, language, capabilities, receive, less, attention, ., fill, gap, ,, thus, propose, novel, framework, ,, comprising, two, modules, :, attentionextractor, ,, responsible, extracting, key, phrases, user, 's, natural, language, requirements, ,, attentioncoder, ,, leverages, extracted, phrases, generate, target, code, solve, requirement, ., framework, pioneers, innovative, idea, seamlessly, integrating, code, llms, traditional, natural, language, processing, tools, ., validate, effectiveness, framework, ,, craft, new, code, generation, benchmark, ,, called, multinl-h, ,, covering, five, natural, languages, ., extensive, experimental, results, demonstrate, effectiveness, proposed, framework, ."
"Natural Language Processing Chains Inside a Cross-lingual Event-Centric
  Knowledge Pipeline for European Union Under-resourced Languages","Diego Alves, Gaurish Thakkar, Marko Tadić",2020-10-23T14:26:30Z,"  This article presents the strategy for developing a platform containing
Language Processing Chains for European Union languages, consisting of
Tokenization to Parsing, also including Named Entity recognition andwith
addition ofSentiment Analysis. These chains are part of the first step of an
event-centric knowledge processing pipeline whose aim is to process
multilingual media information about major events that can cause an impactin
Europe and the rest of the world. Due to the differences in terms of
availability of language resources for each language, we have built this
strategy in three steps, starting with processing chains for the well-resourced
languages and finishing with the development of new modules for the
under-resourced ones. In order to classify all European Union official
languages in terms of resources, we have analysed the size of annotated corpora
as well as the existence of pre-trained models in mainstream Language
Processing tools, and we have combined this information with the proposed
classification published at META-NETwhitepaper series.
","['article', 'presents', 'strategy', 'developing', 'platform', 'containing', 'language', 'processing', 'chains', 'european', 'union', 'languages', ',', 'consisting', 'tokenization', 'parsing', ',', 'also', 'including', 'named', 'entity', 'recognition', 'andwith', 'addition', 'ofsentiment', 'analysis', '.', 'chains', 'part', 'first', 'step', 'event-centric', 'knowledge', 'processing', 'pipeline', 'whose', 'aim', 'process', 'multilingual', 'media', 'information', 'major', 'events', 'cause', 'impactin', 'europe', 'rest', 'world', '.', 'due', 'differences', 'terms', 'availability', 'language', 'resources', 'language', ',', 'built', 'strategy', 'three', 'steps', ',', 'starting', 'processing', 'chains', 'well-resourced', 'languages', 'finishing', 'development', 'new', 'modules', 'under-resourced', 'ones', '.', 'order', 'classify', 'european', 'union', 'official', 'languages', 'terms', 'resources', ',', 'analysed', 'size', 'annotated', 'corpora', 'well', 'existence', 'pre-trained', 'models', 'mainstream', 'language', 'processing', 'tools', ',', 'combined', 'information', 'proposed', 'classification', 'published', 'meta-netwhitepaper', 'series', '.']","article, presents, strategy, developing, platform, containing, language, processing, chains, european, union, languages, ,, consisting, tokenization, parsing, ,, also, including, named, entity, recognition, andwith, addition, ofsentiment, analysis, ., chains, part, first, step, event-centric, knowledge, processing, pipeline, whose, aim, process, multilingual, media, information, major, events, cause, impactin, europe, rest, world, ., due, differences, terms, availability, language, resources, language, ,, built, strategy, three, steps, ,, starting, processing, chains, well-resourced, languages, finishing, development, new, modules, under-resourced, ones, ., order, classify, european, union, official, languages, terms, resources, ,, analysed, size, annotated, corpora, well, existence, pre-trained, models, mainstream, language, processing, tools, ,, combined, information, proposed, classification, published, meta-netwhitepaper, series, ."
Novel Keyword Extraction and Language Detection Approaches,"Malgorzata Pikies, Andronicus Riyono, Junade Ali",2020-09-24T17:28:59Z,"  Fuzzy string matching and language classification are important tools in
Natural Language Processing pipelines, this paper provides advances in both
areas. We propose a fast novel approach to string tokenisation for fuzzy
language matching and experimentally demonstrate an 83.6% decrease in
processing time with an estimated improvement in recall of 3.1% at the cost of
a 2.6% decrease in precision. This approach is able to work even where keywords
are subdivided into multiple words, without needing to scan
character-to-character. So far there has been little work considering using
metadata to enhance language classification algorithms. We provide
observational data and find the Accept-Language header is 14% more likely to
match the classification than the IP Address.
","['fuzzy', 'string', 'matching', 'language', 'classification', 'important', 'tools', 'natural', 'language', 'processing', 'pipelines', ',', 'paper', 'provides', 'advances', 'areas', '.', 'propose', 'fast', 'novel', 'approach', 'string', 'tokenisation', 'fuzzy', 'language', 'matching', 'experimentally', 'demonstrate', '83.6', '%', 'decrease', 'processing', 'time', 'estimated', 'improvement', 'recall', '3.1', '%', 'cost', '2.6', '%', 'decrease', 'precision', '.', 'approach', 'able', 'work', 'even', 'keywords', 'subdivided', 'multiple', 'words', ',', 'without', 'needing', 'scan', 'character-to-character', '.', 'far', 'little', 'work', 'considering', 'using', 'metadata', 'enhance', 'language', 'classification', 'algorithms', '.', 'provide', 'observational', 'data', 'find', 'accept-language', 'header', '14', '%', 'likely', 'match', 'classification', 'ip', 'address', '.']","fuzzy, string, matching, language, classification, important, tools, natural, language, processing, pipelines, ,, paper, provides, advances, areas, ., propose, fast, novel, approach, string, tokenisation, fuzzy, language, matching, experimentally, demonstrate, 83.6, %, decrease, processing, time, estimated, improvement, recall, 3.1, %, cost, 2.6, %, decrease, precision, ., approach, able, work, even, keywords, subdivided, multiple, words, ,, without, needing, scan, character-to-character, ., far, little, work, considering, using, metadata, enhance, language, classification, algorithms, ., provide, observational, data, find, accept-language, header, 14, %, likely, match, classification, ip, address, ."
Morphosyntactic Analysis for CHILDES,"Houjun Liu, Brian MacWhinney",2024-07-17T08:11:24Z,"  Language development researchers are interested in comparing the process of
language learning across languages. Unfortunately, it has been difficult to
construct a consistent quantitative framework for such comparisons. However,
recent advances in AI (Artificial Intelligence) and ML (Machine Learning) are
providing new methods for ASR (automatic speech recognition) and NLP (natural
language processing) that can be brought to bear on this problem. Using the
Batchalign2 program (Liu et al., 2023), we have been transcribing and linking
data for the CHILDES database and have applied the UD (Universal Dependencies)
framework to provide a consistent and comparable morphosyntactic analysis for
27 languages. These new resources open possibilities for deeper crosslinguistic
study of language learning.
","['language', 'development', 'researchers', 'interested', 'comparing', 'process', 'language', 'learning', 'across', 'languages', '.', 'unfortunately', ',', 'difficult', 'construct', 'consistent', 'quantitative', 'framework', 'comparisons', '.', 'however', ',', 'recent', 'advances', 'ai', '(', 'artificial', 'intelligence', ')', 'ml', '(', 'machine', 'learning', ')', 'providing', 'new', 'methods', 'asr', '(', 'automatic', 'speech', 'recognition', ')', 'nlp', '(', 'natural', 'language', 'processing', ')', 'brought', 'bear', 'problem', '.', 'using', 'batchalign2', 'program', '(', 'liu', 'et', 'al.', ',', '2023', ')', ',', 'transcribing', 'linking', 'data', 'childes', 'database', 'applied', 'ud', '(', 'universal', 'dependencies', ')', 'framework', 'provide', 'consistent', 'comparable', 'morphosyntactic', 'analysis', '27', 'languages', '.', 'new', 'resources', 'open', 'possibilities', 'deeper', 'crosslinguistic', 'study', 'language', 'learning', '.']","language, development, researchers, interested, comparing, process, language, learning, across, languages, ., unfortunately, ,, difficult, construct, consistent, quantitative, framework, comparisons, ., however, ,, recent, advances, ai, (, artificial, intelligence, ), ml, (, machine, learning, ), providing, new, methods, asr, (, automatic, speech, recognition, ), nlp, (, natural, language, processing, ), brought, bear, problem, ., using, batchalign2, program, (, liu, et, al., ,, 2023, ), ,, transcribing, linking, data, childes, database, applied, ud, (, universal, dependencies, ), framework, provide, consistent, comparable, morphosyntactic, analysis, 27, languages, ., new, resources, open, possibilities, deeper, crosslinguistic, study, language, learning, ."
"Extracting Weighted Finite Automata from Recurrent Neural Networks for
  Natural Languages","Zeming Wei, Xiyue Zhang, Meng Sun",2022-06-27T09:30:13Z,"  Recurrent Neural Networks (RNNs) have achieved tremendous success in
sequential data processing. However, it is quite challenging to interpret and
verify RNNs' behaviors directly. To this end, many efforts have been made to
extract finite automata from RNNs. Existing approaches such as exact learning
are effective in extracting finite-state models to characterize the state
dynamics of RNNs for formal languages, but are limited in the scalability to
process natural languages. Compositional approaches that are scablable to
natural languages fall short in extraction precision. In this paper, we
identify the transition sparsity problem that heavily impacts the extraction
precision. To address this problem, we propose a transition rule extraction
approach, which is scalable to natural language processing models and effective
in improving extraction precision. Specifically, we propose an empirical method
to complement the missing rules in the transition diagram. In addition, we
further adjust the transition matrices to enhance the context-aware ability of
the extracted weighted finite automaton (WFA). Finally, we propose two data
augmentation tactics to track more dynamic behaviors of the target RNN.
Experiments on two popular natural language datasets show that our method can
extract WFA from RNN for natural language processing with better precision than
existing approaches. Our code is available at
https://github.com/weizeming/Extract_WFA_from_RNN_for_NL.
","['recurrent', 'neural', 'networks', '(', 'rnns', ')', 'achieved', 'tremendous', 'success', 'sequential', 'data', 'processing', '.', 'however', ',', 'quite', 'challenging', 'interpret', 'verify', 'rnns', ""'"", 'behaviors', 'directly', '.', 'end', ',', 'many', 'efforts', 'made', 'extract', 'finite', 'automata', 'rnns', '.', 'existing', 'approaches', 'exact', 'learning', 'effective', 'extracting', 'finite-state', 'models', 'characterize', 'state', 'dynamics', 'rnns', 'formal', 'languages', ',', 'limited', 'scalability', 'process', 'natural', 'languages', '.', 'compositional', 'approaches', 'scablable', 'natural', 'languages', 'fall', 'short', 'extraction', 'precision', '.', 'paper', ',', 'identify', 'transition', 'sparsity', 'problem', 'heavily', 'impacts', 'extraction', 'precision', '.', 'address', 'problem', ',', 'propose', 'transition', 'rule', 'extraction', 'approach', ',', 'scalable', 'natural', 'language', 'processing', 'models', 'effective', 'improving', 'extraction', 'precision', '.', 'specifically', ',', 'propose', 'empirical', 'method', 'complement', 'missing', 'rules', 'transition', 'diagram', '.', 'addition', ',', 'adjust', 'transition', 'matrices', 'enhance', 'context-aware', 'ability', 'extracted', 'weighted', 'finite', 'automaton', '(', 'wfa', ')', '.', 'finally', ',', 'propose', 'two', 'data', 'augmentation', 'tactics', 'track', 'dynamic', 'behaviors', 'target', 'rnn', '.', 'experiments', 'two', 'popular', 'natural', 'language', 'datasets', 'show', 'method', 'extract', 'wfa', 'rnn', 'natural', 'language', 'processing', 'better', 'precision', 'existing', 'approaches', '.', 'code', 'available', 'https', ':', '//github.com/weizeming/extract_wfa_from_rnn_for_nl', '.']","recurrent, neural, networks, (, rnns, ), achieved, tremendous, success, sequential, data, processing, ., however, ,, quite, challenging, interpret, verify, rnns, ', behaviors, directly, ., end, ,, many, efforts, made, extract, finite, automata, rnns, ., existing, approaches, exact, learning, effective, extracting, finite-state, models, characterize, state, dynamics, rnns, formal, languages, ,, limited, scalability, process, natural, languages, ., compositional, approaches, scablable, natural, languages, fall, short, extraction, precision, ., paper, ,, identify, transition, sparsity, problem, heavily, impacts, extraction, precision, ., address, problem, ,, propose, transition, rule, extraction, approach, ,, scalable, natural, language, processing, models, effective, improving, extraction, precision, ., specifically, ,, propose, empirical, method, complement, missing, rules, transition, diagram, ., addition, ,, adjust, transition, matrices, enhance, context-aware, ability, extracted, weighted, finite, automaton, (, wfa, ), ., finally, ,, propose, two, data, augmentation, tactics, track, dynamic, behaviors, target, rnn, ., experiments, two, popular, natural, language, datasets, show, method, extract, wfa, rnn, natural, language, processing, better, precision, existing, approaches, ., code, available, https, :, //github.com/weizeming/extract_wfa_from_rnn_for_nl, ."
The Role of Explanatory Value in Natural Language Processing,Kees van Deemter,2022-09-13T17:19:04Z,"  A key aim of science is explanation, yet the idea of explaining language
phenomena has taken a backseat in mainstream Natural Language Processing (NLP)
and many other areas of Artificial Intelligence. I argue that explanation of
linguistic behaviour should be a main goal of NLP, and that this is not the
same as making NLP models explainable. To illustrate these ideas, some recent
models of human language production are compared with each other. I conclude by
asking what it would mean for NLP research and institutional policies if our
community took explanatory value seriously, while heeding some possible
pitfalls.
","['key', 'aim', 'science', 'explanation', ',', 'yet', 'idea', 'explaining', 'language', 'phenomena', 'taken', 'backseat', 'mainstream', 'natural', 'language', 'processing', '(', 'nlp', ')', 'many', 'areas', 'artificial', 'intelligence', '.', 'argue', 'explanation', 'linguistic', 'behaviour', 'main', 'goal', 'nlp', ',', 'making', 'nlp', 'models', 'explainable', '.', 'illustrate', 'ideas', ',', 'recent', 'models', 'human', 'language', 'production', 'compared', '.', 'conclude', 'asking', 'would', 'mean', 'nlp', 'research', 'institutional', 'policies', 'community', 'took', 'explanatory', 'value', 'seriously', ',', 'heeding', 'possible', 'pitfalls', '.']","key, aim, science, explanation, ,, yet, idea, explaining, language, phenomena, taken, backseat, mainstream, natural, language, processing, (, nlp, ), many, areas, artificial, intelligence, ., argue, explanation, linguistic, behaviour, main, goal, nlp, ,, making, nlp, models, explainable, ., illustrate, ideas, ,, recent, models, human, language, production, compared, ., conclude, asking, would, mean, nlp, research, institutional, policies, community, took, explanatory, value, seriously, ,, heeding, possible, pitfalls, ."
Fast Vocabulary Transfer for Language Model Compression,"Leonidas Gee, Andrea Zugarini, Leonardo Rigutini, Paolo Torroni",2024-02-15T14:37:07Z,"  Real-world business applications require a trade-off between language model
performance and size. We propose a new method for model compression that relies
on vocabulary transfer. We evaluate the method on various vertical domains and
downstream tasks. Our results indicate that vocabulary transfer can be
effectively used in combination with other compression techniques, yielding a
significant reduction in model size and inference time while marginally
compromising on performance.
","['real-world', 'business', 'applications', 'require', 'trade-off', 'language', 'model', 'performance', 'size', '.', 'propose', 'new', 'method', 'model', 'compression', 'relies', 'vocabulary', 'transfer', '.', 'evaluate', 'method', 'various', 'vertical', 'domains', 'downstream', 'tasks', '.', 'results', 'indicate', 'vocabulary', 'transfer', 'effectively', 'used', 'combination', 'compression', 'techniques', ',', 'yielding', 'significant', 'reduction', 'model', 'size', 'inference', 'time', 'marginally', 'compromising', 'performance', '.']","real-world, business, applications, require, trade-off, language, model, performance, size, ., propose, new, method, model, compression, relies, vocabulary, transfer, ., evaluate, method, various, vertical, domains, downstream, tasks, ., results, indicate, vocabulary, transfer, effectively, used, combination, compression, techniques, ,, yielding, significant, reduction, model, size, inference, time, marginally, compromising, performance, ."
From Textual Information Sources to Linked Data in the Agatha Project,"Paulo Quaresma, Vitor Beires Nogueira, Kashyap Raiyani, Roy Bayot, Teresa Gonçalves",2019-09-03T08:27:37Z,"  Automatic reasoning about textual information is a challenging task in modern
Natural Language Processing (NLP) systems. In this work we describe our
proposal for representing and reasoning about Portuguese documents by means of
Linked Data like ontologies and thesauri. Our approach resorts to a specialized
pipeline of natural language processing (part-of-speech tagger, named entity
recognition, semantic role labeling) to populate an ontology for the domain of
criminal investigations. The provided architecture and ontology are language
independent. Although some of the NLP modules are language dependent, they can
be built using adequate AI methodologies.
","['automatic', 'reasoning', 'textual', 'information', 'challenging', 'task', 'modern', 'natural', 'language', 'processing', '(', 'nlp', ')', 'systems', '.', 'work', 'describe', 'proposal', 'representing', 'reasoning', 'portuguese', 'documents', 'means', 'linked', 'data', 'like', 'ontologies', 'thesauri', '.', 'approach', 'resorts', 'specialized', 'pipeline', 'natural', 'language', 'processing', '(', 'part-of-speech', 'tagger', ',', 'named', 'entity', 'recognition', ',', 'semantic', 'role', 'labeling', ')', 'populate', 'ontology', 'domain', 'criminal', 'investigations', '.', 'provided', 'architecture', 'ontology', 'language', 'independent', '.', 'although', 'nlp', 'modules', 'language', 'dependent', ',', 'built', 'using', 'adequate', 'ai', 'methodologies', '.']","automatic, reasoning, textual, information, challenging, task, modern, natural, language, processing, (, nlp, ), systems, ., work, describe, proposal, representing, reasoning, portuguese, documents, means, linked, data, like, ontologies, thesauri, ., approach, resorts, specialized, pipeline, natural, language, processing, (, part-of-speech, tagger, ,, named, entity, recognition, ,, semantic, role, labeling, ), populate, ontology, domain, criminal, investigations, ., provided, architecture, ontology, language, independent, ., although, nlp, modules, language, dependent, ,, built, using, adequate, ai, methodologies, ."
Syllable-based Neural Named Entity Recognition for Myanmar Language,"Hsu Myat Mo, Khin Mar Soe",2019-03-12T05:52:41Z,"  Named Entity Recognition (NER) for Myanmar Language is essential to Myanmar
natural language processing research work. In this work, NER for Myanmar
language is treated as a sequence tagging problem and the effectiveness of deep
neural networks on NER for Myanmar language has been investigated. Experiments
are performed by applying deep neural network architectures on syllable level
Myanmar contexts. Very first manually annotated NER corpus for Myanmar language
is also constructed and proposed. In developing our in-house NER corpus,
sentences from online news website and also sentences supported from
ALT-Parallel-Corpus are also used. This ALT corpus is one part of the Asian
Language Treebank (ALT) project under ASEAN IVO. This paper contributes the
first evaluation of neural network models on NER task for Myanmar language. The
experimental results show that those neural sequence models can produce
promising results compared to the baseline CRF model. Among those neural
architectures, bidirectional LSTM network added CRF layer above gives the
highest F-score value. This work also aims to discover the effectiveness of
neural network approaches to Myanmar textual processing as well as to promote
further researches on this understudied language.
","['named', 'entity', 'recognition', '(', 'ner', ')', 'myanmar', 'language', 'essential', 'myanmar', 'natural', 'language', 'processing', 'research', 'work', '.', 'work', ',', 'ner', 'myanmar', 'language', 'treated', 'sequence', 'tagging', 'problem', 'effectiveness', 'deep', 'neural', 'networks', 'ner', 'myanmar', 'language', 'investigated', '.', 'experiments', 'performed', 'applying', 'deep', 'neural', 'network', 'architectures', 'syllable', 'level', 'myanmar', 'contexts', '.', 'first', 'manually', 'annotated', 'ner', 'corpus', 'myanmar', 'language', 'also', 'constructed', 'proposed', '.', 'developing', 'in-house', 'ner', 'corpus', ',', 'sentences', 'online', 'news', 'website', 'also', 'sentences', 'supported', 'alt-parallel-corpus', 'also', 'used', '.', 'alt', 'corpus', 'one', 'part', 'asian', 'language', 'treebank', '(', 'alt', ')', 'project', 'asean', 'ivo', '.', 'paper', 'contributes', 'first', 'evaluation', 'neural', 'network', 'models', 'ner', 'task', 'myanmar', 'language', '.', 'experimental', 'results', 'show', 'neural', 'sequence', 'models', 'produce', 'promising', 'results', 'compared', 'baseline', 'crf', 'model', '.', 'among', 'neural', 'architectures', ',', 'bidirectional', 'lstm', 'network', 'added', 'crf', 'layer', 'gives', 'highest', 'f-score', 'value', '.', 'work', 'also', 'aims', 'discover', 'effectiveness', 'neural', 'network', 'approaches', 'myanmar', 'textual', 'processing', 'well', 'promote', 'researches', 'understudied', 'language', '.']","named, entity, recognition, (, ner, ), myanmar, language, essential, myanmar, natural, language, processing, research, work, ., work, ,, ner, myanmar, language, treated, sequence, tagging, problem, effectiveness, deep, neural, networks, ner, myanmar, language, investigated, ., experiments, performed, applying, deep, neural, network, architectures, syllable, level, myanmar, contexts, ., first, manually, annotated, ner, corpus, myanmar, language, also, constructed, proposed, ., developing, in-house, ner, corpus, ,, sentences, online, news, website, also, sentences, supported, alt-parallel-corpus, also, used, ., alt, corpus, one, part, asian, language, treebank, (, alt, ), project, asean, ivo, ., paper, contributes, first, evaluation, neural, network, models, ner, task, myanmar, language, ., experimental, results, show, neural, sequence, models, produce, promising, results, compared, baseline, crf, model, ., among, neural, architectures, ,, bidirectional, lstm, network, added, crf, layer, gives, highest, f-score, value, ., work, also, aims, discover, effectiveness, neural, network, approaches, myanmar, textual, processing, well, promote, researches, understudied, language, ."
Large language models in bioinformatics: applications and perspectives,"Jiajia Liu, Mengyuan Yang, Yankai Yu, Haixia Xu, Kang Li, Xiaobo Zhou",2024-01-08T17:26:59Z,"  Large language models (LLMs) are a class of artificial intelligence models
based on deep learning, which have great performance in various tasks,
especially in natural language processing (NLP). Large language models
typically consist of artificial neural networks with numerous parameters,
trained on large amounts of unlabeled input using self-supervised or
semi-supervised learning. However, their potential for solving bioinformatics
problems may even exceed their proficiency in modeling human language. In this
review, we will present a summary of the prominent large language models used
in natural language processing, such as BERT and GPT, and focus on exploring
the applications of large language models at different omics levels in
bioinformatics, mainly including applications of large language models in
genomics, transcriptomics, proteomics, drug discovery and single cell analysis.
Finally, this review summarizes the potential and prospects of large language
models in solving bioinformatic problems.
","['large', 'language', 'models', '(', 'llms', ')', 'class', 'artificial', 'intelligence', 'models', 'based', 'deep', 'learning', ',', 'great', 'performance', 'various', 'tasks', ',', 'especially', 'natural', 'language', 'processing', '(', 'nlp', ')', '.', 'large', 'language', 'models', 'typically', 'consist', 'artificial', 'neural', 'networks', 'numerous', 'parameters', ',', 'trained', 'large', 'amounts', 'unlabeled', 'input', 'using', 'self-supervised', 'semi-supervised', 'learning', '.', 'however', ',', 'potential', 'solving', 'bioinformatics', 'problems', 'may', 'even', 'exceed', 'proficiency', 'modeling', 'human', 'language', '.', 'review', ',', 'present', 'summary', 'prominent', 'large', 'language', 'models', 'used', 'natural', 'language', 'processing', ',', 'bert', 'gpt', ',', 'focus', 'exploring', 'applications', 'large', 'language', 'models', 'different', 'omics', 'levels', 'bioinformatics', ',', 'mainly', 'including', 'applications', 'large', 'language', 'models', 'genomics', ',', 'transcriptomics', ',', 'proteomics', ',', 'drug', 'discovery', 'single', 'cell', 'analysis', '.', 'finally', ',', 'review', 'summarizes', 'potential', 'prospects', 'large', 'language', 'models', 'solving', 'bioinformatic', 'problems', '.']","large, language, models, (, llms, ), class, artificial, intelligence, models, based, deep, learning, ,, great, performance, various, tasks, ,, especially, natural, language, processing, (, nlp, ), ., large, language, models, typically, consist, artificial, neural, networks, numerous, parameters, ,, trained, large, amounts, unlabeled, input, using, self-supervised, semi-supervised, learning, ., however, ,, potential, solving, bioinformatics, problems, may, even, exceed, proficiency, modeling, human, language, ., review, ,, present, summary, prominent, large, language, models, used, natural, language, processing, ,, bert, gpt, ,, focus, exploring, applications, large, language, models, different, omics, levels, bioinformatics, ,, mainly, including, applications, large, language, models, genomics, ,, transcriptomics, ,, proteomics, ,, drug, discovery, single, cell, analysis, ., finally, ,, review, summarizes, potential, prospects, large, language, models, solving, bioinformatic, problems, ."
"Opportunities for Large Language Models and Discourse in Engineering
  Design","Jan Göpfert, Jann M. Weinand, Patrick Kuckertz, Detlef Stolten",2023-06-15T14:46:44Z,"  In recent years, large language models have achieved breakthroughs on a wide
range of benchmarks in natural language processing and continue to increase in
performance. Recently, the advances of large language models have raised
interest outside the natural language processing community and could have a
large impact on daily life. In this paper, we pose the question: How will large
language models and other foundation models shape the future product
development process? We provide the reader with an overview of the subject by
summarizing both recent advances in natural language processing and the use of
information technology in the engineering design process. We argue that
discourse should be regarded as the core of engineering design processes, and
therefore should be represented in a digital artifact. On this basis, we
describe how foundation models such as large language models could contribute
to the design discourse by automating parts thereof that involve creativity and
reasoning, and were previously reserved for humans. We describe how
simulations, experiments, topology optimizations, and other process steps can
be integrated into a machine-actionable, discourse-centric design process.
Finally, we outline the future research that will be necessary for the
implementation of the conceptualized framework.
","['recent', 'years', ',', 'large', 'language', 'models', 'achieved', 'breakthroughs', 'wide', 'range', 'benchmarks', 'natural', 'language', 'processing', 'continue', 'increase', 'performance', '.', 'recently', ',', 'advances', 'large', 'language', 'models', 'raised', 'interest', 'outside', 'natural', 'language', 'processing', 'community', 'could', 'large', 'impact', 'daily', 'life', '.', 'paper', ',', 'pose', 'question', ':', 'large', 'language', 'models', 'foundation', 'models', 'shape', 'future', 'product', 'development', 'process', '?', 'provide', 'reader', 'overview', 'subject', 'summarizing', 'recent', 'advances', 'natural', 'language', 'processing', 'use', 'information', 'technology', 'engineering', 'design', 'process', '.', 'argue', 'discourse', 'regarded', 'core', 'engineering', 'design', 'processes', ',', 'therefore', 'represented', 'digital', 'artifact', '.', 'basis', ',', 'describe', 'foundation', 'models', 'large', 'language', 'models', 'could', 'contribute', 'design', 'discourse', 'automating', 'parts', 'thereof', 'involve', 'creativity', 'reasoning', ',', 'previously', 'reserved', 'humans', '.', 'describe', 'simulations', ',', 'experiments', ',', 'topology', 'optimizations', ',', 'process', 'steps', 'integrated', 'machine-actionable', ',', 'discourse-centric', 'design', 'process', '.', 'finally', ',', 'outline', 'future', 'research', 'necessary', 'implementation', 'conceptualized', 'framework', '.']","recent, years, ,, large, language, models, achieved, breakthroughs, wide, range, benchmarks, natural, language, processing, continue, increase, performance, ., recently, ,, advances, large, language, models, raised, interest, outside, natural, language, processing, community, could, large, impact, daily, life, ., paper, ,, pose, question, :, large, language, models, foundation, models, shape, future, product, development, process, ?, provide, reader, overview, subject, summarizing, recent, advances, natural, language, processing, use, information, technology, engineering, design, process, ., argue, discourse, regarded, core, engineering, design, processes, ,, therefore, represented, digital, artifact, ., basis, ,, describe, foundation, models, large, language, models, could, contribute, design, discourse, automating, parts, thereof, involve, creativity, reasoning, ,, previously, reserved, humans, ., describe, simulations, ,, experiments, ,, topology, optimizations, ,, process, steps, integrated, machine-actionable, ,, discourse-centric, design, process, ., finally, ,, outline, future, research, necessary, implementation, conceptualized, framework, ."
Towards More Robust Natural Language Understanding,Xinliang Frederick Zhang,2021-12-01T17:27:19Z,"  Natural Language Understanding (NLU) is a branch of Natural Language
Processing (NLP) that uses intelligent computer software to understand texts
that encode human knowledge. Recent years have witnessed notable progress
across various NLU tasks with deep learning techniques, especially with
pretrained language models. Besides proposing more advanced model
architectures, constructing more reliable and trustworthy datasets also plays a
huge role in improving NLU systems, without which it would be impossible to
train a decent NLU model. It's worth noting that the human ability of
understanding natural language is flexible and robust. On the contrary, most of
existing NLU systems fail to achieve desirable performance on out-of-domain
data or struggle on handling challenging items (e.g., inherently ambiguous
items, adversarial items) in the real world. Therefore, in order to have NLU
models understand human language more effectively, it is expected to prioritize
the study on robust natural language understanding. In this thesis, we deem
that NLU systems are consisting of two components: NLU models and NLU datasets.
As such, we argue that, to achieve robust NLU, the model architecture/training
and the dataset are equally important. Specifically, we will focus on three NLU
tasks to illustrate the robustness problem in different NLU tasks and our
contributions (i.e., novel models and new datasets) to help achieve more robust
natural language understanding. Moving forward, the ultimate goal for robust
natural language understanding is to build NLU models which can behave humanly.
That is, it's expected that robust NLU systems are capable to transfer the
knowledge from training corpus to unseen documents more reliably and survive
when encountering challenging items even if the system doesn't know a priori of
users' inputs.
","['natural', 'language', 'understanding', '(', 'nlu', ')', 'branch', 'natural', 'language', 'processing', '(', 'nlp', ')', 'uses', 'intelligent', 'computer', 'software', 'understand', 'texts', 'encode', 'human', 'knowledge', '.', 'recent', 'years', 'witnessed', 'notable', 'progress', 'across', 'various', 'nlu', 'tasks', 'deep', 'learning', 'techniques', ',', 'especially', 'pretrained', 'language', 'models', '.', 'besides', 'proposing', 'advanced', 'model', 'architectures', ',', 'constructing', 'reliable', 'trustworthy', 'datasets', 'also', 'plays', 'huge', 'role', 'improving', 'nlu', 'systems', ',', 'without', 'would', 'impossible', 'train', 'decent', 'nlu', 'model', '.', ""'s"", 'worth', 'noting', 'human', 'ability', 'understanding', 'natural', 'language', 'flexible', 'robust', '.', 'contrary', ',', 'existing', 'nlu', 'systems', 'fail', 'achieve', 'desirable', 'performance', 'out-of-domain', 'data', 'struggle', 'handling', 'challenging', 'items', '(', 'e.g.', ',', 'inherently', 'ambiguous', 'items', ',', 'adversarial', 'items', ')', 'real', 'world', '.', 'therefore', ',', 'order', 'nlu', 'models', 'understand', 'human', 'language', 'effectively', ',', 'expected', 'prioritize', 'study', 'robust', 'natural', 'language', 'understanding', '.', 'thesis', ',', 'deem', 'nlu', 'systems', 'consisting', 'two', 'components', ':', 'nlu', 'models', 'nlu', 'datasets', '.', ',', 'argue', ',', 'achieve', 'robust', 'nlu', ',', 'model', 'architecture/training', 'dataset', 'equally', 'important', '.', 'specifically', ',', 'focus', 'three', 'nlu', 'tasks', 'illustrate', 'robustness', 'problem', 'different', 'nlu', 'tasks', 'contributions', '(', 'i.e.', ',', 'novel', 'models', 'new', 'datasets', ')', 'help', 'achieve', 'robust', 'natural', 'language', 'understanding', '.', 'moving', 'forward', ',', 'ultimate', 'goal', 'robust', 'natural', 'language', 'understanding', 'build', 'nlu', 'models', 'behave', 'humanly', '.', ',', ""'s"", 'expected', 'robust', 'nlu', 'systems', 'capable', 'transfer', 'knowledge', 'training', 'corpus', 'unseen', 'documents', 'reliably', 'survive', 'encountering', 'challenging', 'items', 'even', 'system', ""n't"", 'know', 'priori', 'users', ""'"", 'inputs', '.']","natural, language, understanding, (, nlu, ), branch, natural, language, processing, (, nlp, ), uses, intelligent, computer, software, understand, texts, encode, human, knowledge, ., recent, years, witnessed, notable, progress, across, various, nlu, tasks, deep, learning, techniques, ,, especially, pretrained, language, models, ., besides, proposing, advanced, model, architectures, ,, constructing, reliable, trustworthy, datasets, also, plays, huge, role, improving, nlu, systems, ,, without, would, impossible, train, decent, nlu, model, ., 's, worth, noting, human, ability, understanding, natural, language, flexible, robust, ., contrary, ,, existing, nlu, systems, fail, achieve, desirable, performance, out-of-domain, data, struggle, handling, challenging, items, (, e.g., ,, inherently, ambiguous, items, ,, adversarial, items, ), real, world, ., therefore, ,, order, nlu, models, understand, human, language, effectively, ,, expected, prioritize, study, robust, natural, language, understanding, ., thesis, ,, deem, nlu, systems, consisting, two, components, :, nlu, models, nlu, datasets, ., ,, argue, ,, achieve, robust, nlu, ,, model, architecture/training, dataset, equally, important, ., specifically, ,, focus, three, nlu, tasks, illustrate, robustness, problem, different, nlu, tasks, contributions, (, i.e., ,, novel, models, new, datasets, ), help, achieve, robust, natural, language, understanding, ., moving, forward, ,, ultimate, goal, robust, natural, language, understanding, build, nlu, models, behave, humanly, ., ,, 's, expected, robust, nlu, systems, capable, transfer, knowledge, training, corpus, unseen, documents, reliably, survive, encountering, challenging, items, even, system, n't, know, priori, users, ', inputs, ."
"Collaborative construction of lexicographic and parallel datasets for
  African languages: first assessment",Elvis Mboning Tchiaze,2021-03-30T22:43:13Z,"  Faced with a considerable lack of resources in African languages to carry out
work in Natural Language Processing (NLP), Natural Language Understanding (NLU)
and artificial intelligence, the research teams of NTeALan association has set
itself the objective of building open-source platforms for the collaborative
construction of lexicographic data in African languages. In this article, we
present our first reports after 2 years of collaborative construction of
lexicographic resources useful for African NLP tools.
","['faced', 'considerable', 'lack', 'resources', 'african', 'languages', 'carry', 'work', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'natural', 'language', 'understanding', '(', 'nlu', ')', 'artificial', 'intelligence', ',', 'research', 'teams', 'ntealan', 'association', 'set', 'objective', 'building', 'open-source', 'platforms', 'collaborative', 'construction', 'lexicographic', 'data', 'african', 'languages', '.', 'article', ',', 'present', 'first', 'reports', '2', 'years', 'collaborative', 'construction', 'lexicographic', 'resources', 'useful', 'african', 'nlp', 'tools', '.']","faced, considerable, lack, resources, african, languages, carry, work, natural, language, processing, (, nlp, ), ,, natural, language, understanding, (, nlu, ), artificial, intelligence, ,, research, teams, ntealan, association, set, objective, building, open-source, platforms, collaborative, construction, lexicographic, data, african, languages, ., article, ,, present, first, reports, 2, years, collaborative, construction, lexicographic, resources, useful, african, nlp, tools, ."
Knowledge Engineering using Large Language Models,"Bradley P. Allen, Lise Stork, Paul Groth",2023-10-01T10:26:25Z,"  Knowledge engineering is a discipline that focuses on the creation and
maintenance of processes that generate and apply knowledge. Traditionally,
knowledge engineering approaches have focused on knowledge expressed in formal
languages. The emergence of large language models and their capabilities to
effectively work with natural language, in its broadest sense, raises questions
about the foundations and practice of knowledge engineering. Here, we outline
the potential role of LLMs in knowledge engineering, identifying two central
directions: 1) creating hybrid neuro-symbolic knowledge systems; and 2)
enabling knowledge engineering in natural language. Additionally, we formulate
key open research questions to tackle these directions.
","['knowledge', 'engineering', 'discipline', 'focuses', 'creation', 'maintenance', 'processes', 'generate', 'apply', 'knowledge', '.', 'traditionally', ',', 'knowledge', 'engineering', 'approaches', 'focused', 'knowledge', 'expressed', 'formal', 'languages', '.', 'emergence', 'large', 'language', 'models', 'capabilities', 'effectively', 'work', 'natural', 'language', ',', 'broadest', 'sense', ',', 'raises', 'questions', 'foundations', 'practice', 'knowledge', 'engineering', '.', ',', 'outline', 'potential', 'role', 'llms', 'knowledge', 'engineering', ',', 'identifying', 'two', 'central', 'directions', ':', '1', ')', 'creating', 'hybrid', 'neuro-symbolic', 'knowledge', 'systems', ';', '2', ')', 'enabling', 'knowledge', 'engineering', 'natural', 'language', '.', 'additionally', ',', 'formulate', 'key', 'open', 'research', 'questions', 'tackle', 'directions', '.']","knowledge, engineering, discipline, focuses, creation, maintenance, processes, generate, apply, knowledge, ., traditionally, ,, knowledge, engineering, approaches, focused, knowledge, expressed, formal, languages, ., emergence, large, language, models, capabilities, effectively, work, natural, language, ,, broadest, sense, ,, raises, questions, foundations, practice, knowledge, engineering, ., ,, outline, potential, role, llms, knowledge, engineering, ,, identifying, two, central, directions, :, 1, ), creating, hybrid, neuro-symbolic, knowledge, systems, ;, 2, ), enabling, knowledge, engineering, natural, language, ., additionally, ,, formulate, key, open, research, questions, tackle, directions, ."
"Formal concept analysis for evaluating intrinsic dimension of a natural
  language","Sergei O. Kuznetsov, Vasilii A. Gromov, Nikita S. Borodin, Andrei M. Divavin",2023-11-17T20:48:58Z,"  Some results of a computational experiment for determining the intrinsic
dimension of linguistic varieties for the Bengali and Russian languages are
presented. At the same time, both sets of words and sets of bigrams in these
languages were considered separately. The method used to solve this problem was
based on formal concept analysis algorithms. It was found that the intrinsic
dimensions of these languages are significantly less than the dimensions used
in popular neural network models in natural language processing.
","['results', 'computational', 'experiment', 'determining', 'intrinsic', 'dimension', 'linguistic', 'varieties', 'bengali', 'russian', 'languages', 'presented', '.', 'time', ',', 'sets', 'words', 'sets', 'bigrams', 'languages', 'considered', 'separately', '.', 'method', 'used', 'solve', 'problem', 'based', 'formal', 'concept', 'analysis', 'algorithms', '.', 'found', 'intrinsic', 'dimensions', 'languages', 'significantly', 'less', 'dimensions', 'used', 'popular', 'neural', 'network', 'models', 'natural', 'language', 'processing', '.']","results, computational, experiment, determining, intrinsic, dimension, linguistic, varieties, bengali, russian, languages, presented, ., time, ,, sets, words, sets, bigrams, languages, considered, separately, ., method, used, solve, problem, based, formal, concept, analysis, algorithms, ., found, intrinsic, dimensions, languages, significantly, less, dimensions, used, popular, neural, network, models, natural, language, processing, ."
An Assessment of the Impact of OCR Noise on Language Models,"Konstantin Todorov, Giovanni Colavizza",2022-01-26T21:56:14Z,"  Neural language models are the backbone of modern-day natural language
processing applications. Their use on textual heritage collections which have
undergone Optical Character Recognition (OCR) is therefore also increasing.
Nevertheless, our understanding of the impact OCR noise could have on language
models is still limited. We perform an assessment of the impact OCR noise has
on a variety of language models, using data in Dutch, English, French and
German. We find that OCR noise poses a significant obstacle to language
modelling, with language models increasingly diverging from their noiseless
targets as OCR quality lowers. In the presence of small corpora, simpler models
including PPMI and Word2Vec consistently outperform transformer-based models in
this respect.
","['neural', 'language', 'models', 'backbone', 'modern-day', 'natural', 'language', 'processing', 'applications', '.', 'use', 'textual', 'heritage', 'collections', 'undergone', 'optical', 'character', 'recognition', '(', 'ocr', ')', 'therefore', 'also', 'increasing', '.', 'nevertheless', ',', 'understanding', 'impact', 'ocr', 'noise', 'could', 'language', 'models', 'still', 'limited', '.', 'perform', 'assessment', 'impact', 'ocr', 'noise', 'variety', 'language', 'models', ',', 'using', 'data', 'dutch', ',', 'english', ',', 'french', 'german', '.', 'find', 'ocr', 'noise', 'poses', 'significant', 'obstacle', 'language', 'modelling', ',', 'language', 'models', 'increasingly', 'diverging', 'noiseless', 'targets', 'ocr', 'quality', 'lowers', '.', 'presence', 'small', 'corpora', ',', 'simpler', 'models', 'including', 'ppmi', 'word2vec', 'consistently', 'outperform', 'transformer-based', 'models', 'respect', '.']","neural, language, models, backbone, modern-day, natural, language, processing, applications, ., use, textual, heritage, collections, undergone, optical, character, recognition, (, ocr, ), therefore, also, increasing, ., nevertheless, ,, understanding, impact, ocr, noise, could, language, models, still, limited, ., perform, assessment, impact, ocr, noise, variety, language, models, ,, using, data, dutch, ,, english, ,, french, german, ., find, ocr, noise, poses, significant, obstacle, language, modelling, ,, language, models, increasingly, diverging, noiseless, targets, ocr, quality, lowers, ., presence, small, corpora, ,, simpler, models, including, ppmi, word2vec, consistently, outperform, transformer-based, models, respect, ."
Novi jezički modeli za srpski jezik,Mihailo Škorić,2024-02-22T08:48:21Z,"  The paper will briefly present the development history of transformer-based
language models for the Serbian language. Several new models for text
generation and vectorization, trained on the resources of the Society for
Language Resources and Technologies, will also be presented. Ten selected
vectorization models for Serbian, including two new ones, will be compared on
four natural language processing tasks. Paper will analyze which models are the
best for each selected task, how does their size and the size of their training
sets affect the performance on those tasks, and what is the optimal setting to
train the best language models for the Serbian language.
","['paper', 'briefly', 'present', 'development', 'history', 'transformer-based', 'language', 'models', 'serbian', 'language', '.', 'several', 'new', 'models', 'text', 'generation', 'vectorization', ',', 'trained', 'resources', 'society', 'language', 'resources', 'technologies', ',', 'also', 'presented', '.', 'ten', 'selected', 'vectorization', 'models', 'serbian', ',', 'including', 'two', 'new', 'ones', ',', 'compared', 'four', 'natural', 'language', 'processing', 'tasks', '.', 'paper', 'analyze', 'models', 'best', 'selected', 'task', ',', 'size', 'size', 'training', 'sets', 'affect', 'performance', 'tasks', ',', 'optimal', 'setting', 'train', 'best', 'language', 'models', 'serbian', 'language', '.']","paper, briefly, present, development, history, transformer-based, language, models, serbian, language, ., several, new, models, text, generation, vectorization, ,, trained, resources, society, language, resources, technologies, ,, also, presented, ., ten, selected, vectorization, models, serbian, ,, including, two, new, ones, ,, compared, four, natural, language, processing, tasks, ., paper, analyze, models, best, selected, task, ,, size, size, training, sets, affect, performance, tasks, ,, optimal, setting, train, best, language, models, serbian, language, ."
"Saving the legacy of Hero Ibash: Evaluating Four Language Models for
  Aminoacian","Yunze Xiao, Yiyang Pan",2024-02-28T07:22:13Z,"  This study assesses four cutting-edge language models in the underexplored
Aminoacian language. Through evaluation, it scrutinizes their adaptability,
effectiveness, and limitations in text generation, semantic coherence, and
contextual understanding. Uncovering insights into these models' performance in
a low-resourced language, this research pioneers pathways to bridge linguistic
gaps. By offering benchmarks and understanding challenges, it lays groundwork
for future advancements in natural language processing, aiming to elevate the
applicability of language models in similar linguistic landscapes, marking a
significant step toward inclusivity and progress in language technology.
","['study', 'assesses', 'four', 'cutting-edge', 'language', 'models', 'underexplored', 'aminoacian', 'language', '.', 'evaluation', ',', 'scrutinizes', 'adaptability', ',', 'effectiveness', ',', 'limitations', 'text', 'generation', ',', 'semantic', 'coherence', ',', 'contextual', 'understanding', '.', 'uncovering', 'insights', 'models', ""'"", 'performance', 'low-resourced', 'language', ',', 'research', 'pioneers', 'pathways', 'bridge', 'linguistic', 'gaps', '.', 'offering', 'benchmarks', 'understanding', 'challenges', ',', 'lays', 'groundwork', 'future', 'advancements', 'natural', 'language', 'processing', ',', 'aiming', 'elevate', 'applicability', 'language', 'models', 'similar', 'linguistic', 'landscapes', ',', 'marking', 'significant', 'step', 'toward', 'inclusivity', 'progress', 'language', 'technology', '.']","study, assesses, four, cutting-edge, language, models, underexplored, aminoacian, language, ., evaluation, ,, scrutinizes, adaptability, ,, effectiveness, ,, limitations, text, generation, ,, semantic, coherence, ,, contextual, understanding, ., uncovering, insights, models, ', performance, low-resourced, language, ,, research, pioneers, pathways, bridge, linguistic, gaps, ., offering, benchmarks, understanding, challenges, ,, lays, groundwork, future, advancements, natural, language, processing, ,, aiming, elevate, applicability, language, models, similar, linguistic, landscapes, ,, marking, significant, step, toward, inclusivity, progress, language, technology, ."
Scientific Computing with Large Language Models,"Christopher Culver, Peter Hicks, Mihailo Milenkovic, Sanjif Shanmugavelu, Tobias Becker",2024-06-11T13:39:07Z,"  We provide an overview of the emergence of large language models for
scientific computing applications. We highlight use cases that involve natural
language processing of scientific documents and specialized languages designed
to describe physical systems. For the former, chatbot style applications appear
in medicine, mathematics and physics and can be used iteratively with domain
experts for problem solving. We also review specialized languages within
molecular biology, the languages of molecules, proteins, and DNA where language
models are being used to predict properties and even create novel physical
systems at much faster rates than traditional computing methods.
","['provide', 'overview', 'emergence', 'large', 'language', 'models', 'scientific', 'computing', 'applications', '.', 'highlight', 'use', 'cases', 'involve', 'natural', 'language', 'processing', 'scientific', 'documents', 'specialized', 'languages', 'designed', 'describe', 'physical', 'systems', '.', 'former', ',', 'chatbot', 'style', 'applications', 'appear', 'medicine', ',', 'mathematics', 'physics', 'used', 'iteratively', 'domain', 'experts', 'problem', 'solving', '.', 'also', 'review', 'specialized', 'languages', 'within', 'molecular', 'biology', ',', 'languages', 'molecules', ',', 'proteins', ',', 'dna', 'language', 'models', 'used', 'predict', 'properties', 'even', 'create', 'novel', 'physical', 'systems', 'much', 'faster', 'rates', 'traditional', 'computing', 'methods', '.']","provide, overview, emergence, large, language, models, scientific, computing, applications, ., highlight, use, cases, involve, natural, language, processing, scientific, documents, specialized, languages, designed, describe, physical, systems, ., former, ,, chatbot, style, applications, appear, medicine, ,, mathematics, physics, used, iteratively, domain, experts, problem, solving, ., also, review, specialized, languages, within, molecular, biology, ,, languages, molecules, ,, proteins, ,, dna, language, models, used, predict, properties, even, create, novel, physical, systems, much, faster, rates, traditional, computing, methods, ."
"Evolution of Natural Language Processing Technology: Not Just Language
  Processing Towards General Purpose AI",Masahiro Yamamoto,2023-10-10T00:41:38Z,"  Since the invention of computers, communication through natural language
(actual human language) has been a dream technology. However, natural language
is extremely difficult to mathematically formulate, making it difficult to
realize as an algorithm without considering programming. While there have been
numerous technological developments, one cannot say that any results allowing
free utilization have been achieved thus far. In the case of language learning
in humans, for instance when learning one's mother tongue or foreign language,
one must admit that this process is similar to the adage ""practice makes
perfect"" in principle, even though the learning method is significant up to a
point. Deep learning has played a central role in contemporary AI technology in
recent years. When applied to natural language processing (NLP), this produced
unprecedented results. Achievements exceeding the initial predictions have been
reported from the results of learning vast amounts of textual data using deep
learning. For instance, four arithmetic operations could be performed without
explicit learning, thereby enabling the explanation of complex images and the
generation of images from corresponding explanatory texts. It is an accurate
example of the learner embodying the concept of ""practice makes perfect"" by
using vast amounts of textual data. This report provides a technological
explanation of how cutting-edge NLP has made it possible to realize the
""practice makes perfect"" principle. Additionally, examples of how this can be
applied to business are provided. We reported in June 2022 in Japanese on the
NLP movement from late 2021 to early 2022. We would like to summarize this as a
memorandum since this is just the initial movement leading to the current large
language models (LLMs).
","['since', 'invention', 'computers', ',', 'communication', 'natural', 'language', '(', 'actual', 'human', 'language', ')', 'dream', 'technology', '.', 'however', ',', 'natural', 'language', 'extremely', 'difficult', 'mathematically', 'formulate', ',', 'making', 'difficult', 'realize', 'algorithm', 'without', 'considering', 'programming', '.', 'numerous', 'technological', 'developments', ',', 'one', 'say', 'results', 'allowing', 'free', 'utilization', 'achieved', 'thus', 'far', '.', 'case', 'language', 'learning', 'humans', ',', 'instance', 'learning', 'one', ""'s"", 'mother', 'tongue', 'foreign', 'language', ',', 'one', 'must', 'admit', 'process', 'similar', 'adage', '``', 'practice', 'makes', 'perfect', ""''"", 'principle', ',', 'even', 'though', 'learning', 'method', 'significant', 'point', '.', 'deep', 'learning', 'played', 'central', 'role', 'contemporary', 'ai', 'technology', 'recent', 'years', '.', 'applied', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'produced', 'unprecedented', 'results', '.', 'achievements', 'exceeding', 'initial', 'predictions', 'reported', 'results', 'learning', 'vast', 'amounts', 'textual', 'data', 'using', 'deep', 'learning', '.', 'instance', ',', 'four', 'arithmetic', 'operations', 'could', 'performed', 'without', 'explicit', 'learning', ',', 'thereby', 'enabling', 'explanation', 'complex', 'images', 'generation', 'images', 'corresponding', 'explanatory', 'texts', '.', 'accurate', 'example', 'learner', 'embodying', 'concept', '``', 'practice', 'makes', 'perfect', ""''"", 'using', 'vast', 'amounts', 'textual', 'data', '.', 'report', 'provides', 'technological', 'explanation', 'cutting-edge', 'nlp', 'made', 'possible', 'realize', ""''"", 'practice', 'makes', 'perfect', ""''"", 'principle', '.', 'additionally', ',', 'examples', 'applied', 'business', 'provided', '.', 'reported', 'june', '2022', 'japanese', 'nlp', 'movement', 'late', '2021', 'early', '2022.', 'would', 'like', 'summarize', 'memorandum', 'since', 'initial', 'movement', 'leading', 'current', 'large', 'language', 'models', '(', 'llms', ')', '.']","since, invention, computers, ,, communication, natural, language, (, actual, human, language, ), dream, technology, ., however, ,, natural, language, extremely, difficult, mathematically, formulate, ,, making, difficult, realize, algorithm, without, considering, programming, ., numerous, technological, developments, ,, one, say, results, allowing, free, utilization, achieved, thus, far, ., case, language, learning, humans, ,, instance, learning, one, 's, mother, tongue, foreign, language, ,, one, must, admit, process, similar, adage, ``, practice, makes, perfect, '', principle, ,, even, though, learning, method, significant, point, ., deep, learning, played, central, role, contemporary, ai, technology, recent, years, ., applied, natural, language, processing, (, nlp, ), ,, produced, unprecedented, results, ., achievements, exceeding, initial, predictions, reported, results, learning, vast, amounts, textual, data, using, deep, learning, ., instance, ,, four, arithmetic, operations, could, performed, without, explicit, learning, ,, thereby, enabling, explanation, complex, images, generation, images, corresponding, explanatory, texts, ., accurate, example, learner, embodying, concept, ``, practice, makes, perfect, '', using, vast, amounts, textual, data, ., report, provides, technological, explanation, cutting-edge, nlp, made, possible, realize, '', practice, makes, perfect, '', principle, ., additionally, ,, examples, applied, business, provided, ., reported, june, 2022, japanese, nlp, movement, late, 2021, early, 2022., would, like, summarize, memorandum, since, initial, movement, leading, current, large, language, models, (, llms, ), ."
CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex,Immanuel Trummer,2022-04-19T15:19:35Z,"  CodexDB is an SQL processing engine whose internals can be customized via
natural language instructions. CodexDB is based on OpenAI's GPT-3 Codex model
which translates text into code. It is a framework on top of GPT-3 Codex that
decomposes complex SQL queries into a series of simple processing steps,
described in natural language. Processing steps are enriched with user-provided
instructions and descriptions of database properties. Codex translates the
resulting text into query processing code. An early prototype of CodexDB is
able to generate correct code for a majority of queries of the WikiSQL
benchmark and can be customized in various ways.
","['codexdb', 'sql', 'processing', 'engine', 'whose', 'internals', 'customized', 'via', 'natural', 'language', 'instructions', '.', 'codexdb', 'based', 'openai', ""'s"", 'gpt-3', 'codex', 'model', 'translates', 'text', 'code', '.', 'framework', 'top', 'gpt-3', 'codex', 'decomposes', 'complex', 'sql', 'queries', 'series', 'simple', 'processing', 'steps', ',', 'described', 'natural', 'language', '.', 'processing', 'steps', 'enriched', 'user-provided', 'instructions', 'descriptions', 'database', 'properties', '.', 'codex', 'translates', 'resulting', 'text', 'query', 'processing', 'code', '.', 'early', 'prototype', 'codexdb', 'able', 'generate', 'correct', 'code', 'majority', 'queries', 'wikisql', 'benchmark', 'customized', 'various', 'ways', '.']","codexdb, sql, processing, engine, whose, internals, customized, via, natural, language, instructions, ., codexdb, based, openai, 's, gpt-3, codex, model, translates, text, code, ., framework, top, gpt-3, codex, decomposes, complex, sql, queries, series, simple, processing, steps, ,, described, natural, language, ., processing, steps, enriched, user-provided, instructions, descriptions, database, properties, ., codex, translates, resulting, text, query, processing, code, ., early, prototype, codexdb, able, generate, correct, code, majority, queries, wikisql, benchmark, customized, various, ways, ."
"Machine Translation between Spoken Languages and Signed Languages
  Represented in SignWriting","Zifan Jiang, Amit Moryossef, Mathias Müller, Sarah Ebling",2022-10-11T12:28:06Z,"  This paper presents work on novel machine translation (MT) systems between
spoken and signed languages, where signed languages are represented in
SignWriting, a sign language writing system. Our work seeks to address the lack
of out-of-the-box support for signed languages in current MT systems and is
based on the SignBank dataset, which contains pairs of spoken language text and
SignWriting content. We introduce novel methods to parse, factorize, decode,
and evaluate SignWriting, leveraging ideas from neural factored MT. In a
bilingual setup--translating from American Sign Language to (American)
English--our method achieves over 30 BLEU, while in two multilingual
setups--translating in both directions between spoken languages and signed
languages--we achieve over 20 BLEU. We find that common MT techniques used to
improve spoken language translation similarly affect the performance of sign
language translation. These findings validate our use of an intermediate text
representation for signed languages to include them in natural language
processing research.
","['paper', 'presents', 'work', 'novel', 'machine', 'translation', '(', 'mt', ')', 'systems', 'spoken', 'signed', 'languages', ',', 'signed', 'languages', 'represented', 'signwriting', ',', 'sign', 'language', 'writing', 'system', '.', 'work', 'seeks', 'address', 'lack', 'out-of-the-box', 'support', 'signed', 'languages', 'current', 'mt', 'systems', 'based', 'signbank', 'dataset', ',', 'contains', 'pairs', 'spoken', 'language', 'text', 'signwriting', 'content', '.', 'introduce', 'novel', 'methods', 'parse', ',', 'factorize', ',', 'decode', ',', 'evaluate', 'signwriting', ',', 'leveraging', 'ideas', 'neural', 'factored', 'mt', '.', 'bilingual', 'setup', '--', 'translating', 'american', 'sign', 'language', '(', 'american', ')', 'english', '--', 'method', 'achieves', '30', 'bleu', ',', 'two', 'multilingual', 'setups', '--', 'translating', 'directions', 'spoken', 'languages', 'signed', 'languages', '--', 'achieve', '20', 'bleu', '.', 'find', 'common', 'mt', 'techniques', 'used', 'improve', 'spoken', 'language', 'translation', 'similarly', 'affect', 'performance', 'sign', 'language', 'translation', '.', 'findings', 'validate', 'use', 'intermediate', 'text', 'representation', 'signed', 'languages', 'include', 'natural', 'language', 'processing', 'research', '.']","paper, presents, work, novel, machine, translation, (, mt, ), systems, spoken, signed, languages, ,, signed, languages, represented, signwriting, ,, sign, language, writing, system, ., work, seeks, address, lack, out-of-the-box, support, signed, languages, current, mt, systems, based, signbank, dataset, ,, contains, pairs, spoken, language, text, signwriting, content, ., introduce, novel, methods, parse, ,, factorize, ,, decode, ,, evaluate, signwriting, ,, leveraging, ideas, neural, factored, mt, ., bilingual, setup, --, translating, american, sign, language, (, american, ), english, --, method, achieves, 30, bleu, ,, two, multilingual, setups, --, translating, directions, spoken, languages, signed, languages, --, achieve, 20, bleu, ., find, common, mt, techniques, used, improve, spoken, language, translation, similarly, affect, performance, sign, language, translation, ., findings, validate, use, intermediate, text, representation, signed, languages, include, natural, language, processing, research, ."
How Good are Commercial Large Language Models on African Languages?,"Jessica Ojo, Kelechi Ogueji",2023-05-11T02:29:53Z,"  Recent advancements in Natural Language Processing (NLP) has led to the
proliferation of large pretrained language models. These models have been shown
to yield good performance, using in-context learning, even on unseen tasks and
languages. They have also been exposed as commercial APIs as a form of
language-model-as-a-service, with great adoption. However, their performance on
African languages is largely unknown. We present a preliminary analysis of
commercial large language models on two tasks (machine translation and text
classification) across eight African languages, spanning different language
families and geographical areas. Our results suggest that commercial language
models produce below-par performance on African languages. We also find that
they perform better on text classification than machine translation. In
general, our findings present a call-to-action to ensure African languages are
well represented in commercial large language models, given their growing
popularity.
","['recent', 'advancements', 'natural', 'language', 'processing', '(', 'nlp', ')', 'led', 'proliferation', 'large', 'pretrained', 'language', 'models', '.', 'models', 'shown', 'yield', 'good', 'performance', ',', 'using', 'in-context', 'learning', ',', 'even', 'unseen', 'tasks', 'languages', '.', 'also', 'exposed', 'commercial', 'apis', 'form', 'language-model-as-a-service', ',', 'great', 'adoption', '.', 'however', ',', 'performance', 'african', 'languages', 'largely', 'unknown', '.', 'present', 'preliminary', 'analysis', 'commercial', 'large', 'language', 'models', 'two', 'tasks', '(', 'machine', 'translation', 'text', 'classification', ')', 'across', 'eight', 'african', 'languages', ',', 'spanning', 'different', 'language', 'families', 'geographical', 'areas', '.', 'results', 'suggest', 'commercial', 'language', 'models', 'produce', 'below-par', 'performance', 'african', 'languages', '.', 'also', 'find', 'perform', 'better', 'text', 'classification', 'machine', 'translation', '.', 'general', ',', 'findings', 'present', 'call-to-action', 'ensure', 'african', 'languages', 'well', 'represented', 'commercial', 'large', 'language', 'models', ',', 'given', 'growing', 'popularity', '.']","recent, advancements, natural, language, processing, (, nlp, ), led, proliferation, large, pretrained, language, models, ., models, shown, yield, good, performance, ,, using, in-context, learning, ,, even, unseen, tasks, languages, ., also, exposed, commercial, apis, form, language-model-as-a-service, ,, great, adoption, ., however, ,, performance, african, languages, largely, unknown, ., present, preliminary, analysis, commercial, large, language, models, two, tasks, (, machine, translation, text, classification, ), across, eight, african, languages, ,, spanning, different, language, families, geographical, areas, ., results, suggest, commercial, language, models, produce, below-par, performance, african, languages, ., also, find, perform, better, text, classification, machine, translation, ., general, ,, findings, present, call-to-action, ensure, african, languages, well, represented, commercial, large, language, models, ,, given, growing, popularity, ."
"Multilingual Brain Surgeon: Large Language Models Can be Compressed
  Leaving No Language Behind","Hongchuan Zeng, Hongshen Xu, Lu Chen, Kai Yu",2024-04-06T22:16:32Z,"  Large Language Models (LLMs) have ushered in a new era in Natural Language
Processing, but their massive size demands effective compression techniques for
practicality. Although numerous model compression techniques have been
investigated, they typically rely on a calibration set that overlooks the
multilingual context and results in significant accuracy degradation for
low-resource languages. This paper introduces Multilingual Brain Surgeon (MBS),
a novel calibration data sampling method for multilingual LLMs compression. MBS
overcomes the English-centric limitations of existing methods by sampling
calibration data from various languages proportionally to the language
distribution of the model training datasets. Our experiments, conducted on the
BLOOM multilingual LLM, demonstrate that MBS improves the performance of
existing English-centric compression methods, especially for low-resource
languages. We also uncover the dynamics of language interaction during
compression, revealing that the larger the proportion of a language in the
training set and the more similar the language is to the calibration language,
the better performance the language retains after compression. In conclusion,
MBS presents an innovative approach to compressing multilingual LLMs,
addressing the performance disparities and improving the language inclusivity
of existing compression techniques.
","['large', 'language', 'models', '(', 'llms', ')', 'ushered', 'new', 'era', 'natural', 'language', 'processing', ',', 'massive', 'size', 'demands', 'effective', 'compression', 'techniques', 'practicality', '.', 'although', 'numerous', 'model', 'compression', 'techniques', 'investigated', ',', 'typically', 'rely', 'calibration', 'set', 'overlooks', 'multilingual', 'context', 'results', 'significant', 'accuracy', 'degradation', 'low-resource', 'languages', '.', 'paper', 'introduces', 'multilingual', 'brain', 'surgeon', '(', 'mbs', ')', ',', 'novel', 'calibration', 'data', 'sampling', 'method', 'multilingual', 'llms', 'compression', '.', 'mbs', 'overcomes', 'english-centric', 'limitations', 'existing', 'methods', 'sampling', 'calibration', 'data', 'various', 'languages', 'proportionally', 'language', 'distribution', 'model', 'training', 'datasets', '.', 'experiments', ',', 'conducted', 'bloom', 'multilingual', 'llm', ',', 'demonstrate', 'mbs', 'improves', 'performance', 'existing', 'english-centric', 'compression', 'methods', ',', 'especially', 'low-resource', 'languages', '.', 'also', 'uncover', 'dynamics', 'language', 'interaction', 'compression', ',', 'revealing', 'larger', 'proportion', 'language', 'training', 'set', 'similar', 'language', 'calibration', 'language', ',', 'better', 'performance', 'language', 'retains', 'compression', '.', 'conclusion', ',', 'mbs', 'presents', 'innovative', 'approach', 'compressing', 'multilingual', 'llms', ',', 'addressing', 'performance', 'disparities', 'improving', 'language', 'inclusivity', 'existing', 'compression', 'techniques', '.']","large, language, models, (, llms, ), ushered, new, era, natural, language, processing, ,, massive, size, demands, effective, compression, techniques, practicality, ., although, numerous, model, compression, techniques, investigated, ,, typically, rely, calibration, set, overlooks, multilingual, context, results, significant, accuracy, degradation, low-resource, languages, ., paper, introduces, multilingual, brain, surgeon, (, mbs, ), ,, novel, calibration, data, sampling, method, multilingual, llms, compression, ., mbs, overcomes, english-centric, limitations, existing, methods, sampling, calibration, data, various, languages, proportionally, language, distribution, model, training, datasets, ., experiments, ,, conducted, bloom, multilingual, llm, ,, demonstrate, mbs, improves, performance, existing, english-centric, compression, methods, ,, especially, low-resource, languages, ., also, uncover, dynamics, language, interaction, compression, ,, revealing, larger, proportion, language, training, set, similar, language, calibration, language, ,, better, performance, language, retains, compression, ., conclusion, ,, mbs, presents, innovative, approach, compressing, multilingual, llms, ,, addressing, performance, disparities, improving, language, inclusivity, existing, compression, techniques, ."
"COOL, a Context Outlooker, and its Application to Question Answering and
  other Natural Language Processing Tasks","Fangyi Zhu, See-Kiong Ng, Stéphane Bressan",2022-04-01T07:03:40Z,"  Vision outlooker improves the performance of vision transformers, which
implements a self-attention mechanism by adding an outlook attention, a form of
local attention.
  In natural language processing, as has been the case in computer vision and
other domains, transformer-based models constitute the state-of-the-art for
most processing tasks. In this domain, too, many authors have argued and
demonstrated the importance of local context.
  We present an outlook attention mechanism, COOL, for natural language
processing. COOL, added on top of the self-attention layers of a
transformer-based model, encodes local syntactic context considering word
proximity and more pair-wise constraints than dynamic convolution used by
existing approaches.
  A comparative empirical performance evaluation of an implementation of COOL
with different transformer-based models confirms the opportunity for
improvement over a baseline using the original models alone for various natural
language processing tasks, including question answering. The proposed approach
achieves competitive performance with existing state-of-the-art methods on some
tasks.
","['vision', 'outlooker', 'improves', 'performance', 'vision', 'transformers', ',', 'implements', 'self-attention', 'mechanism', 'adding', 'outlook', 'attention', ',', 'form', 'local', 'attention', '.', 'natural', 'language', 'processing', ',', 'case', 'computer', 'vision', 'domains', ',', 'transformer-based', 'models', 'constitute', 'state-of-the-art', 'processing', 'tasks', '.', 'domain', ',', ',', 'many', 'authors', 'argued', 'demonstrated', 'importance', 'local', 'context', '.', 'present', 'outlook', 'attention', 'mechanism', ',', 'cool', ',', 'natural', 'language', 'processing', '.', 'cool', ',', 'added', 'top', 'self-attention', 'layers', 'transformer-based', 'model', ',', 'encodes', 'local', 'syntactic', 'context', 'considering', 'word', 'proximity', 'pair-wise', 'constraints', 'dynamic', 'convolution', 'used', 'existing', 'approaches', '.', 'comparative', 'empirical', 'performance', 'evaluation', 'implementation', 'cool', 'different', 'transformer-based', 'models', 'confirms', 'opportunity', 'improvement', 'baseline', 'using', 'original', 'models', 'alone', 'various', 'natural', 'language', 'processing', 'tasks', ',', 'including', 'question', 'answering', '.', 'proposed', 'approach', 'achieves', 'competitive', 'performance', 'existing', 'state-of-the-art', 'methods', 'tasks', '.']","vision, outlooker, improves, performance, vision, transformers, ,, implements, self-attention, mechanism, adding, outlook, attention, ,, form, local, attention, ., natural, language, processing, ,, case, computer, vision, domains, ,, transformer-based, models, constitute, state-of-the-art, processing, tasks, ., domain, ,, ,, many, authors, argued, demonstrated, importance, local, context, ., present, outlook, attention, mechanism, ,, cool, ,, natural, language, processing, ., cool, ,, added, top, self-attention, layers, transformer-based, model, ,, encodes, local, syntactic, context, considering, word, proximity, pair-wise, constraints, dynamic, convolution, used, existing, approaches, ., comparative, empirical, performance, evaluation, implementation, cool, different, transformer-based, models, confirms, opportunity, improvement, baseline, using, original, models, alone, various, natural, language, processing, tasks, ,, including, question, answering, ., proposed, approach, achieves, competitive, performance, existing, state-of-the-art, methods, tasks, ."
"From Natural Language Instructions to Complex Processes: Issues in
  Chaining Trigger Action Rules","Nobuhiro Ito, Yuya Suzuki, Akiko Aizawa",2020-01-08T11:44:47Z,"  Automation services for complex business processes usually require a high
level of information technology literacy. There is a strong demand for a
smartly assisted process automation (IPA: intelligent process automation)
service that enables even general users to easily use advanced automation. A
natural language interface for such automation is expected as an elemental
technology for the IPA realization. The workflow targeted by IPA is generally
composed of a combination of multiple tasks. However, semantic parsing, one of
the natural language processing methods, for such complex workflows has not yet
been fully studied. The reasons are that (1) the formal expression and grammar
of the workflow required for semantic analysis have not been sufficiently
examined and (2) the dataset of the workflow formal expression with its
corresponding natural language description required for learning workflow
semantics did not exist. This paper defines a new grammar for complex workflows
with chaining machine-executable meaning representations for semantic parsing.
The representations are at a high abstraction level. Additionally, an approach
to creating datasets is proposed based on this grammar.
","['automation', 'services', 'complex', 'business', 'processes', 'usually', 'require', 'high', 'level', 'information', 'technology', 'literacy', '.', 'strong', 'demand', 'smartly', 'assisted', 'process', 'automation', '(', 'ipa', ':', 'intelligent', 'process', 'automation', ')', 'service', 'enables', 'even', 'general', 'users', 'easily', 'use', 'advanced', 'automation', '.', 'natural', 'language', 'interface', 'automation', 'expected', 'elemental', 'technology', 'ipa', 'realization', '.', 'workflow', 'targeted', 'ipa', 'generally', 'composed', 'combination', 'multiple', 'tasks', '.', 'however', ',', 'semantic', 'parsing', ',', 'one', 'natural', 'language', 'processing', 'methods', ',', 'complex', 'workflows', 'yet', 'fully', 'studied', '.', 'reasons', '(', '1', ')', 'formal', 'expression', 'grammar', 'workflow', 'required', 'semantic', 'analysis', 'sufficiently', 'examined', '(', '2', ')', 'dataset', 'workflow', 'formal', 'expression', 'corresponding', 'natural', 'language', 'description', 'required', 'learning', 'workflow', 'semantics', 'exist', '.', 'paper', 'defines', 'new', 'grammar', 'complex', 'workflows', 'chaining', 'machine-executable', 'meaning', 'representations', 'semantic', 'parsing', '.', 'representations', 'high', 'abstraction', 'level', '.', 'additionally', ',', 'approach', 'creating', 'datasets', 'proposed', 'based', 'grammar', '.']","automation, services, complex, business, processes, usually, require, high, level, information, technology, literacy, ., strong, demand, smartly, assisted, process, automation, (, ipa, :, intelligent, process, automation, ), service, enables, even, general, users, easily, use, advanced, automation, ., natural, language, interface, automation, expected, elemental, technology, ipa, realization, ., workflow, targeted, ipa, generally, composed, combination, multiple, tasks, ., however, ,, semantic, parsing, ,, one, natural, language, processing, methods, ,, complex, workflows, yet, fully, studied, ., reasons, (, 1, ), formal, expression, grammar, workflow, required, semantic, analysis, sufficiently, examined, (, 2, ), dataset, workflow, formal, expression, corresponding, natural, language, description, required, learning, workflow, semantics, exist, ., paper, defines, new, grammar, complex, workflows, chaining, machine-executable, meaning, representations, semantic, parsing, ., representations, high, abstraction, level, ., additionally, ,, approach, creating, datasets, proposed, based, grammar, ."
Exploring Software Naturalness through Neural Language Models,"Luca Buratti, Saurabh Pujar, Mihaela Bornea, Scott McCarley, Yunhui Zheng, Gaetano Rossiello, Alessandro Morari, Jim Laredo, Veronika Thost, Yufan Zhuang, Giacomo Domeniconi",2020-06-22T21:56:14Z,"  The Software Naturalness hypothesis argues that programming languages can be
understood through the same techniques used in natural language processing. We
explore this hypothesis through the use of a pre-trained transformer-based
language model to perform code analysis tasks. Present approaches to code
analysis depend heavily on features derived from the Abstract Syntax Tree (AST)
while our transformer-based language models work on raw source code. This work
is the first to investigate whether such language models can discover AST
features automatically. To achieve this, we introduce a sequence labeling task
that directly probes the language models understanding of AST. Our results show
that transformer based language models achieve high accuracy in the AST tagging
task. Furthermore, we evaluate our model on a software vulnerability
identification task. Importantly, we show that our approach obtains
vulnerability identification results comparable to graph based approaches that
rely heavily on compilers for feature extraction.
","['software', 'naturalness', 'hypothesis', 'argues', 'programming', 'languages', 'understood', 'techniques', 'used', 'natural', 'language', 'processing', '.', 'explore', 'hypothesis', 'use', 'pre-trained', 'transformer-based', 'language', 'model', 'perform', 'code', 'analysis', 'tasks', '.', 'present', 'approaches', 'code', 'analysis', 'depend', 'heavily', 'features', 'derived', 'abstract', 'syntax', 'tree', '(', 'ast', ')', 'transformer-based', 'language', 'models', 'work', 'raw', 'source', 'code', '.', 'work', 'first', 'investigate', 'whether', 'language', 'models', 'discover', 'ast', 'features', 'automatically', '.', 'achieve', ',', 'introduce', 'sequence', 'labeling', 'task', 'directly', 'probes', 'language', 'models', 'understanding', 'ast', '.', 'results', 'show', 'transformer', 'based', 'language', 'models', 'achieve', 'high', 'accuracy', 'ast', 'tagging', 'task', '.', 'furthermore', ',', 'evaluate', 'model', 'software', 'vulnerability', 'identification', 'task', '.', 'importantly', ',', 'show', 'approach', 'obtains', 'vulnerability', 'identification', 'results', 'comparable', 'graph', 'based', 'approaches', 'rely', 'heavily', 'compilers', 'feature', 'extraction', '.']","software, naturalness, hypothesis, argues, programming, languages, understood, techniques, used, natural, language, processing, ., explore, hypothesis, use, pre-trained, transformer-based, language, model, perform, code, analysis, tasks, ., present, approaches, code, analysis, depend, heavily, features, derived, abstract, syntax, tree, (, ast, ), transformer-based, language, models, work, raw, source, code, ., work, first, investigate, whether, language, models, discover, ast, features, automatically, ., achieve, ,, introduce, sequence, labeling, task, directly, probes, language, models, understanding, ast, ., results, show, transformer, based, language, models, achieve, high, accuracy, ast, tagging, task, ., furthermore, ,, evaluate, model, software, vulnerability, identification, task, ., importantly, ,, show, approach, obtains, vulnerability, identification, results, comparable, graph, based, approaches, rely, heavily, compilers, feature, extraction, ."
"From BERT to GPT-3 Codex: Harnessing the Potential of Very Large
  Language Models for Data Management",Immanuel Trummer,2023-06-15T17:59:29Z,"  Large language models have recently advanced the state of the art on many
natural language processing benchmarks. The newest generation of models can be
applied to a variety of tasks with little to no specialized training. This
technology creates various opportunities for applications in the context of
data management.
  The tutorial will introduce participants to basic background on language
models, discuss different methods to use language models, and give an overview
and short demonstration of available libraries and APIs. Models for generating
natural language will be considered as well as models, such as GPT-3 Codex,
which complete program code or generate code from natural language
instructions. Finally, the tutorial will discuss recent research in the
database community that exploits language models in the context of traditional
database systems or proposes novel system architectures that are based on them.
  The tutorial is targeted at database researchers. No prior background on
language models is required. The goal of the tutorial is to introduce database
researchers to the latest generation of language models, and to their use cases
in the domain of data management.
","['large', 'language', 'models', 'recently', 'advanced', 'state', 'art', 'many', 'natural', 'language', 'processing', 'benchmarks', '.', 'newest', 'generation', 'models', 'applied', 'variety', 'tasks', 'little', 'specialized', 'training', '.', 'technology', 'creates', 'various', 'opportunities', 'applications', 'context', 'data', 'management', '.', 'tutorial', 'introduce', 'participants', 'basic', 'background', 'language', 'models', ',', 'discuss', 'different', 'methods', 'use', 'language', 'models', ',', 'give', 'overview', 'short', 'demonstration', 'available', 'libraries', 'apis', '.', 'models', 'generating', 'natural', 'language', 'considered', 'well', 'models', ',', 'gpt-3', 'codex', ',', 'complete', 'program', 'code', 'generate', 'code', 'natural', 'language', 'instructions', '.', 'finally', ',', 'tutorial', 'discuss', 'recent', 'research', 'database', 'community', 'exploits', 'language', 'models', 'context', 'traditional', 'database', 'systems', 'proposes', 'novel', 'system', 'architectures', 'based', '.', 'tutorial', 'targeted', 'database', 'researchers', '.', 'prior', 'background', 'language', 'models', 'required', '.', 'goal', 'tutorial', 'introduce', 'database', 'researchers', 'latest', 'generation', 'language', 'models', ',', 'use', 'cases', 'domain', 'data', 'management', '.']","large, language, models, recently, advanced, state, art, many, natural, language, processing, benchmarks, ., newest, generation, models, applied, variety, tasks, little, specialized, training, ., technology, creates, various, opportunities, applications, context, data, management, ., tutorial, introduce, participants, basic, background, language, models, ,, discuss, different, methods, use, language, models, ,, give, overview, short, demonstration, available, libraries, apis, ., models, generating, natural, language, considered, well, models, ,, gpt-3, codex, ,, complete, program, code, generate, code, natural, language, instructions, ., finally, ,, tutorial, discuss, recent, research, database, community, exploits, language, models, context, traditional, database, systems, proposes, novel, system, architectures, based, ., tutorial, targeted, database, researchers, ., prior, background, language, models, required, ., goal, tutorial, introduce, database, researchers, latest, generation, language, models, ,, use, cases, domain, data, management, ."
"Improving Arithmetic Reasoning Ability of Large Language Models through
  Relation Tuples, Verification and Dynamic Feedback","Zhongtao Miao, Kaiyan Zhao, Yoshimasa Tsuruoka",2024-06-25T18:21:00Z,"  Current representations used in reasoning steps of large language models can
mostly be categorized into two main types: (1) natural language, which is
difficult to verify; and (2) non-natural language, usually programming code,
which is difficult for people who are unfamiliar with coding to read. In this
paper, we propose to use a semi-structured form to represent reasoning steps of
large language models. Specifically, we use relation tuples, which are not only
human-readable but also machine-friendly and easier to verify than natural
language. We implement a framework that includes three main components: (1)
introducing relation tuples into the reasoning steps of large language models;
(2) implementing an automatic verification process of reasoning steps with a
local code interpreter based on relation tuples; and (3) integrating a simple
and effective dynamic feedback mechanism, which we found helpful for
self-improvement of large language models. The experimental results on various
arithmetic datasets demonstrate the effectiveness of our method in improving
the arithmetic reasoning ability of large language models. The source code is
available at https://github.com/gpgg/art.
","['current', 'representations', 'used', 'reasoning', 'steps', 'large', 'language', 'models', 'mostly', 'categorized', 'two', 'main', 'types', ':', '(', '1', ')', 'natural', 'language', ',', 'difficult', 'verify', ';', '(', '2', ')', 'non-natural', 'language', ',', 'usually', 'programming', 'code', ',', 'difficult', 'people', 'unfamiliar', 'coding', 'read', '.', 'paper', ',', 'propose', 'use', 'semi-structured', 'form', 'represent', 'reasoning', 'steps', 'large', 'language', 'models', '.', 'specifically', ',', 'use', 'relation', 'tuples', ',', 'human-readable', 'also', 'machine-friendly', 'easier', 'verify', 'natural', 'language', '.', 'implement', 'framework', 'includes', 'three', 'main', 'components', ':', '(', '1', ')', 'introducing', 'relation', 'tuples', 'reasoning', 'steps', 'large', 'language', 'models', ';', '(', '2', ')', 'implementing', 'automatic', 'verification', 'process', 'reasoning', 'steps', 'local', 'code', 'interpreter', 'based', 'relation', 'tuples', ';', '(', '3', ')', 'integrating', 'simple', 'effective', 'dynamic', 'feedback', 'mechanism', ',', 'found', 'helpful', 'self-improvement', 'large', 'language', 'models', '.', 'experimental', 'results', 'various', 'arithmetic', 'datasets', 'demonstrate', 'effectiveness', 'method', 'improving', 'arithmetic', 'reasoning', 'ability', 'large', 'language', 'models', '.', 'source', 'code', 'available', 'https', ':', '//github.com/gpgg/art', '.']","current, representations, used, reasoning, steps, large, language, models, mostly, categorized, two, main, types, :, (, 1, ), natural, language, ,, difficult, verify, ;, (, 2, ), non-natural, language, ,, usually, programming, code, ,, difficult, people, unfamiliar, coding, read, ., paper, ,, propose, use, semi-structured, form, represent, reasoning, steps, large, language, models, ., specifically, ,, use, relation, tuples, ,, human-readable, also, machine-friendly, easier, verify, natural, language, ., implement, framework, includes, three, main, components, :, (, 1, ), introducing, relation, tuples, reasoning, steps, large, language, models, ;, (, 2, ), implementing, automatic, verification, process, reasoning, steps, local, code, interpreter, based, relation, tuples, ;, (, 3, ), integrating, simple, effective, dynamic, feedback, mechanism, ,, found, helpful, self-improvement, large, language, models, ., experimental, results, various, arithmetic, datasets, demonstrate, effectiveness, method, improving, arithmetic, reasoning, ability, large, language, models, ., source, code, available, https, :, //github.com/gpgg/art, ."
"Zero-shot cross-lingual transfer language selection using linguistic
  similarity","Juuso Eronen, Michal Ptaszynski, Fumito Masui",2023-01-31T15:56:40Z,"  We study the selection of transfer languages for different Natural Language
Processing tasks, specifically sentiment analysis, named entity recognition and
dependency parsing. In order to select an optimal transfer language, we propose
to utilize different linguistic similarity metrics to measure the distance
between languages and make the choice of transfer language based on this
information instead of relying on intuition. We demonstrate that linguistic
similarity correlates with cross-lingual transfer performance for all of the
proposed tasks. We also show that there is a statistically significant
difference in choosing the optimal language as the transfer source instead of
English. This allows us to select a more suitable transfer language which can
be used to better leverage knowledge from high-resource languages in order to
improve the performance of language applications lacking data. For the study,
we used datasets from eight different languages from three language families.
","['study', 'selection', 'transfer', 'languages', 'different', 'natural', 'language', 'processing', 'tasks', ',', 'specifically', 'sentiment', 'analysis', ',', 'named', 'entity', 'recognition', 'dependency', 'parsing', '.', 'order', 'select', 'optimal', 'transfer', 'language', ',', 'propose', 'utilize', 'different', 'linguistic', 'similarity', 'metrics', 'measure', 'distance', 'languages', 'make', 'choice', 'transfer', 'language', 'based', 'information', 'instead', 'relying', 'intuition', '.', 'demonstrate', 'linguistic', 'similarity', 'correlates', 'cross-lingual', 'transfer', 'performance', 'proposed', 'tasks', '.', 'also', 'show', 'statistically', 'significant', 'difference', 'choosing', 'optimal', 'language', 'transfer', 'source', 'instead', 'english', '.', 'allows', 'us', 'select', 'suitable', 'transfer', 'language', 'used', 'better', 'leverage', 'knowledge', 'high-resource', 'languages', 'order', 'improve', 'performance', 'language', 'applications', 'lacking', 'data', '.', 'study', ',', 'used', 'datasets', 'eight', 'different', 'languages', 'three', 'language', 'families', '.']","study, selection, transfer, languages, different, natural, language, processing, tasks, ,, specifically, sentiment, analysis, ,, named, entity, recognition, dependency, parsing, ., order, select, optimal, transfer, language, ,, propose, utilize, different, linguistic, similarity, metrics, measure, distance, languages, make, choice, transfer, language, based, information, instead, relying, intuition, ., demonstrate, linguistic, similarity, correlates, cross-lingual, transfer, performance, proposed, tasks, ., also, show, statistically, significant, difference, choosing, optimal, language, transfer, source, instead, english, ., allows, us, select, suitable, transfer, language, used, better, leverage, knowledge, high-resource, languages, order, improve, performance, language, applications, lacking, data, ., study, ,, used, datasets, eight, different, languages, three, language, families, ."
"Kallaama: A Transcribed Speech Dataset about Agriculture in the Three
  Most Widely Spoken Languages in Senegal","Elodie Gauthier, Aminata Ndiaye, Abdoulaye Guissé",2024-04-02T14:31:14Z,"  This work is part of the Kallaama project, whose objective is to produce and
disseminate national languages corpora for speech technologies developments, in
the field of agriculture. Except for Wolof, which benefits from some language
data for natural language processing, national languages of Senegal are largely
ignored by language technology providers. However, such technologies are keys
to the protection, promotion and teaching of these languages. Kallaama focuses
on the 3 main spoken languages by Senegalese people: Wolof, Pulaar and Sereer.
These languages are widely spoken by the population, with around 10 million of
native Senegalese speakers, not to mention those outside the country. However,
they remain under-resourced in terms of machine-readable data that can be used
for automatic processing and language technologies, all the more so in the
agricultural sector. We release a transcribed speech dataset containing 125
hours of recordings, about agriculture, in each of the above-mentioned
languages. These resources are specifically designed for Automatic Speech
Recognition purpose, including traditional approaches. To build such
technologies, we provide textual corpora in Wolof and Pulaar, and a
pronunciation lexicon containing 49,132 entries from the Wolof dataset.
","['work', 'part', 'kallaama', 'project', ',', 'whose', 'objective', 'produce', 'disseminate', 'national', 'languages', 'corpora', 'speech', 'technologies', 'developments', ',', 'field', 'agriculture', '.', 'except', 'wolof', ',', 'benefits', 'language', 'data', 'natural', 'language', 'processing', ',', 'national', 'languages', 'senegal', 'largely', 'ignored', 'language', 'technology', 'providers', '.', 'however', ',', 'technologies', 'keys', 'protection', ',', 'promotion', 'teaching', 'languages', '.', 'kallaama', 'focuses', '3', 'main', 'spoken', 'languages', 'senegalese', 'people', ':', 'wolof', ',', 'pulaar', 'sereer', '.', 'languages', 'widely', 'spoken', 'population', ',', 'around', '10', 'million', 'native', 'senegalese', 'speakers', ',', 'mention', 'outside', 'country', '.', 'however', ',', 'remain', 'under-resourced', 'terms', 'machine-readable', 'data', 'used', 'automatic', 'processing', 'language', 'technologies', ',', 'agricultural', 'sector', '.', 'release', 'transcribed', 'speech', 'dataset', 'containing', '125', 'hours', 'recordings', ',', 'agriculture', ',', 'above-mentioned', 'languages', '.', 'resources', 'specifically', 'designed', 'automatic', 'speech', 'recognition', 'purpose', ',', 'including', 'traditional', 'approaches', '.', 'build', 'technologies', ',', 'provide', 'textual', 'corpora', 'wolof', 'pulaar', ',', 'pronunciation', 'lexicon', 'containing', '49,132', 'entries', 'wolof', 'dataset', '.']","work, part, kallaama, project, ,, whose, objective, produce, disseminate, national, languages, corpora, speech, technologies, developments, ,, field, agriculture, ., except, wolof, ,, benefits, language, data, natural, language, processing, ,, national, languages, senegal, largely, ignored, language, technology, providers, ., however, ,, technologies, keys, protection, ,, promotion, teaching, languages, ., kallaama, focuses, 3, main, spoken, languages, senegalese, people, :, wolof, ,, pulaar, sereer, ., languages, widely, spoken, population, ,, around, 10, million, native, senegalese, speakers, ,, mention, outside, country, ., however, ,, remain, under-resourced, terms, machine-readable, data, used, automatic, processing, language, technologies, ,, agricultural, sector, ., release, transcribed, speech, dataset, containing, 125, hours, recordings, ,, agriculture, ,, above-mentioned, languages, ., resources, specifically, designed, automatic, speech, recognition, purpose, ,, including, traditional, approaches, ., build, technologies, ,, provide, textual, corpora, wolof, pulaar, ,, pronunciation, lexicon, containing, 49,132, entries, wolof, dataset, ."
"Contextualising Levels of Language Resourcedness affecting Digital
  Processing of Text","C. Maria Keet, Langa Khumalo",2023-09-29T07:48:24Z,"  Application domains such as digital humanities and tool like chatbots involve
some form of processing natural language, from digitising hardcopies to speech
generation. The language of the content is typically characterised as either a
low resource language (LRL) or high resource language (HRL), also known as
resource-scarce and well-resourced languages, respectively. African languages
have been characterized as resource-scarce languages (Bosch et al. 2007;
Pretorius & Bosch 2003; Keet & Khumalo 2014) and English is by far the most
well-resourced language. Varied language resources are used to develop software
systems for these languages to accomplish a wide range of tasks. In this paper
we argue that the dichotomous typology LRL and HRL for all languages is
problematic. Through a clear understanding of language resources situated in a
society, a matrix is developed that characterizes languages as Very LRL, LRL,
RL, HRL and Very HRL. The characterization is based on the typology of
contextual features for each category, rather than counting tools, and
motivation is provided for each feature and each characterization. The
contextualisation of resourcedness, with a focus on African languages in this
paper, and an increased understanding of where on the scale the language used
in a project is, may assist in, among others, better planning of research and
implementation projects. We thus argue in this paper that the characterization
of language resources within a given scale in a project is an indispensable
component particularly in the context of low-resourced languages.
","['application', 'domains', 'digital', 'humanities', 'tool', 'like', 'chatbots', 'involve', 'form', 'processing', 'natural', 'language', ',', 'digitising', 'hardcopies', 'speech', 'generation', '.', 'language', 'content', 'typically', 'characterised', 'either', 'low', 'resource', 'language', '(', 'lrl', ')', 'high', 'resource', 'language', '(', 'hrl', ')', ',', 'also', 'known', 'resource-scarce', 'well-resourced', 'languages', ',', 'respectively', '.', 'african', 'languages', 'characterized', 'resource-scarce', 'languages', '(', 'bosch', 'et', 'al', '.', '2007', ';', 'pretorius', '&', 'bosch', '2003', ';', 'keet', '&', 'khumalo', '2014', ')', 'english', 'far', 'well-resourced', 'language', '.', 'varied', 'language', 'resources', 'used', 'develop', 'software', 'systems', 'languages', 'accomplish', 'wide', 'range', 'tasks', '.', 'paper', 'argue', 'dichotomous', 'typology', 'lrl', 'hrl', 'languages', 'problematic', '.', 'clear', 'understanding', 'language', 'resources', 'situated', 'society', ',', 'matrix', 'developed', 'characterizes', 'languages', 'lrl', ',', 'lrl', ',', 'rl', ',', 'hrl', 'hrl', '.', 'characterization', 'based', 'typology', 'contextual', 'features', 'category', ',', 'rather', 'counting', 'tools', ',', 'motivation', 'provided', 'feature', 'characterization', '.', 'contextualisation', 'resourcedness', ',', 'focus', 'african', 'languages', 'paper', ',', 'increased', 'understanding', 'scale', 'language', 'used', 'project', ',', 'may', 'assist', ',', 'among', 'others', ',', 'better', 'planning', 'research', 'implementation', 'projects', '.', 'thus', 'argue', 'paper', 'characterization', 'language', 'resources', 'within', 'given', 'scale', 'project', 'indispensable', 'component', 'particularly', 'context', 'low-resourced', 'languages', '.']","application, domains, digital, humanities, tool, like, chatbots, involve, form, processing, natural, language, ,, digitising, hardcopies, speech, generation, ., language, content, typically, characterised, either, low, resource, language, (, lrl, ), high, resource, language, (, hrl, ), ,, also, known, resource-scarce, well-resourced, languages, ,, respectively, ., african, languages, characterized, resource-scarce, languages, (, bosch, et, al, ., 2007, ;, pretorius, &, bosch, 2003, ;, keet, &, khumalo, 2014, ), english, far, well-resourced, language, ., varied, language, resources, used, develop, software, systems, languages, accomplish, wide, range, tasks, ., paper, argue, dichotomous, typology, lrl, hrl, languages, problematic, ., clear, understanding, language, resources, situated, society, ,, matrix, developed, characterizes, languages, lrl, ,, lrl, ,, rl, ,, hrl, hrl, ., characterization, based, typology, contextual, features, category, ,, rather, counting, tools, ,, motivation, provided, feature, characterization, ., contextualisation, resourcedness, ,, focus, african, languages, paper, ,, increased, understanding, scale, language, used, project, ,, may, assist, ,, among, others, ,, better, planning, research, implementation, projects, ., thus, argue, paper, characterization, language, resources, within, given, scale, project, indispensable, component, particularly, context, low-resourced, languages, ."
"Unnatural language processing: How do language models handle
  machine-generated prompts?","Corentin Kervadec, Francesca Franzon, Marco Baroni",2023-10-24T13:32:20Z,"  Language model prompt optimization research has shown that semantically and
grammatically well-formed manually crafted prompts are routinely outperformed
by automatically generated token sequences with no apparent meaning or
syntactic structure, including sequences of vectors from a model's embedding
space. We use machine-generated prompts to probe how models respond to input
that is not composed of natural language expressions. We study the behavior of
models of different sizes in multiple semantic tasks in response to both
continuous and discrete machine-generated prompts, and compare it to the
behavior in response to human-generated natural-language prompts. Even when
producing a similar output, machine-generated and human prompts trigger
different response patterns through the network processing pathways, including
different perplexities, different attention and output entropy distributions,
and different unit activation profiles. We provide preliminary insight into the
nature of the units activated by different prompt types, suggesting that only
natural language prompts recruit a genuinely linguistic circuit.
","['language', 'model', 'prompt', 'optimization', 'research', 'shown', 'semantically', 'grammatically', 'well-formed', 'manually', 'crafted', 'prompts', 'routinely', 'outperformed', 'automatically', 'generated', 'token', 'sequences', 'apparent', 'meaning', 'syntactic', 'structure', ',', 'including', 'sequences', 'vectors', 'model', ""'s"", 'embedding', 'space', '.', 'use', 'machine-generated', 'prompts', 'probe', 'models', 'respond', 'input', 'composed', 'natural', 'language', 'expressions', '.', 'study', 'behavior', 'models', 'different', 'sizes', 'multiple', 'semantic', 'tasks', 'response', 'continuous', 'discrete', 'machine-generated', 'prompts', ',', 'compare', 'behavior', 'response', 'human-generated', 'natural-language', 'prompts', '.', 'even', 'producing', 'similar', 'output', ',', 'machine-generated', 'human', 'prompts', 'trigger', 'different', 'response', 'patterns', 'network', 'processing', 'pathways', ',', 'including', 'different', 'perplexities', ',', 'different', 'attention', 'output', 'entropy', 'distributions', ',', 'different', 'unit', 'activation', 'profiles', '.', 'provide', 'preliminary', 'insight', 'nature', 'units', 'activated', 'different', 'prompt', 'types', ',', 'suggesting', 'natural', 'language', 'prompts', 'recruit', 'genuinely', 'linguistic', 'circuit', '.']","language, model, prompt, optimization, research, shown, semantically, grammatically, well-formed, manually, crafted, prompts, routinely, outperformed, automatically, generated, token, sequences, apparent, meaning, syntactic, structure, ,, including, sequences, vectors, model, 's, embedding, space, ., use, machine-generated, prompts, probe, models, respond, input, composed, natural, language, expressions, ., study, behavior, models, different, sizes, multiple, semantic, tasks, response, continuous, discrete, machine-generated, prompts, ,, compare, behavior, response, human-generated, natural-language, prompts, ., even, producing, similar, output, ,, machine-generated, human, prompts, trigger, different, response, patterns, network, processing, pathways, ,, including, different, perplexities, ,, different, attention, output, entropy, distributions, ,, different, unit, activation, profiles, ., provide, preliminary, insight, nature, units, activated, different, prompt, types, ,, suggesting, natural, language, prompts, recruit, genuinely, linguistic, circuit, ."
Evolution of transfer learning in natural language processing,"Aditya Malte, Pratik Ratadiya",2019-10-16T14:24:37Z,"  In this paper, we present a study of the recent advancements which have
helped bring Transfer Learning to NLP through the use of semi-supervised
training. We discuss cutting-edge methods and architectures such as BERT, GPT,
ELMo, ULMFit among others. Classically, tasks in natural language processing
have been performed through rule-based and statistical methodologies. However,
owing to the vast nature of natural languages these methods do not generalise
well and failed to learn the nuances of language. Thus machine learning
algorithms such as Naive Bayes and decision trees coupled with traditional
models such as Bag-of-Words and N-grams were used to usurp this problem.
Eventually, with the advent of advanced recurrent neural network architectures
such as the LSTM, we were able to achieve state-of-the-art performance in
several natural language processing tasks such as text classification and
machine translation. We talk about how Transfer Learning has brought about the
well-known ImageNet moment for NLP. Several advanced architectures such as the
Transformer and its variants have allowed practitioners to leverage knowledge
gained from unrelated task to drastically fasten convergence and provide better
performance on the target task. This survey represents an effort at providing a
succinct yet complete understanding of the recent advances in natural language
processing using deep learning in with a special focus on detailing transfer
learning and its potential advantages.
","['paper', ',', 'present', 'study', 'recent', 'advancements', 'helped', 'bring', 'transfer', 'learning', 'nlp', 'use', 'semi-supervised', 'training', '.', 'discuss', 'cutting-edge', 'methods', 'architectures', 'bert', ',', 'gpt', ',', 'elmo', ',', 'ulmfit', 'among', 'others', '.', 'classically', ',', 'tasks', 'natural', 'language', 'processing', 'performed', 'rule-based', 'statistical', 'methodologies', '.', 'however', ',', 'owing', 'vast', 'nature', 'natural', 'languages', 'methods', 'generalise', 'well', 'failed', 'learn', 'nuances', 'language', '.', 'thus', 'machine', 'learning', 'algorithms', 'naive', 'bayes', 'decision', 'trees', 'coupled', 'traditional', 'models', 'bag-of-words', 'n-grams', 'used', 'usurp', 'problem', '.', 'eventually', ',', 'advent', 'advanced', 'recurrent', 'neural', 'network', 'architectures', 'lstm', ',', 'able', 'achieve', 'state-of-the-art', 'performance', 'several', 'natural', 'language', 'processing', 'tasks', 'text', 'classification', 'machine', 'translation', '.', 'talk', 'transfer', 'learning', 'brought', 'well-known', 'imagenet', 'moment', 'nlp', '.', 'several', 'advanced', 'architectures', 'transformer', 'variants', 'allowed', 'practitioners', 'leverage', 'knowledge', 'gained', 'unrelated', 'task', 'drastically', 'fasten', 'convergence', 'provide', 'better', 'performance', 'target', 'task', '.', 'survey', 'represents', 'effort', 'providing', 'succinct', 'yet', 'complete', 'understanding', 'recent', 'advances', 'natural', 'language', 'processing', 'using', 'deep', 'learning', 'special', 'focus', 'detailing', 'transfer', 'learning', 'potential', 'advantages', '.']","paper, ,, present, study, recent, advancements, helped, bring, transfer, learning, nlp, use, semi-supervised, training, ., discuss, cutting-edge, methods, architectures, bert, ,, gpt, ,, elmo, ,, ulmfit, among, others, ., classically, ,, tasks, natural, language, processing, performed, rule-based, statistical, methodologies, ., however, ,, owing, vast, nature, natural, languages, methods, generalise, well, failed, learn, nuances, language, ., thus, machine, learning, algorithms, naive, bayes, decision, trees, coupled, traditional, models, bag-of-words, n-grams, used, usurp, problem, ., eventually, ,, advent, advanced, recurrent, neural, network, architectures, lstm, ,, able, achieve, state-of-the-art, performance, several, natural, language, processing, tasks, text, classification, machine, translation, ., talk, transfer, learning, brought, well-known, imagenet, moment, nlp, ., several, advanced, architectures, transformer, variants, allowed, practitioners, leverage, knowledge, gained, unrelated, task, drastically, fasten, convergence, provide, better, performance, target, task, ., survey, represents, effort, providing, succinct, yet, complete, understanding, recent, advances, natural, language, processing, using, deep, learning, special, focus, detailing, transfer, learning, potential, advantages, ."
"Text2Cohort: Facilitating Intuitive Access to Biomedical Data with
  Natural Language Cohort Discovery","Pranav Kulkarni, Adway Kanhere, Paul H. Yi, Vishwa S. Parekh",2023-05-12T17:46:06Z,"  The Imaging Data Commons (IDC) is a cloud-based database that provides
researchers with open access to cancer imaging data, with the goal of
facilitating collaboration. However, cohort discovery within the IDC database
has a significant technical learning curve. Recently, large language models
(LLM) have demonstrated exceptional utility for natural language processing
tasks. We developed Text2Cohort, a LLM-powered toolkit to facilitate
user-friendly natural language cohort discovery in the IDC. Our method
translates user input into IDC queries using grounding techniques and returns
the query's response. We evaluate Text2Cohort on 50 natural language inputs,
from information extraction to cohort discovery. Our toolkit successfully
generated responses with an 88% accuracy and 0.94 F1 score. We demonstrate that
Text2Cohort can enable researchers to discover and curate cohorts on IDC with
high levels of accuracy using natural language in a more intuitive and
user-friendly way.
","['imaging', 'data', 'commons', '(', 'idc', ')', 'cloud-based', 'database', 'provides', 'researchers', 'open', 'access', 'cancer', 'imaging', 'data', ',', 'goal', 'facilitating', 'collaboration', '.', 'however', ',', 'cohort', 'discovery', 'within', 'idc', 'database', 'significant', 'technical', 'learning', 'curve', '.', 'recently', ',', 'large', 'language', 'models', '(', 'llm', ')', 'demonstrated', 'exceptional', 'utility', 'natural', 'language', 'processing', 'tasks', '.', 'developed', 'text2cohort', ',', 'llm-powered', 'toolkit', 'facilitate', 'user-friendly', 'natural', 'language', 'cohort', 'discovery', 'idc', '.', 'method', 'translates', 'user', 'input', 'idc', 'queries', 'using', 'grounding', 'techniques', 'returns', 'query', ""'s"", 'response', '.', 'evaluate', 'text2cohort', '50', 'natural', 'language', 'inputs', ',', 'information', 'extraction', 'cohort', 'discovery', '.', 'toolkit', 'successfully', 'generated', 'responses', '88', '%', 'accuracy', '0.94', 'f1', 'score', '.', 'demonstrate', 'text2cohort', 'enable', 'researchers', 'discover', 'curate', 'cohorts', 'idc', 'high', 'levels', 'accuracy', 'using', 'natural', 'language', 'intuitive', 'user-friendly', 'way', '.']","imaging, data, commons, (, idc, ), cloud-based, database, provides, researchers, open, access, cancer, imaging, data, ,, goal, facilitating, collaboration, ., however, ,, cohort, discovery, within, idc, database, significant, technical, learning, curve, ., recently, ,, large, language, models, (, llm, ), demonstrated, exceptional, utility, natural, language, processing, tasks, ., developed, text2cohort, ,, llm-powered, toolkit, facilitate, user-friendly, natural, language, cohort, discovery, idc, ., method, translates, user, input, idc, queries, using, grounding, techniques, returns, query, 's, response, ., evaluate, text2cohort, 50, natural, language, inputs, ,, information, extraction, cohort, discovery, ., toolkit, successfully, generated, responses, 88, %, accuracy, 0.94, f1, score, ., demonstrate, text2cohort, enable, researchers, discover, curate, cohorts, idc, high, levels, accuracy, using, natural, language, intuitive, user-friendly, way, ."
"LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian
  Language","Pierpaolo Basile, Elio Musacchio, Marco Polignano, Lucia Siciliani, Giuseppe Fiameni, Giovanni Semeraro",2023-12-15T18:06:22Z,"  Large Language Models represent state-of-the-art linguistic models designed
to equip computers with the ability to comprehend natural language. With its
exceptional capacity to capture complex contextual relationships, the LLaMA
(Large Language Model Meta AI) family represents a novel advancement in the
field of natural language processing by releasing foundational models designed
to improve the natural language understanding abilities of the transformer
architecture thanks to their large amount of trainable parameters (7, 13, and
70 billion parameters). In many natural language understanding tasks, these
models obtain the same performances as private company models such as OpenAI
Chat-GPT with the advantage to make publicly available weights and code for
research and commercial uses. In this work, we investigate the possibility of
Language Adaptation for LLaMA models, explicitly focusing on addressing the
challenge of Italian Language coverage. Adopting an open science approach, we
explore various tuning approaches to ensure a high-quality text generated in
Italian suitable for common tasks in this underrepresented language in the
original models' datasets. We aim to release effective text generation models
with strong linguistic properties for many tasks that seem challenging using
multilingual or general-purpose LLMs. By leveraging an open science philosophy,
this study contributes to Language Adaptation strategies for the Italian
language by introducing the novel LLaMAntino family of Italian LLMs.
","['large', 'language', 'models', 'represent', 'state-of-the-art', 'linguistic', 'models', 'designed', 'equip', 'computers', 'ability', 'comprehend', 'natural', 'language', '.', 'exceptional', 'capacity', 'capture', 'complex', 'contextual', 'relationships', ',', 'llama', '(', 'large', 'language', 'model', 'meta', 'ai', ')', 'family', 'represents', 'novel', 'advancement', 'field', 'natural', 'language', 'processing', 'releasing', 'foundational', 'models', 'designed', 'improve', 'natural', 'language', 'understanding', 'abilities', 'transformer', 'architecture', 'thanks', 'large', 'amount', 'trainable', 'parameters', '(', '7', ',', '13', ',', '70', 'billion', 'parameters', ')', '.', 'many', 'natural', 'language', 'understanding', 'tasks', ',', 'models', 'obtain', 'performances', 'private', 'company', 'models', 'openai', 'chat-gpt', 'advantage', 'make', 'publicly', 'available', 'weights', 'code', 'research', 'commercial', 'uses', '.', 'work', ',', 'investigate', 'possibility', 'language', 'adaptation', 'llama', 'models', ',', 'explicitly', 'focusing', 'addressing', 'challenge', 'italian', 'language', 'coverage', '.', 'adopting', 'open', 'science', 'approach', ',', 'explore', 'various', 'tuning', 'approaches', 'ensure', 'high-quality', 'text', 'generated', 'italian', 'suitable', 'common', 'tasks', 'underrepresented', 'language', 'original', 'models', ""'"", 'datasets', '.', 'aim', 'release', 'effective', 'text', 'generation', 'models', 'strong', 'linguistic', 'properties', 'many', 'tasks', 'seem', 'challenging', 'using', 'multilingual', 'general-purpose', 'llms', '.', 'leveraging', 'open', 'science', 'philosophy', ',', 'study', 'contributes', 'language', 'adaptation', 'strategies', 'italian', 'language', 'introducing', 'novel', 'llamantino', 'family', 'italian', 'llms', '.']","large, language, models, represent, state-of-the-art, linguistic, models, designed, equip, computers, ability, comprehend, natural, language, ., exceptional, capacity, capture, complex, contextual, relationships, ,, llama, (, large, language, model, meta, ai, ), family, represents, novel, advancement, field, natural, language, processing, releasing, foundational, models, designed, improve, natural, language, understanding, abilities, transformer, architecture, thanks, large, amount, trainable, parameters, (, 7, ,, 13, ,, 70, billion, parameters, ), ., many, natural, language, understanding, tasks, ,, models, obtain, performances, private, company, models, openai, chat-gpt, advantage, make, publicly, available, weights, code, research, commercial, uses, ., work, ,, investigate, possibility, language, adaptation, llama, models, ,, explicitly, focusing, addressing, challenge, italian, language, coverage, ., adopting, open, science, approach, ,, explore, various, tuning, approaches, ensure, high-quality, text, generated, italian, suitable, common, tasks, underrepresented, language, original, models, ', datasets, ., aim, release, effective, text, generation, models, strong, linguistic, properties, many, tasks, seem, challenging, using, multilingual, general-purpose, llms, ., leveraging, open, science, philosophy, ,, study, contributes, language, adaptation, strategies, italian, language, introducing, novel, llamantino, family, italian, llms, ."
"Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa
  Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP
  dalam bahasa Indonesia",Mukhlis Amien,2023-03-28T02:31:47Z,"  This study provides an overview of the history of the development of Natural
Language Processing (NLP) in the context of the Indonesian language, with a
focus on the basic technologies, methods, and practical applications that have
been developed. This review covers developments in basic NLP technologies such
as stemming, part-of-speech tagging, and related methods; practical
applications in cross-language information retrieval systems, information
extraction, and sentiment analysis; and methods and techniques used in
Indonesian language NLP research, such as machine learning, statistics-based
machine translation, and conflict-based approaches. This study also explores
the application of NLP in Indonesian language industry and research and
identifies challenges and opportunities in Indonesian language NLP research and
development. Recommendations for future Indonesian language NLP research and
development include developing more efficient methods and technologies,
expanding NLP applications, increasing sustainability, further research into
the potential of NLP, and promoting interdisciplinary collaboration. It is
hoped that this review will help researchers, practitioners, and the government
to understand the development of Indonesian language NLP and identify
opportunities for further research and development.
","['study', 'provides', 'overview', 'history', 'development', 'natural', 'language', 'processing', '(', 'nlp', ')', 'context', 'indonesian', 'language', ',', 'focus', 'basic', 'technologies', ',', 'methods', ',', 'practical', 'applications', 'developed', '.', 'review', 'covers', 'developments', 'basic', 'nlp', 'technologies', 'stemming', ',', 'part-of-speech', 'tagging', ',', 'related', 'methods', ';', 'practical', 'applications', 'cross-language', 'information', 'retrieval', 'systems', ',', 'information', 'extraction', ',', 'sentiment', 'analysis', ';', 'methods', 'techniques', 'used', 'indonesian', 'language', 'nlp', 'research', ',', 'machine', 'learning', ',', 'statistics-based', 'machine', 'translation', ',', 'conflict-based', 'approaches', '.', 'study', 'also', 'explores', 'application', 'nlp', 'indonesian', 'language', 'industry', 'research', 'identifies', 'challenges', 'opportunities', 'indonesian', 'language', 'nlp', 'research', 'development', '.', 'recommendations', 'future', 'indonesian', 'language', 'nlp', 'research', 'development', 'include', 'developing', 'efficient', 'methods', 'technologies', ',', 'expanding', 'nlp', 'applications', ',', 'increasing', 'sustainability', ',', 'research', 'potential', 'nlp', ',', 'promoting', 'interdisciplinary', 'collaboration', '.', 'hoped', 'review', 'help', 'researchers', ',', 'practitioners', ',', 'government', 'understand', 'development', 'indonesian', 'language', 'nlp', 'identify', 'opportunities', 'research', 'development', '.']","study, provides, overview, history, development, natural, language, processing, (, nlp, ), context, indonesian, language, ,, focus, basic, technologies, ,, methods, ,, practical, applications, developed, ., review, covers, developments, basic, nlp, technologies, stemming, ,, part-of-speech, tagging, ,, related, methods, ;, practical, applications, cross-language, information, retrieval, systems, ,, information, extraction, ,, sentiment, analysis, ;, methods, techniques, used, indonesian, language, nlp, research, ,, machine, learning, ,, statistics-based, machine, translation, ,, conflict-based, approaches, ., study, also, explores, application, nlp, indonesian, language, industry, research, identifies, challenges, opportunities, indonesian, language, nlp, research, development, ., recommendations, future, indonesian, language, nlp, research, development, include, developing, efficient, methods, technologies, ,, expanding, nlp, applications, ,, increasing, sustainability, ,, research, potential, nlp, ,, promoting, interdisciplinary, collaboration, ., hoped, review, help, researchers, ,, practitioners, ,, government, understand, development, indonesian, language, nlp, identify, opportunities, research, development, ."
Generalized Optimal Linear Orders,Rishi Bommasani,2021-08-13T13:10:15Z,"  The sequential structure of language, and the order of words in a sentence
specifically, plays a central role in human language processing. Consequently,
in designing computational models of language, the de facto approach is to
present sentences to machines with the words ordered in the same order as in
the original human-authored sentence. The very essence of this work is to
question the implicit assumption that this is desirable and inject theoretical
soundness into the consideration of word order in natural language processing.
In this thesis, we begin by uniting the disparate treatments of word order in
cognitive science, psycholinguistics, computational linguistics, and natural
language processing under a flexible algorithmic framework. We proceed to use
this heterogeneous theoretical foundation as the basis for exploring new word
orders with an undercurrent of psycholinguistic optimality. In particular, we
focus on notions of dependency length minimization given the difficulties in
human and computational language processing in handling long-distance
dependencies. We then discuss algorithms for finding optimal word orders
efficiently in spite of the combinatorial space of possibilities. We conclude
by addressing the implications of these word orders on human language and their
downstream impacts when integrated in computational models.
","['sequential', 'structure', 'language', ',', 'order', 'words', 'sentence', 'specifically', ',', 'plays', 'central', 'role', 'human', 'language', 'processing', '.', 'consequently', ',', 'designing', 'computational', 'models', 'language', ',', 'de', 'facto', 'approach', 'present', 'sentences', 'machines', 'words', 'ordered', 'order', 'original', 'human-authored', 'sentence', '.', 'essence', 'work', 'question', 'implicit', 'assumption', 'desirable', 'inject', 'theoretical', 'soundness', 'consideration', 'word', 'order', 'natural', 'language', 'processing', '.', 'thesis', ',', 'begin', 'uniting', 'disparate', 'treatments', 'word', 'order', 'cognitive', 'science', ',', 'psycholinguistics', ',', 'computational', 'linguistics', ',', 'natural', 'language', 'processing', 'flexible', 'algorithmic', 'framework', '.', 'proceed', 'use', 'heterogeneous', 'theoretical', 'foundation', 'basis', 'exploring', 'new', 'word', 'orders', 'undercurrent', 'psycholinguistic', 'optimality', '.', 'particular', ',', 'focus', 'notions', 'dependency', 'length', 'minimization', 'given', 'difficulties', 'human', 'computational', 'language', 'processing', 'handling', 'long-distance', 'dependencies', '.', 'discuss', 'algorithms', 'finding', 'optimal', 'word', 'orders', 'efficiently', 'spite', 'combinatorial', 'space', 'possibilities', '.', 'conclude', 'addressing', 'implications', 'word', 'orders', 'human', 'language', 'downstream', 'impacts', 'integrated', 'computational', 'models', '.']","sequential, structure, language, ,, order, words, sentence, specifically, ,, plays, central, role, human, language, processing, ., consequently, ,, designing, computational, models, language, ,, de, facto, approach, present, sentences, machines, words, ordered, order, original, human-authored, sentence, ., essence, work, question, implicit, assumption, desirable, inject, theoretical, soundness, consideration, word, order, natural, language, processing, ., thesis, ,, begin, uniting, disparate, treatments, word, order, cognitive, science, ,, psycholinguistics, ,, computational, linguistics, ,, natural, language, processing, flexible, algorithmic, framework, ., proceed, use, heterogeneous, theoretical, foundation, basis, exploring, new, word, orders, undercurrent, psycholinguistic, optimality, ., particular, ,, focus, notions, dependency, length, minimization, given, difficulties, human, computational, language, processing, handling, long-distance, dependencies, ., discuss, algorithms, finding, optimal, word, orders, efficiently, spite, combinatorial, space, possibilities, ., conclude, addressing, implications, word, orders, human, language, downstream, impacts, integrated, computational, models, ."
"Listen, Interact and Talk: Learning to Speak via Interaction","Haichao Zhang, Haonan Yu, Wei Xu",2017-05-28T07:48:14Z,"  One of the long-term goals of artificial intelligence is to build an agent
that can communicate intelligently with human in natural language. Most
existing work on natural language learning relies heavily on training over a
pre-collected dataset with annotated labels, leading to an agent that
essentially captures the statistics of the fixed external training data. As the
training data is essentially a static snapshot representation of the knowledge
from the annotator, the agent trained this way is limited in adaptiveness and
generalization of its behavior. Moreover, this is very different from the
language learning process of humans, where language is acquired during
communication by taking speaking action and learning from the consequences of
speaking action in an interactive manner. This paper presents an interactive
setting for grounded natural language learning, where an agent learns natural
language by interacting with a teacher and learning from feedback, thus
learning and improving language skills while taking part in the conversation.
To achieve this goal, we propose a model which incorporates both imitation and
reinforcement by leveraging jointly sentence and reward feedbacks from the
teacher. Experiments are conducted to validate the effectiveness of the
proposed approach.
","['one', 'long-term', 'goals', 'artificial', 'intelligence', 'build', 'agent', 'communicate', 'intelligently', 'human', 'natural', 'language', '.', 'existing', 'work', 'natural', 'language', 'learning', 'relies', 'heavily', 'training', 'pre-collected', 'dataset', 'annotated', 'labels', ',', 'leading', 'agent', 'essentially', 'captures', 'statistics', 'fixed', 'external', 'training', 'data', '.', 'training', 'data', 'essentially', 'static', 'snapshot', 'representation', 'knowledge', 'annotator', ',', 'agent', 'trained', 'way', 'limited', 'adaptiveness', 'generalization', 'behavior', '.', 'moreover', ',', 'different', 'language', 'learning', 'process', 'humans', ',', 'language', 'acquired', 'communication', 'taking', 'speaking', 'action', 'learning', 'consequences', 'speaking', 'action', 'interactive', 'manner', '.', 'paper', 'presents', 'interactive', 'setting', 'grounded', 'natural', 'language', 'learning', ',', 'agent', 'learns', 'natural', 'language', 'interacting', 'teacher', 'learning', 'feedback', ',', 'thus', 'learning', 'improving', 'language', 'skills', 'taking', 'part', 'conversation', '.', 'achieve', 'goal', ',', 'propose', 'model', 'incorporates', 'imitation', 'reinforcement', 'leveraging', 'jointly', 'sentence', 'reward', 'feedbacks', 'teacher', '.', 'experiments', 'conducted', 'validate', 'effectiveness', 'proposed', 'approach', '.']","one, long-term, goals, artificial, intelligence, build, agent, communicate, intelligently, human, natural, language, ., existing, work, natural, language, learning, relies, heavily, training, pre-collected, dataset, annotated, labels, ,, leading, agent, essentially, captures, statistics, fixed, external, training, data, ., training, data, essentially, static, snapshot, representation, knowledge, annotator, ,, agent, trained, way, limited, adaptiveness, generalization, behavior, ., moreover, ,, different, language, learning, process, humans, ,, language, acquired, communication, taking, speaking, action, learning, consequences, speaking, action, interactive, manner, ., paper, presents, interactive, setting, grounded, natural, language, learning, ,, agent, learns, natural, language, interacting, teacher, learning, feedback, ,, thus, learning, improving, language, skills, taking, part, conversation, ., achieve, goal, ,, propose, model, incorporates, imitation, reinforcement, leveraging, jointly, sentence, reward, feedbacks, teacher, ., experiments, conducted, validate, effectiveness, proposed, approach, ."
Spiral Language Modeling,"Yong Cao, Yukun Feng, Shaohui Kuang, Gu Xu",2021-12-20T14:08:38Z,"  In almost all text generation applications, word sequences are constructed in
a left-to-right (L2R) or right-to-left (R2L) manner, as natural language
sentences are written either L2R or R2L. However, we find that the natural
language written order is not essential for text generation. In this paper, we
propose Spiral Language Modeling (SLM), a general approach that enables one to
construct natural language sentences beyond the L2R and R2L order. SLM allows
one to form natural language text by starting from an arbitrary token inside
the result text and expanding the rest tokens around the selected ones. It
makes the decoding order a new optimization objective besides the language
model perplexity, which further improves the diversity and quality of the
generated text. Furthermore, SLM makes it possible to manipulate the text
construction process by selecting a proper starting token. SLM also introduces
generation orderings as additional regularization to improve model robustness
in low-resource scenarios. Experiments on 8 widely studied Neural Machine
Translation (NMT) tasks show that SLM is constantly effective with up to 4.7
BLEU increase comparing to the conventional L2R decoding approach.
","['almost', 'text', 'generation', 'applications', ',', 'word', 'sequences', 'constructed', 'left-to-right', '(', 'l2r', ')', 'right-to-left', '(', 'r2l', ')', 'manner', ',', 'natural', 'language', 'sentences', 'written', 'either', 'l2r', 'r2l', '.', 'however', ',', 'find', 'natural', 'language', 'written', 'order', 'essential', 'text', 'generation', '.', 'paper', ',', 'propose', 'spiral', 'language', 'modeling', '(', 'slm', ')', ',', 'general', 'approach', 'enables', 'one', 'construct', 'natural', 'language', 'sentences', 'beyond', 'l2r', 'r2l', 'order', '.', 'slm', 'allows', 'one', 'form', 'natural', 'language', 'text', 'starting', 'arbitrary', 'token', 'inside', 'result', 'text', 'expanding', 'rest', 'tokens', 'around', 'selected', 'ones', '.', 'makes', 'decoding', 'order', 'new', 'optimization', 'objective', 'besides', 'language', 'model', 'perplexity', ',', 'improves', 'diversity', 'quality', 'generated', 'text', '.', 'furthermore', ',', 'slm', 'makes', 'possible', 'manipulate', 'text', 'construction', 'process', 'selecting', 'proper', 'starting', 'token', '.', 'slm', 'also', 'introduces', 'generation', 'orderings', 'additional', 'regularization', 'improve', 'model', 'robustness', 'low-resource', 'scenarios', '.', 'experiments', '8', 'widely', 'studied', 'neural', 'machine', 'translation', '(', 'nmt', ')', 'tasks', 'show', 'slm', 'constantly', 'effective', '4.7', 'bleu', 'increase', 'comparing', 'conventional', 'l2r', 'decoding', 'approach', '.']","almost, text, generation, applications, ,, word, sequences, constructed, left-to-right, (, l2r, ), right-to-left, (, r2l, ), manner, ,, natural, language, sentences, written, either, l2r, r2l, ., however, ,, find, natural, language, written, order, essential, text, generation, ., paper, ,, propose, spiral, language, modeling, (, slm, ), ,, general, approach, enables, one, construct, natural, language, sentences, beyond, l2r, r2l, order, ., slm, allows, one, form, natural, language, text, starting, arbitrary, token, inside, result, text, expanding, rest, tokens, around, selected, ones, ., makes, decoding, order, new, optimization, objective, besides, language, model, perplexity, ,, improves, diversity, quality, generated, text, ., furthermore, ,, slm, makes, possible, manipulate, text, construction, process, selecting, proper, starting, token, ., slm, also, introduces, generation, orderings, additional, regularization, improve, model, robustness, low-resource, scenarios, ., experiments, 8, widely, studied, neural, machine, translation, (, nmt, ), tasks, show, slm, constantly, effective, 4.7, bleu, increase, comparing, conventional, l2r, decoding, approach, ."
Leveraging Large Language Models to Generate Answer Set Programs,"Adam Ishay, Zhun Yang, Joohyung Lee",2023-07-15T03:40:55Z,"  Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated
exceptional performance in various natural language processing tasks and have
shown the ability to solve certain reasoning problems. However, their reasoning
capabilities are limited and relatively shallow, despite the application of
various prompting techniques. In contrast, formal logic is adept at handling
complex reasoning, but translating natural language descriptions into formal
logic is a challenging task that non-experts struggle with. This paper proposes
a neuro-symbolic method that combines the strengths of large language models
and answer set programming. Specifically, we employ an LLM to transform natural
language descriptions of logic puzzles into answer set programs. We carefully
design prompts for an LLM to convert natural language descriptions into answer
set programs in a step by step manner. Surprisingly, with just a few in-context
learning examples, LLMs can generate reasonably complex answer set programs.
The majority of errors made are relatively simple and can be easily corrected
by humans, thus enabling LLMs to effectively assist in the creation of answer
set programs.
","['large', 'language', 'models', '(', 'llms', ')', ',', 'gpt-3', 'gpt-4', ',', 'demonstrated', 'exceptional', 'performance', 'various', 'natural', 'language', 'processing', 'tasks', 'shown', 'ability', 'solve', 'certain', 'reasoning', 'problems', '.', 'however', ',', 'reasoning', 'capabilities', 'limited', 'relatively', 'shallow', ',', 'despite', 'application', 'various', 'prompting', 'techniques', '.', 'contrast', ',', 'formal', 'logic', 'adept', 'handling', 'complex', 'reasoning', ',', 'translating', 'natural', 'language', 'descriptions', 'formal', 'logic', 'challenging', 'task', 'non-experts', 'struggle', '.', 'paper', 'proposes', 'neuro-symbolic', 'method', 'combines', 'strengths', 'large', 'language', 'models', 'answer', 'set', 'programming', '.', 'specifically', ',', 'employ', 'llm', 'transform', 'natural', 'language', 'descriptions', 'logic', 'puzzles', 'answer', 'set', 'programs', '.', 'carefully', 'design', 'prompts', 'llm', 'convert', 'natural', 'language', 'descriptions', 'answer', 'set', 'programs', 'step', 'step', 'manner', '.', 'surprisingly', ',', 'in-context', 'learning', 'examples', ',', 'llms', 'generate', 'reasonably', 'complex', 'answer', 'set', 'programs', '.', 'majority', 'errors', 'made', 'relatively', 'simple', 'easily', 'corrected', 'humans', ',', 'thus', 'enabling', 'llms', 'effectively', 'assist', 'creation', 'answer', 'set', 'programs', '.']","large, language, models, (, llms, ), ,, gpt-3, gpt-4, ,, demonstrated, exceptional, performance, various, natural, language, processing, tasks, shown, ability, solve, certain, reasoning, problems, ., however, ,, reasoning, capabilities, limited, relatively, shallow, ,, despite, application, various, prompting, techniques, ., contrast, ,, formal, logic, adept, handling, complex, reasoning, ,, translating, natural, language, descriptions, formal, logic, challenging, task, non-experts, struggle, ., paper, proposes, neuro-symbolic, method, combines, strengths, large, language, models, answer, set, programming, ., specifically, ,, employ, llm, transform, natural, language, descriptions, logic, puzzles, answer, set, programs, ., carefully, design, prompts, llm, convert, natural, language, descriptions, answer, set, programs, step, step, manner, ., surprisingly, ,, in-context, learning, examples, ,, llms, generate, reasonably, complex, answer, set, programs, ., majority, errors, made, relatively, simple, easily, corrected, humans, ,, thus, enabling, llms, effectively, assist, creation, answer, set, programs, ."
From Text to CQL: Bridging Natural Language and Corpus Search Engine,"Luming Lu, Jiyuan An, Yujie Wang, Liner yang, Cunliang Kong, Zhenghao Liu, Shuo Wang, Haozhe Lin, Mingwei Fang, Yaping Huang, Erhong Yang",2024-02-21T12:11:28Z,"  Natural Language Processing (NLP) technologies have revolutionized the way we
interact with information systems, with a significant focus on converting
natural language queries into formal query languages such as SQL. However, less
emphasis has been placed on the Corpus Query Language (CQL), a critical tool
for linguistic research and detailed analysis within text corpora. The manual
construction of CQL queries is a complex and time-intensive task that requires
a great deal of expertise, which presents a notable challenge for both
researchers and practitioners. This paper presents the first text-to-CQL task
that aims to automate the translation of natural language into CQL. We present
a comprehensive framework for this task, including a specifically curated
large-scale dataset and methodologies leveraging large language models (LLMs)
for effective text-to-CQL task. In addition, we established advanced evaluation
metrics to assess the syntactic and semantic accuracy of the generated queries.
We created innovative LLM-based conversion approaches and detailed experiments.
The results demonstrate the efficacy of our methods and provide insights into
the complexities of text-to-CQL task.
","['natural', 'language', 'processing', '(', 'nlp', ')', 'technologies', 'revolutionized', 'way', 'interact', 'information', 'systems', ',', 'significant', 'focus', 'converting', 'natural', 'language', 'queries', 'formal', 'query', 'languages', 'sql', '.', 'however', ',', 'less', 'emphasis', 'placed', 'corpus', 'query', 'language', '(', 'cql', ')', ',', 'critical', 'tool', 'linguistic', 'research', 'detailed', 'analysis', 'within', 'text', 'corpora', '.', 'manual', 'construction', 'cql', 'queries', 'complex', 'time-intensive', 'task', 'requires', 'great', 'deal', 'expertise', ',', 'presents', 'notable', 'challenge', 'researchers', 'practitioners', '.', 'paper', 'presents', 'first', 'text-to-cql', 'task', 'aims', 'automate', 'translation', 'natural', 'language', 'cql', '.', 'present', 'comprehensive', 'framework', 'task', ',', 'including', 'specifically', 'curated', 'large-scale', 'dataset', 'methodologies', 'leveraging', 'large', 'language', 'models', '(', 'llms', ')', 'effective', 'text-to-cql', 'task', '.', 'addition', ',', 'established', 'advanced', 'evaluation', 'metrics', 'assess', 'syntactic', 'semantic', 'accuracy', 'generated', 'queries', '.', 'created', 'innovative', 'llm-based', 'conversion', 'approaches', 'detailed', 'experiments', '.', 'results', 'demonstrate', 'efficacy', 'methods', 'provide', 'insights', 'complexities', 'text-to-cql', 'task', '.']","natural, language, processing, (, nlp, ), technologies, revolutionized, way, interact, information, systems, ,, significant, focus, converting, natural, language, queries, formal, query, languages, sql, ., however, ,, less, emphasis, placed, corpus, query, language, (, cql, ), ,, critical, tool, linguistic, research, detailed, analysis, within, text, corpora, ., manual, construction, cql, queries, complex, time-intensive, task, requires, great, deal, expertise, ,, presents, notable, challenge, researchers, practitioners, ., paper, presents, first, text-to-cql, task, aims, automate, translation, natural, language, cql, ., present, comprehensive, framework, task, ,, including, specifically, curated, large-scale, dataset, methodologies, leveraging, large, language, models, (, llms, ), effective, text-to-cql, task, ., addition, ,, established, advanced, evaluation, metrics, assess, syntactic, semantic, accuracy, generated, queries, ., created, innovative, llm-based, conversion, approaches, detailed, experiments, ., results, demonstrate, efficacy, methods, provide, insights, complexities, text-to-cql, task, ."
Natural Language Decomposition and Interpretation of Complex Utterances,"Harsh Jhamtani, Hao Fang, Patrick Xia, Eran Levy, Jacob Andreas, Ben Van Durme",2023-05-15T14:35:00Z,"  Designing natural language interfaces has historically required collecting
supervised data to translate user requests into carefully designed intent
representations. This requires enumerating and labeling a long tail of user
requests, which is challenging. At the same time, large language models (LLMs)
encode knowledge about goals and plans that can help conversational assistants
interpret user requests requiring numerous steps to complete. We introduce an
approach to handle complex-intent-bearing utterances from a user via a process
of hierarchical natural language decomposition and interpretation. Our approach
uses a pre-trained language model to decompose a complex utterance into a
sequence of simpler natural language steps and interprets each step using the
language-to-program model designed for the interface. To test our approach, we
collect and release DeCU -- a new NL-to-program benchmark to evaluate
Decomposition of Complex Utterances. Experiments show that the proposed
approach enables the interpretation of complex utterances with almost no
complex training data, while outperforming standard few-shot prompting
approaches.
","['designing', 'natural', 'language', 'interfaces', 'historically', 'required', 'collecting', 'supervised', 'data', 'translate', 'user', 'requests', 'carefully', 'designed', 'intent', 'representations', '.', 'requires', 'enumerating', 'labeling', 'long', 'tail', 'user', 'requests', ',', 'challenging', '.', 'time', ',', 'large', 'language', 'models', '(', 'llms', ')', 'encode', 'knowledge', 'goals', 'plans', 'help', 'conversational', 'assistants', 'interpret', 'user', 'requests', 'requiring', 'numerous', 'steps', 'complete', '.', 'introduce', 'approach', 'handle', 'complex-intent-bearing', 'utterances', 'user', 'via', 'process', 'hierarchical', 'natural', 'language', 'decomposition', 'interpretation', '.', 'approach', 'uses', 'pre-trained', 'language', 'model', 'decompose', 'complex', 'utterance', 'sequence', 'simpler', 'natural', 'language', 'steps', 'interprets', 'step', 'using', 'language-to-program', 'model', 'designed', 'interface', '.', 'test', 'approach', ',', 'collect', 'release', 'decu', '--', 'new', 'nl-to-program', 'benchmark', 'evaluate', 'decomposition', 'complex', 'utterances', '.', 'experiments', 'show', 'proposed', 'approach', 'enables', 'interpretation', 'complex', 'utterances', 'almost', 'complex', 'training', 'data', ',', 'outperforming', 'standard', 'few-shot', 'prompting', 'approaches', '.']","designing, natural, language, interfaces, historically, required, collecting, supervised, data, translate, user, requests, carefully, designed, intent, representations, ., requires, enumerating, labeling, long, tail, user, requests, ,, challenging, ., time, ,, large, language, models, (, llms, ), encode, knowledge, goals, plans, help, conversational, assistants, interpret, user, requests, requiring, numerous, steps, complete, ., introduce, approach, handle, complex-intent-bearing, utterances, user, via, process, hierarchical, natural, language, decomposition, interpretation, ., approach, uses, pre-trained, language, model, decompose, complex, utterance, sequence, simpler, natural, language, steps, interprets, step, using, language-to-program, model, designed, interface, ., test, approach, ,, collect, release, decu, --, new, nl-to-program, benchmark, evaluate, decomposition, complex, utterances, ., experiments, show, proposed, approach, enables, interpretation, complex, utterances, almost, complex, training, data, ,, outperforming, standard, few-shot, prompting, approaches, ."
Do Large Language Models Mirror Cognitive Language Processing?,"Yuqi Ren, Renren Jin, Tongxuan Zhang, Deyi Xiong",2024-02-28T03:38:20Z,"  Large Language Models (LLMs) have demonstrated remarkable abilities in text
comprehension and logical reasoning, indicating that the text representations
learned by LLMs can facilitate their language processing capabilities. In
cognitive science, brain cognitive processing signals are typically utilized to
study human language processing. Therefore, it is natural to ask how well the
text embeddings from LLMs align with the brain cognitive processing signals,
and how training strategies affect the LLM-brain alignment? In this paper, we
employ Representational Similarity Analysis (RSA) to measure the alignment
between 23 mainstream LLMs and fMRI signals of the brain to evaluate how
effectively LLMs simulate cognitive language processing. We empirically
investigate the impact of various factors (e.g., pre-training data size, model
scaling, alignment training, and prompts) on such LLM-brain alignment.
Experimental results indicate that pre-training data size and model scaling are
positively correlated with LLM-brain similarity, and alignment training can
significantly improve LLM-brain similarity. Explicit prompts contribute to the
consistency of LLMs with brain cognitive language processing, while nonsensical
noisy prompts may attenuate such alignment. Additionally, the performance of a
wide range of LLM evaluations (e.g., MMLU, Chatbot Arena) is highly correlated
with the LLM-brain similarity.
","['large', 'language', 'models', '(', 'llms', ')', 'demonstrated', 'remarkable', 'abilities', 'text', 'comprehension', 'logical', 'reasoning', ',', 'indicating', 'text', 'representations', 'learned', 'llms', 'facilitate', 'language', 'processing', 'capabilities', '.', 'cognitive', 'science', ',', 'brain', 'cognitive', 'processing', 'signals', 'typically', 'utilized', 'study', 'human', 'language', 'processing', '.', 'therefore', ',', 'natural', 'ask', 'well', 'text', 'embeddings', 'llms', 'align', 'brain', 'cognitive', 'processing', 'signals', ',', 'training', 'strategies', 'affect', 'llm-brain', 'alignment', '?', 'paper', ',', 'employ', 'representational', 'similarity', 'analysis', '(', 'rsa', ')', 'measure', 'alignment', '23', 'mainstream', 'llms', 'fmri', 'signals', 'brain', 'evaluate', 'effectively', 'llms', 'simulate', 'cognitive', 'language', 'processing', '.', 'empirically', 'investigate', 'impact', 'various', 'factors', '(', 'e.g.', ',', 'pre-training', 'data', 'size', ',', 'model', 'scaling', ',', 'alignment', 'training', ',', 'prompts', ')', 'llm-brain', 'alignment', '.', 'experimental', 'results', 'indicate', 'pre-training', 'data', 'size', 'model', 'scaling', 'positively', 'correlated', 'llm-brain', 'similarity', ',', 'alignment', 'training', 'significantly', 'improve', 'llm-brain', 'similarity', '.', 'explicit', 'prompts', 'contribute', 'consistency', 'llms', 'brain', 'cognitive', 'language', 'processing', ',', 'nonsensical', 'noisy', 'prompts', 'may', 'attenuate', 'alignment', '.', 'additionally', ',', 'performance', 'wide', 'range', 'llm', 'evaluations', '(', 'e.g.', ',', 'mmlu', ',', 'chatbot', 'arena', ')', 'highly', 'correlated', 'llm-brain', 'similarity', '.']","large, language, models, (, llms, ), demonstrated, remarkable, abilities, text, comprehension, logical, reasoning, ,, indicating, text, representations, learned, llms, facilitate, language, processing, capabilities, ., cognitive, science, ,, brain, cognitive, processing, signals, typically, utilized, study, human, language, processing, ., therefore, ,, natural, ask, well, text, embeddings, llms, align, brain, cognitive, processing, signals, ,, training, strategies, affect, llm-brain, alignment, ?, paper, ,, employ, representational, similarity, analysis, (, rsa, ), measure, alignment, 23, mainstream, llms, fmri, signals, brain, evaluate, effectively, llms, simulate, cognitive, language, processing, ., empirically, investigate, impact, various, factors, (, e.g., ,, pre-training, data, size, ,, model, scaling, ,, alignment, training, ,, prompts, ), llm-brain, alignment, ., experimental, results, indicate, pre-training, data, size, model, scaling, positively, correlated, llm-brain, similarity, ,, alignment, training, significantly, improve, llm-brain, similarity, ., explicit, prompts, contribute, consistency, llms, brain, cognitive, language, processing, ,, nonsensical, noisy, prompts, may, attenuate, alignment, ., additionally, ,, performance, wide, range, llm, evaluations, (, e.g., ,, mmlu, ,, chatbot, arena, ), highly, correlated, llm-brain, similarity, ."
"HinFlair: pre-trained contextual string embeddings for pos tagging and
  text classification in the Hindi language",Harsh Patel,2021-01-18T09:23:35Z,"  Recent advancements in language models based on recurrent neural networks and
transformers architecture have achieved state-of-the-art results on a wide
range of natural language processing tasks such as pos tagging, named entity
recognition, and text classification. However, most of these language models
are pre-trained in high resource languages like English, German, Spanish.
Multi-lingual language models include Indian languages like Hindi, Telugu,
Bengali in their training corpus, but they often fail to represent the
linguistic features of these languages as they are not the primary language of
the study. We introduce HinFlair, which is a language representation model
(contextual string embeddings) pre-trained on a large monolingual Hindi corpus.
Experiments were conducted on 6 text classification datasets and a Hindi
dependency treebank to analyze the performance of these contextualized string
embeddings for the Hindi language. Results show that HinFlair outperforms
previous state-of-the-art publicly available pre-trained embeddings for
downstream tasks like text classification and pos tagging. Also, HinFlair when
combined with FastText embeddings outperforms many transformers-based language
models trained particularly for the Hindi language.
","['recent', 'advancements', 'language', 'models', 'based', 'recurrent', 'neural', 'networks', 'transformers', 'architecture', 'achieved', 'state-of-the-art', 'results', 'wide', 'range', 'natural', 'language', 'processing', 'tasks', 'pos', 'tagging', ',', 'named', 'entity', 'recognition', ',', 'text', 'classification', '.', 'however', ',', 'language', 'models', 'pre-trained', 'high', 'resource', 'languages', 'like', 'english', ',', 'german', ',', 'spanish', '.', 'multi-lingual', 'language', 'models', 'include', 'indian', 'languages', 'like', 'hindi', ',', 'telugu', ',', 'bengali', 'training', 'corpus', ',', 'often', 'fail', 'represent', 'linguistic', 'features', 'languages', 'primary', 'language', 'study', '.', 'introduce', 'hinflair', ',', 'language', 'representation', 'model', '(', 'contextual', 'string', 'embeddings', ')', 'pre-trained', 'large', 'monolingual', 'hindi', 'corpus', '.', 'experiments', 'conducted', '6', 'text', 'classification', 'datasets', 'hindi', 'dependency', 'treebank', 'analyze', 'performance', 'contextualized', 'string', 'embeddings', 'hindi', 'language', '.', 'results', 'show', 'hinflair', 'outperforms', 'previous', 'state-of-the-art', 'publicly', 'available', 'pre-trained', 'embeddings', 'downstream', 'tasks', 'like', 'text', 'classification', 'pos', 'tagging', '.', 'also', ',', 'hinflair', 'combined', 'fasttext', 'embeddings', 'outperforms', 'many', 'transformers-based', 'language', 'models', 'trained', 'particularly', 'hindi', 'language', '.']","recent, advancements, language, models, based, recurrent, neural, networks, transformers, architecture, achieved, state-of-the-art, results, wide, range, natural, language, processing, tasks, pos, tagging, ,, named, entity, recognition, ,, text, classification, ., however, ,, language, models, pre-trained, high, resource, languages, like, english, ,, german, ,, spanish, ., multi-lingual, language, models, include, indian, languages, like, hindi, ,, telugu, ,, bengali, training, corpus, ,, often, fail, represent, linguistic, features, languages, primary, language, study, ., introduce, hinflair, ,, language, representation, model, (, contextual, string, embeddings, ), pre-trained, large, monolingual, hindi, corpus, ., experiments, conducted, 6, text, classification, datasets, hindi, dependency, treebank, analyze, performance, contextualized, string, embeddings, hindi, language, ., results, show, hinflair, outperforms, previous, state-of-the-art, publicly, available, pre-trained, embeddings, downstream, tasks, like, text, classification, pos, tagging, ., also, ,, hinflair, combined, fasttext, embeddings, outperforms, many, transformers-based, language, models, trained, particularly, hindi, language, ."
A Principled Framework for Evaluating on Typologically Diverse Languages,"Esther Ploeger, Wessel Poelman, Andreas Holck Høeg-Petersen, Anders Schlichtkrull, Miryam de Lhoneux, Johannes Bjerva",2024-07-06T09:31:02Z,"  Beyond individual languages, multilingual natural language processing (NLP)
research increasingly aims to develop models that perform well across languages
generally. However, evaluating these systems on all the world's languages is
practically infeasible. To attain generalizability, representative language
sampling is essential. Previous work argues that generalizable multilingual
evaluation sets should contain languages with diverse typological properties.
However, 'typologically diverse' language samples have been found to vary
considerably in this regard, and popular sampling methods are flawed and
inconsistent. We present a language sampling framework for selecting highly
typologically diverse languages given a sampling frame, informed by language
typology. We compare sampling methods with a range of metrics and find that our
systematic methods consistently retrieve more typologically diverse language
selections than previous methods in NLP. Moreover, we provide evidence that
this affects generalizability in multilingual model evaluation, emphasizing the
importance of diverse language sampling in NLP evaluation.
","['beyond', 'individual', 'languages', ',', 'multilingual', 'natural', 'language', 'processing', '(', 'nlp', ')', 'research', 'increasingly', 'aims', 'develop', 'models', 'perform', 'well', 'across', 'languages', 'generally', '.', 'however', ',', 'evaluating', 'systems', 'world', ""'s"", 'languages', 'practically', 'infeasible', '.', 'attain', 'generalizability', ',', 'representative', 'language', 'sampling', 'essential', '.', 'previous', 'work', 'argues', 'generalizable', 'multilingual', 'evaluation', 'sets', 'contain', 'languages', 'diverse', 'typological', 'properties', '.', 'however', ',', ""'typologically"", 'diverse', ""'"", 'language', 'samples', 'found', 'vary', 'considerably', 'regard', ',', 'popular', 'sampling', 'methods', 'flawed', 'inconsistent', '.', 'present', 'language', 'sampling', 'framework', 'selecting', 'highly', 'typologically', 'diverse', 'languages', 'given', 'sampling', 'frame', ',', 'informed', 'language', 'typology', '.', 'compare', 'sampling', 'methods', 'range', 'metrics', 'find', 'systematic', 'methods', 'consistently', 'retrieve', 'typologically', 'diverse', 'language', 'selections', 'previous', 'methods', 'nlp', '.', 'moreover', ',', 'provide', 'evidence', 'affects', 'generalizability', 'multilingual', 'model', 'evaluation', ',', 'emphasizing', 'importance', 'diverse', 'language', 'sampling', 'nlp', 'evaluation', '.']","beyond, individual, languages, ,, multilingual, natural, language, processing, (, nlp, ), research, increasingly, aims, develop, models, perform, well, across, languages, generally, ., however, ,, evaluating, systems, world, 's, languages, practically, infeasible, ., attain, generalizability, ,, representative, language, sampling, essential, ., previous, work, argues, generalizable, multilingual, evaluation, sets, contain, languages, diverse, typological, properties, ., however, ,, 'typologically, diverse, ', language, samples, found, vary, considerably, regard, ,, popular, sampling, methods, flawed, inconsistent, ., present, language, sampling, framework, selecting, highly, typologically, diverse, languages, given, sampling, frame, ,, informed, language, typology, ., compare, sampling, methods, range, metrics, find, systematic, methods, consistently, retrieve, typologically, diverse, language, selections, previous, methods, nlp, ., moreover, ,, provide, evidence, affects, generalizability, multilingual, model, evaluation, ,, emphasizing, importance, diverse, language, sampling, nlp, evaluation, ."
Functorial Language Games for Question Answering,"Giovanni de Felice, Elena Di Lavore, Mario Román, Alexis Toumi",2020-05-19T13:35:13Z,"  We present some categorical investigations into Wittgenstein's
language-games, with applications to game-theoretic pragmatics and
question-answering in natural language processing.
","['present', 'categorical', 'investigations', 'wittgenstein', ""'s"", 'language-games', ',', 'applications', 'game-theoretic', 'pragmatics', 'question-answering', 'natural', 'language', 'processing', '.']","present, categorical, investigations, wittgenstein, 's, language-games, ,, applications, game-theoretic, pragmatics, question-answering, natural, language, processing, ."
"Bilingual Lexicon Induction for Low-Resource Languages using Graph
  Matching via Optimal Transport","Kelly Marchisio, Ali Saad-Eldin, Kevin Duh, Carey Priebe, Philipp Koehn",2022-10-25T23:09:20Z,"  Bilingual lexicons form a critical component of various natural language
processing applications, including unsupervised and semisupervised machine
translation and crosslingual information retrieval. We improve bilingual
lexicon induction performance across 40 language pairs with a graph-matching
method based on optimal transport. The method is especially strong with low
amounts of supervision.
","['bilingual', 'lexicons', 'form', 'critical', 'component', 'various', 'natural', 'language', 'processing', 'applications', ',', 'including', 'unsupervised', 'semisupervised', 'machine', 'translation', 'crosslingual', 'information', 'retrieval', '.', 'improve', 'bilingual', 'lexicon', 'induction', 'performance', 'across', '40', 'language', 'pairs', 'graph-matching', 'method', 'based', 'optimal', 'transport', '.', 'method', 'especially', 'strong', 'low', 'amounts', 'supervision', '.']","bilingual, lexicons, form, critical, component, various, natural, language, processing, applications, ,, including, unsupervised, semisupervised, machine, translation, crosslingual, information, retrieval, ., improve, bilingual, lexicon, induction, performance, across, 40, language, pairs, graph-matching, method, based, optimal, transport, ., method, especially, strong, low, amounts, supervision, ."
"Improving Clinical NLP Performance through Language Model-Generated
  Synthetic Clinical Data","Shan Chen, Jack Gallifant, Marco Guevara, Yanjun Gao, Majid Afshar, Timothy Miller, Dmitriy Dligach, Danielle S. Bitterman",2024-03-28T15:44:18Z,"  Generative models have been showing potential for producing data in mass.
This study explores the enhancement of clinical natural language processing
performance by utilizing synthetic data generated from advanced language
models. Promising results show feasible applications in such a high-stakes
domain.
","['generative', 'models', 'showing', 'potential', 'producing', 'data', 'mass', '.', 'study', 'explores', 'enhancement', 'clinical', 'natural', 'language', 'processing', 'performance', 'utilizing', 'synthetic', 'data', 'generated', 'advanced', 'language', 'models', '.', 'promising', 'results', 'show', 'feasible', 'applications', 'high-stakes', 'domain', '.']","generative, models, showing, potential, producing, data, mass, ., study, explores, enhancement, clinical, natural, language, processing, performance, utilizing, synthetic, data, generated, advanced, language, models, ., promising, results, show, feasible, applications, high-stakes, domain, ."
Prompt Engineering for Healthcare: Methodologies and Applications,"Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong Ma, Haixing Dai, Qiushi Yang, Yanqing Kang, Jinru Wu, Huawen Hu, Chenxi Yue, Haiyang Zhang, Yiheng Liu, Yi Pan, Zhengliang Liu, Lichao Sun, Xiang Li, Bao Ge, Xi Jiang, Dajiang Zhu, Yixuan Yuan, Dinggang Shen, Tianming Liu, Shu Zhang",2023-04-28T08:03:42Z,"  Prompt engineering is a critical technique in the field of natural language
processing that involves designing and optimizing the prompts used to input
information into models, aiming to enhance their performance on specific tasks.
With the recent advancements in large language models, prompt engineering has
shown significant superiority across various domains and has become
increasingly important in the healthcare domain. However, there is a lack of
comprehensive reviews specifically focusing on prompt engineering in the
medical field. This review will introduce the latest advances in prompt
engineering in the field of natural language processing for the medical field.
First, we will provide the development of prompt engineering and emphasize its
significant contributions to healthcare natural language processing
applications such as question-answering systems, text summarization, and
machine translation. With the continuous improvement of general large language
models, the importance of prompt engineering in the healthcare domain is
becoming increasingly prominent. The aim of this article is to provide useful
resources and bridges for healthcare natural language processing researchers to
better explore the application of prompt engineering in this field. We hope
that this review can provide new ideas and inspire for research and application
in medical natural language processing.
","['prompt', 'engineering', 'critical', 'technique', 'field', 'natural', 'language', 'processing', 'involves', 'designing', 'optimizing', 'prompts', 'used', 'input', 'information', 'models', ',', 'aiming', 'enhance', 'performance', 'specific', 'tasks', '.', 'recent', 'advancements', 'large', 'language', 'models', ',', 'prompt', 'engineering', 'shown', 'significant', 'superiority', 'across', 'various', 'domains', 'become', 'increasingly', 'important', 'healthcare', 'domain', '.', 'however', ',', 'lack', 'comprehensive', 'reviews', 'specifically', 'focusing', 'prompt', 'engineering', 'medical', 'field', '.', 'review', 'introduce', 'latest', 'advances', 'prompt', 'engineering', 'field', 'natural', 'language', 'processing', 'medical', 'field', '.', 'first', ',', 'provide', 'development', 'prompt', 'engineering', 'emphasize', 'significant', 'contributions', 'healthcare', 'natural', 'language', 'processing', 'applications', 'question-answering', 'systems', ',', 'text', 'summarization', ',', 'machine', 'translation', '.', 'continuous', 'improvement', 'general', 'large', 'language', 'models', ',', 'importance', 'prompt', 'engineering', 'healthcare', 'domain', 'becoming', 'increasingly', 'prominent', '.', 'aim', 'article', 'provide', 'useful', 'resources', 'bridges', 'healthcare', 'natural', 'language', 'processing', 'researchers', 'better', 'explore', 'application', 'prompt', 'engineering', 'field', '.', 'hope', 'review', 'provide', 'new', 'ideas', 'inspire', 'research', 'application', 'medical', 'natural', 'language', 'processing', '.']","prompt, engineering, critical, technique, field, natural, language, processing, involves, designing, optimizing, prompts, used, input, information, models, ,, aiming, enhance, performance, specific, tasks, ., recent, advancements, large, language, models, ,, prompt, engineering, shown, significant, superiority, across, various, domains, become, increasingly, important, healthcare, domain, ., however, ,, lack, comprehensive, reviews, specifically, focusing, prompt, engineering, medical, field, ., review, introduce, latest, advances, prompt, engineering, field, natural, language, processing, medical, field, ., first, ,, provide, development, prompt, engineering, emphasize, significant, contributions, healthcare, natural, language, processing, applications, question-answering, systems, ,, text, summarization, ,, machine, translation, ., continuous, improvement, general, large, language, models, ,, importance, prompt, engineering, healthcare, domain, becoming, increasingly, prominent, ., aim, article, provide, useful, resources, bridges, healthcare, natural, language, processing, researchers, better, explore, application, prompt, engineering, field, ., hope, review, provide, new, ideas, inspire, research, application, medical, natural, language, processing, ."
"Process-To-Text: A Framework for the Quantitative Description of
  Processes in Natural Language","Yago Fontenla-Seco, Alberto Bugarín-Diz, Manuel Lama",2023-05-23T13:14:34Z,"  In this paper we present the Process-To-Text (P2T) framework for the
automatic generation of textual descriptive explanations of processes. P2T
integrates three AI paradigms: process mining for extracting temporal and
structural information from a process, fuzzy linguistic protoforms for
modelling uncertain terms, and natural language generation for building the
explanations. A real use-case in the cardiology domain is presented, showing
the potential of P2T for providing natural language explanations addressed to
specialists.
","['paper', 'present', 'process-to-text', '(', 'p2t', ')', 'framework', 'automatic', 'generation', 'textual', 'descriptive', 'explanations', 'processes', '.', 'p2t', 'integrates', 'three', 'ai', 'paradigms', ':', 'process', 'mining', 'extracting', 'temporal', 'structural', 'information', 'process', ',', 'fuzzy', 'linguistic', 'protoforms', 'modelling', 'uncertain', 'terms', ',', 'natural', 'language', 'generation', 'building', 'explanations', '.', 'real', 'use-case', 'cardiology', 'domain', 'presented', ',', 'showing', 'potential', 'p2t', 'providing', 'natural', 'language', 'explanations', 'addressed', 'specialists', '.']","paper, present, process-to-text, (, p2t, ), framework, automatic, generation, textual, descriptive, explanations, processes, ., p2t, integrates, three, ai, paradigms, :, process, mining, extracting, temporal, structural, information, process, ,, fuzzy, linguistic, protoforms, modelling, uncertain, terms, ,, natural, language, generation, building, explanations, ., real, use-case, cardiology, domain, presented, ,, showing, potential, p2t, providing, natural, language, explanations, addressed, specialists, ."
"Parameter-Efficient Conversational Recommender System as a Language
  Processing Task","Mathieu Ravaut, Hao Zhang, Lu Xu, Aixin Sun, Yong Liu",2024-01-25T14:07:34Z,"  Conversational recommender systems (CRS) aim to recommend relevant items to
users by eliciting user preference through natural language conversation. Prior
work often utilizes external knowledge graphs for items' semantic information,
a language model for dialogue generation, and a recommendation module for
ranking relevant items. This combination of multiple components suffers from a
cumbersome training process, and leads to semantic misalignment issues between
dialogue generation and item recommendation. In this paper, we represent items
in natural language and formulate CRS as a natural language processing task.
Accordingly, we leverage the power of pre-trained language models to encode
items, understand user intent via conversation, perform item recommendation
through semantic matching, and generate dialogues. As a unified model, our
PECRS (Parameter-Efficient CRS), can be optimized in a single stage, without
relying on non-textual metadata such as a knowledge graph. Experiments on two
benchmark CRS datasets, ReDial and INSPIRED, demonstrate the effectiveness of
PECRS on recommendation and conversation. Our code is available at:
https://github.com/Ravoxsg/efficient_unified_crs.
","['conversational', 'recommender', 'systems', '(', 'crs', ')', 'aim', 'recommend', 'relevant', 'items', 'users', 'eliciting', 'user', 'preference', 'natural', 'language', 'conversation', '.', 'prior', 'work', 'often', 'utilizes', 'external', 'knowledge', 'graphs', 'items', ""'"", 'semantic', 'information', ',', 'language', 'model', 'dialogue', 'generation', ',', 'recommendation', 'module', 'ranking', 'relevant', 'items', '.', 'combination', 'multiple', 'components', 'suffers', 'cumbersome', 'training', 'process', ',', 'leads', 'semantic', 'misalignment', 'issues', 'dialogue', 'generation', 'item', 'recommendation', '.', 'paper', ',', 'represent', 'items', 'natural', 'language', 'formulate', 'crs', 'natural', 'language', 'processing', 'task', '.', 'accordingly', ',', 'leverage', 'power', 'pre-trained', 'language', 'models', 'encode', 'items', ',', 'understand', 'user', 'intent', 'via', 'conversation', ',', 'perform', 'item', 'recommendation', 'semantic', 'matching', ',', 'generate', 'dialogues', '.', 'unified', 'model', ',', 'pecrs', '(', 'parameter-efficient', 'crs', ')', ',', 'optimized', 'single', 'stage', ',', 'without', 'relying', 'non-textual', 'metadata', 'knowledge', 'graph', '.', 'experiments', 'two', 'benchmark', 'crs', 'datasets', ',', 'redial', 'inspired', ',', 'demonstrate', 'effectiveness', 'pecrs', 'recommendation', 'conversation', '.', 'code', 'available', ':', 'https', ':', '//github.com/ravoxsg/efficient_unified_crs', '.']","conversational, recommender, systems, (, crs, ), aim, recommend, relevant, items, users, eliciting, user, preference, natural, language, conversation, ., prior, work, often, utilizes, external, knowledge, graphs, items, ', semantic, information, ,, language, model, dialogue, generation, ,, recommendation, module, ranking, relevant, items, ., combination, multiple, components, suffers, cumbersome, training, process, ,, leads, semantic, misalignment, issues, dialogue, generation, item, recommendation, ., paper, ,, represent, items, natural, language, formulate, crs, natural, language, processing, task, ., accordingly, ,, leverage, power, pre-trained, language, models, encode, items, ,, understand, user, intent, via, conversation, ,, perform, item, recommendation, semantic, matching, ,, generate, dialogues, ., unified, model, ,, pecrs, (, parameter-efficient, crs, ), ,, optimized, single, stage, ,, without, relying, non-textual, metadata, knowledge, graph, ., experiments, two, benchmark, crs, datasets, ,, redial, inspired, ,, demonstrate, effectiveness, pecrs, recommendation, conversation, ., code, available, :, https, :, //github.com/ravoxsg/efficient_unified_crs, ."
"InstructProtein: Aligning Human and Protein Language via Knowledge
  Instruction","Zeyuan Wang, Qiang Zhang, Keyan Ding, Ming Qin, Xiang Zhuang, Xiaotong Li, Huajun Chen",2023-10-05T02:45:39Z,"  Large Language Models (LLMs) have revolutionized the field of natural
language processing, but they fall short in comprehending biological sequences
such as proteins. To address this challenge, we propose InstructProtein, an
innovative LLM that possesses bidirectional generation capabilities in both
human and protein languages: (i) taking a protein sequence as input to predict
its textual function description and (ii) using natural language to prompt
protein sequence generation. To achieve this, we first pre-train an LLM on both
protein and natural language corpora, enabling it to comprehend individual
languages. Then supervised instruction tuning is employed to facilitate the
alignment of these two distinct languages. Herein, we introduce a knowledge
graph-based instruction generation framework to construct a high-quality
instruction dataset, addressing annotation imbalance and instruction deficits
in existing protein-text corpus. In particular, the instructions inherit the
structural relations between proteins and function annotations in knowledge
graphs, which empowers our model to engage in the causal modeling of protein
functions, akin to the chain-of-thought processes in natural languages.
Extensive experiments on bidirectional protein-text generation tasks show that
InstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,
InstructProtein serves as a pioneering step towards text-based protein function
prediction and sequence design, effectively bridging the gap between protein
and human language understanding.
","['large', 'language', 'models', '(', 'llms', ')', 'revolutionized', 'field', 'natural', 'language', 'processing', ',', 'fall', 'short', 'comprehending', 'biological', 'sequences', 'proteins', '.', 'address', 'challenge', ',', 'propose', 'instructprotein', ',', 'innovative', 'llm', 'possesses', 'bidirectional', 'generation', 'capabilities', 'human', 'protein', 'languages', ':', '(', ')', 'taking', 'protein', 'sequence', 'input', 'predict', 'textual', 'function', 'description', '(', 'ii', ')', 'using', 'natural', 'language', 'prompt', 'protein', 'sequence', 'generation', '.', 'achieve', ',', 'first', 'pre-train', 'llm', 'protein', 'natural', 'language', 'corpora', ',', 'enabling', 'comprehend', 'individual', 'languages', '.', 'supervised', 'instruction', 'tuning', 'employed', 'facilitate', 'alignment', 'two', 'distinct', 'languages', '.', 'herein', ',', 'introduce', 'knowledge', 'graph-based', 'instruction', 'generation', 'framework', 'construct', 'high-quality', 'instruction', 'dataset', ',', 'addressing', 'annotation', 'imbalance', 'instruction', 'deficits', 'existing', 'protein-text', 'corpus', '.', 'particular', ',', 'instructions', 'inherit', 'structural', 'relations', 'proteins', 'function', 'annotations', 'knowledge', 'graphs', ',', 'empowers', 'model', 'engage', 'causal', 'modeling', 'protein', 'functions', ',', 'akin', 'chain-of-thought', 'processes', 'natural', 'languages', '.', 'extensive', 'experiments', 'bidirectional', 'protein-text', 'generation', 'tasks', 'show', 'instructprotein', 'outperforms', 'state-of-the-art', 'llms', 'large', 'margins', '.', 'moreover', ',', 'instructprotein', 'serves', 'pioneering', 'step', 'towards', 'text-based', 'protein', 'function', 'prediction', 'sequence', 'design', ',', 'effectively', 'bridging', 'gap', 'protein', 'human', 'language', 'understanding', '.']","large, language, models, (, llms, ), revolutionized, field, natural, language, processing, ,, fall, short, comprehending, biological, sequences, proteins, ., address, challenge, ,, propose, instructprotein, ,, innovative, llm, possesses, bidirectional, generation, capabilities, human, protein, languages, :, (, ), taking, protein, sequence, input, predict, textual, function, description, (, ii, ), using, natural, language, prompt, protein, sequence, generation, ., achieve, ,, first, pre-train, llm, protein, natural, language, corpora, ,, enabling, comprehend, individual, languages, ., supervised, instruction, tuning, employed, facilitate, alignment, two, distinct, languages, ., herein, ,, introduce, knowledge, graph-based, instruction, generation, framework, construct, high-quality, instruction, dataset, ,, addressing, annotation, imbalance, instruction, deficits, existing, protein-text, corpus, ., particular, ,, instructions, inherit, structural, relations, proteins, function, annotations, knowledge, graphs, ,, empowers, model, engage, causal, modeling, protein, functions, ,, akin, chain-of-thought, processes, natural, languages, ., extensive, experiments, bidirectional, protein-text, generation, tasks, show, instructprotein, outperforms, state-of-the-art, llms, large, margins, ., moreover, ,, instructprotein, serves, pioneering, step, towards, text-based, protein, function, prediction, sequence, design, ,, effectively, bridging, gap, protein, human, language, understanding, ."
"Using Natural Language Processing and Networks to Automate Structured
  Literature Reviews: An Application to Farmers Climate Change Adaptation","Sofia Gil-Clavel, Tatiana Filatova",2023-06-16T10:05:47Z,"  The fast-growing number of research articles makes it problematic for
scholars to keep track of the new findings related to their areas of expertise.
Furthermore, linking knowledge across disciplines in rapidly developing fields
becomes challenging for complex topics like climate change that demand
interdisciplinary solutions. At the same time, the rise of Black Box types of
text summarization makes it difficult to understand how text relationships are
built, let alone relate to existing theories conceptualizing cause-effect
relationships and permitting hypothesizing. This work aims to sensibly use
Natural Language Processing by extracting variables relations and synthesizing
their findings using networks while relating to key concepts dominant in
relevant disciplines. As an example, we apply our methodology to the analysis
of farmers' adaptation to climate change. For this, we perform a Natural
Language Processing analysis of publications returned by Scopus in August 2022.
Results show that the use of Natural Language Processing together with networks
in a descriptive manner offers a fast and interpretable way to synthesize
literature review findings as long as researchers back up results with theory.
","['fast-growing', 'number', 'research', 'articles', 'makes', 'problematic', 'scholars', 'keep', 'track', 'new', 'findings', 'related', 'areas', 'expertise', '.', 'furthermore', ',', 'linking', 'knowledge', 'across', 'disciplines', 'rapidly', 'developing', 'fields', 'becomes', 'challenging', 'complex', 'topics', 'like', 'climate', 'change', 'demand', 'interdisciplinary', 'solutions', '.', 'time', ',', 'rise', 'black', 'box', 'types', 'text', 'summarization', 'makes', 'difficult', 'understand', 'text', 'relationships', 'built', ',', 'let', 'alone', 'relate', 'existing', 'theories', 'conceptualizing', 'cause-effect', 'relationships', 'permitting', 'hypothesizing', '.', 'work', 'aims', 'sensibly', 'use', 'natural', 'language', 'processing', 'extracting', 'variables', 'relations', 'synthesizing', 'findings', 'using', 'networks', 'relating', 'key', 'concepts', 'dominant', 'relevant', 'disciplines', '.', 'example', ',', 'apply', 'methodology', 'analysis', 'farmers', ""'"", 'adaptation', 'climate', 'change', '.', ',', 'perform', 'natural', 'language', 'processing', 'analysis', 'publications', 'returned', 'scopus', 'august', '2022.', 'results', 'show', 'use', 'natural', 'language', 'processing', 'together', 'networks', 'descriptive', 'manner', 'offers', 'fast', 'interpretable', 'way', 'synthesize', 'literature', 'review', 'findings', 'long', 'researchers', 'back', 'results', 'theory', '.']","fast-growing, number, research, articles, makes, problematic, scholars, keep, track, new, findings, related, areas, expertise, ., furthermore, ,, linking, knowledge, across, disciplines, rapidly, developing, fields, becomes, challenging, complex, topics, like, climate, change, demand, interdisciplinary, solutions, ., time, ,, rise, black, box, types, text, summarization, makes, difficult, understand, text, relationships, built, ,, let, alone, relate, existing, theories, conceptualizing, cause-effect, relationships, permitting, hypothesizing, ., work, aims, sensibly, use, natural, language, processing, extracting, variables, relations, synthesizing, findings, using, networks, relating, key, concepts, dominant, relevant, disciplines, ., example, ,, apply, methodology, analysis, farmers, ', adaptation, climate, change, ., ,, perform, natural, language, processing, analysis, publications, returned, scopus, august, 2022., results, show, use, natural, language, processing, together, networks, descriptive, manner, offers, fast, interpretable, way, synthesize, literature, review, findings, long, researchers, back, results, theory, ."
Exploring the Landscape of Natural Language Processing Research,"Tim Schopf, Karim Arabi, Florian Matthes",2023-07-20T07:33:30Z,"  As an efficient approach to understand, generate, and process natural
language texts, research in natural language processing (NLP) has exhibited a
rapid spread and wide adoption in recent years. Given the increasing research
work in this area, several NLP-related approaches have been surveyed in the
research community. However, a comprehensive study that categorizes established
topics, identifies trends, and outlines areas for future research remains
absent. Contributing to closing this gap, we have systematically classified and
analyzed research papers in the ACL Anthology. As a result, we present a
structured overview of the research landscape, provide a taxonomy of fields of
study in NLP, analyze recent developments in NLP, summarize our findings, and
highlight directions for future work.
","['efficient', 'approach', 'understand', ',', 'generate', ',', 'process', 'natural', 'language', 'texts', ',', 'research', 'natural', 'language', 'processing', '(', 'nlp', ')', 'exhibited', 'rapid', 'spread', 'wide', 'adoption', 'recent', 'years', '.', 'given', 'increasing', 'research', 'work', 'area', ',', 'several', 'nlp-related', 'approaches', 'surveyed', 'research', 'community', '.', 'however', ',', 'comprehensive', 'study', 'categorizes', 'established', 'topics', ',', 'identifies', 'trends', ',', 'outlines', 'areas', 'future', 'research', 'remains', 'absent', '.', 'contributing', 'closing', 'gap', ',', 'systematically', 'classified', 'analyzed', 'research', 'papers', 'acl', 'anthology', '.', 'result', ',', 'present', 'structured', 'overview', 'research', 'landscape', ',', 'provide', 'taxonomy', 'fields', 'study', 'nlp', ',', 'analyze', 'recent', 'developments', 'nlp', ',', 'summarize', 'findings', ',', 'highlight', 'directions', 'future', 'work', '.']","efficient, approach, understand, ,, generate, ,, process, natural, language, texts, ,, research, natural, language, processing, (, nlp, ), exhibited, rapid, spread, wide, adoption, recent, years, ., given, increasing, research, work, area, ,, several, nlp-related, approaches, surveyed, research, community, ., however, ,, comprehensive, study, categorizes, established, topics, ,, identifies, trends, ,, outlines, areas, future, research, remains, absent, ., contributing, closing, gap, ,, systematically, classified, analyzed, research, papers, acl, anthology, ., result, ,, present, structured, overview, research, landscape, ,, provide, taxonomy, fields, study, nlp, ,, analyze, recent, developments, nlp, ,, summarize, findings, ,, highlight, directions, future, work, ."
Natural Language Processing and Multimodal Stock Price Prediction,"Kevin Taylor, Jerry Ng",2024-01-03T01:21:30Z,"  In the realm of financial decision-making, predicting stock prices is
pivotal. Artificial intelligence techniques such as long short-term memory
networks (LSTMs), support-vector machines (SVMs), and natural language
processing (NLP) models are commonly employed to predict said prices. This
paper utilizes stock percentage change as training data, in contrast to the
traditional use of raw currency values, with a focus on analyzing publicly
released news articles. The choice of percentage change aims to provide models
with context regarding the significance of price fluctuations and overall price
change impact on a given stock. The study employs specialized BERT natural
language processing models to predict stock price trends, with a particular
emphasis on various data modalities. The results showcase the capabilities of
such strategies with a small natural language processing model to accurately
predict overall stock trends, and highlight the effectiveness of certain data
features and sector-specific data.
","['realm', 'financial', 'decision-making', ',', 'predicting', 'stock', 'prices', 'pivotal', '.', 'artificial', 'intelligence', 'techniques', 'long', 'short-term', 'memory', 'networks', '(', 'lstms', ')', ',', 'support-vector', 'machines', '(', 'svms', ')', ',', 'natural', 'language', 'processing', '(', 'nlp', ')', 'models', 'commonly', 'employed', 'predict', 'said', 'prices', '.', 'paper', 'utilizes', 'stock', 'percentage', 'change', 'training', 'data', ',', 'contrast', 'traditional', 'use', 'raw', 'currency', 'values', ',', 'focus', 'analyzing', 'publicly', 'released', 'news', 'articles', '.', 'choice', 'percentage', 'change', 'aims', 'provide', 'models', 'context', 'regarding', 'significance', 'price', 'fluctuations', 'overall', 'price', 'change', 'impact', 'given', 'stock', '.', 'study', 'employs', 'specialized', 'bert', 'natural', 'language', 'processing', 'models', 'predict', 'stock', 'price', 'trends', ',', 'particular', 'emphasis', 'various', 'data', 'modalities', '.', 'results', 'showcase', 'capabilities', 'strategies', 'small', 'natural', 'language', 'processing', 'model', 'accurately', 'predict', 'overall', 'stock', 'trends', ',', 'highlight', 'effectiveness', 'certain', 'data', 'features', 'sector-specific', 'data', '.']","realm, financial, decision-making, ,, predicting, stock, prices, pivotal, ., artificial, intelligence, techniques, long, short-term, memory, networks, (, lstms, ), ,, support-vector, machines, (, svms, ), ,, natural, language, processing, (, nlp, ), models, commonly, employed, predict, said, prices, ., paper, utilizes, stock, percentage, change, training, data, ,, contrast, traditional, use, raw, currency, values, ,, focus, analyzing, publicly, released, news, articles, ., choice, percentage, change, aims, provide, models, context, regarding, significance, price, fluctuations, overall, price, change, impact, given, stock, ., study, employs, specialized, bert, natural, language, processing, models, predict, stock, price, trends, ,, particular, emphasis, various, data, modalities, ., results, showcase, capabilities, strategies, small, natural, language, processing, model, accurately, predict, overall, stock, trends, ,, highlight, effectiveness, certain, data, features, sector-specific, data, ."
Visualizing RNN States with Predictive Semantic Encodings,"Lindsey Sawatzky, Steven Bergner, Fred Popowich",2019-08-01T19:24:59Z,"  Recurrent Neural Networks are an effective and prevalent tool used to model
sequential data such as natural language text. However, their deep nature and
massive number of parameters pose a challenge for those intending to study
precisely how they work. We present a visual technique that gives a high level
intuition behind the semantics of the hidden states within Recurrent Neural
Networks. This semantic encoding allows for hidden states to be compared
throughout the model independent of their internal details. The proposed
technique is displayed in a proof of concept visualization tool which is
demonstrated to visualize the natural language processing task of language
modelling.
","['recurrent', 'neural', 'networks', 'effective', 'prevalent', 'tool', 'used', 'model', 'sequential', 'data', 'natural', 'language', 'text', '.', 'however', ',', 'deep', 'nature', 'massive', 'number', 'parameters', 'pose', 'challenge', 'intending', 'study', 'precisely', 'work', '.', 'present', 'visual', 'technique', 'gives', 'high', 'level', 'intuition', 'behind', 'semantics', 'hidden', 'states', 'within', 'recurrent', 'neural', 'networks', '.', 'semantic', 'encoding', 'allows', 'hidden', 'states', 'compared', 'throughout', 'model', 'independent', 'internal', 'details', '.', 'proposed', 'technique', 'displayed', 'proof', 'concept', 'visualization', 'tool', 'demonstrated', 'visualize', 'natural', 'language', 'processing', 'task', 'language', 'modelling', '.']","recurrent, neural, networks, effective, prevalent, tool, used, model, sequential, data, natural, language, text, ., however, ,, deep, nature, massive, number, parameters, pose, challenge, intending, study, precisely, work, ., present, visual, technique, gives, high, level, intuition, behind, semantics, hidden, states, within, recurrent, neural, networks, ., semantic, encoding, allows, hidden, states, compared, throughout, model, independent, internal, details, ., proposed, technique, displayed, proof, concept, visualization, tool, demonstrated, visualize, natural, language, processing, task, language, modelling, ."
ALTER: Auxiliary Text Rewriting Tool for Natural Language Generation,"Qiongkai Xu, Chenchen Xu, Lizhen Qu",2019-09-14T09:18:44Z,"  In this paper, we describe ALTER, an auxiliary text rewriting tool that
facilitates the rewriting process for natural language generation tasks, such
as paraphrasing, text simplification, fairness-aware text rewriting, and text
style transfer. Our tool is characterized by two features, i) recording of
word-level revision histories and ii) flexible auxiliary edit support and
feedback to annotators. The text rewriting assist and traceable rewriting
history are potentially beneficial to the future research of natural language
generation.
","['paper', ',', 'describe', 'alter', ',', 'auxiliary', 'text', 'rewriting', 'tool', 'facilitates', 'rewriting', 'process', 'natural', 'language', 'generation', 'tasks', ',', 'paraphrasing', ',', 'text', 'simplification', ',', 'fairness-aware', 'text', 'rewriting', ',', 'text', 'style', 'transfer', '.', 'tool', 'characterized', 'two', 'features', ',', ')', 'recording', 'word-level', 'revision', 'histories', 'ii', ')', 'flexible', 'auxiliary', 'edit', 'support', 'feedback', 'annotators', '.', 'text', 'rewriting', 'assist', 'traceable', 'rewriting', 'history', 'potentially', 'beneficial', 'future', 'research', 'natural', 'language', 'generation', '.']","paper, ,, describe, alter, ,, auxiliary, text, rewriting, tool, facilitates, rewriting, process, natural, language, generation, tasks, ,, paraphrasing, ,, text, simplification, ,, fairness-aware, text, rewriting, ,, text, style, transfer, ., tool, characterized, two, features, ,, ), recording, word-level, revision, histories, ii, ), flexible, auxiliary, edit, support, feedback, annotators, ., text, rewriting, assist, traceable, rewriting, history, potentially, beneficial, future, research, natural, language, generation, ."
"A Hybrid Natural Language Generation System Integrating Rules and Deep
  Learning Algorithms","Wei Wei, Bei Zhou, Georgios Leontidis",2020-06-15T00:50:41Z,"  This paper proposes an enhanced natural language generation system combining
the merits of both rule-based approaches and modern deep learning algorithms,
boosting its performance to the extent where the generated textual content is
capable of exhibiting agile human-writing styles and the content logic of which
is highly controllable. We also come up with a novel approach called HMCU to
measure the performance of the natural language processing comprehensively and
precisely.
","['paper', 'proposes', 'enhanced', 'natural', 'language', 'generation', 'system', 'combining', 'merits', 'rule-based', 'approaches', 'modern', 'deep', 'learning', 'algorithms', ',', 'boosting', 'performance', 'extent', 'generated', 'textual', 'content', 'capable', 'exhibiting', 'agile', 'human-writing', 'styles', 'content', 'logic', 'highly', 'controllable', '.', 'also', 'come', 'novel', 'approach', 'called', 'hmcu', 'measure', 'performance', 'natural', 'language', 'processing', 'comprehensively', 'precisely', '.']","paper, proposes, enhanced, natural, language, generation, system, combining, merits, rule-based, approaches, modern, deep, learning, algorithms, ,, boosting, performance, extent, generated, textual, content, capable, exhibiting, agile, human-writing, styles, content, logic, highly, controllable, ., also, come, novel, approach, called, hmcu, measure, performance, natural, language, processing, comprehensively, precisely, ."
"NUIG-Shubhanker@Dravidian-CodeMix-FIRE2020: Sentiment Analysis of
  Code-Mixed Dravidian text using XLNet","Shubhanker Banerjee, Arun Jayapal, Sajeetha Thavareesan",2020-10-15T14:09:02Z,"  Social media has penetrated into multilingual societies, however most of them
use English to be a preferred language for communication. So it looks natural
for them to mix their cultural language with English during conversations
resulting in abundance of multilingual data, call this code-mixed data,
available in todays' world.Downstream NLP tasks using such data is challenging
due to the semantic nature of it being spread across multiple languages.One
such Natural Language Processing task is sentiment analysis, for this we use an
auto-regressive XLNet model to perform sentiment analysis on code-mixed
Tamil-English and Malayalam-English datasets.
","['social', 'media', 'penetrated', 'multilingual', 'societies', ',', 'however', 'use', 'english', 'preferred', 'language', 'communication', '.', 'looks', 'natural', 'mix', 'cultural', 'language', 'english', 'conversations', 'resulting', 'abundance', 'multilingual', 'data', ',', 'call', 'code-mixed', 'data', ',', 'available', 'todays', ""'"", 'world.downstream', 'nlp', 'tasks', 'using', 'data', 'challenging', 'due', 'semantic', 'nature', 'spread', 'across', 'multiple', 'languages.one', 'natural', 'language', 'processing', 'task', 'sentiment', 'analysis', ',', 'use', 'auto-regressive', 'xlnet', 'model', 'perform', 'sentiment', 'analysis', 'code-mixed', 'tamil-english', 'malayalam-english', 'datasets', '.']","social, media, penetrated, multilingual, societies, ,, however, use, english, preferred, language, communication, ., looks, natural, mix, cultural, language, english, conversations, resulting, abundance, multilingual, data, ,, call, code-mixed, data, ,, available, todays, ', world.downstream, nlp, tasks, using, data, challenging, due, semantic, nature, spread, across, multiple, languages.one, natural, language, processing, task, sentiment, analysis, ,, use, auto-regressive, xlnet, model, perform, sentiment, analysis, code-mixed, tamil-english, malayalam-english, datasets, ."
"The impact of lexical and grammatical processing on generating code from
  natural language","Nathanaël Beau, Benoît Crabbé",2022-02-28T17:23:30Z,"  Considering the seq2seq architecture of TranX for natural language to code
translation, we identify four key components of importance: grammatical
constraints, lexical preprocessing, input representations, and copy mechanisms.
To study the impact of these components, we use a state-of-the-art architecture
that relies on BERT encoder and a grammar-based decoder for which a
formalization is provided. The paper highlights the importance of the lexical
substitution component in the current natural language to code systems.
","['considering', 'seq2seq', 'architecture', 'tranx', 'natural', 'language', 'code', 'translation', ',', 'identify', 'four', 'key', 'components', 'importance', ':', 'grammatical', 'constraints', ',', 'lexical', 'preprocessing', ',', 'input', 'representations', ',', 'copy', 'mechanisms', '.', 'study', 'impact', 'components', ',', 'use', 'state-of-the-art', 'architecture', 'relies', 'bert', 'encoder', 'grammar-based', 'decoder', 'formalization', 'provided', '.', 'paper', 'highlights', 'importance', 'lexical', 'substitution', 'component', 'current', 'natural', 'language', 'code', 'systems', '.']","considering, seq2seq, architecture, tranx, natural, language, code, translation, ,, identify, four, key, components, importance, :, grammatical, constraints, ,, lexical, preprocessing, ,, input, representations, ,, copy, mechanisms, ., study, impact, components, ,, use, state-of-the-art, architecture, relies, bert, encoder, grammar-based, decoder, formalization, provided, ., paper, highlights, importance, lexical, substitution, component, current, natural, language, code, systems, ."
"Automatic Debate Evaluation with Argumentation Semantics and Natural
  Language Argument Graph Networks","Ramon Ruiz-Dolz, Stella Heras, Ana García-Fornes",2022-03-28T11:09:07Z,"  The lack of annotated data on professional argumentation and complete
argumentative debates has led to the oversimplification and the inability of
approaching more complex natural language processing tasks. Such is the case of
the automatic debate evaluation. In this paper, we propose an original hybrid
method to automatically evaluate argumentative debates. For that purpose, we
combine concepts from argumentation theory such as argumentation frameworks and
semantics, with Transformer-based architectures and neural graph networks.
Furthermore, we obtain promising results that lay the basis on an unexplored
new instance of the automatic analysis of natural language arguments.
","['lack', 'annotated', 'data', 'professional', 'argumentation', 'complete', 'argumentative', 'debates', 'led', 'oversimplification', 'inability', 'approaching', 'complex', 'natural', 'language', 'processing', 'tasks', '.', 'case', 'automatic', 'debate', 'evaluation', '.', 'paper', ',', 'propose', 'original', 'hybrid', 'method', 'automatically', 'evaluate', 'argumentative', 'debates', '.', 'purpose', ',', 'combine', 'concepts', 'argumentation', 'theory', 'argumentation', 'frameworks', 'semantics', ',', 'transformer-based', 'architectures', 'neural', 'graph', 'networks', '.', 'furthermore', ',', 'obtain', 'promising', 'results', 'lay', 'basis', 'unexplored', 'new', 'instance', 'automatic', 'analysis', 'natural', 'language', 'arguments', '.']","lack, annotated, data, professional, argumentation, complete, argumentative, debates, led, oversimplification, inability, approaching, complex, natural, language, processing, tasks, ., case, automatic, debate, evaluation, ., paper, ,, propose, original, hybrid, method, automatically, evaluate, argumentative, debates, ., purpose, ,, combine, concepts, argumentation, theory, argumentation, frameworks, semantics, ,, transformer-based, architectures, neural, graph, networks, ., furthermore, ,, obtain, promising, results, lay, basis, unexplored, new, instance, automatic, analysis, natural, language, arguments, ."
Fine-grained Sentiment Classification using BERT,"Manish Munikar, Sushil Shakya, Aakash Shrestha",2019-10-04T09:20:48Z,"  Sentiment classification is an important process in understanding people's
perception towards a product, service, or topic. Many natural language
processing models have been proposed to solve the sentiment classification
problem. However, most of them have focused on binary sentiment classification.
In this paper, we use a promising deep learning model called BERT to solve the
fine-grained sentiment classification task. Experiments show that our model
outperforms other popular models for this task without sophisticated
architecture. We also demonstrate the effectiveness of transfer learning in
natural language processing in the process.
","['sentiment', 'classification', 'important', 'process', 'understanding', 'people', ""'s"", 'perception', 'towards', 'product', ',', 'service', ',', 'topic', '.', 'many', 'natural', 'language', 'processing', 'models', 'proposed', 'solve', 'sentiment', 'classification', 'problem', '.', 'however', ',', 'focused', 'binary', 'sentiment', 'classification', '.', 'paper', ',', 'use', 'promising', 'deep', 'learning', 'model', 'called', 'bert', 'solve', 'fine-grained', 'sentiment', 'classification', 'task', '.', 'experiments', 'show', 'model', 'outperforms', 'popular', 'models', 'task', 'without', 'sophisticated', 'architecture', '.', 'also', 'demonstrate', 'effectiveness', 'transfer', 'learning', 'natural', 'language', 'processing', 'process', '.']","sentiment, classification, important, process, understanding, people, 's, perception, towards, product, ,, service, ,, topic, ., many, natural, language, processing, models, proposed, solve, sentiment, classification, problem, ., however, ,, focused, binary, sentiment, classification, ., paper, ,, use, promising, deep, learning, model, called, bert, solve, fine-grained, sentiment, classification, task, ., experiments, show, model, outperforms, popular, models, task, without, sophisticated, architecture, ., also, demonstrate, effectiveness, transfer, learning, natural, language, processing, process, ."
"Explaining Natural Language Processing Classifiers with Occlusion and
  Language Modeling",David Harbecke,2021-01-28T09:44:04Z,"  Deep neural networks are powerful statistical learners. However, their
predictions do not come with an explanation of their process. To analyze these
models, explanation methods are being developed. We present a novel explanation
method, called OLM, for natural language processing classifiers. This method
combines occlusion and language modeling, which are techniques central to
explainability and NLP, respectively. OLM gives explanations that are
theoretically sound and easy to understand.
  We make several contributions to the theory of explanation methods. Axioms
for explanation methods are an interesting theoretical concept to explore their
basics and deduce methods. We introduce a new axiom, give its intuition and
show it contradicts another existing axiom. Additionally, we point out
theoretical difficulties of existing gradient-based and some occlusion-based
explanation methods in natural language processing. We provide an extensive
argument why evaluation of explanation methods is difficult. We compare OLM to
other explanation methods and underline its uniqueness experimentally. Finally,
we investigate corner cases of OLM and discuss its validity and possible
improvements.
","['deep', 'neural', 'networks', 'powerful', 'statistical', 'learners', '.', 'however', ',', 'predictions', 'come', 'explanation', 'process', '.', 'analyze', 'models', ',', 'explanation', 'methods', 'developed', '.', 'present', 'novel', 'explanation', 'method', ',', 'called', 'olm', ',', 'natural', 'language', 'processing', 'classifiers', '.', 'method', 'combines', 'occlusion', 'language', 'modeling', ',', 'techniques', 'central', 'explainability', 'nlp', ',', 'respectively', '.', 'olm', 'gives', 'explanations', 'theoretically', 'sound', 'easy', 'understand', '.', 'make', 'several', 'contributions', 'theory', 'explanation', 'methods', '.', 'axioms', 'explanation', 'methods', 'interesting', 'theoretical', 'concept', 'explore', 'basics', 'deduce', 'methods', '.', 'introduce', 'new', 'axiom', ',', 'give', 'intuition', 'show', 'contradicts', 'another', 'existing', 'axiom', '.', 'additionally', ',', 'point', 'theoretical', 'difficulties', 'existing', 'gradient-based', 'occlusion-based', 'explanation', 'methods', 'natural', 'language', 'processing', '.', 'provide', 'extensive', 'argument', 'evaluation', 'explanation', 'methods', 'difficult', '.', 'compare', 'olm', 'explanation', 'methods', 'underline', 'uniqueness', 'experimentally', '.', 'finally', ',', 'investigate', 'corner', 'cases', 'olm', 'discuss', 'validity', 'possible', 'improvements', '.']","deep, neural, networks, powerful, statistical, learners, ., however, ,, predictions, come, explanation, process, ., analyze, models, ,, explanation, methods, developed, ., present, novel, explanation, method, ,, called, olm, ,, natural, language, processing, classifiers, ., method, combines, occlusion, language, modeling, ,, techniques, central, explainability, nlp, ,, respectively, ., olm, gives, explanations, theoretically, sound, easy, understand, ., make, several, contributions, theory, explanation, methods, ., axioms, explanation, methods, interesting, theoretical, concept, explore, basics, deduce, methods, ., introduce, new, axiom, ,, give, intuition, show, contradicts, another, existing, axiom, ., additionally, ,, point, theoretical, difficulties, existing, gradient-based, occlusion-based, explanation, methods, natural, language, processing, ., provide, extensive, argument, evaluation, explanation, methods, difficult, ., compare, olm, explanation, methods, underline, uniqueness, experimentally, ., finally, ,, investigate, corner, cases, olm, discuss, validity, possible, improvements, ."
"Research on color recipe recommendation based on unstructured data using
  TENN","Seongsu Jhang, Donghwi Yoo, Jaeyong Kown",2024-08-17T04:45:48Z,"  Recently, services and business models based on large language models, such
as OpenAI Chatgpt, Google BARD, and Microsoft copilot, have been introduced,
and the applications utilizing natural language processing with deep learning
are increasing, and it is one of the natural language preprocessing methods.
Conversion to machine language through tokenization and processing of
unstructured data are increasing. Although algorithms that can understand and
apply human language are becoming increasingly sophisticated, it is difficult
to apply them to processes that rely on human emotions and senses in industries
that still mainly deal with standardized data. In particular, in processes
where brightness, saturation, and color information are essential, such as
painting and injection molding, most small and medium-sized companies,
excluding large corporations, rely on the tacit knowledge and sensibility of
color mixers, and even customer companies often present non-standardized
requirements. . In this paper, we proposed TENN to infer color recipe based on
unstructured data with emotional natural language, and demonstrated it.
","['recently', ',', 'services', 'business', 'models', 'based', 'large', 'language', 'models', ',', 'openai', 'chatgpt', ',', 'google', 'bard', ',', 'microsoft', 'copilot', ',', 'introduced', ',', 'applications', 'utilizing', 'natural', 'language', 'processing', 'deep', 'learning', 'increasing', ',', 'one', 'natural', 'language', 'preprocessing', 'methods', '.', 'conversion', 'machine', 'language', 'tokenization', 'processing', 'unstructured', 'data', 'increasing', '.', 'although', 'algorithms', 'understand', 'apply', 'human', 'language', 'becoming', 'increasingly', 'sophisticated', ',', 'difficult', 'apply', 'processes', 'rely', 'human', 'emotions', 'senses', 'industries', 'still', 'mainly', 'deal', 'standardized', 'data', '.', 'particular', ',', 'processes', 'brightness', ',', 'saturation', ',', 'color', 'information', 'essential', ',', 'painting', 'injection', 'molding', ',', 'small', 'medium-sized', 'companies', ',', 'excluding', 'large', 'corporations', ',', 'rely', 'tacit', 'knowledge', 'sensibility', 'color', 'mixers', ',', 'even', 'customer', 'companies', 'often', 'present', 'non-standardized', 'requirements', '.', '.', 'paper', ',', 'proposed', 'tenn', 'infer', 'color', 'recipe', 'based', 'unstructured', 'data', 'emotional', 'natural', 'language', ',', 'demonstrated', '.']","recently, ,, services, business, models, based, large, language, models, ,, openai, chatgpt, ,, google, bard, ,, microsoft, copilot, ,, introduced, ,, applications, utilizing, natural, language, processing, deep, learning, increasing, ,, one, natural, language, preprocessing, methods, ., conversion, machine, language, tokenization, processing, unstructured, data, increasing, ., although, algorithms, understand, apply, human, language, becoming, increasingly, sophisticated, ,, difficult, apply, processes, rely, human, emotions, senses, industries, still, mainly, deal, standardized, data, ., particular, ,, processes, brightness, ,, saturation, ,, color, information, essential, ,, painting, injection, molding, ,, small, medium-sized, companies, ,, excluding, large, corporations, ,, rely, tacit, knowledge, sensibility, color, mixers, ,, even, customer, companies, often, present, non-standardized, requirements, ., ., paper, ,, proposed, tenn, infer, color, recipe, based, unstructured, data, emotional, natural, language, ,, demonstrated, ."
"The Influence of Data Pre-processing and Post-processing on Long
  Document Summarization","Xinwei Du, Kailun Dong, Yuchen Zhang, Yongsheng Li, Ruei-Yu Tsay",2021-12-03T00:56:17Z,"  Long document summarization is an important and hard task in the field of
natural language processing. A good performance of the long document
summarization reveals the model has a decent understanding of the human
language. Currently, most researches focus on how to modify the attention
mechanism of the transformer to achieve a higher ROUGE score. The study of data
pre-processing and post-processing are relatively few. In this paper, we use
two pre-processing methods and a post-processing method and analyze the effect
of these methods on various long document summarization models.
","['long', 'document', 'summarization', 'important', 'hard', 'task', 'field', 'natural', 'language', 'processing', '.', 'good', 'performance', 'long', 'document', 'summarization', 'reveals', 'model', 'decent', 'understanding', 'human', 'language', '.', 'currently', ',', 'researches', 'focus', 'modify', 'attention', 'mechanism', 'transformer', 'achieve', 'higher', 'rouge', 'score', '.', 'study', 'data', 'pre-processing', 'post-processing', 'relatively', '.', 'paper', ',', 'use', 'two', 'pre-processing', 'methods', 'post-processing', 'method', 'analyze', 'effect', 'methods', 'various', 'long', 'document', 'summarization', 'models', '.']","long, document, summarization, important, hard, task, field, natural, language, processing, ., good, performance, long, document, summarization, reveals, model, decent, understanding, human, language, ., currently, ,, researches, focus, modify, attention, mechanism, transformer, achieve, higher, rouge, score, ., study, data, pre-processing, post-processing, relatively, ., paper, ,, use, two, pre-processing, methods, post-processing, method, analyze, effect, methods, various, long, document, summarization, models, ."
"ArNLI: Arabic Natural Language Inference for Entailment and
  Contradiction Detection","Khloud Al Jallad, Nada Ghneim",2022-09-28T09:37:16Z,"  Natural Language Inference (NLI) is a hot topic research in natural language
processing, contradiction detection between sentences is a special case of NLI.
This is considered a difficult NLP task which has a big influence when added as
a component in many NLP applications, such as Question Answering Systems, text
Summarization. Arabic Language is one of the most challenging low-resources
languages in detecting contradictions due to its rich lexical, semantics
ambiguity. We have created a data set of more than 12k sentences and named
ArNLI, that will be publicly available. Moreover, we have applied a new model
inspired by Stanford contradiction detection proposed solutions on English
language. We proposed an approach to detect contradictions between pairs of
sentences in Arabic language using contradiction vector combined with language
model vector as an input to machine learning model. We analyzed results of
different traditional machine learning classifiers and compared their results
on our created data set (ArNLI) and on an automatic translation of both PHEME,
SICK English data sets. Best results achieved using Random Forest classifier
with an accuracy of 99%, 60%, 75% on PHEME, SICK and ArNLI respectively.
","['natural', 'language', 'inference', '(', 'nli', ')', 'hot', 'topic', 'research', 'natural', 'language', 'processing', ',', 'contradiction', 'detection', 'sentences', 'special', 'case', 'nli', '.', 'considered', 'difficult', 'nlp', 'task', 'big', 'influence', 'added', 'component', 'many', 'nlp', 'applications', ',', 'question', 'answering', 'systems', ',', 'text', 'summarization', '.', 'arabic', 'language', 'one', 'challenging', 'low-resources', 'languages', 'detecting', 'contradictions', 'due', 'rich', 'lexical', ',', 'semantics', 'ambiguity', '.', 'created', 'data', 'set', '12k', 'sentences', 'named', 'arnli', ',', 'publicly', 'available', '.', 'moreover', ',', 'applied', 'new', 'model', 'inspired', 'stanford', 'contradiction', 'detection', 'proposed', 'solutions', 'english', 'language', '.', 'proposed', 'approach', 'detect', 'contradictions', 'pairs', 'sentences', 'arabic', 'language', 'using', 'contradiction', 'vector', 'combined', 'language', 'model', 'vector', 'input', 'machine', 'learning', 'model', '.', 'analyzed', 'results', 'different', 'traditional', 'machine', 'learning', 'classifiers', 'compared', 'results', 'created', 'data', 'set', '(', 'arnli', ')', 'automatic', 'translation', 'pheme', ',', 'sick', 'english', 'data', 'sets', '.', 'best', 'results', 'achieved', 'using', 'random', 'forest', 'classifier', 'accuracy', '99', '%', ',', '60', '%', ',', '75', '%', 'pheme', ',', 'sick', 'arnli', 'respectively', '.']","natural, language, inference, (, nli, ), hot, topic, research, natural, language, processing, ,, contradiction, detection, sentences, special, case, nli, ., considered, difficult, nlp, task, big, influence, added, component, many, nlp, applications, ,, question, answering, systems, ,, text, summarization, ., arabic, language, one, challenging, low-resources, languages, detecting, contradictions, due, rich, lexical, ,, semantics, ambiguity, ., created, data, set, 12k, sentences, named, arnli, ,, publicly, available, ., moreover, ,, applied, new, model, inspired, stanford, contradiction, detection, proposed, solutions, english, language, ., proposed, approach, detect, contradictions, pairs, sentences, arabic, language, using, contradiction, vector, combined, language, model, vector, input, machine, learning, model, ., analyzed, results, different, traditional, machine, learning, classifiers, compared, results, created, data, set, (, arnli, ), automatic, translation, pheme, ,, sick, english, data, sets, ., best, results, achieved, using, random, forest, classifier, accuracy, 99, %, ,, 60, %, ,, 75, %, pheme, ,, sick, arnli, respectively, ."
"Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study
  of African-American English",Jamell Dacon,2022-06-03T01:05:58Z,"  Currently, natural language processing (NLP) models proliferate language
discrimination leading to potentially harmful societal impacts as a result of
biased outcomes. For example, part-of-speech taggers trained on Mainstream
American English (MAE) produce non-interpretable results when applied to
African American English (AAE) as a result of language features not seen during
training. In this work, we incorporate a human-in-the-loop paradigm to gain a
better understanding of AAE speakers' behavior and their language use, and
highlight the need for dialectal language inclusivity so that native AAE
speakers can extensively interact with NLP systems while reducing feelings of
disenfranchisement.
","['currently', ',', 'natural', 'language', 'processing', '(', 'nlp', ')', 'models', 'proliferate', 'language', 'discrimination', 'leading', 'potentially', 'harmful', 'societal', 'impacts', 'result', 'biased', 'outcomes', '.', 'example', ',', 'part-of-speech', 'taggers', 'trained', 'mainstream', 'american', 'english', '(', 'mae', ')', 'produce', 'non-interpretable', 'results', 'applied', 'african', 'american', 'english', '(', 'aae', ')', 'result', 'language', 'features', 'seen', 'training', '.', 'work', ',', 'incorporate', 'human-in-the-loop', 'paradigm', 'gain', 'better', 'understanding', 'aae', 'speakers', ""'"", 'behavior', 'language', 'use', ',', 'highlight', 'need', 'dialectal', 'language', 'inclusivity', 'native', 'aae', 'speakers', 'extensively', 'interact', 'nlp', 'systems', 'reducing', 'feelings', 'disenfranchisement', '.']","currently, ,, natural, language, processing, (, nlp, ), models, proliferate, language, discrimination, leading, potentially, harmful, societal, impacts, result, biased, outcomes, ., example, ,, part-of-speech, taggers, trained, mainstream, american, english, (, mae, ), produce, non-interpretable, results, applied, african, american, english, (, aae, ), result, language, features, seen, training, ., work, ,, incorporate, human-in-the-loop, paradigm, gain, better, understanding, aae, speakers, ', behavior, language, use, ,, highlight, need, dialectal, language, inclusivity, native, aae, speakers, extensively, interact, nlp, systems, reducing, feelings, disenfranchisement, ."
Differentially Private Language Models Benefit from Public Pre-training,"Gavin Kerrigan, Dylan Slack, Jens Tuyls",2020-09-13T00:50:44Z,"  Language modeling is a keystone task in natural language processing. When
training a language model on sensitive information, differential privacy (DP)
allows us to quantify the degree to which our private data is protected.
However, training algorithms which enforce differential privacy often lead to
degradation in model quality. We study the feasibility of learning a language
model which is simultaneously high-quality and privacy preserving by tuning a
public base model on a private corpus. We find that DP fine-tuning boosts the
performance of language models in the private domain, making the training of
such models possible.
","['language', 'modeling', 'keystone', 'task', 'natural', 'language', 'processing', '.', 'training', 'language', 'model', 'sensitive', 'information', ',', 'differential', 'privacy', '(', 'dp', ')', 'allows', 'us', 'quantify', 'degree', 'private', 'data', 'protected', '.', 'however', ',', 'training', 'algorithms', 'enforce', 'differential', 'privacy', 'often', 'lead', 'degradation', 'model', 'quality', '.', 'study', 'feasibility', 'learning', 'language', 'model', 'simultaneously', 'high-quality', 'privacy', 'preserving', 'tuning', 'public', 'base', 'model', 'private', 'corpus', '.', 'find', 'dp', 'fine-tuning', 'boosts', 'performance', 'language', 'models', 'private', 'domain', ',', 'making', 'training', 'models', 'possible', '.']","language, modeling, keystone, task, natural, language, processing, ., training, language, model, sensitive, information, ,, differential, privacy, (, dp, ), allows, us, quantify, degree, private, data, protected, ., however, ,, training, algorithms, enforce, differential, privacy, often, lead, degradation, model, quality, ., study, feasibility, learning, language, model, simultaneously, high-quality, privacy, preserving, tuning, public, base, model, private, corpus, ., find, dp, fine-tuning, boosts, performance, language, models, private, domain, ,, making, training, models, possible, ."
Formal Aspects of Language Modeling,"Ryan Cotterell, Anej Svete, Clara Meister, Tianyu Liu, Li Du",2023-11-07T20:21:42Z,"  Large language models have become one of the most commonly deployed NLP
inventions. In the past half-decade, their integration into core natural
language processing tools has dramatically increased the performance of such
tools, and they have entered the public discourse surrounding artificial
intelligence. Consequently, it is important for both developers and researchers
alike to understand the mathematical foundations of large language models, as
well as how to implement them. These notes are the accompaniment to the
theoretical portion of the ETH Z\""urich course on large language models,
covering what constitutes a language model from a formal, theoretical
perspective.
","['large', 'language', 'models', 'become', 'one', 'commonly', 'deployed', 'nlp', 'inventions', '.', 'past', 'half-decade', ',', 'integration', 'core', 'natural', 'language', 'processing', 'tools', 'dramatically', 'increased', 'performance', 'tools', ',', 'entered', 'public', 'discourse', 'surrounding', 'artificial', 'intelligence', '.', 'consequently', ',', 'important', 'developers', 'researchers', 'alike', 'understand', 'mathematical', 'foundations', 'large', 'language', 'models', ',', 'well', 'implement', '.', 'notes', 'accompaniment', 'theoretical', 'portion', 'eth', 'z\\', ""''"", 'urich', 'course', 'large', 'language', 'models', ',', 'covering', 'constitutes', 'language', 'model', 'formal', ',', 'theoretical', 'perspective', '.']","large, language, models, become, one, commonly, deployed, nlp, inventions, ., past, half-decade, ,, integration, core, natural, language, processing, tools, dramatically, increased, performance, tools, ,, entered, public, discourse, surrounding, artificial, intelligence, ., consequently, ,, important, developers, researchers, alike, understand, mathematical, foundations, large, language, models, ,, well, implement, ., notes, accompaniment, theoretical, portion, eth, z\, '', urich, course, large, language, models, ,, covering, constitutes, language, model, formal, ,, theoretical, perspective, ."
"Modelling Word Burstiness in Natural Language: A Generalised Polya
  Process for Document Language Models in Information Retrieval",Ronan Cummins,2017-08-20T19:41:58Z,"  We introduce a generalised multivariate Polya process for document language
modelling. The framework outlined here generalises a number of statistical
language models used in information retrieval for modelling document
generation. In particular, we show that the choice of replacement matrix M
ultimately defines the type of random process and therefore defines a
particular type of document language model. We show that a particular variant
of the general model is useful for modelling term-specific burstiness.
Furthermore, via experimentation we show that this variant significantly
improves retrieval effectiveness over a strong baseline on a number of small
test collections.
","['introduce', 'generalised', 'multivariate', 'polya', 'process', 'document', 'language', 'modelling', '.', 'framework', 'outlined', 'generalises', 'number', 'statistical', 'language', 'models', 'used', 'information', 'retrieval', 'modelling', 'document', 'generation', '.', 'particular', ',', 'show', 'choice', 'replacement', 'matrix', 'ultimately', 'defines', 'type', 'random', 'process', 'therefore', 'defines', 'particular', 'type', 'document', 'language', 'model', '.', 'show', 'particular', 'variant', 'general', 'model', 'useful', 'modelling', 'term-specific', 'burstiness', '.', 'furthermore', ',', 'via', 'experimentation', 'show', 'variant', 'significantly', 'improves', 'retrieval', 'effectiveness', 'strong', 'baseline', 'number', 'small', 'test', 'collections', '.']","introduce, generalised, multivariate, polya, process, document, language, modelling, ., framework, outlined, generalises, number, statistical, language, models, used, information, retrieval, modelling, document, generation, ., particular, ,, show, choice, replacement, matrix, ultimately, defines, type, random, process, therefore, defines, particular, type, document, language, model, ., show, particular, variant, general, model, useful, modelling, term-specific, burstiness, ., furthermore, ,, via, experimentation, show, variant, significantly, improves, retrieval, effectiveness, strong, baseline, number, small, test, collections, ."
"Information Propagation by Composited Labels in Natural Language
  Processing",Takeshi Inagaki,2022-05-23T23:19:14Z,"  In natural language processing (NLP), labeling on regions of text, such as
words, sentences and paragraphs, is a basic task. In this paper, label is
defined as map between mention of entity in a region on text and context of
entity in a broader region on text containing the mention. This definition
naturally introduces linkage of entities induced from inclusion relation of
regions, and connected entities form a graph representing information flow
defined by map. It also enables calculation of information loss through map
using entropy, and entropy lost is regarded as distance between two entities
over a path on graph.
","['natural', 'language', 'processing', '(', 'nlp', ')', ',', 'labeling', 'regions', 'text', ',', 'words', ',', 'sentences', 'paragraphs', ',', 'basic', 'task', '.', 'paper', ',', 'label', 'defined', 'map', 'mention', 'entity', 'region', 'text', 'context', 'entity', 'broader', 'region', 'text', 'containing', 'mention', '.', 'definition', 'naturally', 'introduces', 'linkage', 'entities', 'induced', 'inclusion', 'relation', 'regions', ',', 'connected', 'entities', 'form', 'graph', 'representing', 'information', 'flow', 'defined', 'map', '.', 'also', 'enables', 'calculation', 'information', 'loss', 'map', 'using', 'entropy', ',', 'entropy', 'lost', 'regarded', 'distance', 'two', 'entities', 'path', 'graph', '.']","natural, language, processing, (, nlp, ), ,, labeling, regions, text, ,, words, ,, sentences, paragraphs, ,, basic, task, ., paper, ,, label, defined, map, mention, entity, region, text, context, entity, broader, region, text, containing, mention, ., definition, naturally, introduces, linkage, entities, induced, inclusion, relation, regions, ,, connected, entities, form, graph, representing, information, flow, defined, map, ., also, enables, calculation, information, loss, map, using, entropy, ,, entropy, lost, regarded, distance, two, entities, path, graph, ."
Natural language processing on customer note data,"Andrew Hilditch, David Webb, Jozef Baca, Tom Armitage, Matthew Shardlow, Peter Appleby",2023-05-03T10:36:56Z,"  Automatic analysis of customer data for businesses is an area that is of
interest to companies. Business to business data is studied rarely in academia
due to the sensitive nature of such information. Applying natural language
processing can speed up the analysis of prohibitively large sets of data. This
paper addresses this subject and applies sentiment analysis, topic modelling
and keyword extraction to a B2B data set. We show that accurate sentiment can
be extracted from the notes automatically and the notes can be sorted by
relevance into different topics. We see that without clear separation topics
can lack relevance to a business context.
","['automatic', 'analysis', 'customer', 'data', 'businesses', 'area', 'interest', 'companies', '.', 'business', 'business', 'data', 'studied', 'rarely', 'academia', 'due', 'sensitive', 'nature', 'information', '.', 'applying', 'natural', 'language', 'processing', 'speed', 'analysis', 'prohibitively', 'large', 'sets', 'data', '.', 'paper', 'addresses', 'subject', 'applies', 'sentiment', 'analysis', ',', 'topic', 'modelling', 'keyword', 'extraction', 'b2b', 'data', 'set', '.', 'show', 'accurate', 'sentiment', 'extracted', 'notes', 'automatically', 'notes', 'sorted', 'relevance', 'different', 'topics', '.', 'see', 'without', 'clear', 'separation', 'topics', 'lack', 'relevance', 'business', 'context', '.']","automatic, analysis, customer, data, businesses, area, interest, companies, ., business, business, data, studied, rarely, academia, due, sensitive, nature, information, ., applying, natural, language, processing, speed, analysis, prohibitively, large, sets, data, ., paper, addresses, subject, applies, sentiment, analysis, ,, topic, modelling, keyword, extraction, b2b, data, set, ., show, accurate, sentiment, extracted, notes, automatically, notes, sorted, relevance, different, topics, ., see, without, clear, separation, topics, lack, relevance, business, context, ."
"Exploring Natural Language Processing Methods for Interactive Behaviour
  Modelling","Guanhua Zhang, Matteo Bortoletto, Zhiming Hu, Lei Shi, Mihai Bâce, Andreas Bulling",2023-03-28T15:15:03Z,"  Analysing and modelling interactive behaviour is an important topic in
human-computer interaction (HCI) and a key requirement for the development of
intelligent interactive systems. Interactive behaviour has a sequential
(actions happen one after another) and hierarchical (a sequence of actions
forms an activity driven by interaction goals) structure, which may be similar
to the structure of natural language. Designed based on such a structure,
natural language processing (NLP) methods have achieved groundbreaking success
in various downstream tasks. However, few works linked interactive behaviour
with natural language. In this paper, we explore the similarity between
interactive behaviour and natural language by applying an NLP method, byte pair
encoding (BPE), to encode mouse and keyboard behaviour. We then analyse the
vocabulary, i.e., the set of action sequences, learnt by BPE, as well as use
the vocabulary to encode the input behaviour for interactive task recognition.
An existing dataset collected in constrained lab settings and our novel
out-of-the-lab dataset were used for evaluation. Results show that this natural
language-inspired approach not only learns action sequences that reflect
specific interaction goals, but also achieves higher F1 scores on task
recognition than other methods. Our work reveals the similarity between
interactive behaviour and natural language, and presents the potential of
applying the new pack of methods that leverage insights from NLP to model
interactive behaviour in HCI.
","['analysing', 'modelling', 'interactive', 'behaviour', 'important', 'topic', 'human-computer', 'interaction', '(', 'hci', ')', 'key', 'requirement', 'development', 'intelligent', 'interactive', 'systems', '.', 'interactive', 'behaviour', 'sequential', '(', 'actions', 'happen', 'one', 'another', ')', 'hierarchical', '(', 'sequence', 'actions', 'forms', 'activity', 'driven', 'interaction', 'goals', ')', 'structure', ',', 'may', 'similar', 'structure', 'natural', 'language', '.', 'designed', 'based', 'structure', ',', 'natural', 'language', 'processing', '(', 'nlp', ')', 'methods', 'achieved', 'groundbreaking', 'success', 'various', 'downstream', 'tasks', '.', 'however', ',', 'works', 'linked', 'interactive', 'behaviour', 'natural', 'language', '.', 'paper', ',', 'explore', 'similarity', 'interactive', 'behaviour', 'natural', 'language', 'applying', 'nlp', 'method', ',', 'byte', 'pair', 'encoding', '(', 'bpe', ')', ',', 'encode', 'mouse', 'keyboard', 'behaviour', '.', 'analyse', 'vocabulary', ',', 'i.e.', ',', 'set', 'action', 'sequences', ',', 'learnt', 'bpe', ',', 'well', 'use', 'vocabulary', 'encode', 'input', 'behaviour', 'interactive', 'task', 'recognition', '.', 'existing', 'dataset', 'collected', 'constrained', 'lab', 'settings', 'novel', 'out-of-the-lab', 'dataset', 'used', 'evaluation', '.', 'results', 'show', 'natural', 'language-inspired', 'approach', 'learns', 'action', 'sequences', 'reflect', 'specific', 'interaction', 'goals', ',', 'also', 'achieves', 'higher', 'f1', 'scores', 'task', 'recognition', 'methods', '.', 'work', 'reveals', 'similarity', 'interactive', 'behaviour', 'natural', 'language', ',', 'presents', 'potential', 'applying', 'new', 'pack', 'methods', 'leverage', 'insights', 'nlp', 'model', 'interactive', 'behaviour', 'hci', '.']","analysing, modelling, interactive, behaviour, important, topic, human-computer, interaction, (, hci, ), key, requirement, development, intelligent, interactive, systems, ., interactive, behaviour, sequential, (, actions, happen, one, another, ), hierarchical, (, sequence, actions, forms, activity, driven, interaction, goals, ), structure, ,, may, similar, structure, natural, language, ., designed, based, structure, ,, natural, language, processing, (, nlp, ), methods, achieved, groundbreaking, success, various, downstream, tasks, ., however, ,, works, linked, interactive, behaviour, natural, language, ., paper, ,, explore, similarity, interactive, behaviour, natural, language, applying, nlp, method, ,, byte, pair, encoding, (, bpe, ), ,, encode, mouse, keyboard, behaviour, ., analyse, vocabulary, ,, i.e., ,, set, action, sequences, ,, learnt, bpe, ,, well, use, vocabulary, encode, input, behaviour, interactive, task, recognition, ., existing, dataset, collected, constrained, lab, settings, novel, out-of-the-lab, dataset, used, evaluation, ., results, show, natural, language-inspired, approach, learns, action, sequences, reflect, specific, interaction, goals, ,, also, achieves, higher, f1, scores, task, recognition, methods, ., work, reveals, similarity, interactive, behaviour, natural, language, ,, presents, potential, applying, new, pack, methods, leverage, insights, nlp, model, interactive, behaviour, hci, ."
"EvoText: Enhancing Natural Language Generation Models via
  Self-Escalation Learning for Up-to-Date Knowledge and Improved Performance","Zhengqing Yuan, Huiwen Xue, Chao Zhang, Yongming Liu",2023-02-08T06:09:55Z,"  In recent years, pretrained models have been widely used in various fields,
including natural language understanding, computer vision, and natural language
generation. However, the performance of these language generation models is
highly dependent on the model size and the dataset size. While larger models
excel in some aspects, they cannot learn up-to-date knowledge and are
relatively difficult to relearn. In this paper, we introduce EvoText, a novel
training method that enhances the performance of any natural language
generation model without requiring additional datasets during the entire
training process (although a prior dataset is necessary for pretraining).
EvoText employs two models: $G$, a text generation model, and $D$, a model that
can determine whether the data generated by $G$ is legitimate. Initially, the
fine-tuned $D$ model serves as the knowledge base. The text generated by $G$ is
then input to $D$ to determine whether it is legitimate. Finally, $G$ is
fine-tuned based on $D$'s output. EvoText enables the model to learn up-to-date
knowledge through a self-escalation process that builds on a priori knowledge.
When EvoText needs to learn something new, it simply fine-tunes the $D$ model.
Our approach applies to autoregressive language modeling for all Transformer
classes. With EvoText, eight models achieved stable improvements in seven
natural language processing tasks without any changes to the model structure.
","['recent', 'years', ',', 'pretrained', 'models', 'widely', 'used', 'various', 'fields', ',', 'including', 'natural', 'language', 'understanding', ',', 'computer', 'vision', ',', 'natural', 'language', 'generation', '.', 'however', ',', 'performance', 'language', 'generation', 'models', 'highly', 'dependent', 'model', 'size', 'dataset', 'size', '.', 'larger', 'models', 'excel', 'aspects', ',', 'learn', 'up-to-date', 'knowledge', 'relatively', 'difficult', 'relearn', '.', 'paper', ',', 'introduce', 'evotext', ',', 'novel', 'training', 'method', 'enhances', 'performance', 'natural', 'language', 'generation', 'model', 'without', 'requiring', 'additional', 'datasets', 'entire', 'training', 'process', '(', 'although', 'prior', 'dataset', 'necessary', 'pretraining', ')', '.', 'evotext', 'employs', 'two', 'models', ':', '$', 'g', '$', ',', 'text', 'generation', 'model', ',', '$', '$', ',', 'model', 'determine', 'whether', 'data', 'generated', '$', 'g', '$', 'legitimate', '.', 'initially', ',', 'fine-tuned', '$', '$', 'model', 'serves', 'knowledge', 'base', '.', 'text', 'generated', '$', 'g', '$', 'input', '$', '$', 'determine', 'whether', 'legitimate', '.', 'finally', ',', '$', 'g', '$', 'fine-tuned', 'based', '$', '$', ""'s"", 'output', '.', 'evotext', 'enables', 'model', 'learn', 'up-to-date', 'knowledge', 'self-escalation', 'process', 'builds', 'priori', 'knowledge', '.', 'evotext', 'needs', 'learn', 'something', 'new', ',', 'simply', 'fine-tunes', '$', '$', 'model', '.', 'approach', 'applies', 'autoregressive', 'language', 'modeling', 'transformer', 'classes', '.', 'evotext', ',', 'eight', 'models', 'achieved', 'stable', 'improvements', 'seven', 'natural', 'language', 'processing', 'tasks', 'without', 'changes', 'model', 'structure', '.']","recent, years, ,, pretrained, models, widely, used, various, fields, ,, including, natural, language, understanding, ,, computer, vision, ,, natural, language, generation, ., however, ,, performance, language, generation, models, highly, dependent, model, size, dataset, size, ., larger, models, excel, aspects, ,, learn, up-to-date, knowledge, relatively, difficult, relearn, ., paper, ,, introduce, evotext, ,, novel, training, method, enhances, performance, natural, language, generation, model, without, requiring, additional, datasets, entire, training, process, (, although, prior, dataset, necessary, pretraining, ), ., evotext, employs, two, models, :, $, g, $, ,, text, generation, model, ,, $, $, ,, model, determine, whether, data, generated, $, g, $, legitimate, ., initially, ,, fine-tuned, $, $, model, serves, knowledge, base, ., text, generated, $, g, $, input, $, $, determine, whether, legitimate, ., finally, ,, $, g, $, fine-tuned, based, $, $, 's, output, ., evotext, enables, model, learn, up-to-date, knowledge, self-escalation, process, builds, priori, knowledge, ., evotext, needs, learn, something, new, ,, simply, fine-tunes, $, $, model, ., approach, applies, autoregressive, language, modeling, transformer, classes, ., evotext, ,, eight, models, achieved, stable, improvements, seven, natural, language, processing, tasks, without, changes, model, structure, ."
"Leveraging Large Language Models through Natural Language Processing to
  provide interpretable Machine Learning predictions of mental deterioration in
  real time","Francisco de Arriba-Pérez, Silvia García-Méndez",2024-09-05T09:27:05Z,"  Based on official estimates, 50 million people worldwide are affected by
dementia, and this number increases by 10 million new patients every year.
Without a cure, clinical prognostication and early intervention represent the
most effective ways to delay its progression. To this end, Artificial
Intelligence and computational linguistics can be exploited for natural
language analysis, personalized assessment, monitoring, and treatment. However,
traditional approaches need more semantic knowledge management and
explicability capabilities. Moreover, using Large Language Models (LLMs) for
cognitive decline diagnosis is still scarce, even though these models represent
the most advanced way for clinical-patient communication using intelligent
systems. Consequently, we leverage an LLM using the latest Natural Language
Processing (NLP) techniques in a chatbot solution to provide interpretable
Machine Learning prediction of cognitive decline in real-time.
Linguistic-conceptual features are exploited for appropriate natural language
analysis. Through explainability, we aim to fight potential biases of the
models and improve their potential to help clinical workers in their diagnosis
decisions. More in detail, the proposed pipeline is composed of (i) data
extraction employing NLP-based prompt engineering; (ii) stream-based data
processing including feature engineering, analysis, and selection; (iii)
real-time classification; and (iv) the explainability dashboard to provide
visual and natural language descriptions of the prediction outcome.
Classification results exceed 80 % in all evaluation metrics, with a recall
value for the mental deterioration class about 85 %. To sum up, we contribute
with an affordable, flexible, non-invasive, personalized diagnostic system to
this work.
","['based', 'official', 'estimates', ',', '50', 'million', 'people', 'worldwide', 'affected', 'dementia', ',', 'number', 'increases', '10', 'million', 'new', 'patients', 'every', 'year', '.', 'without', 'cure', ',', 'clinical', 'prognostication', 'early', 'intervention', 'represent', 'effective', 'ways', 'delay', 'progression', '.', 'end', ',', 'artificial', 'intelligence', 'computational', 'linguistics', 'exploited', 'natural', 'language', 'analysis', ',', 'personalized', 'assessment', ',', 'monitoring', ',', 'treatment', '.', 'however', ',', 'traditional', 'approaches', 'need', 'semantic', 'knowledge', 'management', 'explicability', 'capabilities', '.', 'moreover', ',', 'using', 'large', 'language', 'models', '(', 'llms', ')', 'cognitive', 'decline', 'diagnosis', 'still', 'scarce', ',', 'even', 'though', 'models', 'represent', 'advanced', 'way', 'clinical-patient', 'communication', 'using', 'intelligent', 'systems', '.', 'consequently', ',', 'leverage', 'llm', 'using', 'latest', 'natural', 'language', 'processing', '(', 'nlp', ')', 'techniques', 'chatbot', 'solution', 'provide', 'interpretable', 'machine', 'learning', 'prediction', 'cognitive', 'decline', 'real-time', '.', 'linguistic-conceptual', 'features', 'exploited', 'appropriate', 'natural', 'language', 'analysis', '.', 'explainability', ',', 'aim', 'fight', 'potential', 'biases', 'models', 'improve', 'potential', 'help', 'clinical', 'workers', 'diagnosis', 'decisions', '.', 'detail', ',', 'proposed', 'pipeline', 'composed', '(', ')', 'data', 'extraction', 'employing', 'nlp-based', 'prompt', 'engineering', ';', '(', 'ii', ')', 'stream-based', 'data', 'processing', 'including', 'feature', 'engineering', ',', 'analysis', ',', 'selection', ';', '(', 'iii', ')', 'real-time', 'classification', ';', '(', 'iv', ')', 'explainability', 'dashboard', 'provide', 'visual', 'natural', 'language', 'descriptions', 'prediction', 'outcome', '.', 'classification', 'results', 'exceed', '80', '%', 'evaluation', 'metrics', ',', 'recall', 'value', 'mental', 'deterioration', 'class', '85', '%', '.', 'sum', ',', 'contribute', 'affordable', ',', 'flexible', ',', 'non-invasive', ',', 'personalized', 'diagnostic', 'system', 'work', '.']","based, official, estimates, ,, 50, million, people, worldwide, affected, dementia, ,, number, increases, 10, million, new, patients, every, year, ., without, cure, ,, clinical, prognostication, early, intervention, represent, effective, ways, delay, progression, ., end, ,, artificial, intelligence, computational, linguistics, exploited, natural, language, analysis, ,, personalized, assessment, ,, monitoring, ,, treatment, ., however, ,, traditional, approaches, need, semantic, knowledge, management, explicability, capabilities, ., moreover, ,, using, large, language, models, (, llms, ), cognitive, decline, diagnosis, still, scarce, ,, even, though, models, represent, advanced, way, clinical-patient, communication, using, intelligent, systems, ., consequently, ,, leverage, llm, using, latest, natural, language, processing, (, nlp, ), techniques, chatbot, solution, provide, interpretable, machine, learning, prediction, cognitive, decline, real-time, ., linguistic-conceptual, features, exploited, appropriate, natural, language, analysis, ., explainability, ,, aim, fight, potential, biases, models, improve, potential, help, clinical, workers, diagnosis, decisions, ., detail, ,, proposed, pipeline, composed, (, ), data, extraction, employing, nlp-based, prompt, engineering, ;, (, ii, ), stream-based, data, processing, including, feature, engineering, ,, analysis, ,, selection, ;, (, iii, ), real-time, classification, ;, (, iv, ), explainability, dashboard, provide, visual, natural, language, descriptions, prediction, outcome, ., classification, results, exceed, 80, %, evaluation, metrics, ,, recall, value, mental, deterioration, class, 85, %, ., sum, ,, contribute, affordable, ,, flexible, ,, non-invasive, ,, personalized, diagnostic, system, work, ."
"Guiding Symbolic Natural Language Grammar Induction via
  Transformer-Based Sequence Probabilities","Ben Goertzel, Andres Suarez Madrigal, Gino Yu",2020-05-26T06:18:47Z,"  A novel approach to automated learning of syntactic rules governing natural
languages is proposed, based on using probabilities assigned to sentences (and
potentially longer word sequences) by transformer neural network language
models to guide symbolic learning processes like clustering and rule induction.
This method exploits the learned linguistic knowledge in transformers, without
any reference to their inner representations; hence, the technique is readily
adaptable to the continuous appearance of more powerful language models. We
show a proof-of-concept example of our proposed technique, using it to guide
unsupervised symbolic link-grammar induction methods drawn from our prior
research.
","['novel', 'approach', 'automated', 'learning', 'syntactic', 'rules', 'governing', 'natural', 'languages', 'proposed', ',', 'based', 'using', 'probabilities', 'assigned', 'sentences', '(', 'potentially', 'longer', 'word', 'sequences', ')', 'transformer', 'neural', 'network', 'language', 'models', 'guide', 'symbolic', 'learning', 'processes', 'like', 'clustering', 'rule', 'induction', '.', 'method', 'exploits', 'learned', 'linguistic', 'knowledge', 'transformers', ',', 'without', 'reference', 'inner', 'representations', ';', 'hence', ',', 'technique', 'readily', 'adaptable', 'continuous', 'appearance', 'powerful', 'language', 'models', '.', 'show', 'proof-of-concept', 'example', 'proposed', 'technique', ',', 'using', 'guide', 'unsupervised', 'symbolic', 'link-grammar', 'induction', 'methods', 'drawn', 'prior', 'research', '.']","novel, approach, automated, learning, syntactic, rules, governing, natural, languages, proposed, ,, based, using, probabilities, assigned, sentences, (, potentially, longer, word, sequences, ), transformer, neural, network, language, models, guide, symbolic, learning, processes, like, clustering, rule, induction, ., method, exploits, learned, linguistic, knowledge, transformers, ,, without, reference, inner, representations, ;, hence, ,, technique, readily, adaptable, continuous, appearance, powerful, language, models, ., show, proof-of-concept, example, proposed, technique, ,, using, guide, unsupervised, symbolic, link-grammar, induction, methods, drawn, prior, research, ."
Pre-trained Language Model Based Active Learning for Sentence Matching,"Guirong Bai, Shizhu He, Kang Liu, Jun Zhao, Zaiqing Nie",2020-10-12T08:24:36Z,"  Active learning is able to significantly reduce the annotation cost for
data-driven techniques. However, previous active learning approaches for
natural language processing mainly depend on the entropy-based uncertainty
criterion, and ignore the characteristics of natural language. In this paper,
we propose a pre-trained language model based active learning approach for
sentence matching. Differing from previous active learning, it can provide
linguistic criteria to measure instances and help select more efficient
instances for annotation. Experiments demonstrate our approach can achieve
greater accuracy with fewer labeled training instances.
","['active', 'learning', 'able', 'significantly', 'reduce', 'annotation', 'cost', 'data-driven', 'techniques', '.', 'however', ',', 'previous', 'active', 'learning', 'approaches', 'natural', 'language', 'processing', 'mainly', 'depend', 'entropy-based', 'uncertainty', 'criterion', ',', 'ignore', 'characteristics', 'natural', 'language', '.', 'paper', ',', 'propose', 'pre-trained', 'language', 'model', 'based', 'active', 'learning', 'approach', 'sentence', 'matching', '.', 'differing', 'previous', 'active', 'learning', ',', 'provide', 'linguistic', 'criteria', 'measure', 'instances', 'help', 'select', 'efficient', 'instances', 'annotation', '.', 'experiments', 'demonstrate', 'approach', 'achieve', 'greater', 'accuracy', 'fewer', 'labeled', 'training', 'instances', '.']","active, learning, able, significantly, reduce, annotation, cost, data-driven, techniques, ., however, ,, previous, active, learning, approaches, natural, language, processing, mainly, depend, entropy-based, uncertainty, criterion, ,, ignore, characteristics, natural, language, ., paper, ,, propose, pre-trained, language, model, based, active, learning, approach, sentence, matching, ., differing, previous, active, learning, ,, provide, linguistic, criteria, measure, instances, help, select, efficient, instances, annotation, ., experiments, demonstrate, approach, achieve, greater, accuracy, fewer, labeled, training, instances, ."
"A Systematic Evaluation of Large Language Models for Natural Language
  Generation Tasks","Xuanfan Ni, Piji Li",2024-05-16T16:56:54Z,"  Recent efforts have evaluated large language models (LLMs) in areas such as
commonsense reasoning, mathematical reasoning, and code generation. However, to
the best of our knowledge, no work has specifically investigated the
performance of LLMs in natural language generation (NLG) tasks, a pivotal
criterion for determining model excellence. Thus, this paper conducts a
comprehensive evaluation of well-known and high-performing LLMs, namely
ChatGPT, ChatGLM, T5-based models, LLaMA-based models, and Pythia-based models,
in the context of NLG tasks. We select English and Chinese datasets
encompassing Dialogue Generation and Text Summarization. Moreover, we propose a
common evaluation setting that incorporates input templates and post-processing
strategies. Our study reports both automatic results, accompanied by a detailed
analysis.
","['recent', 'efforts', 'evaluated', 'large', 'language', 'models', '(', 'llms', ')', 'areas', 'commonsense', 'reasoning', ',', 'mathematical', 'reasoning', ',', 'code', 'generation', '.', 'however', ',', 'best', 'knowledge', ',', 'work', 'specifically', 'investigated', 'performance', 'llms', 'natural', 'language', 'generation', '(', 'nlg', ')', 'tasks', ',', 'pivotal', 'criterion', 'determining', 'model', 'excellence', '.', 'thus', ',', 'paper', 'conducts', 'comprehensive', 'evaluation', 'well-known', 'high-performing', 'llms', ',', 'namely', 'chatgpt', ',', 'chatglm', ',', 't5-based', 'models', ',', 'llama-based', 'models', ',', 'pythia-based', 'models', ',', 'context', 'nlg', 'tasks', '.', 'select', 'english', 'chinese', 'datasets', 'encompassing', 'dialogue', 'generation', 'text', 'summarization', '.', 'moreover', ',', 'propose', 'common', 'evaluation', 'setting', 'incorporates', 'input', 'templates', 'post-processing', 'strategies', '.', 'study', 'reports', 'automatic', 'results', ',', 'accompanied', 'detailed', 'analysis', '.']","recent, efforts, evaluated, large, language, models, (, llms, ), areas, commonsense, reasoning, ,, mathematical, reasoning, ,, code, generation, ., however, ,, best, knowledge, ,, work, specifically, investigated, performance, llms, natural, language, generation, (, nlg, ), tasks, ,, pivotal, criterion, determining, model, excellence, ., thus, ,, paper, conducts, comprehensive, evaluation, well-known, high-performing, llms, ,, namely, chatgpt, ,, chatglm, ,, t5-based, models, ,, llama-based, models, ,, pythia-based, models, ,, context, nlg, tasks, ., select, english, chinese, datasets, encompassing, dialogue, generation, text, summarization, ., moreover, ,, propose, common, evaluation, setting, incorporates, input, templates, post-processing, strategies, ., study, reports, automatic, results, ,, accompanied, detailed, analysis, ."
"Comparing Complex Concepts with Transformers: Matching Patent Claims
  Against Natural Language Text","Matthias Blume, Ghobad Heidari, Christoph Hewel",2024-07-14T22:31:07Z,"  A key capability in managing patent applications or a patent portfolio is
comparing claims to other text, e.g. a patent specification. Because the
language of claims is different from language used elsewhere in the patent
application or in non-patent text, this has been challenging for computer based
natural language processing. We test two new LLM-based approaches and find that
both provide substantially better performance than previously published values.
The ability to match dense information from one domain against much more
distributed information expressed in a different vocabulary may also be useful
beyond the intellectual property space.
","['key', 'capability', 'managing', 'patent', 'applications', 'patent', 'portfolio', 'comparing', 'claims', 'text', ',', 'e.g', '.', 'patent', 'specification', '.', 'language', 'claims', 'different', 'language', 'used', 'elsewhere', 'patent', 'application', 'non-patent', 'text', ',', 'challenging', 'computer', 'based', 'natural', 'language', 'processing', '.', 'test', 'two', 'new', 'llm-based', 'approaches', 'find', 'provide', 'substantially', 'better', 'performance', 'previously', 'published', 'values', '.', 'ability', 'match', 'dense', 'information', 'one', 'domain', 'much', 'distributed', 'information', 'expressed', 'different', 'vocabulary', 'may', 'also', 'useful', 'beyond', 'intellectual', 'property', 'space', '.']","key, capability, managing, patent, applications, patent, portfolio, comparing, claims, text, ,, e.g, ., patent, specification, ., language, claims, different, language, used, elsewhere, patent, application, non-patent, text, ,, challenging, computer, based, natural, language, processing, ., test, two, new, llm-based, approaches, find, provide, substantially, better, performance, previously, published, values, ., ability, match, dense, information, one, domain, much, distributed, information, expressed, different, vocabulary, may, also, useful, beyond, intellectual, property, space, ."
Resources for Turkish Natural Language Processing: A critical survey,"Çağrı Çöltekin, A. Seza Doğruöz, Özlem Çetinoğlu",2022-04-11T12:23:07Z,"  This paper presents a comprehensive survey of corpora and lexical resources
available for Turkish. We review a broad range of resources, focusing on the
ones that are publicly available. In addition to providing information about
the available linguistic resources, we present a set of recommendations, and
identify gaps in the data available for conducting research and building
applications in Turkish Linguistics and Natural Language Processing.
","['paper', 'presents', 'comprehensive', 'survey', 'corpora', 'lexical', 'resources', 'available', 'turkish', '.', 'review', 'broad', 'range', 'resources', ',', 'focusing', 'ones', 'publicly', 'available', '.', 'addition', 'providing', 'information', 'available', 'linguistic', 'resources', ',', 'present', 'set', 'recommendations', ',', 'identify', 'gaps', 'data', 'available', 'conducting', 'research', 'building', 'applications', 'turkish', 'linguistics', 'natural', 'language', 'processing', '.']","paper, presents, comprehensive, survey, corpora, lexical, resources, available, turkish, ., review, broad, range, resources, ,, focusing, ones, publicly, available, ., addition, providing, information, available, linguistic, resources, ,, present, set, recommendations, ,, identify, gaps, data, available, conducting, research, building, applications, turkish, linguistics, natural, language, processing, ."
"AraMUS: Pushing the Limits of Data and Model Scale for Arabic Natural
  Language Processing","Asaad Alghamdi, Xinyu Duan, Wei Jiang, Zhenhai Wang, Yimeng Wu, Qingrong Xia, Zhefeng Wang, Yi Zheng, Mehdi Rezagholizadeh, Baoxing Huai, Peilun Cheng, Abbas Ghaddar",2023-06-11T22:55:18Z,"  Developing monolingual large Pre-trained Language Models (PLMs) is shown to
be very successful in handling different tasks in Natural Language Processing
(NLP). In this work, we present AraMUS, the largest Arabic PLM with 11B
parameters trained on 529GB of high-quality Arabic textual data. AraMUS
achieves state-of-the-art performances on a diverse set of Arabic
classification and generative tasks. Moreover, AraMUS shows impressive few-shot
learning abilities compared with the best existing Arabic PLMs.
","['developing', 'monolingual', 'large', 'pre-trained', 'language', 'models', '(', 'plms', ')', 'shown', 'successful', 'handling', 'different', 'tasks', 'natural', 'language', 'processing', '(', 'nlp', ')', '.', 'work', ',', 'present', 'aramus', ',', 'largest', 'arabic', 'plm', '11b', 'parameters', 'trained', '529gb', 'high-quality', 'arabic', 'textual', 'data', '.', 'aramus', 'achieves', 'state-of-the-art', 'performances', 'diverse', 'set', 'arabic', 'classification', 'generative', 'tasks', '.', 'moreover', ',', 'aramus', 'shows', 'impressive', 'few-shot', 'learning', 'abilities', 'compared', 'best', 'existing', 'arabic', 'plms', '.']","developing, monolingual, large, pre-trained, language, models, (, plms, ), shown, successful, handling, different, tasks, natural, language, processing, (, nlp, ), ., work, ,, present, aramus, ,, largest, arabic, plm, 11b, parameters, trained, 529gb, high-quality, arabic, textual, data, ., aramus, achieves, state-of-the-art, performances, diverse, set, arabic, classification, generative, tasks, ., moreover, ,, aramus, shows, impressive, few-shot, learning, abilities, compared, best, existing, arabic, plms, ."
Partial Tensorized Transformers for Natural Language Processing,"Subhadra Vadlamannati, Ryan Solgi",2023-10-30T23:19:06Z,"  The transformer architecture has revolutionized Natural Language Processing
(NLP) and other machine-learning tasks, due to its unprecedented accuracy.
However, their extensive memory and parameter requirements often hinder their
practical applications. In this work, we study the effect of tensor-train
decomposition to improve the accuracy and compress transformer vision-language
neural networks, namely BERT and ViT. We focus both on embedding-layer
compression and partial tensorization of neural networks (PTNN) through an
algorithmic approach. Our novel PTNN approach significantly improves the
accuracy of existing models by up to 5%, all without the need for post-training
adjustments, breaking new ground in the field of tensor decomposition.
","['transformer', 'architecture', 'revolutionized', 'natural', 'language', 'processing', '(', 'nlp', ')', 'machine-learning', 'tasks', ',', 'due', 'unprecedented', 'accuracy', '.', 'however', ',', 'extensive', 'memory', 'parameter', 'requirements', 'often', 'hinder', 'practical', 'applications', '.', 'work', ',', 'study', 'effect', 'tensor-train', 'decomposition', 'improve', 'accuracy', 'compress', 'transformer', 'vision-language', 'neural', 'networks', ',', 'namely', 'bert', 'vit', '.', 'focus', 'embedding-layer', 'compression', 'partial', 'tensorization', 'neural', 'networks', '(', 'ptnn', ')', 'algorithmic', 'approach', '.', 'novel', 'ptnn', 'approach', 'significantly', 'improves', 'accuracy', 'existing', 'models', '5', '%', ',', 'without', 'need', 'post-training', 'adjustments', ',', 'breaking', 'new', 'ground', 'field', 'tensor', 'decomposition', '.']","transformer, architecture, revolutionized, natural, language, processing, (, nlp, ), machine-learning, tasks, ,, due, unprecedented, accuracy, ., however, ,, extensive, memory, parameter, requirements, often, hinder, practical, applications, ., work, ,, study, effect, tensor-train, decomposition, improve, accuracy, compress, transformer, vision-language, neural, networks, ,, namely, bert, vit, ., focus, embedding-layer, compression, partial, tensorization, neural, networks, (, ptnn, ), algorithmic, approach, ., novel, ptnn, approach, significantly, improves, accuracy, existing, models, 5, %, ,, without, need, post-training, adjustments, ,, breaking, new, ground, field, tensor, decomposition, ."
"Towards Natural Language Question Answering over Earth Observation
  Linked Data using Attention-based Neural Machine Translation","Abhishek V. Potnis, Rajat C. Shinde, Surya S. Durbha",2021-01-23T06:12:20Z,"  With an increase in Geospatial Linked Open Data being adopted and published
over the web, there is a need to develop intuitive interfaces and systems for
seamless and efficient exploratory analysis of such rich heterogeneous
multi-modal datasets. This work is geared towards improving the exploration
process of Earth Observation (EO) Linked Data by developing a natural language
interface to facilitate querying. Questions asked over Earth Observation Linked
Data have an inherent spatio-temporal dimension and can be represented using
GeoSPARQL. This paper seeks to study and analyze the use of RNN-based neural
machine translation with attention for transforming natural language questions
into GeoSPARQL queries. Specifically, it aims to assess the feasibility of a
neural approach for identifying and mapping spatial predicates in natural
language to GeoSPARQL's topology vocabulary extension including - Egenhofer and
RCC8 relations. The queries can then be executed over a triple store to yield
answers for the natural language questions. A dataset consisting of mappings
from natural language questions to GeoSPARQL queries over the Corine Land
Cover(CLC) Linked Data has been created to train and validate the deep neural
network. From our experiments, it is evident that neural machine translation
with attention is a promising approach for the task of translating spatial
predicates in natural language questions to GeoSPARQL queries.
","['increase', 'geospatial', 'linked', 'open', 'data', 'adopted', 'published', 'web', ',', 'need', 'develop', 'intuitive', 'interfaces', 'systems', 'seamless', 'efficient', 'exploratory', 'analysis', 'rich', 'heterogeneous', 'multi-modal', 'datasets', '.', 'work', 'geared', 'towards', 'improving', 'exploration', 'process', 'earth', 'observation', '(', 'eo', ')', 'linked', 'data', 'developing', 'natural', 'language', 'interface', 'facilitate', 'querying', '.', 'questions', 'asked', 'earth', 'observation', 'linked', 'data', 'inherent', 'spatio-temporal', 'dimension', 'represented', 'using', 'geosparql', '.', 'paper', 'seeks', 'study', 'analyze', 'use', 'rnn-based', 'neural', 'machine', 'translation', 'attention', 'transforming', 'natural', 'language', 'questions', 'geosparql', 'queries', '.', 'specifically', ',', 'aims', 'assess', 'feasibility', 'neural', 'approach', 'identifying', 'mapping', 'spatial', 'predicates', 'natural', 'language', 'geosparql', ""'s"", 'topology', 'vocabulary', 'extension', 'including', '-', 'egenhofer', 'rcc8', 'relations', '.', 'queries', 'executed', 'triple', 'store', 'yield', 'answers', 'natural', 'language', 'questions', '.', 'dataset', 'consisting', 'mappings', 'natural', 'language', 'questions', 'geosparql', 'queries', 'corine', 'land', 'cover', '(', 'clc', ')', 'linked', 'data', 'created', 'train', 'validate', 'deep', 'neural', 'network', '.', 'experiments', ',', 'evident', 'neural', 'machine', 'translation', 'attention', 'promising', 'approach', 'task', 'translating', 'spatial', 'predicates', 'natural', 'language', 'questions', 'geosparql', 'queries', '.']","increase, geospatial, linked, open, data, adopted, published, web, ,, need, develop, intuitive, interfaces, systems, seamless, efficient, exploratory, analysis, rich, heterogeneous, multi-modal, datasets, ., work, geared, towards, improving, exploration, process, earth, observation, (, eo, ), linked, data, developing, natural, language, interface, facilitate, querying, ., questions, asked, earth, observation, linked, data, inherent, spatio-temporal, dimension, represented, using, geosparql, ., paper, seeks, study, analyze, use, rnn-based, neural, machine, translation, attention, transforming, natural, language, questions, geosparql, queries, ., specifically, ,, aims, assess, feasibility, neural, approach, identifying, mapping, spatial, predicates, natural, language, geosparql, 's, topology, vocabulary, extension, including, -, egenhofer, rcc8, relations, ., queries, executed, triple, store, yield, answers, natural, language, questions, ., dataset, consisting, mappings, natural, language, questions, geosparql, queries, corine, land, cover, (, clc, ), linked, data, created, train, validate, deep, neural, network, ., experiments, ,, evident, neural, machine, translation, attention, promising, approach, task, translating, spatial, predicates, natural, language, questions, geosparql, queries, ."
"EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural
  Language Processing","Iker de la Iglesia, Aitziber Atutxa, Koldo Gojenola, Ander Barrena",2023-06-12T18:56:25Z,"  The utilization of clinical reports for various secondary purposes, including
health research and treatment monitoring, is crucial for enhancing patient
care. Natural Language Processing (NLP) tools have emerged as valuable assets
for extracting and processing relevant information from these reports. However,
the availability of specialized language models for the clinical domain in
Spanish has been limited.
  In this paper, we introduce EriBERTa, a bilingual domain-specific language
model pre-trained on extensive medical and clinical corpora. We demonstrate
that EriBERTa outperforms previous Spanish language models in the clinical
domain, showcasing its superior capabilities in understanding medical texts and
extracting meaningful information. Moreover, EriBERTa exhibits promising
transfer learning abilities, allowing for knowledge transfer from one language
to another. This aspect is particularly beneficial given the scarcity of
Spanish clinical data.
","['utilization', 'clinical', 'reports', 'various', 'secondary', 'purposes', ',', 'including', 'health', 'research', 'treatment', 'monitoring', ',', 'crucial', 'enhancing', 'patient', 'care', '.', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tools', 'emerged', 'valuable', 'assets', 'extracting', 'processing', 'relevant', 'information', 'reports', '.', 'however', ',', 'availability', 'specialized', 'language', 'models', 'clinical', 'domain', 'spanish', 'limited', '.', 'paper', ',', 'introduce', 'eriberta', ',', 'bilingual', 'domain-specific', 'language', 'model', 'pre-trained', 'extensive', 'medical', 'clinical', 'corpora', '.', 'demonstrate', 'eriberta', 'outperforms', 'previous', 'spanish', 'language', 'models', 'clinical', 'domain', ',', 'showcasing', 'superior', 'capabilities', 'understanding', 'medical', 'texts', 'extracting', 'meaningful', 'information', '.', 'moreover', ',', 'eriberta', 'exhibits', 'promising', 'transfer', 'learning', 'abilities', ',', 'allowing', 'knowledge', 'transfer', 'one', 'language', 'another', '.', 'aspect', 'particularly', 'beneficial', 'given', 'scarcity', 'spanish', 'clinical', 'data', '.']","utilization, clinical, reports, various, secondary, purposes, ,, including, health, research, treatment, monitoring, ,, crucial, enhancing, patient, care, ., natural, language, processing, (, nlp, ), tools, emerged, valuable, assets, extracting, processing, relevant, information, reports, ., however, ,, availability, specialized, language, models, clinical, domain, spanish, limited, ., paper, ,, introduce, eriberta, ,, bilingual, domain-specific, language, model, pre-trained, extensive, medical, clinical, corpora, ., demonstrate, eriberta, outperforms, previous, spanish, language, models, clinical, domain, ,, showcasing, superior, capabilities, understanding, medical, texts, extracting, meaningful, information, ., moreover, ,, eriberta, exhibits, promising, transfer, learning, abilities, ,, allowing, knowledge, transfer, one, language, another, ., aspect, particularly, beneficial, given, scarcity, spanish, clinical, data, ."
Crosslingual Retrieval Augmented In-context Learning for Bangla,"Xiaoqian Li, Ercong Nie, Sheng Liang",2023-11-01T15:32:50Z,"  The promise of Large Language Models (LLMs) in Natural Language Processing
has often been overshadowed by their limited performance in low-resource
languages such as Bangla. To address this, our paper presents a pioneering
approach that utilizes cross-lingual retrieval augmented in-context learning.
By strategically sourcing semantically similar prompts from high-resource
language, we enable multilingual pretrained language models (MPLMs), especially
the generative model BLOOMZ, to successfully boost performance on Bangla tasks.
Our extensive evaluation highlights that the cross-lingual retrieval augmented
prompts bring steady improvements to MPLMs over the zero-shot performance.
","['promise', 'large', 'language', 'models', '(', 'llms', ')', 'natural', 'language', 'processing', 'often', 'overshadowed', 'limited', 'performance', 'low-resource', 'languages', 'bangla', '.', 'address', ',', 'paper', 'presents', 'pioneering', 'approach', 'utilizes', 'cross-lingual', 'retrieval', 'augmented', 'in-context', 'learning', '.', 'strategically', 'sourcing', 'semantically', 'similar', 'prompts', 'high-resource', 'language', ',', 'enable', 'multilingual', 'pretrained', 'language', 'models', '(', 'mplms', ')', ',', 'especially', 'generative', 'model', 'bloomz', ',', 'successfully', 'boost', 'performance', 'bangla', 'tasks', '.', 'extensive', 'evaluation', 'highlights', 'cross-lingual', 'retrieval', 'augmented', 'prompts', 'bring', 'steady', 'improvements', 'mplms', 'zero-shot', 'performance', '.']","promise, large, language, models, (, llms, ), natural, language, processing, often, overshadowed, limited, performance, low-resource, languages, bangla, ., address, ,, paper, presents, pioneering, approach, utilizes, cross-lingual, retrieval, augmented, in-context, learning, ., strategically, sourcing, semantically, similar, prompts, high-resource, language, ,, enable, multilingual, pretrained, language, models, (, mplms, ), ,, especially, generative, model, bloomz, ,, successfully, boost, performance, bangla, tasks, ., extensive, evaluation, highlights, cross-lingual, retrieval, augmented, prompts, bring, steady, improvements, mplms, zero-shot, performance, ."
"Development of a rule-based lemmatization algorithm through Finite State
  Machine for Uzbek language","Maksud Sharipov, Ogabek Sobirov",2022-10-28T09:21:06Z,"  Lemmatization is one of the core concepts in natural language processing,
thus creating a lemmatization tool is an important task. This paper discusses
the construction of a lemmatization algorithm for the Uzbek language. The main
purpose of the work is to remove affixes of words in the Uzbek language by
means of the finite state machine and to identify a lemma (a word that can be
found in the dictionary) of the word. The process of removing affixes uses a
database of affixes and part of speech knowledge. This lemmatization consists
of the general rules and a part of speech data of the Uzbek language, affixes,
classification of affixes, removing affixes on the basis of the finite state
machine for each class, as well as a definition of this word lemma.
","['lemmatization', 'one', 'core', 'concepts', 'natural', 'language', 'processing', ',', 'thus', 'creating', 'lemmatization', 'tool', 'important', 'task', '.', 'paper', 'discusses', 'construction', 'lemmatization', 'algorithm', 'uzbek', 'language', '.', 'main', 'purpose', 'work', 'remove', 'affixes', 'words', 'uzbek', 'language', 'means', 'finite', 'state', 'machine', 'identify', 'lemma', '(', 'word', 'found', 'dictionary', ')', 'word', '.', 'process', 'removing', 'affixes', 'uses', 'database', 'affixes', 'part', 'speech', 'knowledge', '.', 'lemmatization', 'consists', 'general', 'rules', 'part', 'speech', 'data', 'uzbek', 'language', ',', 'affixes', ',', 'classification', 'affixes', ',', 'removing', 'affixes', 'basis', 'finite', 'state', 'machine', 'class', ',', 'well', 'definition', 'word', 'lemma', '.']","lemmatization, one, core, concepts, natural, language, processing, ,, thus, creating, lemmatization, tool, important, task, ., paper, discusses, construction, lemmatization, algorithm, uzbek, language, ., main, purpose, work, remove, affixes, words, uzbek, language, means, finite, state, machine, identify, lemma, (, word, found, dictionary, ), word, ., process, removing, affixes, uses, database, affixes, part, speech, knowledge, ., lemmatization, consists, general, rules, part, speech, data, uzbek, language, ,, affixes, ,, classification, affixes, ,, removing, affixes, basis, finite, state, machine, class, ,, well, definition, word, lemma, ."
"Evaluating the Translation Performance of Large Language Models Based on
  Euas-20","Yan Huang, Wei Liu",2024-08-06T11:49:11Z,"  In recent years, with the rapid development of deep learning technology,
large language models (LLMs) such as BERT and GPT have achieved breakthrough
results in natural language processing tasks. Machine translation (MT), as one
of the core tasks of natural language processing, has also benefited from the
development of large language models and achieved a qualitative leap. Despite
the significant progress in translation performance achieved by large language
models, machine translation still faces many challenges. Therefore, in this
paper, we construct the dataset Euas-20 to evaluate the performance of large
language models on translation tasks, the translation ability on different
languages, and the effect of pre-training data on the translation ability of
LLMs for researchers and developers.
","['recent', 'years', ',', 'rapid', 'development', 'deep', 'learning', 'technology', ',', 'large', 'language', 'models', '(', 'llms', ')', 'bert', 'gpt', 'achieved', 'breakthrough', 'results', 'natural', 'language', 'processing', 'tasks', '.', 'machine', 'translation', '(', 'mt', ')', ',', 'one', 'core', 'tasks', 'natural', 'language', 'processing', ',', 'also', 'benefited', 'development', 'large', 'language', 'models', 'achieved', 'qualitative', 'leap', '.', 'despite', 'significant', 'progress', 'translation', 'performance', 'achieved', 'large', 'language', 'models', ',', 'machine', 'translation', 'still', 'faces', 'many', 'challenges', '.', 'therefore', ',', 'paper', ',', 'construct', 'dataset', 'euas-20', 'evaluate', 'performance', 'large', 'language', 'models', 'translation', 'tasks', ',', 'translation', 'ability', 'different', 'languages', ',', 'effect', 'pre-training', 'data', 'translation', 'ability', 'llms', 'researchers', 'developers', '.']","recent, years, ,, rapid, development, deep, learning, technology, ,, large, language, models, (, llms, ), bert, gpt, achieved, breakthrough, results, natural, language, processing, tasks, ., machine, translation, (, mt, ), ,, one, core, tasks, natural, language, processing, ,, also, benefited, development, large, language, models, achieved, qualitative, leap, ., despite, significant, progress, translation, performance, achieved, large, language, models, ,, machine, translation, still, faces, many, challenges, ., therefore, ,, paper, ,, construct, dataset, euas-20, evaluate, performance, large, language, models, translation, tasks, ,, translation, ability, different, languages, ,, effect, pre-training, data, translation, ability, llms, researchers, developers, ."
"Knowledge-driven Natural Language Understanding of English Text and its
  Applications","Kinjal Basu, Sarat Varanasi, Farhad Shakerin, Joaquin Arias, Gopal Gupta",2021-01-27T22:02:50Z,"  Understanding the meaning of a text is a fundamental challenge of natural
language understanding (NLU) research. An ideal NLU system should process a
language in a way that is not exclusive to a single task or a dataset. Keeping
this in mind, we have introduced a novel knowledge driven semantic
representation approach for English text. By leveraging the VerbNet lexicon, we
are able to map syntax tree of the text to its commonsense meaning represented
using basic knowledge primitives. The general purpose knowledge represented
from our approach can be used to build any reasoning based NLU system that can
also provide justification. We applied this approach to construct two NLU
applications that we present here: SQuARE (Semantic-based Question Answering
and Reasoning Engine) and StaCACK (Stateful Conversational Agent using
Commonsense Knowledge). Both these systems work by ""truly understanding"" the
natural language text they process and both provide natural language
explanations for their responses while maintaining high accuracy.
","['understanding', 'meaning', 'text', 'fundamental', 'challenge', 'natural', 'language', 'understanding', '(', 'nlu', ')', 'research', '.', 'ideal', 'nlu', 'system', 'process', 'language', 'way', 'exclusive', 'single', 'task', 'dataset', '.', 'keeping', 'mind', ',', 'introduced', 'novel', 'knowledge', 'driven', 'semantic', 'representation', 'approach', 'english', 'text', '.', 'leveraging', 'verbnet', 'lexicon', ',', 'able', 'map', 'syntax', 'tree', 'text', 'commonsense', 'meaning', 'represented', 'using', 'basic', 'knowledge', 'primitives', '.', 'general', 'purpose', 'knowledge', 'represented', 'approach', 'used', 'build', 'reasoning', 'based', 'nlu', 'system', 'also', 'provide', 'justification', '.', 'applied', 'approach', 'construct', 'two', 'nlu', 'applications', 'present', ':', 'square', '(', 'semantic-based', 'question', 'answering', 'reasoning', 'engine', ')', 'stacack', '(', 'stateful', 'conversational', 'agent', 'using', 'commonsense', 'knowledge', ')', '.', 'systems', 'work', '``', 'truly', 'understanding', ""''"", 'natural', 'language', 'text', 'process', 'provide', 'natural', 'language', 'explanations', 'responses', 'maintaining', 'high', 'accuracy', '.']","understanding, meaning, text, fundamental, challenge, natural, language, understanding, (, nlu, ), research, ., ideal, nlu, system, process, language, way, exclusive, single, task, dataset, ., keeping, mind, ,, introduced, novel, knowledge, driven, semantic, representation, approach, english, text, ., leveraging, verbnet, lexicon, ,, able, map, syntax, tree, text, commonsense, meaning, represented, using, basic, knowledge, primitives, ., general, purpose, knowledge, represented, approach, used, build, reasoning, based, nlu, system, also, provide, justification, ., applied, approach, construct, two, nlu, applications, present, :, square, (, semantic-based, question, answering, reasoning, engine, ), stacack, (, stateful, conversational, agent, using, commonsense, knowledge, ), ., systems, work, ``, truly, understanding, '', natural, language, text, process, provide, natural, language, explanations, responses, maintaining, high, accuracy, ."
"Language-Family Adapters for Low-Resource Multilingual Neural Machine
  Translation","Alexandra Chronopoulou, Dario Stojanovski, Alexander Fraser",2022-09-30T05:02:42Z,"  Large multilingual models trained with self-supervision achieve
state-of-the-art results in a wide range of natural language processing tasks.
Self-supervised pretrained models are often fine-tuned on parallel data from
one or multiple language pairs for machine translation. Multilingual
fine-tuning improves performance on low-resource languages but requires
modifying the entire model and can be prohibitively expensive. Training a new
adapter on each language pair or training a single adapter on all language
pairs without updating the pretrained model has been proposed as a
parameter-efficient alternative. However, the former does not permit any
sharing between languages, while the latter shares parameters for all languages
and is susceptible to negative interference. In this paper, we propose training
language-family adapters on top of mBART-50 to facilitate cross-lingual
transfer. Our approach outperforms related baselines, yielding higher
translation scores on average when translating from English to 17 different
low-resource languages. We also show that language-family adapters provide an
effective method to translate to languages unseen during pretraining.
","['large', 'multilingual', 'models', 'trained', 'self-supervision', 'achieve', 'state-of-the-art', 'results', 'wide', 'range', 'natural', 'language', 'processing', 'tasks', '.', 'self-supervised', 'pretrained', 'models', 'often', 'fine-tuned', 'parallel', 'data', 'one', 'multiple', 'language', 'pairs', 'machine', 'translation', '.', 'multilingual', 'fine-tuning', 'improves', 'performance', 'low-resource', 'languages', 'requires', 'modifying', 'entire', 'model', 'prohibitively', 'expensive', '.', 'training', 'new', 'adapter', 'language', 'pair', 'training', 'single', 'adapter', 'language', 'pairs', 'without', 'updating', 'pretrained', 'model', 'proposed', 'parameter-efficient', 'alternative', '.', 'however', ',', 'former', 'permit', 'sharing', 'languages', ',', 'latter', 'shares', 'parameters', 'languages', 'susceptible', 'negative', 'interference', '.', 'paper', ',', 'propose', 'training', 'language-family', 'adapters', 'top', 'mbart-50', 'facilitate', 'cross-lingual', 'transfer', '.', 'approach', 'outperforms', 'related', 'baselines', ',', 'yielding', 'higher', 'translation', 'scores', 'average', 'translating', 'english', '17', 'different', 'low-resource', 'languages', '.', 'also', 'show', 'language-family', 'adapters', 'provide', 'effective', 'method', 'translate', 'languages', 'unseen', 'pretraining', '.']","large, multilingual, models, trained, self-supervision, achieve, state-of-the-art, results, wide, range, natural, language, processing, tasks, ., self-supervised, pretrained, models, often, fine-tuned, parallel, data, one, multiple, language, pairs, machine, translation, ., multilingual, fine-tuning, improves, performance, low-resource, languages, requires, modifying, entire, model, prohibitively, expensive, ., training, new, adapter, language, pair, training, single, adapter, language, pairs, without, updating, pretrained, model, proposed, parameter-efficient, alternative, ., however, ,, former, permit, sharing, languages, ,, latter, shares, parameters, languages, susceptible, negative, interference, ., paper, ,, propose, training, language-family, adapters, top, mbart-50, facilitate, cross-lingual, transfer, ., approach, outperforms, related, baselines, ,, yielding, higher, translation, scores, average, translating, english, 17, different, low-resource, languages, ., also, show, language-family, adapters, provide, effective, method, translate, languages, unseen, pretraining, ."
"NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language
  Selection for Low-Resource Multilingual Sentiment Analysis","Mingyang Wang, Heike Adel, Lukas Lange, Jannik Strötgen, Hinrich Schütze",2023-04-28T21:02:58Z,"  This paper describes our system developed for the SemEval-2023 Task 12
""Sentiment Analysis for Low-resource African Languages using Twitter Dataset"".
Sentiment analysis is one of the most widely studied applications in natural
language processing. However, most prior work still focuses on a small number
of high-resource languages. Building reliable sentiment analysis systems for
low-resource languages remains challenging, due to the limited training data in
this task. In this work, we propose to leverage language-adaptive and
task-adaptive pretraining on African texts and study transfer learning with
source language selection on top of an African language-centric pretrained
language model. Our key findings are: (1) Adapting the pretrained model to the
target language and task using a small yet relevant corpus improves performance
remarkably by more than 10 F1 score points. (2) Selecting source languages with
positive transfer gains during training can avoid harmful interference from
dissimilar languages, leading to better results in multilingual and
cross-lingual settings. In the shared task, our system wins 8 out of 15 tracks
and, in particular, performs best in the multilingual evaluation.
","['paper', 'describes', 'system', 'developed', 'semeval-2023', 'task', '12', ""''"", 'sentiment', 'analysis', 'low-resource', 'african', 'languages', 'using', 'twitter', 'dataset', ""''"", '.', 'sentiment', 'analysis', 'one', 'widely', 'studied', 'applications', 'natural', 'language', 'processing', '.', 'however', ',', 'prior', 'work', 'still', 'focuses', 'small', 'number', 'high-resource', 'languages', '.', 'building', 'reliable', 'sentiment', 'analysis', 'systems', 'low-resource', 'languages', 'remains', 'challenging', ',', 'due', 'limited', 'training', 'data', 'task', '.', 'work', ',', 'propose', 'leverage', 'language-adaptive', 'task-adaptive', 'pretraining', 'african', 'texts', 'study', 'transfer', 'learning', 'source', 'language', 'selection', 'top', 'african', 'language-centric', 'pretrained', 'language', 'model', '.', 'key', 'findings', ':', '(', '1', ')', 'adapting', 'pretrained', 'model', 'target', 'language', 'task', 'using', 'small', 'yet', 'relevant', 'corpus', 'improves', 'performance', 'remarkably', '10', 'f1', 'score', 'points', '.', '(', '2', ')', 'selecting', 'source', 'languages', 'positive', 'transfer', 'gains', 'training', 'avoid', 'harmful', 'interference', 'dissimilar', 'languages', ',', 'leading', 'better', 'results', 'multilingual', 'cross-lingual', 'settings', '.', 'shared', 'task', ',', 'system', 'wins', '8', '15', 'tracks', ',', 'particular', ',', 'performs', 'best', 'multilingual', 'evaluation', '.']","paper, describes, system, developed, semeval-2023, task, 12, '', sentiment, analysis, low-resource, african, languages, using, twitter, dataset, '', ., sentiment, analysis, one, widely, studied, applications, natural, language, processing, ., however, ,, prior, work, still, focuses, small, number, high-resource, languages, ., building, reliable, sentiment, analysis, systems, low-resource, languages, remains, challenging, ,, due, limited, training, data, task, ., work, ,, propose, leverage, language-adaptive, task-adaptive, pretraining, african, texts, study, transfer, learning, source, language, selection, top, african, language-centric, pretrained, language, model, ., key, findings, :, (, 1, ), adapting, pretrained, model, target, language, task, using, small, yet, relevant, corpus, improves, performance, remarkably, 10, f1, score, points, ., (, 2, ), selecting, source, languages, positive, transfer, gains, training, avoid, harmful, interference, dissimilar, languages, ,, leading, better, results, multilingual, cross-lingual, settings, ., shared, task, ,, system, wins, 8, 15, tracks, ,, particular, ,, performs, best, multilingual, evaluation, ."
Efficiently Adapting Pretrained Language Models To New Languages,"Zoltan Csaki, Pian Pawakapan, Urmish Thakker, Qiantong Xu",2023-11-09T20:59:08Z,"  Recent large language models (LLM) exhibit sub-optimal performance on
low-resource languages, as the training data of these models is usually
dominated by English and other high-resource languages. Furthermore, it is
challenging to train models for low-resource languages, especially from
scratch, due to a lack of high quality training data. Adapting pretrained LLMs
reduces the need for data in the new language while also providing cross
lingual transfer capabilities. However, naively adapting to new languages leads
to catastrophic forgetting and poor tokenizer efficiency. In this work, we
study how to efficiently adapt any existing pretrained LLM to a new language
without running into these issues. In particular, we improve the encoding
efficiency of the tokenizer by adding new tokens from the target language and
study the data mixing recipe to mitigate forgetting. Our experiments on
adapting an English LLM to Hungarian and Thai show that our recipe can reach
better performance than open source models on the target language, with minimal
regressions on English.
","['recent', 'large', 'language', 'models', '(', 'llm', ')', 'exhibit', 'sub-optimal', 'performance', 'low-resource', 'languages', ',', 'training', 'data', 'models', 'usually', 'dominated', 'english', 'high-resource', 'languages', '.', 'furthermore', ',', 'challenging', 'train', 'models', 'low-resource', 'languages', ',', 'especially', 'scratch', ',', 'due', 'lack', 'high', 'quality', 'training', 'data', '.', 'adapting', 'pretrained', 'llms', 'reduces', 'need', 'data', 'new', 'language', 'also', 'providing', 'cross', 'lingual', 'transfer', 'capabilities', '.', 'however', ',', 'naively', 'adapting', 'new', 'languages', 'leads', 'catastrophic', 'forgetting', 'poor', 'tokenizer', 'efficiency', '.', 'work', ',', 'study', 'efficiently', 'adapt', 'existing', 'pretrained', 'llm', 'new', 'language', 'without', 'running', 'issues', '.', 'particular', ',', 'improve', 'encoding', 'efficiency', 'tokenizer', 'adding', 'new', 'tokens', 'target', 'language', 'study', 'data', 'mixing', 'recipe', 'mitigate', 'forgetting', '.', 'experiments', 'adapting', 'english', 'llm', 'hungarian', 'thai', 'show', 'recipe', 'reach', 'better', 'performance', 'open', 'source', 'models', 'target', 'language', ',', 'minimal', 'regressions', 'english', '.']","recent, large, language, models, (, llm, ), exhibit, sub-optimal, performance, low-resource, languages, ,, training, data, models, usually, dominated, english, high-resource, languages, ., furthermore, ,, challenging, train, models, low-resource, languages, ,, especially, scratch, ,, due, lack, high, quality, training, data, ., adapting, pretrained, llms, reduces, need, data, new, language, also, providing, cross, lingual, transfer, capabilities, ., however, ,, naively, adapting, new, languages, leads, catastrophic, forgetting, poor, tokenizer, efficiency, ., work, ,, study, efficiently, adapt, existing, pretrained, llm, new, language, without, running, issues, ., particular, ,, improve, encoding, efficiency, tokenizer, adding, new, tokens, target, language, study, data, mixing, recipe, mitigate, forgetting, ., experiments, adapting, english, llm, hungarian, thai, show, recipe, reach, better, performance, open, source, models, target, language, ,, minimal, regressions, english, ."
SignCLIP: Connecting Text and Sign Language by Contrastive Learning,"Zifan Jiang, Gerard Sant, Amit Moryossef, Mathias Müller, Rico Sennrich, Sarah Ebling",2024-07-01T13:17:35Z,"  We present SignCLIP, which re-purposes CLIP (Contrastive Language-Image
Pretraining) to project spoken language text and sign language videos, two
classes of natural languages of distinct modalities, into the same space.
SignCLIP is an efficient method of learning useful visual representations for
sign language processing from large-scale, multilingual video-text pairs,
without directly optimizing for a specific task or sign language which is often
of limited size.
  We pretrain SignCLIP on Spreadthesign, a prominent sign language dictionary
consisting of ~500 thousand video clips in up to 44 sign languages, and
evaluate it with various downstream datasets. SignCLIP discerns in-domain
signing with notable text-to-video/video-to-text retrieval accuracy. It also
performs competitively for out-of-domain downstream tasks such as isolated sign
language recognition upon essential few-shot prompting or fine-tuning.
  We analyze the latent space formed by the spoken language text and sign
language poses, which provides additional linguistic insights. Our code and
models are openly available.
","['present', 'signclip', ',', 're-purposes', 'clip', '(', 'contrastive', 'language-image', 'pretraining', ')', 'project', 'spoken', 'language', 'text', 'sign', 'language', 'videos', ',', 'two', 'classes', 'natural', 'languages', 'distinct', 'modalities', ',', 'space', '.', 'signclip', 'efficient', 'method', 'learning', 'useful', 'visual', 'representations', 'sign', 'language', 'processing', 'large-scale', ',', 'multilingual', 'video-text', 'pairs', ',', 'without', 'directly', 'optimizing', 'specific', 'task', 'sign', 'language', 'often', 'limited', 'size', '.', 'pretrain', 'signclip', 'spreadthesign', ',', 'prominent', 'sign', 'language', 'dictionary', 'consisting', '~500', 'thousand', 'video', 'clips', '44', 'sign', 'languages', ',', 'evaluate', 'various', 'downstream', 'datasets', '.', 'signclip', 'discerns', 'in-domain', 'signing', 'notable', 'text-to-video/video-to-text', 'retrieval', 'accuracy', '.', 'also', 'performs', 'competitively', 'out-of-domain', 'downstream', 'tasks', 'isolated', 'sign', 'language', 'recognition', 'upon', 'essential', 'few-shot', 'prompting', 'fine-tuning', '.', 'analyze', 'latent', 'space', 'formed', 'spoken', 'language', 'text', 'sign', 'language', 'poses', ',', 'provides', 'additional', 'linguistic', 'insights', '.', 'code', 'models', 'openly', 'available', '.']","present, signclip, ,, re-purposes, clip, (, contrastive, language-image, pretraining, ), project, spoken, language, text, sign, language, videos, ,, two, classes, natural, languages, distinct, modalities, ,, space, ., signclip, efficient, method, learning, useful, visual, representations, sign, language, processing, large-scale, ,, multilingual, video-text, pairs, ,, without, directly, optimizing, specific, task, sign, language, often, limited, size, ., pretrain, signclip, spreadthesign, ,, prominent, sign, language, dictionary, consisting, ~500, thousand, video, clips, 44, sign, languages, ,, evaluate, various, downstream, datasets, ., signclip, discerns, in-domain, signing, notable, text-to-video/video-to-text, retrieval, accuracy, ., also, performs, competitively, out-of-domain, downstream, tasks, isolated, sign, language, recognition, upon, essential, few-shot, prompting, fine-tuning, ., analyze, latent, space, formed, spoken, language, text, sign, language, poses, ,, provides, additional, linguistic, insights, ., code, models, openly, available, ."
"Make Up Your Mind! Adversarial Generation of Inconsistent Natural
  Language Explanations","Oana-Maria Camburu, Brendan Shillingford, Pasquale Minervini, Thomas Lukasiewicz, Phil Blunsom",2019-10-07T20:14:23Z,"  To increase trust in artificial intelligence systems, a promising research
direction consists of designing neural models capable of generating natural
language explanations for their predictions. In this work, we show that such
models are nonetheless prone to generating mutually inconsistent explanations,
such as ""Because there is a dog in the image"" and ""Because there is no dog in
the [same] image"", exposing flaws in either the decision-making process of the
model or in the generation of the explanations. We introduce a simple yet
effective adversarial framework for sanity checking models against the
generation of inconsistent natural language explanations. Moreover, as part of
the framework, we address the problem of adversarial attacks with full target
sequences, a scenario that was not previously addressed in sequence-to-sequence
attacks. Finally, we apply our framework on a state-of-the-art neural natural
language inference model that provides natural language explanations for its
predictions. Our framework shows that this model is capable of generating a
significant number of inconsistent explanations.
","['increase', 'trust', 'artificial', 'intelligence', 'systems', ',', 'promising', 'research', 'direction', 'consists', 'designing', 'neural', 'models', 'capable', 'generating', 'natural', 'language', 'explanations', 'predictions', '.', 'work', ',', 'show', 'models', 'nonetheless', 'prone', 'generating', 'mutually', 'inconsistent', 'explanations', ',', '``', 'dog', 'image', ""''"", '``', 'dog', '[', ']', 'image', ""''"", ',', 'exposing', 'flaws', 'either', 'decision-making', 'process', 'model', 'generation', 'explanations', '.', 'introduce', 'simple', 'yet', 'effective', 'adversarial', 'framework', 'sanity', 'checking', 'models', 'generation', 'inconsistent', 'natural', 'language', 'explanations', '.', 'moreover', ',', 'part', 'framework', ',', 'address', 'problem', 'adversarial', 'attacks', 'full', 'target', 'sequences', ',', 'scenario', 'previously', 'addressed', 'sequence-to-sequence', 'attacks', '.', 'finally', ',', 'apply', 'framework', 'state-of-the-art', 'neural', 'natural', 'language', 'inference', 'model', 'provides', 'natural', 'language', 'explanations', 'predictions', '.', 'framework', 'shows', 'model', 'capable', 'generating', 'significant', 'number', 'inconsistent', 'explanations', '.']","increase, trust, artificial, intelligence, systems, ,, promising, research, direction, consists, designing, neural, models, capable, generating, natural, language, explanations, predictions, ., work, ,, show, models, nonetheless, prone, generating, mutually, inconsistent, explanations, ,, ``, dog, image, '', ``, dog, [, ], image, '', ,, exposing, flaws, either, decision-making, process, model, generation, explanations, ., introduce, simple, yet, effective, adversarial, framework, sanity, checking, models, generation, inconsistent, natural, language, explanations, ., moreover, ,, part, framework, ,, address, problem, adversarial, attacks, full, target, sequences, ,, scenario, previously, addressed, sequence-to-sequence, attacks, ., finally, ,, apply, framework, state-of-the-art, neural, natural, language, inference, model, provides, natural, language, explanations, predictions, ., framework, shows, model, capable, generating, significant, number, inconsistent, explanations, ."
"xDBTagger: Explainable Natural Language Interface to Databases Using
  Keyword Mappings and Schema Graph","Arif Usta, Akifhan Karakayali, Özgür Ulusoy",2022-10-07T18:17:09Z,"  Translating natural language queries (NLQ) into structured query language
(SQL) in interfaces to relational databases is a challenging task that has been
widely studied by researchers from both the database and natural language
processing communities. Numerous works have been proposed to attack the natural
language interfaces to databases (NLIDB) problem either as a conventional
pipeline-based or an end-to-end deep-learning-based solution. Nevertheless,
regardless of the approach preferred, such solutions exhibit black-box nature,
which makes it difficult for potential users targeted by these systems to
comprehend the decisions made to produce the translated SQL. To this end, we
propose xDBTagger, an explainable hybrid translation pipeline that explains the
decisions made along the way to the user both textually and visually. We also
evaluate xDBTagger quantitatively in three real-world relational databases. The
evaluation results indicate that in addition to being fully interpretable,
xDBTagger is effective in terms of accuracy and translates the queries more
efficiently compared to other state-of-the-art pipeline-based systems up to
10000 times.
","['translating', 'natural', 'language', 'queries', '(', 'nlq', ')', 'structured', 'query', 'language', '(', 'sql', ')', 'interfaces', 'relational', 'databases', 'challenging', 'task', 'widely', 'studied', 'researchers', 'database', 'natural', 'language', 'processing', 'communities', '.', 'numerous', 'works', 'proposed', 'attack', 'natural', 'language', 'interfaces', 'databases', '(', 'nlidb', ')', 'problem', 'either', 'conventional', 'pipeline-based', 'end-to-end', 'deep-learning-based', 'solution', '.', 'nevertheless', ',', 'regardless', 'approach', 'preferred', ',', 'solutions', 'exhibit', 'black-box', 'nature', ',', 'makes', 'difficult', 'potential', 'users', 'targeted', 'systems', 'comprehend', 'decisions', 'made', 'produce', 'translated', 'sql', '.', 'end', ',', 'propose', 'xdbtagger', ',', 'explainable', 'hybrid', 'translation', 'pipeline', 'explains', 'decisions', 'made', 'along', 'way', 'user', 'textually', 'visually', '.', 'also', 'evaluate', 'xdbtagger', 'quantitatively', 'three', 'real-world', 'relational', 'databases', '.', 'evaluation', 'results', 'indicate', 'addition', 'fully', 'interpretable', ',', 'xdbtagger', 'effective', 'terms', 'accuracy', 'translates', 'queries', 'efficiently', 'compared', 'state-of-the-art', 'pipeline-based', 'systems', '10000', 'times', '.']","translating, natural, language, queries, (, nlq, ), structured, query, language, (, sql, ), interfaces, relational, databases, challenging, task, widely, studied, researchers, database, natural, language, processing, communities, ., numerous, works, proposed, attack, natural, language, interfaces, databases, (, nlidb, ), problem, either, conventional, pipeline-based, end-to-end, deep-learning-based, solution, ., nevertheless, ,, regardless, approach, preferred, ,, solutions, exhibit, black-box, nature, ,, makes, difficult, potential, users, targeted, systems, comprehend, decisions, made, produce, translated, sql, ., end, ,, propose, xdbtagger, ,, explainable, hybrid, translation, pipeline, explains, decisions, made, along, way, user, textually, visually, ., also, evaluate, xdbtagger, quantitatively, three, real-world, relational, databases, ., evaluation, results, indicate, addition, fully, interpretable, ,, xdbtagger, effective, terms, accuracy, translates, queries, efficiently, compared, state-of-the-art, pipeline-based, systems, 10000, times, ."
"Adapting general-purpose speech recognition engine output for
  domain-specific natural language question answering","C. Anantaram, Sunil Kumar Kopparapu",2017-10-12T12:18:16Z,"  Speech-based natural language question-answering interfaces to enterprise
systems are gaining a lot of attention. General-purpose speech engines can be
integrated with NLP systems to provide such interfaces. Usually,
general-purpose speech engines are trained on large `general' corpus. However,
when such engines are used for specific domains, they may not recognize
domain-specific words well, and may produce erroneous output. Further, the
accent and the environmental conditions in which the speaker speaks a sentence
may induce the speech engine to inaccurately recognize certain words. The
subsequent natural language question-answering does not produce the requisite
results as the question does not accurately represent what the speaker
intended. Thus, the speech engine's output may need to be adapted for a domain
before further natural language processing is carried out. We present two
mechanisms for such an adaptation, one based on evolutionary development and
the other based on machine learning, and show how we can repair the
speech-output to make the subsequent natural language question-answering
better.
","['speech-based', 'natural', 'language', 'question-answering', 'interfaces', 'enterprise', 'systems', 'gaining', 'lot', 'attention', '.', 'general-purpose', 'speech', 'engines', 'integrated', 'nlp', 'systems', 'provide', 'interfaces', '.', 'usually', ',', 'general-purpose', 'speech', 'engines', 'trained', 'large', '`', 'general', ""'"", 'corpus', '.', 'however', ',', 'engines', 'used', 'specific', 'domains', ',', 'may', 'recognize', 'domain-specific', 'words', 'well', ',', 'may', 'produce', 'erroneous', 'output', '.', ',', 'accent', 'environmental', 'conditions', 'speaker', 'speaks', 'sentence', 'may', 'induce', 'speech', 'engine', 'inaccurately', 'recognize', 'certain', 'words', '.', 'subsequent', 'natural', 'language', 'question-answering', 'produce', 'requisite', 'results', 'question', 'accurately', 'represent', 'speaker', 'intended', '.', 'thus', ',', 'speech', 'engine', ""'s"", 'output', 'may', 'need', 'adapted', 'domain', 'natural', 'language', 'processing', 'carried', '.', 'present', 'two', 'mechanisms', 'adaptation', ',', 'one', 'based', 'evolutionary', 'development', 'based', 'machine', 'learning', ',', 'show', 'repair', 'speech-output', 'make', 'subsequent', 'natural', 'language', 'question-answering', 'better', '.']","speech-based, natural, language, question-answering, interfaces, enterprise, systems, gaining, lot, attention, ., general-purpose, speech, engines, integrated, nlp, systems, provide, interfaces, ., usually, ,, general-purpose, speech, engines, trained, large, `, general, ', corpus, ., however, ,, engines, used, specific, domains, ,, may, recognize, domain-specific, words, well, ,, may, produce, erroneous, output, ., ,, accent, environmental, conditions, speaker, speaks, sentence, may, induce, speech, engine, inaccurately, recognize, certain, words, ., subsequent, natural, language, question-answering, produce, requisite, results, question, accurately, represent, speaker, intended, ., thus, ,, speech, engine, 's, output, may, need, adapted, domain, natural, language, processing, carried, ., present, two, mechanisms, adaptation, ,, one, based, evolutionary, development, based, machine, learning, ,, show, repair, speech-output, make, subsequent, natural, language, question-answering, better, ."
CLEVR-X: A Visual Reasoning Dataset for Natural Language Explanations,"Leonard Salewski, A. Sophia Koepke, Hendrik P. A. Lensch, Zeynep Akata",2022-04-05T17:38:04Z,"  Providing explanations in the context of Visual Question Answering (VQA)
presents a fundamental problem in machine learning. To obtain detailed insights
into the process of generating natural language explanations for VQA, we
introduce the large-scale CLEVR-X dataset that extends the CLEVR dataset with
natural language explanations. For each image-question pair in the CLEVR
dataset, CLEVR-X contains multiple structured textual explanations which are
derived from the original scene graphs. By construction, the CLEVR-X
explanations are correct and describe the reasoning and visual information that
is necessary to answer a given question. We conducted a user study to confirm
that the ground-truth explanations in our proposed dataset are indeed complete
and relevant. We present baseline results for generating natural language
explanations in the context of VQA using two state-of-the-art frameworks on the
CLEVR-X dataset. Furthermore, we provide a detailed analysis of the explanation
generation quality for different question and answer types. Additionally, we
study the influence of using different numbers of ground-truth explanations on
the convergence of natural language generation (NLG) metrics. The CLEVR-X
dataset is publicly available at
\url{https://explainableml.github.io/CLEVR-X/}.
","['providing', 'explanations', 'context', 'visual', 'question', 'answering', '(', 'vqa', ')', 'presents', 'fundamental', 'problem', 'machine', 'learning', '.', 'obtain', 'detailed', 'insights', 'process', 'generating', 'natural', 'language', 'explanations', 'vqa', ',', 'introduce', 'large-scale', 'clevr-x', 'dataset', 'extends', 'clevr', 'dataset', 'natural', 'language', 'explanations', '.', 'image-question', 'pair', 'clevr', 'dataset', ',', 'clevr-x', 'contains', 'multiple', 'structured', 'textual', 'explanations', 'derived', 'original', 'scene', 'graphs', '.', 'construction', ',', 'clevr-x', 'explanations', 'correct', 'describe', 'reasoning', 'visual', 'information', 'necessary', 'answer', 'given', 'question', '.', 'conducted', 'user', 'study', 'confirm', 'ground-truth', 'explanations', 'proposed', 'dataset', 'indeed', 'complete', 'relevant', '.', 'present', 'baseline', 'results', 'generating', 'natural', 'language', 'explanations', 'context', 'vqa', 'using', 'two', 'state-of-the-art', 'frameworks', 'clevr-x', 'dataset', '.', 'furthermore', ',', 'provide', 'detailed', 'analysis', 'explanation', 'generation', 'quality', 'different', 'question', 'answer', 'types', '.', 'additionally', ',', 'study', 'influence', 'using', 'different', 'numbers', 'ground-truth', 'explanations', 'convergence', 'natural', 'language', 'generation', '(', 'nlg', ')', 'metrics', '.', 'clevr-x', 'dataset', 'publicly', 'available', '\\url', '{', 'https', ':', '//explainableml.github.io/clevr-x/', '}', '.']","providing, explanations, context, visual, question, answering, (, vqa, ), presents, fundamental, problem, machine, learning, ., obtain, detailed, insights, process, generating, natural, language, explanations, vqa, ,, introduce, large-scale, clevr-x, dataset, extends, clevr, dataset, natural, language, explanations, ., image-question, pair, clevr, dataset, ,, clevr-x, contains, multiple, structured, textual, explanations, derived, original, scene, graphs, ., construction, ,, clevr-x, explanations, correct, describe, reasoning, visual, information, necessary, answer, given, question, ., conducted, user, study, confirm, ground-truth, explanations, proposed, dataset, indeed, complete, relevant, ., present, baseline, results, generating, natural, language, explanations, context, vqa, using, two, state-of-the-art, frameworks, clevr-x, dataset, ., furthermore, ,, provide, detailed, analysis, explanation, generation, quality, different, question, answer, types, ., additionally, ,, study, influence, using, different, numbers, ground-truth, explanations, convergence, natural, language, generation, (, nlg, ), metrics, ., clevr-x, dataset, publicly, available, \url, {, https, :, //explainableml.github.io/clevr-x/, }, ."
"A Model of Anaphoric Ambiguities using Sheaf Theoretic Quantum-like
  Contextuality and BERT","Kin Ian Lo, Mehrnoosh Sadrzadeh, Shane Mansfield",2022-08-11T09:31:15Z,"  Ambiguities of natural language do not preclude us from using it and context
helps in getting ideas across. They, nonetheless, pose a key challenge to the
development of competent machines to understand natural language and use it as
humans do. Contextuality is an unparalleled phenomenon in quantum mechanics,
where different mathematical formalisms have been put forwards to understand
and reason about it. In this paper, we construct a schema for anaphoric
ambiguities that exhibits quantum-like contextuality. We use a recently
developed criterion of sheaf-theoretic contextuality that is applicable to
signalling models. We then take advantage of the neural word embedding engine
BERT to instantiate the schema to natural language examples and extract
probability distributions for the instances. As a result, plenty of
sheaf-contextual examples were discovered in the natural language corpora BERT
utilises. Our hope is that these examples will pave the way for future research
and for finding ways to extend applications of quantum computing to natural
language processing.
","['ambiguities', 'natural', 'language', 'preclude', 'us', 'using', 'context', 'helps', 'getting', 'ideas', 'across', '.', ',', 'nonetheless', ',', 'pose', 'key', 'challenge', 'development', 'competent', 'machines', 'understand', 'natural', 'language', 'use', 'humans', '.', 'contextuality', 'unparalleled', 'phenomenon', 'quantum', 'mechanics', ',', 'different', 'mathematical', 'formalisms', 'put', 'forwards', 'understand', 'reason', '.', 'paper', ',', 'construct', 'schema', 'anaphoric', 'ambiguities', 'exhibits', 'quantum-like', 'contextuality', '.', 'use', 'recently', 'developed', 'criterion', 'sheaf-theoretic', 'contextuality', 'applicable', 'signalling', 'models', '.', 'take', 'advantage', 'neural', 'word', 'embedding', 'engine', 'bert', 'instantiate', 'schema', 'natural', 'language', 'examples', 'extract', 'probability', 'distributions', 'instances', '.', 'result', ',', 'plenty', 'sheaf-contextual', 'examples', 'discovered', 'natural', 'language', 'corpora', 'bert', 'utilises', '.', 'hope', 'examples', 'pave', 'way', 'future', 'research', 'finding', 'ways', 'extend', 'applications', 'quantum', 'computing', 'natural', 'language', 'processing', '.']","ambiguities, natural, language, preclude, us, using, context, helps, getting, ideas, across, ., ,, nonetheless, ,, pose, key, challenge, development, competent, machines, understand, natural, language, use, humans, ., contextuality, unparalleled, phenomenon, quantum, mechanics, ,, different, mathematical, formalisms, put, forwards, understand, reason, ., paper, ,, construct, schema, anaphoric, ambiguities, exhibits, quantum-like, contextuality, ., use, recently, developed, criterion, sheaf-theoretic, contextuality, applicable, signalling, models, ., take, advantage, neural, word, embedding, engine, bert, instantiate, schema, natural, language, examples, extract, probability, distributions, instances, ., result, ,, plenty, sheaf-contextual, examples, discovered, natural, language, corpora, bert, utilises, ., hope, examples, pave, way, future, research, finding, ways, extend, applications, quantum, computing, natural, language, processing, ."
"Generating Valid and Natural Adversarial Examples with Large Language
  Models","Zimu Wang, Wei Wang, Qi Chen, Qiufeng Wang, Anh Nguyen",2023-11-20T15:57:04Z,"  Deep learning-based natural language processing (NLP) models, particularly
pre-trained language models (PLMs), have been revealed to be vulnerable to
adversarial attacks. However, the adversarial examples generated by many
mainstream word-level adversarial attack models are neither valid nor natural,
leading to the loss of semantic maintenance, grammaticality, and human
imperceptibility. Based on the exceptional capacity of language understanding
and generation of large language models (LLMs), we propose LLM-Attack, which
aims at generating both valid and natural adversarial examples with LLMs. The
method consists of two stages: word importance ranking (which searches for the
most vulnerable words) and word synonym replacement (which substitutes them
with their synonyms obtained from LLMs). Experimental results on the Movie
Review (MR), IMDB, and Yelp Review Polarity datasets against the baseline
adversarial attack models illustrate the effectiveness of LLM-Attack, and it
outperforms the baselines in human and GPT-4 evaluation by a significant
margin. The model can generate adversarial examples that are typically valid
and natural, with the preservation of semantic meaning, grammaticality, and
human imperceptibility.
","['deep', 'learning-based', 'natural', 'language', 'processing', '(', 'nlp', ')', 'models', ',', 'particularly', 'pre-trained', 'language', 'models', '(', 'plms', ')', ',', 'revealed', 'vulnerable', 'adversarial', 'attacks', '.', 'however', ',', 'adversarial', 'examples', 'generated', 'many', 'mainstream', 'word-level', 'adversarial', 'attack', 'models', 'neither', 'valid', 'natural', ',', 'leading', 'loss', 'semantic', 'maintenance', ',', 'grammaticality', ',', 'human', 'imperceptibility', '.', 'based', 'exceptional', 'capacity', 'language', 'understanding', 'generation', 'large', 'language', 'models', '(', 'llms', ')', ',', 'propose', 'llm-attack', ',', 'aims', 'generating', 'valid', 'natural', 'adversarial', 'examples', 'llms', '.', 'method', 'consists', 'two', 'stages', ':', 'word', 'importance', 'ranking', '(', 'searches', 'vulnerable', 'words', ')', 'word', 'synonym', 'replacement', '(', 'substitutes', 'synonyms', 'obtained', 'llms', ')', '.', 'experimental', 'results', 'movie', 'review', '(', 'mr', ')', ',', 'imdb', ',', 'yelp', 'review', 'polarity', 'datasets', 'baseline', 'adversarial', 'attack', 'models', 'illustrate', 'effectiveness', 'llm-attack', ',', 'outperforms', 'baselines', 'human', 'gpt-4', 'evaluation', 'significant', 'margin', '.', 'model', 'generate', 'adversarial', 'examples', 'typically', 'valid', 'natural', ',', 'preservation', 'semantic', 'meaning', ',', 'grammaticality', ',', 'human', 'imperceptibility', '.']","deep, learning-based, natural, language, processing, (, nlp, ), models, ,, particularly, pre-trained, language, models, (, plms, ), ,, revealed, vulnerable, adversarial, attacks, ., however, ,, adversarial, examples, generated, many, mainstream, word-level, adversarial, attack, models, neither, valid, natural, ,, leading, loss, semantic, maintenance, ,, grammaticality, ,, human, imperceptibility, ., based, exceptional, capacity, language, understanding, generation, large, language, models, (, llms, ), ,, propose, llm-attack, ,, aims, generating, valid, natural, adversarial, examples, llms, ., method, consists, two, stages, :, word, importance, ranking, (, searches, vulnerable, words, ), word, synonym, replacement, (, substitutes, synonyms, obtained, llms, ), ., experimental, results, movie, review, (, mr, ), ,, imdb, ,, yelp, review, polarity, datasets, baseline, adversarial, attack, models, illustrate, effectiveness, llm-attack, ,, outperforms, baselines, human, gpt-4, evaluation, significant, margin, ., model, generate, adversarial, examples, typically, valid, natural, ,, preservation, semantic, meaning, ,, grammaticality, ,, human, imperceptibility, ."
"Insights into Natural Language Database Query Errors: From Attention
  Misalignment to User Handling Strategies","Zheng Ning, Yuan Tian, Zheng Zhang, Tianyi Zhang, Toby Li",2024-02-11T20:52:29Z,"  Querying structured databases with natural language (NL2SQL) has remained a
difficult problem for years. Recently, the advancement of machine learning
(ML), natural language processing (NLP), and large language models (LLM) have
led to significant improvements in performance, with the best model achieving
~85% percent accuracy on the benchmark Spider dataset. However, there is a lack
of a systematic understanding of the types, causes, and effectiveness of
error-handling mechanisms of errors for erroneous queries nowadays. To bridge
the gap, a taxonomy of errors made by four representative NL2SQL models was
built in this work, along with an in-depth analysis of the errors. Second, the
causes of model errors were explored by analyzing the model-human attention
alignment to the natural language query. Last, a within-subjects user study
with 26 participants was conducted to investigate the effectiveness of three
interactive error-handling mechanisms in NL2SQL. Findings from this paper shed
light on the design of model structure and error discovery and repair
strategies for natural language data query interfaces in the future.
","['querying', 'structured', 'databases', 'natural', 'language', '(', 'nl2sql', ')', 'remained', 'difficult', 'problem', 'years', '.', 'recently', ',', 'advancement', 'machine', 'learning', '(', 'ml', ')', ',', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'large', 'language', 'models', '(', 'llm', ')', 'led', 'significant', 'improvements', 'performance', ',', 'best', 'model', 'achieving', '~85', '%', 'percent', 'accuracy', 'benchmark', 'spider', 'dataset', '.', 'however', ',', 'lack', 'systematic', 'understanding', 'types', ',', 'causes', ',', 'effectiveness', 'error-handling', 'mechanisms', 'errors', 'erroneous', 'queries', 'nowadays', '.', 'bridge', 'gap', ',', 'taxonomy', 'errors', 'made', 'four', 'representative', 'nl2sql', 'models', 'built', 'work', ',', 'along', 'in-depth', 'analysis', 'errors', '.', 'second', ',', 'causes', 'model', 'errors', 'explored', 'analyzing', 'model-human', 'attention', 'alignment', 'natural', 'language', 'query', '.', 'last', ',', 'within-subjects', 'user', 'study', '26', 'participants', 'conducted', 'investigate', 'effectiveness', 'three', 'interactive', 'error-handling', 'mechanisms', 'nl2sql', '.', 'findings', 'paper', 'shed', 'light', 'design', 'model', 'structure', 'error', 'discovery', 'repair', 'strategies', 'natural', 'language', 'data', 'query', 'interfaces', 'future', '.']","querying, structured, databases, natural, language, (, nl2sql, ), remained, difficult, problem, years, ., recently, ,, advancement, machine, learning, (, ml, ), ,, natural, language, processing, (, nlp, ), ,, large, language, models, (, llm, ), led, significant, improvements, performance, ,, best, model, achieving, ~85, %, percent, accuracy, benchmark, spider, dataset, ., however, ,, lack, systematic, understanding, types, ,, causes, ,, effectiveness, error-handling, mechanisms, errors, erroneous, queries, nowadays, ., bridge, gap, ,, taxonomy, errors, made, four, representative, nl2sql, models, built, work, ,, along, in-depth, analysis, errors, ., second, ,, causes, model, errors, explored, analyzing, model-human, attention, alignment, natural, language, query, ., last, ,, within-subjects, user, study, 26, participants, conducted, investigate, effectiveness, three, interactive, error-handling, mechanisms, nl2sql, ., findings, paper, shed, light, design, model, structure, error, discovery, repair, strategies, natural, language, data, query, interfaces, future, ."
Natural Language Processing for Dialects of a Language: A Survey,"Aditya Joshi, Raj Dabre, Diptesh Kanojia, Zhuang Li, Haolan Zhan, Gholamreza Haffari, Doris Dippold",2024-01-11T03:04:38Z,"  State-of-the-art natural language processing (NLP) models are trained on
massive training corpora, and report a superlative performance on evaluation
datasets. This survey delves into an important attribute of these datasets: the
dialect of a language. Motivated by the performance degradation of NLP models
for dialectic datasets and its implications for the equity of language
technologies, we survey past research in NLP for dialects in terms of datasets,
and approaches. We describe a wide range of NLP tasks in terms of two
categories: natural language understanding (NLU) (for tasks such as dialect
classification, sentiment analysis, parsing, and NLU benchmarks) and natural
language generation (NLG) (for summarisation, machine translation, and dialogue
systems). The survey is also broad in its coverage of languages which include
English, Arabic, German among others. We observe that past work in NLP
concerning dialects goes deeper than mere dialect classification, and . This
includes early approaches that used sentence transduction that lead to the
recent approaches that integrate hypernetworks into LoRA. We expect that this
survey will be useful to NLP researchers interested in building equitable
language technologies by rethinking LLM benchmarks and model architectures.
","['state-of-the-art', 'natural', 'language', 'processing', '(', 'nlp', ')', 'models', 'trained', 'massive', 'training', 'corpora', ',', 'report', 'superlative', 'performance', 'evaluation', 'datasets', '.', 'survey', 'delves', 'important', 'attribute', 'datasets', ':', 'dialect', 'language', '.', 'motivated', 'performance', 'degradation', 'nlp', 'models', 'dialectic', 'datasets', 'implications', 'equity', 'language', 'technologies', ',', 'survey', 'past', 'research', 'nlp', 'dialects', 'terms', 'datasets', ',', 'approaches', '.', 'describe', 'wide', 'range', 'nlp', 'tasks', 'terms', 'two', 'categories', ':', 'natural', 'language', 'understanding', '(', 'nlu', ')', '(', 'tasks', 'dialect', 'classification', ',', 'sentiment', 'analysis', ',', 'parsing', ',', 'nlu', 'benchmarks', ')', 'natural', 'language', 'generation', '(', 'nlg', ')', '(', 'summarisation', ',', 'machine', 'translation', ',', 'dialogue', 'systems', ')', '.', 'survey', 'also', 'broad', 'coverage', 'languages', 'include', 'english', ',', 'arabic', ',', 'german', 'among', 'others', '.', 'observe', 'past', 'work', 'nlp', 'concerning', 'dialects', 'goes', 'deeper', 'mere', 'dialect', 'classification', ',', '.', 'includes', 'early', 'approaches', 'used', 'sentence', 'transduction', 'lead', 'recent', 'approaches', 'integrate', 'hypernetworks', 'lora', '.', 'expect', 'survey', 'useful', 'nlp', 'researchers', 'interested', 'building', 'equitable', 'language', 'technologies', 'rethinking', 'llm', 'benchmarks', 'model', 'architectures', '.']","state-of-the-art, natural, language, processing, (, nlp, ), models, trained, massive, training, corpora, ,, report, superlative, performance, evaluation, datasets, ., survey, delves, important, attribute, datasets, :, dialect, language, ., motivated, performance, degradation, nlp, models, dialectic, datasets, implications, equity, language, technologies, ,, survey, past, research, nlp, dialects, terms, datasets, ,, approaches, ., describe, wide, range, nlp, tasks, terms, two, categories, :, natural, language, understanding, (, nlu, ), (, tasks, dialect, classification, ,, sentiment, analysis, ,, parsing, ,, nlu, benchmarks, ), natural, language, generation, (, nlg, ), (, summarisation, ,, machine, translation, ,, dialogue, systems, ), ., survey, also, broad, coverage, languages, include, english, ,, arabic, ,, german, among, others, ., observe, past, work, nlp, concerning, dialects, goes, deeper, mere, dialect, classification, ,, ., includes, early, approaches, used, sentence, transduction, lead, recent, approaches, integrate, hypernetworks, lora, ., expect, survey, useful, nlp, researchers, interested, building, equitable, language, technologies, rethinking, llm, benchmarks, model, architectures, ."
"The neural correlates of logical-mathematical symbol systems processing
  resemble that of spatial cognition more than natural language processing","Yuannan Li, Shan Xu, Jia Liu",2024-06-20T14:31:09Z,"  The ability to manipulate logical-mathematical symbols (LMS), encompassing
tasks such as calculation, reasoning, and programming, is a cognitive skill
arguably unique to humans. Considering the relatively recent emergence of this
ability in human evolutionary history, it has been suggested that LMS
processing may build upon more fundamental cognitive systems, possibly through
neuronal recycling. Previous studies have pinpointed two primary candidates,
natural language processing and spatial cognition. Existing comparisons between
these domains largely relied on task-level comparison, which may be confounded
by task idiosyncrasy. The present study instead compared the neural correlates
at the domain level with both automated meta-analysis and synthesized maps
based on three representative LMS tasks, reasoning, calculation, and mental
programming. Our results revealed a more substantial cortical overlap between
LMS processing and spatial cognition, in contrast to language processing.
Furthermore, in regions activated by both spatial and language processing, the
multivariate activation pattern for LMS processing exhibited greater
multivariate similarity to spatial cognition than to language processing. A
hierarchical clustering analysis further indicated that typical LMS tasks were
indistinguishable from spatial cognition tasks at the neural level, suggesting
an inherent connection between these two cognitive processes. Taken together,
our findings support the hypothesis that spatial cognition is likely the basis
of LMS processing, which may shed light on the limitations of large language
models in logical reasoning, particularly those trained exclusively on textual
data without explicit emphasis on spatial content.
","['ability', 'manipulate', 'logical-mathematical', 'symbols', '(', 'lms', ')', ',', 'encompassing', 'tasks', 'calculation', ',', 'reasoning', ',', 'programming', ',', 'cognitive', 'skill', 'arguably', 'unique', 'humans', '.', 'considering', 'relatively', 'recent', 'emergence', 'ability', 'human', 'evolutionary', 'history', ',', 'suggested', 'lms', 'processing', 'may', 'build', 'upon', 'fundamental', 'cognitive', 'systems', ',', 'possibly', 'neuronal', 'recycling', '.', 'previous', 'studies', 'pinpointed', 'two', 'primary', 'candidates', ',', 'natural', 'language', 'processing', 'spatial', 'cognition', '.', 'existing', 'comparisons', 'domains', 'largely', 'relied', 'task-level', 'comparison', ',', 'may', 'confounded', 'task', 'idiosyncrasy', '.', 'present', 'study', 'instead', 'compared', 'neural', 'correlates', 'domain', 'level', 'automated', 'meta-analysis', 'synthesized', 'maps', 'based', 'three', 'representative', 'lms', 'tasks', ',', 'reasoning', ',', 'calculation', ',', 'mental', 'programming', '.', 'results', 'revealed', 'substantial', 'cortical', 'overlap', 'lms', 'processing', 'spatial', 'cognition', ',', 'contrast', 'language', 'processing', '.', 'furthermore', ',', 'regions', 'activated', 'spatial', 'language', 'processing', ',', 'multivariate', 'activation', 'pattern', 'lms', 'processing', 'exhibited', 'greater', 'multivariate', 'similarity', 'spatial', 'cognition', 'language', 'processing', '.', 'hierarchical', 'clustering', 'analysis', 'indicated', 'typical', 'lms', 'tasks', 'indistinguishable', 'spatial', 'cognition', 'tasks', 'neural', 'level', ',', 'suggesting', 'inherent', 'connection', 'two', 'cognitive', 'processes', '.', 'taken', 'together', ',', 'findings', 'support', 'hypothesis', 'spatial', 'cognition', 'likely', 'basis', 'lms', 'processing', ',', 'may', 'shed', 'light', 'limitations', 'large', 'language', 'models', 'logical', 'reasoning', ',', 'particularly', 'trained', 'exclusively', 'textual', 'data', 'without', 'explicit', 'emphasis', 'spatial', 'content', '.']","ability, manipulate, logical-mathematical, symbols, (, lms, ), ,, encompassing, tasks, calculation, ,, reasoning, ,, programming, ,, cognitive, skill, arguably, unique, humans, ., considering, relatively, recent, emergence, ability, human, evolutionary, history, ,, suggested, lms, processing, may, build, upon, fundamental, cognitive, systems, ,, possibly, neuronal, recycling, ., previous, studies, pinpointed, two, primary, candidates, ,, natural, language, processing, spatial, cognition, ., existing, comparisons, domains, largely, relied, task-level, comparison, ,, may, confounded, task, idiosyncrasy, ., present, study, instead, compared, neural, correlates, domain, level, automated, meta-analysis, synthesized, maps, based, three, representative, lms, tasks, ,, reasoning, ,, calculation, ,, mental, programming, ., results, revealed, substantial, cortical, overlap, lms, processing, spatial, cognition, ,, contrast, language, processing, ., furthermore, ,, regions, activated, spatial, language, processing, ,, multivariate, activation, pattern, lms, processing, exhibited, greater, multivariate, similarity, spatial, cognition, language, processing, ., hierarchical, clustering, analysis, indicated, typical, lms, tasks, indistinguishable, spatial, cognition, tasks, neural, level, ,, suggesting, inherent, connection, two, cognitive, processes, ., taken, together, ,, findings, support, hypothesis, spatial, cognition, likely, basis, lms, processing, ,, may, shed, light, limitations, large, language, models, logical, reasoning, ,, particularly, trained, exclusively, textual, data, without, explicit, emphasis, spatial, content, ."
Visualization Generation with Large Language Models: An Evaluation,"Guozheng Li, Xinyu Wang, Gerile Aodeng, Shunyuan Zheng, Yu Zhang, Chuangxin Ou, Song Wang, Chi Harold Liu",2024-01-20T15:28:22Z,"  Analysts frequently need to create visualizations in the data analysis
process to obtain and communicate insights. To reduce the burden of creating
visualizations, previous research has developed various approaches for analysts
to create visualizations from natural language queries. Recent studies have
demonstrated the capabilities of large language models in natural language
understanding and code generation tasks. The capabilities imply the potential
of using large language models to generate visualization specifications from
natural language queries. In this paper, we evaluate the capability of a large
language model to generate visualization specifications on the task of natural
language to visualization (NL2VIS). More specifically, we have opted for
GPT-3.5 and Vega-Lite to represent large language models and visualization
specifications, respectively. The evaluation is conducted on the nvBench
dataset. In the evaluation, we utilize both zero-shot and few-shot prompt
strategies. The results demonstrate that GPT-3.5 surpasses previous NL2VIS
approaches. Additionally, the performance of few-shot prompts is higher than
that of zero-shot prompts. We discuss the limitations of GPT-3.5 on NL2VIS,
such as misunderstanding the data attributes and grammar errors in generated
specifications. We also summarized several directions, such as correcting the
ground truth and reducing the ambiguities in natural language queries, to
improve the NL2VIS benchmark.
","['analysts', 'frequently', 'need', 'create', 'visualizations', 'data', 'analysis', 'process', 'obtain', 'communicate', 'insights', '.', 'reduce', 'burden', 'creating', 'visualizations', ',', 'previous', 'research', 'developed', 'various', 'approaches', 'analysts', 'create', 'visualizations', 'natural', 'language', 'queries', '.', 'recent', 'studies', 'demonstrated', 'capabilities', 'large', 'language', 'models', 'natural', 'language', 'understanding', 'code', 'generation', 'tasks', '.', 'capabilities', 'imply', 'potential', 'using', 'large', 'language', 'models', 'generate', 'visualization', 'specifications', 'natural', 'language', 'queries', '.', 'paper', ',', 'evaluate', 'capability', 'large', 'language', 'model', 'generate', 'visualization', 'specifications', 'task', 'natural', 'language', 'visualization', '(', 'nl2vis', ')', '.', 'specifically', ',', 'opted', 'gpt-3.5', 'vega-lite', 'represent', 'large', 'language', 'models', 'visualization', 'specifications', ',', 'respectively', '.', 'evaluation', 'conducted', 'nvbench', 'dataset', '.', 'evaluation', ',', 'utilize', 'zero-shot', 'few-shot', 'prompt', 'strategies', '.', 'results', 'demonstrate', 'gpt-3.5', 'surpasses', 'previous', 'nl2vis', 'approaches', '.', 'additionally', ',', 'performance', 'few-shot', 'prompts', 'higher', 'zero-shot', 'prompts', '.', 'discuss', 'limitations', 'gpt-3.5', 'nl2vis', ',', 'misunderstanding', 'data', 'attributes', 'grammar', 'errors', 'generated', 'specifications', '.', 'also', 'summarized', 'several', 'directions', ',', 'correcting', 'ground', 'truth', 'reducing', 'ambiguities', 'natural', 'language', 'queries', ',', 'improve', 'nl2vis', 'benchmark', '.']","analysts, frequently, need, create, visualizations, data, analysis, process, obtain, communicate, insights, ., reduce, burden, creating, visualizations, ,, previous, research, developed, various, approaches, analysts, create, visualizations, natural, language, queries, ., recent, studies, demonstrated, capabilities, large, language, models, natural, language, understanding, code, generation, tasks, ., capabilities, imply, potential, using, large, language, models, generate, visualization, specifications, natural, language, queries, ., paper, ,, evaluate, capability, large, language, model, generate, visualization, specifications, task, natural, language, visualization, (, nl2vis, ), ., specifically, ,, opted, gpt-3.5, vega-lite, represent, large, language, models, visualization, specifications, ,, respectively, ., evaluation, conducted, nvbench, dataset, ., evaluation, ,, utilize, zero-shot, few-shot, prompt, strategies, ., results, demonstrate, gpt-3.5, surpasses, previous, nl2vis, approaches, ., additionally, ,, performance, few-shot, prompts, higher, zero-shot, prompts, ., discuss, limitations, gpt-3.5, nl2vis, ,, misunderstanding, data, attributes, grammar, errors, generated, specifications, ., also, summarized, several, directions, ,, correcting, ground, truth, reducing, ambiguities, natural, language, queries, ,, improve, nl2vis, benchmark, ."
"A Novel Patent Similarity Measurement Methodology: Semantic Distance and
  Technological Distance","Yongmin Yoo, Cheonkam Jeong, Sanguk Gim, Junwon Lee, Zachary Schimke, Deaho Seo",2023-03-23T07:55:31Z,"  Patent similarity analysis plays a crucial role in evaluating the risk of
patent infringement. Nonetheless, this analysis is predominantly conducted
manually by legal experts, often resulting in a time-consuming process. Recent
advances in natural language processing technology offer a promising avenue for
automating this process. However, methods for measuring similarity between
patents still rely on experts manually classifying patents. Due to the recent
development of artificial intelligence technology, a lot of research is being
conducted focusing on the semantic similarity of patents using natural language
processing technology. However, it is difficult to accurately analyze patent
data, which are legal documents representing complex technologies, using
existing natural language processing technologies. To address these
limitations, we propose a hybrid methodology that takes into account
bibliographic similarity, measures the similarity between patents by
considering the semantic similarity of patents, the technical similarity
between patents, and the bibliographic information of patents. Using natural
language processing techniques, we measure semantic similarity based on patent
text and calculate technical similarity through the degree of coexistence of
International patent classification (IPC) codes. The similarity of
bibliographic information of a patent is calculated using the special
characteristics of the patent: citation information, inventor information, and
assignee information. We propose a model that assigns reasonable weights to
each similarity method considered. With the help of experts, we performed
manual similarity evaluations on 420 pairs and evaluated the performance of our
model based on this data. We have empirically shown that our method outperforms
recent natural language processing techniques.
","['patent', 'similarity', 'analysis', 'plays', 'crucial', 'role', 'evaluating', 'risk', 'patent', 'infringement', '.', 'nonetheless', ',', 'analysis', 'predominantly', 'conducted', 'manually', 'legal', 'experts', ',', 'often', 'resulting', 'time-consuming', 'process', '.', 'recent', 'advances', 'natural', 'language', 'processing', 'technology', 'offer', 'promising', 'avenue', 'automating', 'process', '.', 'however', ',', 'methods', 'measuring', 'similarity', 'patents', 'still', 'rely', 'experts', 'manually', 'classifying', 'patents', '.', 'due', 'recent', 'development', 'artificial', 'intelligence', 'technology', ',', 'lot', 'research', 'conducted', 'focusing', 'semantic', 'similarity', 'patents', 'using', 'natural', 'language', 'processing', 'technology', '.', 'however', ',', 'difficult', 'accurately', 'analyze', 'patent', 'data', ',', 'legal', 'documents', 'representing', 'complex', 'technologies', ',', 'using', 'existing', 'natural', 'language', 'processing', 'technologies', '.', 'address', 'limitations', ',', 'propose', 'hybrid', 'methodology', 'takes', 'account', 'bibliographic', 'similarity', ',', 'measures', 'similarity', 'patents', 'considering', 'semantic', 'similarity', 'patents', ',', 'technical', 'similarity', 'patents', ',', 'bibliographic', 'information', 'patents', '.', 'using', 'natural', 'language', 'processing', 'techniques', ',', 'measure', 'semantic', 'similarity', 'based', 'patent', 'text', 'calculate', 'technical', 'similarity', 'degree', 'coexistence', 'international', 'patent', 'classification', '(', 'ipc', ')', 'codes', '.', 'similarity', 'bibliographic', 'information', 'patent', 'calculated', 'using', 'special', 'characteristics', 'patent', ':', 'citation', 'information', ',', 'inventor', 'information', ',', 'assignee', 'information', '.', 'propose', 'model', 'assigns', 'reasonable', 'weights', 'similarity', 'method', 'considered', '.', 'help', 'experts', ',', 'performed', 'manual', 'similarity', 'evaluations', '420', 'pairs', 'evaluated', 'performance', 'model', 'based', 'data', '.', 'empirically', 'shown', 'method', 'outperforms', 'recent', 'natural', 'language', 'processing', 'techniques', '.']","patent, similarity, analysis, plays, crucial, role, evaluating, risk, patent, infringement, ., nonetheless, ,, analysis, predominantly, conducted, manually, legal, experts, ,, often, resulting, time-consuming, process, ., recent, advances, natural, language, processing, technology, offer, promising, avenue, automating, process, ., however, ,, methods, measuring, similarity, patents, still, rely, experts, manually, classifying, patents, ., due, recent, development, artificial, intelligence, technology, ,, lot, research, conducted, focusing, semantic, similarity, patents, using, natural, language, processing, technology, ., however, ,, difficult, accurately, analyze, patent, data, ,, legal, documents, representing, complex, technologies, ,, using, existing, natural, language, processing, technologies, ., address, limitations, ,, propose, hybrid, methodology, takes, account, bibliographic, similarity, ,, measures, similarity, patents, considering, semantic, similarity, patents, ,, technical, similarity, patents, ,, bibliographic, information, patents, ., using, natural, language, processing, techniques, ,, measure, semantic, similarity, based, patent, text, calculate, technical, similarity, degree, coexistence, international, patent, classification, (, ipc, ), codes, ., similarity, bibliographic, information, patent, calculated, using, special, characteristics, patent, :, citation, information, ,, inventor, information, ,, assignee, information, ., propose, model, assigns, reasonable, weights, similarity, method, considered, ., help, experts, ,, performed, manual, similarity, evaluations, 420, pairs, evaluated, performance, model, based, data, ., empirically, shown, method, outperforms, recent, natural, language, processing, techniques, ."
"Temporal Video-Language Alignment Network for Reward Shaping in
  Reinforcement Learning","Ziyuan Cao, Reshma Anugundanahalli Ramachandra, Kelin Yu",2023-02-08T09:25:21Z,"  Designing appropriate reward functions for Reinforcement Learning (RL)
approaches has been a significant problem, especially for complex environments
such as Atari games. Utilizing natural language instructions to provide
intermediate rewards to RL agents in a process known as reward shaping can help
the agent in reaching the goal state faster. In this work, we propose a natural
language-based reward shaping approach that maps trajectories from the
Montezuma's Revenge game environment to corresponding natural language
instructions using an extension of the LanguagE-Action Reward Network (LEARN)
framework. These trajectory-language mappings are further used to generate
intermediate rewards which are integrated into reward functions that can be
utilized to learn an optimal policy for any standard RL algorithms. For a set
of 15 tasks from Atari's Montezuma's Revenge game, the Ext-LEARN approach leads
to the successful completion of tasks more often on average than the reward
shaping approach that uses the LEARN framework and performs even better than
the reward shaping framework without natural language-based rewards.
","['designing', 'appropriate', 'reward', 'functions', 'reinforcement', 'learning', '(', 'rl', ')', 'approaches', 'significant', 'problem', ',', 'especially', 'complex', 'environments', 'atari', 'games', '.', 'utilizing', 'natural', 'language', 'instructions', 'provide', 'intermediate', 'rewards', 'rl', 'agents', 'process', 'known', 'reward', 'shaping', 'help', 'agent', 'reaching', 'goal', 'state', 'faster', '.', 'work', ',', 'propose', 'natural', 'language-based', 'reward', 'shaping', 'approach', 'maps', 'trajectories', 'montezuma', ""'s"", 'revenge', 'game', 'environment', 'corresponding', 'natural', 'language', 'instructions', 'using', 'extension', 'language-action', 'reward', 'network', '(', 'learn', ')', 'framework', '.', 'trajectory-language', 'mappings', 'used', 'generate', 'intermediate', 'rewards', 'integrated', 'reward', 'functions', 'utilized', 'learn', 'optimal', 'policy', 'standard', 'rl', 'algorithms', '.', 'set', '15', 'tasks', 'atari', ""'s"", 'montezuma', ""'s"", 'revenge', 'game', ',', 'ext-learn', 'approach', 'leads', 'successful', 'completion', 'tasks', 'often', 'average', 'reward', 'shaping', 'approach', 'uses', 'learn', 'framework', 'performs', 'even', 'better', 'reward', 'shaping', 'framework', 'without', 'natural', 'language-based', 'rewards', '.']","designing, appropriate, reward, functions, reinforcement, learning, (, rl, ), approaches, significant, problem, ,, especially, complex, environments, atari, games, ., utilizing, natural, language, instructions, provide, intermediate, rewards, rl, agents, process, known, reward, shaping, help, agent, reaching, goal, state, faster, ., work, ,, propose, natural, language-based, reward, shaping, approach, maps, trajectories, montezuma, 's, revenge, game, environment, corresponding, natural, language, instructions, using, extension, language-action, reward, network, (, learn, ), framework, ., trajectory-language, mappings, used, generate, intermediate, rewards, integrated, reward, functions, utilized, learn, optimal, policy, standard, rl, algorithms, ., set, 15, tasks, atari, 's, montezuma, 's, revenge, game, ,, ext-learn, approach, leads, successful, completion, tasks, often, average, reward, shaping, approach, uses, learn, framework, performs, even, better, reward, shaping, framework, without, natural, language-based, rewards, ."
"IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe
  Biomedical Natural Language Inference for Clinical Trials","Shreyasi Mandal, Ashutosh Modi",2024-04-06T05:44:53Z,"  Large Language models (LLMs) have demonstrated state-of-the-art performance
in various natural language processing (NLP) tasks across multiple domains, yet
they are prone to shortcut learning and factual inconsistencies. This research
investigates LLMs' robustness, consistency, and faithful reasoning when
performing Natural Language Inference (NLI) on breast cancer Clinical Trial
Reports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical Natural
Language Inference for Clinical Trials. We examine the reasoning capabilities
of LLMs and their adeptness at logical problem-solving. A comparative analysis
is conducted on pre-trained language models (PLMs), GPT-3.5, and Gemini Pro
under zero-shot settings using Retrieval-Augmented Generation (RAG) framework,
integrating various reasoning chains. The evaluation yields an F1 score of
0.69, consistency of 0.71, and a faithfulness score of 0.90 on the test
dataset.
","['large', 'language', 'models', '(', 'llms', ')', 'demonstrated', 'state-of-the-art', 'performance', 'various', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', 'across', 'multiple', 'domains', ',', 'yet', 'prone', 'shortcut', 'learning', 'factual', 'inconsistencies', '.', 'research', 'investigates', 'llms', ""'"", 'robustness', ',', 'consistency', ',', 'faithful', 'reasoning', 'performing', 'natural', 'language', 'inference', '(', 'nli', ')', 'breast', 'cancer', 'clinical', 'trial', 'reports', '(', 'ctrs', ')', 'context', 'semeval', '2024', 'task', '2', ':', 'safe', 'biomedical', 'natural', 'language', 'inference', 'clinical', 'trials', '.', 'examine', 'reasoning', 'capabilities', 'llms', 'adeptness', 'logical', 'problem-solving', '.', 'comparative', 'analysis', 'conducted', 'pre-trained', 'language', 'models', '(', 'plms', ')', ',', 'gpt-3.5', ',', 'gemini', 'pro', 'zero-shot', 'settings', 'using', 'retrieval-augmented', 'generation', '(', 'rag', ')', 'framework', ',', 'integrating', 'various', 'reasoning', 'chains', '.', 'evaluation', 'yields', 'f1', 'score', '0.69', ',', 'consistency', '0.71', ',', 'faithfulness', 'score', '0.90', 'test', 'dataset', '.']","large, language, models, (, llms, ), demonstrated, state-of-the-art, performance, various, natural, language, processing, (, nlp, ), tasks, across, multiple, domains, ,, yet, prone, shortcut, learning, factual, inconsistencies, ., research, investigates, llms, ', robustness, ,, consistency, ,, faithful, reasoning, performing, natural, language, inference, (, nli, ), breast, cancer, clinical, trial, reports, (, ctrs, ), context, semeval, 2024, task, 2, :, safe, biomedical, natural, language, inference, clinical, trials, ., examine, reasoning, capabilities, llms, adeptness, logical, problem-solving, ., comparative, analysis, conducted, pre-trained, language, models, (, plms, ), ,, gpt-3.5, ,, gemini, pro, zero-shot, settings, using, retrieval-augmented, generation, (, rag, ), framework, ,, integrating, various, reasoning, chains, ., evaluation, yields, f1, score, 0.69, ,, consistency, 0.71, ,, faithfulness, score, 0.90, test, dataset, ."
"GeoReasoner: Reasoning On Geospatially Grounded Context For Natural
  Language Understanding","Yibo Yan, Joey Lee",2024-08-21T06:35:21Z,"  In human reading and communication, individuals tend to engage in geospatial
reasoning, which involves recognizing geographic entities and making informed
inferences about their interrelationships. To mimic such cognitive process,
current methods either utilize conventional natural language understanding
toolkits, or directly apply models pretrained on geo-related natural language
corpora. However, these methods face two significant challenges: i) they do not
generalize well to unseen geospatial scenarios, and ii) they overlook the
importance of integrating geospatial context from geographical databases with
linguistic information from the Internet. To handle these challenges, we
propose GeoReasoner, a language model capable of reasoning on geospatially
grounded natural language. Specifically, it first leverages Large Language
Models (LLMs) to generate a comprehensive location description based on
linguistic and geospatial information. It also encodes direction and distance
information into spatial embedding via treating them as pseudo-sentences.
Consequently, the model is trained on both anchor-level and neighbor-level
inputs to learn geo-entity representation. Extensive experimental results
demonstrate GeoReasoner's superiority in three tasks: toponym recognition,
toponym linking, and geo-entity typing, compared to the state-of-the-art
baselines.
","['human', 'reading', 'communication', ',', 'individuals', 'tend', 'engage', 'geospatial', 'reasoning', ',', 'involves', 'recognizing', 'geographic', 'entities', 'making', 'informed', 'inferences', 'interrelationships', '.', 'mimic', 'cognitive', 'process', ',', 'current', 'methods', 'either', 'utilize', 'conventional', 'natural', 'language', 'understanding', 'toolkits', ',', 'directly', 'apply', 'models', 'pretrained', 'geo-related', 'natural', 'language', 'corpora', '.', 'however', ',', 'methods', 'face', 'two', 'significant', 'challenges', ':', ')', 'generalize', 'well', 'unseen', 'geospatial', 'scenarios', ',', 'ii', ')', 'overlook', 'importance', 'integrating', 'geospatial', 'context', 'geographical', 'databases', 'linguistic', 'information', 'internet', '.', 'handle', 'challenges', ',', 'propose', 'georeasoner', ',', 'language', 'model', 'capable', 'reasoning', 'geospatially', 'grounded', 'natural', 'language', '.', 'specifically', ',', 'first', 'leverages', 'large', 'language', 'models', '(', 'llms', ')', 'generate', 'comprehensive', 'location', 'description', 'based', 'linguistic', 'geospatial', 'information', '.', 'also', 'encodes', 'direction', 'distance', 'information', 'spatial', 'embedding', 'via', 'treating', 'pseudo-sentences', '.', 'consequently', ',', 'model', 'trained', 'anchor-level', 'neighbor-level', 'inputs', 'learn', 'geo-entity', 'representation', '.', 'extensive', 'experimental', 'results', 'demonstrate', 'georeasoner', ""'s"", 'superiority', 'three', 'tasks', ':', 'toponym', 'recognition', ',', 'toponym', 'linking', ',', 'geo-entity', 'typing', ',', 'compared', 'state-of-the-art', 'baselines', '.']","human, reading, communication, ,, individuals, tend, engage, geospatial, reasoning, ,, involves, recognizing, geographic, entities, making, informed, inferences, interrelationships, ., mimic, cognitive, process, ,, current, methods, either, utilize, conventional, natural, language, understanding, toolkits, ,, directly, apply, models, pretrained, geo-related, natural, language, corpora, ., however, ,, methods, face, two, significant, challenges, :, ), generalize, well, unseen, geospatial, scenarios, ,, ii, ), overlook, importance, integrating, geospatial, context, geographical, databases, linguistic, information, internet, ., handle, challenges, ,, propose, georeasoner, ,, language, model, capable, reasoning, geospatially, grounded, natural, language, ., specifically, ,, first, leverages, large, language, models, (, llms, ), generate, comprehensive, location, description, based, linguistic, geospatial, information, ., also, encodes, direction, distance, information, spatial, embedding, via, treating, pseudo-sentences, ., consequently, ,, model, trained, anchor-level, neighbor-level, inputs, learn, geo-entity, representation, ., extensive, experimental, results, demonstrate, georeasoner, 's, superiority, three, tasks, :, toponym, recognition, ,, toponym, linking, ,, geo-entity, typing, ,, compared, state-of-the-art, baselines, ."
"Morphological Processing of Low-Resource Languages: Where We Are and
  What's Next","Adam Wiemerslage, Miikka Silfverberg, Changbing Yang, Arya D. McCarthy, Garrett Nicolai, Eliana Colunga, Katharina Kann",2022-03-16T19:47:04Z,"  Automatic morphological processing can aid downstream natural language
processing applications, especially for low-resource languages, and assist
language documentation efforts for endangered languages. Having long been
multilingual, the field of computational morphology is increasingly moving
towards approaches suitable for languages with minimal or no annotated
resources. First, we survey recent developments in computational morphology
with a focus on low-resource languages. Second, we argue that the field is
ready to tackle the logical next challenge: understanding a language's
morphology from raw text alone. We perform an empirical study on a truly
unsupervised version of the paradigm completion task and show that, while
existing state-of-the-art models bridged by two newly proposed models we devise
perform reasonably, there is still much room for improvement. The stakes are
high: solving this task will increase the language coverage of morphological
resources by a number of magnitudes.
","['automatic', 'morphological', 'processing', 'aid', 'downstream', 'natural', 'language', 'processing', 'applications', ',', 'especially', 'low-resource', 'languages', ',', 'assist', 'language', 'documentation', 'efforts', 'endangered', 'languages', '.', 'long', 'multilingual', ',', 'field', 'computational', 'morphology', 'increasingly', 'moving', 'towards', 'approaches', 'suitable', 'languages', 'minimal', 'annotated', 'resources', '.', 'first', ',', 'survey', 'recent', 'developments', 'computational', 'morphology', 'focus', 'low-resource', 'languages', '.', 'second', ',', 'argue', 'field', 'ready', 'tackle', 'logical', 'next', 'challenge', ':', 'understanding', 'language', ""'s"", 'morphology', 'raw', 'text', 'alone', '.', 'perform', 'empirical', 'study', 'truly', 'unsupervised', 'version', 'paradigm', 'completion', 'task', 'show', ',', 'existing', 'state-of-the-art', 'models', 'bridged', 'two', 'newly', 'proposed', 'models', 'devise', 'perform', 'reasonably', ',', 'still', 'much', 'room', 'improvement', '.', 'stakes', 'high', ':', 'solving', 'task', 'increase', 'language', 'coverage', 'morphological', 'resources', 'number', 'magnitudes', '.']","automatic, morphological, processing, aid, downstream, natural, language, processing, applications, ,, especially, low-resource, languages, ,, assist, language, documentation, efforts, endangered, languages, ., long, multilingual, ,, field, computational, morphology, increasingly, moving, towards, approaches, suitable, languages, minimal, annotated, resources, ., first, ,, survey, recent, developments, computational, morphology, focus, low-resource, languages, ., second, ,, argue, field, ready, tackle, logical, next, challenge, :, understanding, language, 's, morphology, raw, text, alone, ., perform, empirical, study, truly, unsupervised, version, paradigm, completion, task, show, ,, existing, state-of-the-art, models, bridged, two, newly, proposed, models, devise, perform, reasonably, ,, still, much, room, improvement, ., stakes, high, :, solving, task, increase, language, coverage, morphological, resources, number, magnitudes, ."
Implementation of general formal translators,Iosif Iulian Petrila,2022-12-16T13:55:22Z,"  The general translator formalism and computing specific implementations are
proposed. The implementation of specific elements necessary to process the
source and destination information within the translators are presented. Some
common directives or instructions, such as classes and procedures, were unified
and generalized in order to allow general translations implementations. In
order to cover general cases, two levels of processing are required, related to
the source and destination information appropriate transformations, with the
related control and processing instructions. The proposed general translator
elements are useful for processing natural or artificial information described
through any types of languages or systems.
","['general', 'translator', 'formalism', 'computing', 'specific', 'implementations', 'proposed', '.', 'implementation', 'specific', 'elements', 'necessary', 'process', 'source', 'destination', 'information', 'within', 'translators', 'presented', '.', 'common', 'directives', 'instructions', ',', 'classes', 'procedures', ',', 'unified', 'generalized', 'order', 'allow', 'general', 'translations', 'implementations', '.', 'order', 'cover', 'general', 'cases', ',', 'two', 'levels', 'processing', 'required', ',', 'related', 'source', 'destination', 'information', 'appropriate', 'transformations', ',', 'related', 'control', 'processing', 'instructions', '.', 'proposed', 'general', 'translator', 'elements', 'useful', 'processing', 'natural', 'artificial', 'information', 'described', 'types', 'languages', 'systems', '.']","general, translator, formalism, computing, specific, implementations, proposed, ., implementation, specific, elements, necessary, process, source, destination, information, within, translators, presented, ., common, directives, instructions, ,, classes, procedures, ,, unified, generalized, order, allow, general, translations, implementations, ., order, cover, general, cases, ,, two, levels, processing, required, ,, related, source, destination, information, appropriate, transformations, ,, related, control, processing, instructions, ., proposed, general, translator, elements, useful, processing, natural, artificial, information, described, types, languages, systems, ."
"NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark
  Dataset for Generative Language Models in Norwegian","Peng Liu, Lemei Zhang, Terje Nissen Farup, Even W. Lauvrak, Jon Espen Ingvaldsen, Simen Eide, Jon Atle Gulla, Zhirong Yang",2023-12-03T08:09:45Z,"  Recent advancements in Generative Language Models (GLMs) have transformed
Natural Language Processing (NLP) by showcasing the effectiveness of the
""pre-train, prompt, and predict"" paradigm in utilizing pre-trained GLM
knowledge for diverse applications. Despite their potential, these capabilities
lack adequate quantitative characterization due to the absence of comprehensive
benchmarks, particularly for low-resource languages. Existing low-resource
benchmarks focus on discriminative language models like BERT, neglecting the
evaluation of generative language models. Moreover, current benchmarks often
overlook measuring generalization performance across multiple tasks, a crucial
metric for GLMs.
  To bridge these gaps, we introduce NLEBench, a comprehensive benchmark
tailored for evaluating natural language generation capabilities in Norwegian,
a low-resource language. We use Norwegian as a case study to explore whether
current GLMs and benchmarks in mainstream languages like English can reveal the
unique characteristics of underrepresented languages. NLEBench encompasses a
suite of real-world NLP tasks ranging from news storytelling, summarization,
open-domain conversation, natural language understanding, instruction
fine-tuning, toxicity and bias evaluation, to self-curated Chain-of-Thought
investigation. It features two high-quality, human-annotated datasets: an
instruction dataset covering traditional Norwegian cultures, idioms, slang, and
special expressions, and a document-grounded multi-label dataset for topic
classification, question answering, and summarization. This paper also
introduces foundational Norwegian Generative Language Models (NorGLMs)
developed with diverse parameter scales and Transformer-based architectures.
Systematic evaluations on the proposed benchmark suite provide insights into
the capabilities and scalability of NorGLMs across various downstream tasks.
","['recent', 'advancements', 'generative', 'language', 'models', '(', 'glms', ')', 'transformed', 'natural', 'language', 'processing', '(', 'nlp', ')', 'showcasing', 'effectiveness', ""''"", 'pre-train', ',', 'prompt', ',', 'predict', ""''"", 'paradigm', 'utilizing', 'pre-trained', 'glm', 'knowledge', 'diverse', 'applications', '.', 'despite', 'potential', ',', 'capabilities', 'lack', 'adequate', 'quantitative', 'characterization', 'due', 'absence', 'comprehensive', 'benchmarks', ',', 'particularly', 'low-resource', 'languages', '.', 'existing', 'low-resource', 'benchmarks', 'focus', 'discriminative', 'language', 'models', 'like', 'bert', ',', 'neglecting', 'evaluation', 'generative', 'language', 'models', '.', 'moreover', ',', 'current', 'benchmarks', 'often', 'overlook', 'measuring', 'generalization', 'performance', 'across', 'multiple', 'tasks', ',', 'crucial', 'metric', 'glms', '.', 'bridge', 'gaps', ',', 'introduce', 'nlebench', ',', 'comprehensive', 'benchmark', 'tailored', 'evaluating', 'natural', 'language', 'generation', 'capabilities', 'norwegian', ',', 'low-resource', 'language', '.', 'use', 'norwegian', 'case', 'study', 'explore', 'whether', 'current', 'glms', 'benchmarks', 'mainstream', 'languages', 'like', 'english', 'reveal', 'unique', 'characteristics', 'underrepresented', 'languages', '.', 'nlebench', 'encompasses', 'suite', 'real-world', 'nlp', 'tasks', 'ranging', 'news', 'storytelling', ',', 'summarization', ',', 'open-domain', 'conversation', ',', 'natural', 'language', 'understanding', ',', 'instruction', 'fine-tuning', ',', 'toxicity', 'bias', 'evaluation', ',', 'self-curated', 'chain-of-thought', 'investigation', '.', 'features', 'two', 'high-quality', ',', 'human-annotated', 'datasets', ':', 'instruction', 'dataset', 'covering', 'traditional', 'norwegian', 'cultures', ',', 'idioms', ',', 'slang', ',', 'special', 'expressions', ',', 'document-grounded', 'multi-label', 'dataset', 'topic', 'classification', ',', 'question', 'answering', ',', 'summarization', '.', 'paper', 'also', 'introduces', 'foundational', 'norwegian', 'generative', 'language', 'models', '(', 'norglms', ')', 'developed', 'diverse', 'parameter', 'scales', 'transformer-based', 'architectures', '.', 'systematic', 'evaluations', 'proposed', 'benchmark', 'suite', 'provide', 'insights', 'capabilities', 'scalability', 'norglms', 'across', 'various', 'downstream', 'tasks', '.']","recent, advancements, generative, language, models, (, glms, ), transformed, natural, language, processing, (, nlp, ), showcasing, effectiveness, '', pre-train, ,, prompt, ,, predict, '', paradigm, utilizing, pre-trained, glm, knowledge, diverse, applications, ., despite, potential, ,, capabilities, lack, adequate, quantitative, characterization, due, absence, comprehensive, benchmarks, ,, particularly, low-resource, languages, ., existing, low-resource, benchmarks, focus, discriminative, language, models, like, bert, ,, neglecting, evaluation, generative, language, models, ., moreover, ,, current, benchmarks, often, overlook, measuring, generalization, performance, across, multiple, tasks, ,, crucial, metric, glms, ., bridge, gaps, ,, introduce, nlebench, ,, comprehensive, benchmark, tailored, evaluating, natural, language, generation, capabilities, norwegian, ,, low-resource, language, ., use, norwegian, case, study, explore, whether, current, glms, benchmarks, mainstream, languages, like, english, reveal, unique, characteristics, underrepresented, languages, ., nlebench, encompasses, suite, real-world, nlp, tasks, ranging, news, storytelling, ,, summarization, ,, open-domain, conversation, ,, natural, language, understanding, ,, instruction, fine-tuning, ,, toxicity, bias, evaluation, ,, self-curated, chain-of-thought, investigation, ., features, two, high-quality, ,, human-annotated, datasets, :, instruction, dataset, covering, traditional, norwegian, cultures, ,, idioms, ,, slang, ,, special, expressions, ,, document-grounded, multi-label, dataset, topic, classification, ,, question, answering, ,, summarization, ., paper, also, introduces, foundational, norwegian, generative, language, models, (, norglms, ), developed, diverse, parameter, scales, transformer-based, architectures, ., systematic, evaluations, proposed, benchmark, suite, provide, insights, capabilities, scalability, norglms, across, various, downstream, tasks, ."
Comparing Generative Chatbots Based on Process Requirements,"Luis Fernando Lins, Nathalia Nascimento, Paulo Alencar, Toacy Oliveira, Donald Cowan",2023-11-28T18:25:22Z,"  Business processes are commonly represented by modelling languages, such as
Event-driven Process Chain (EPC), Yet Another Workflow Language (YAWL), and the
most popular standard notation for modelling business processes, the Business
Process Model and Notation (BPMN). Most recently, chatbots, programs that allow
users to interact with a machine using natural language, have been increasingly
used for business process execution support. A recent category of chatbots
worth mentioning is generative-based chatbots, powered by Large Language Models
(LLMs) such as OpenAI's Generative Pre-Trained Transformer (GPT) model and
Google's Pathways Language Model (PaLM), which are trained on billions of
parameters and support conversational intelligence. However, it is not clear
whether generative-based chatbots are able to understand and meet the
requirements of constructs such as those provided by BPMN for process execution
support. This paper presents a case study to compare the performance of
prominent generative models, GPT and PaLM, in the context of process execution
support. The research sheds light into the challenging problem of using
conversational approaches supported by generative chatbots as a means to
understand process-aware modelling notations and support users to execute their
tasks.
","['business', 'processes', 'commonly', 'represented', 'modelling', 'languages', ',', 'event-driven', 'process', 'chain', '(', 'epc', ')', ',', 'yet', 'another', 'workflow', 'language', '(', 'yawl', ')', ',', 'popular', 'standard', 'notation', 'modelling', 'business', 'processes', ',', 'business', 'process', 'model', 'notation', '(', 'bpmn', ')', '.', 'recently', ',', 'chatbots', ',', 'programs', 'allow', 'users', 'interact', 'machine', 'using', 'natural', 'language', ',', 'increasingly', 'used', 'business', 'process', 'execution', 'support', '.', 'recent', 'category', 'chatbots', 'worth', 'mentioning', 'generative-based', 'chatbots', ',', 'powered', 'large', 'language', 'models', '(', 'llms', ')', 'openai', ""'s"", 'generative', 'pre-trained', 'transformer', '(', 'gpt', ')', 'model', 'google', ""'s"", 'pathways', 'language', 'model', '(', 'palm', ')', ',', 'trained', 'billions', 'parameters', 'support', 'conversational', 'intelligence', '.', 'however', ',', 'clear', 'whether', 'generative-based', 'chatbots', 'able', 'understand', 'meet', 'requirements', 'constructs', 'provided', 'bpmn', 'process', 'execution', 'support', '.', 'paper', 'presents', 'case', 'study', 'compare', 'performance', 'prominent', 'generative', 'models', ',', 'gpt', 'palm', ',', 'context', 'process', 'execution', 'support', '.', 'research', 'sheds', 'light', 'challenging', 'problem', 'using', 'conversational', 'approaches', 'supported', 'generative', 'chatbots', 'means', 'understand', 'process-aware', 'modelling', 'notations', 'support', 'users', 'execute', 'tasks', '.']","business, processes, commonly, represented, modelling, languages, ,, event-driven, process, chain, (, epc, ), ,, yet, another, workflow, language, (, yawl, ), ,, popular, standard, notation, modelling, business, processes, ,, business, process, model, notation, (, bpmn, ), ., recently, ,, chatbots, ,, programs, allow, users, interact, machine, using, natural, language, ,, increasingly, used, business, process, execution, support, ., recent, category, chatbots, worth, mentioning, generative-based, chatbots, ,, powered, large, language, models, (, llms, ), openai, 's, generative, pre-trained, transformer, (, gpt, ), model, google, 's, pathways, language, model, (, palm, ), ,, trained, billions, parameters, support, conversational, intelligence, ., however, ,, clear, whether, generative-based, chatbots, able, understand, meet, requirements, constructs, provided, bpmn, process, execution, support, ., paper, presents, case, study, compare, performance, prominent, generative, models, ,, gpt, palm, ,, context, process, execution, support, ., research, sheds, light, challenging, problem, using, conversational, approaches, supported, generative, chatbots, means, understand, process-aware, modelling, notations, support, users, execute, tasks, ."
"On the relation between dependency distance, crossing dependencies, and
  parsing. Comment on ""Dependency distance: a new perspective on syntactic
  patterns in natural languages"" by Haitao Liu et al",Carlos Gómez-Rodríguez,2017-05-27T16:19:37Z,"  Liu et al. (2017) provide a comprehensive account of research on dependency
distance in human languages. While the article is a very rich and useful report
on this complex subject, here I will expand on a few specific issues where
research in computational linguistics (specifically natural language
processing) can inform DDM research, and vice versa. These aspects have not
been explored much in the article by Liu et al. or elsewhere, probably due to
the little overlap between both research communities, but they may provide
interesting insights for improving our understanding of the evolution of human
languages, the mechanisms by which the brain processes and understands
language, and the construction of effective computer systems to achieve this
goal.
","['liu', 'et', 'al', '.', '(', '2017', ')', 'provide', 'comprehensive', 'account', 'research', 'dependency', 'distance', 'human', 'languages', '.', 'article', 'rich', 'useful', 'report', 'complex', 'subject', ',', 'expand', 'specific', 'issues', 'research', 'computational', 'linguistics', '(', 'specifically', 'natural', 'language', 'processing', ')', 'inform', 'ddm', 'research', ',', 'vice', 'versa', '.', 'aspects', 'explored', 'much', 'article', 'liu', 'et', 'al', '.', 'elsewhere', ',', 'probably', 'due', 'little', 'overlap', 'research', 'communities', ',', 'may', 'provide', 'interesting', 'insights', 'improving', 'understanding', 'evolution', 'human', 'languages', ',', 'mechanisms', 'brain', 'processes', 'understands', 'language', ',', 'construction', 'effective', 'computer', 'systems', 'achieve', 'goal', '.']","liu, et, al, ., (, 2017, ), provide, comprehensive, account, research, dependency, distance, human, languages, ., article, rich, useful, report, complex, subject, ,, expand, specific, issues, research, computational, linguistics, (, specifically, natural, language, processing, ), inform, ddm, research, ,, vice, versa, ., aspects, explored, much, article, liu, et, al, ., elsewhere, ,, probably, due, little, overlap, research, communities, ,, may, provide, interesting, insights, improving, understanding, evolution, human, languages, ,, mechanisms, brain, processes, understands, language, ,, construction, effective, computer, systems, achieve, goal, ."
UR-FUNNY: A Multimodal Language Dataset for Understanding Humor,"Md Kamrul Hasan, Wasifur Rahman, Amir Zadeh, Jianyuan Zhong, Md Iftekhar Tanveer, Louis-Philippe Morency,  Mohammed,  Hoque",2019-04-14T03:15:38Z,"  Humor is a unique and creative communicative behavior displayed during social
interactions. It is produced in a multimodal manner, through the usage of words
(text), gestures (vision) and prosodic cues (acoustic). Understanding humor
from these three modalities falls within boundaries of multimodal language; a
recent research trend in natural language processing that models natural
language as it happens in face-to-face communication. Although humor detection
is an established research area in NLP, in a multimodal context it is an
understudied area. This paper presents a diverse multimodal dataset, called
UR-FUNNY, to open the door to understanding multimodal language used in
expressing humor. The dataset and accompanying studies, present a framework in
multimodal humor detection for the natural language processing community.
UR-FUNNY is publicly available for research.
","['humor', 'unique', 'creative', 'communicative', 'behavior', 'displayed', 'social', 'interactions', '.', 'produced', 'multimodal', 'manner', ',', 'usage', 'words', '(', 'text', ')', ',', 'gestures', '(', 'vision', ')', 'prosodic', 'cues', '(', 'acoustic', ')', '.', 'understanding', 'humor', 'three', 'modalities', 'falls', 'within', 'boundaries', 'multimodal', 'language', ';', 'recent', 'research', 'trend', 'natural', 'language', 'processing', 'models', 'natural', 'language', 'happens', 'face-to-face', 'communication', '.', 'although', 'humor', 'detection', 'established', 'research', 'area', 'nlp', ',', 'multimodal', 'context', 'understudied', 'area', '.', 'paper', 'presents', 'diverse', 'multimodal', 'dataset', ',', 'called', 'ur-funny', ',', 'open', 'door', 'understanding', 'multimodal', 'language', 'used', 'expressing', 'humor', '.', 'dataset', 'accompanying', 'studies', ',', 'present', 'framework', 'multimodal', 'humor', 'detection', 'natural', 'language', 'processing', 'community', '.', 'ur-funny', 'publicly', 'available', 'research', '.']","humor, unique, creative, communicative, behavior, displayed, social, interactions, ., produced, multimodal, manner, ,, usage, words, (, text, ), ,, gestures, (, vision, ), prosodic, cues, (, acoustic, ), ., understanding, humor, three, modalities, falls, within, boundaries, multimodal, language, ;, recent, research, trend, natural, language, processing, models, natural, language, happens, face-to-face, communication, ., although, humor, detection, established, research, area, nlp, ,, multimodal, context, understudied, area, ., paper, presents, diverse, multimodal, dataset, ,, called, ur-funny, ,, open, door, understanding, multimodal, language, used, expressing, humor, ., dataset, accompanying, studies, ,, present, framework, multimodal, humor, detection, natural, language, processing, community, ., ur-funny, publicly, available, research, ."
Pumping lemmas for classes of languages generated by folding systems,Jorge C. Lucero,2019-10-18T17:30:04Z,"  Geometric folding processes are ubiquitous in natural systems ranging from
protein biochemistry to patterns of insect wings and leaves. In a previous
study, a folding operation between strings of formal languages was introduced
as a model of such processes. The operation was then used to define a folding
system (F-system) as a construct consisting of a core language, containing the
strings to be folded, and a folding procedure language, which defines how the
folding is done. This paper reviews main definitions associated with F-systems
and next it determines necessary conditions for a language to belong to classes
generated by such systems. The conditions are stated in the form of pumping
lemmas and four classes are considered, in which the core and folding procedure
languages are both regular, one of them is regular and the other context-free,
or both are context-free. Full demonstrations of the lemmas are provided, and
the analysis is illustrated with examples.
","['geometric', 'folding', 'processes', 'ubiquitous', 'natural', 'systems', 'ranging', 'protein', 'biochemistry', 'patterns', 'insect', 'wings', 'leaves', '.', 'previous', 'study', ',', 'folding', 'operation', 'strings', 'formal', 'languages', 'introduced', 'model', 'processes', '.', 'operation', 'used', 'define', 'folding', 'system', '(', 'f-system', ')', 'construct', 'consisting', 'core', 'language', ',', 'containing', 'strings', 'folded', ',', 'folding', 'procedure', 'language', ',', 'defines', 'folding', 'done', '.', 'paper', 'reviews', 'main', 'definitions', 'associated', 'f-systems', 'next', 'determines', 'necessary', 'conditions', 'language', 'belong', 'classes', 'generated', 'systems', '.', 'conditions', 'stated', 'form', 'pumping', 'lemmas', 'four', 'classes', 'considered', ',', 'core', 'folding', 'procedure', 'languages', 'regular', ',', 'one', 'regular', 'context-free', ',', 'context-free', '.', 'full', 'demonstrations', 'lemmas', 'provided', ',', 'analysis', 'illustrated', 'examples', '.']","geometric, folding, processes, ubiquitous, natural, systems, ranging, protein, biochemistry, patterns, insect, wings, leaves, ., previous, study, ,, folding, operation, strings, formal, languages, introduced, model, processes, ., operation, used, define, folding, system, (, f-system, ), construct, consisting, core, language, ,, containing, strings, folded, ,, folding, procedure, language, ,, defines, folding, done, ., paper, reviews, main, definitions, associated, f-systems, next, determines, necessary, conditions, language, belong, classes, generated, systems, ., conditions, stated, form, pumping, lemmas, four, classes, considered, ,, core, folding, procedure, languages, regular, ,, one, regular, context-free, ,, context-free, ., full, demonstrations, lemmas, provided, ,, analysis, illustrated, examples, ."
Integrating question answering and text-to-SQL in Portuguese,"Marcos Menon José, Marcelo Archanjo José, Denis Deratani Mauá, Fábio Gagliardi Cozman",2022-02-08T18:23:03Z,"  Deep learning transformers have drastically improved systems that
automatically answer questions in natural language. However, different
questions demand different answering techniques; here we propose, build and
validate an architecture that integrates different modules to answer two
distinct kinds of queries. Our architecture takes a free-form natural language
text and classifies it to send it either to a Neural Question Answering
Reasoner or a Natural Language parser to SQL. We implemented a complete system
for the Portuguese language, using some of the main tools available for the
language and translating training and testing datasets. Experiments show that
our system selects the appropriate answering method with high accuracy (over
99\%), thus validating a modular question answering strategy.
","['deep', 'learning', 'transformers', 'drastically', 'improved', 'systems', 'automatically', 'answer', 'questions', 'natural', 'language', '.', 'however', ',', 'different', 'questions', 'demand', 'different', 'answering', 'techniques', ';', 'propose', ',', 'build', 'validate', 'architecture', 'integrates', 'different', 'modules', 'answer', 'two', 'distinct', 'kinds', 'queries', '.', 'architecture', 'takes', 'free-form', 'natural', 'language', 'text', 'classifies', 'send', 'either', 'neural', 'question', 'answering', 'reasoner', 'natural', 'language', 'parser', 'sql', '.', 'implemented', 'complete', 'system', 'portuguese', 'language', ',', 'using', 'main', 'tools', 'available', 'language', 'translating', 'training', 'testing', 'datasets', '.', 'experiments', 'show', 'system', 'selects', 'appropriate', 'answering', 'method', 'high', 'accuracy', '(', '99\\', '%', ')', ',', 'thus', 'validating', 'modular', 'question', 'answering', 'strategy', '.']","deep, learning, transformers, drastically, improved, systems, automatically, answer, questions, natural, language, ., however, ,, different, questions, demand, different, answering, techniques, ;, propose, ,, build, validate, architecture, integrates, different, modules, answer, two, distinct, kinds, queries, ., architecture, takes, free-form, natural, language, text, classifies, send, either, neural, question, answering, reasoner, natural, language, parser, sql, ., implemented, complete, system, portuguese, language, ,, using, main, tools, available, language, translating, training, testing, datasets, ., experiments, show, system, selects, appropriate, answering, method, high, accuracy, (, 99\, %, ), ,, thus, validating, modular, question, answering, strategy, ."
"$C^3$: Confidence Calibration Model Cascade for Inference-Efficient
  Cross-Lingual Natural Language Understanding","Taixi Lu, Haoyu Wang, Huajie Shao, Jing Gao, Huaxiu Yao",2024-02-25T05:07:56Z,"  Cross-lingual natural language understanding (NLU) is a critical task in
natural language processing (NLP). Recent advancements have seen multilingual
pre-trained language models (mPLMs) significantly enhance the performance of
these tasks. However, mPLMs necessitate substantial resources and incur high
computational costs during inference, posing challenges for deployment in
real-world and real-time systems. Existing model cascade methods seek to
enhance inference efficiency by greedily selecting the lightest model capable
of processing the current input from a variety of models, based on model
confidence scores. Nonetheless, deep models tend to exhibit overconfidence, and
confidence distributions vary across languages. This leads to the emission of
confident but incorrect predictions by smaller models, hindering their ability
to generalize effectively across test languages. In this study, we introduce a
confidence calibration model cascade ($C^3$) method. This approach, simple yet
effective, involves calibration prior to cascade inference, thereby enhancing
cascade accuracy through more reliable predictions. Extensive experiments
conducted on three cross-lingual benchmarks demonstrate that $C^3$
significantly outperforms all state-of-the-art baselines.
","['cross-lingual', 'natural', 'language', 'understanding', '(', 'nlu', ')', 'critical', 'task', 'natural', 'language', 'processing', '(', 'nlp', ')', '.', 'recent', 'advancements', 'seen', 'multilingual', 'pre-trained', 'language', 'models', '(', 'mplms', ')', 'significantly', 'enhance', 'performance', 'tasks', '.', 'however', ',', 'mplms', 'necessitate', 'substantial', 'resources', 'incur', 'high', 'computational', 'costs', 'inference', ',', 'posing', 'challenges', 'deployment', 'real-world', 'real-time', 'systems', '.', 'existing', 'model', 'cascade', 'methods', 'seek', 'enhance', 'inference', 'efficiency', 'greedily', 'selecting', 'lightest', 'model', 'capable', 'processing', 'current', 'input', 'variety', 'models', ',', 'based', 'model', 'confidence', 'scores', '.', 'nonetheless', ',', 'deep', 'models', 'tend', 'exhibit', 'overconfidence', ',', 'confidence', 'distributions', 'vary', 'across', 'languages', '.', 'leads', 'emission', 'confident', 'incorrect', 'predictions', 'smaller', 'models', ',', 'hindering', 'ability', 'generalize', 'effectively', 'across', 'test', 'languages', '.', 'study', ',', 'introduce', 'confidence', 'calibration', 'model', 'cascade', '(', '$', 'c^3', '$', ')', 'method', '.', 'approach', ',', 'simple', 'yet', 'effective', ',', 'involves', 'calibration', 'prior', 'cascade', 'inference', ',', 'thereby', 'enhancing', 'cascade', 'accuracy', 'reliable', 'predictions', '.', 'extensive', 'experiments', 'conducted', 'three', 'cross-lingual', 'benchmarks', 'demonstrate', '$', 'c^3', '$', 'significantly', 'outperforms', 'state-of-the-art', 'baselines', '.']","cross-lingual, natural, language, understanding, (, nlu, ), critical, task, natural, language, processing, (, nlp, ), ., recent, advancements, seen, multilingual, pre-trained, language, models, (, mplms, ), significantly, enhance, performance, tasks, ., however, ,, mplms, necessitate, substantial, resources, incur, high, computational, costs, inference, ,, posing, challenges, deployment, real-world, real-time, systems, ., existing, model, cascade, methods, seek, enhance, inference, efficiency, greedily, selecting, lightest, model, capable, processing, current, input, variety, models, ,, based, model, confidence, scores, ., nonetheless, ,, deep, models, tend, exhibit, overconfidence, ,, confidence, distributions, vary, across, languages, ., leads, emission, confident, incorrect, predictions, smaller, models, ,, hindering, ability, generalize, effectively, across, test, languages, ., study, ,, introduce, confidence, calibration, model, cascade, (, $, c^3, $, ), method, ., approach, ,, simple, yet, effective, ,, involves, calibration, prior, cascade, inference, ,, thereby, enhancing, cascade, accuracy, reliable, predictions, ., extensive, experiments, conducted, three, cross-lingual, benchmarks, demonstrate, $, c^3, $, significantly, outperforms, state-of-the-art, baselines, ."
"LangTopo: Aligning Language Descriptions of Graphs with Tokenized
  Topological Modeling","Zhong Guan, Hongke Zhao, Likang Wu, Ming He, Jianpin Fan",2024-06-19T06:20:22Z,"  Recently, large language models (LLMs) have been widely researched in the
field of graph machine learning due to their outstanding abilities in language
comprehension and learning. However, the significant gap between natural
language tasks and topological structure modeling poses a nonnegligible
challenge. Specifically, since natural language descriptions are not sufficient
for LLMs to understand and process graph-structured data, fine-tuned LLMs
perform even worse than some traditional GNN models on graph tasks, lacking
inherent modeling capabilities for graph structures. Existing research overly
emphasizes LLMs' understanding of semantic information captured by external
models, while inadequately exploring graph topological structure modeling,
thereby overlooking the genuine capabilities that LLMs lack. Consequently, in
this paper, we introduce a new framework, LangTopo, which aligns graph
structure modeling with natural language understanding at the token level.
LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs
by constructing a codebook for the graph modality and performs consistency
maximization. This process aligns the text description of LLM with the
topological modeling of GNN, allowing LLM to learn the ability of GNN to
capture graph structures, enabling LLM to handle graph-structured data
independently. We demonstrate the effectiveness of our proposed method on
multiple datasets.
","['recently', ',', 'large', 'language', 'models', '(', 'llms', ')', 'widely', 'researched', 'field', 'graph', 'machine', 'learning', 'due', 'outstanding', 'abilities', 'language', 'comprehension', 'learning', '.', 'however', ',', 'significant', 'gap', 'natural', 'language', 'tasks', 'topological', 'structure', 'modeling', 'poses', 'nonnegligible', 'challenge', '.', 'specifically', ',', 'since', 'natural', 'language', 'descriptions', 'sufficient', 'llms', 'understand', 'process', 'graph-structured', 'data', ',', 'fine-tuned', 'llms', 'perform', 'even', 'worse', 'traditional', 'gnn', 'models', 'graph', 'tasks', ',', 'lacking', 'inherent', 'modeling', 'capabilities', 'graph', 'structures', '.', 'existing', 'research', 'overly', 'emphasizes', 'llms', ""'"", 'understanding', 'semantic', 'information', 'captured', 'external', 'models', ',', 'inadequately', 'exploring', 'graph', 'topological', 'structure', 'modeling', ',', 'thereby', 'overlooking', 'genuine', 'capabilities', 'llms', 'lack', '.', 'consequently', ',', 'paper', ',', 'introduce', 'new', 'framework', ',', 'langtopo', ',', 'aligns', 'graph', 'structure', 'modeling', 'natural', 'language', 'understanding', 'token', 'level', '.', 'langtopo', 'quantifies', 'graph', 'structure', 'modeling', 'capabilities', 'gnns', 'llms', 'constructing', 'codebook', 'graph', 'modality', 'performs', 'consistency', 'maximization', '.', 'process', 'aligns', 'text', 'description', 'llm', 'topological', 'modeling', 'gnn', ',', 'allowing', 'llm', 'learn', 'ability', 'gnn', 'capture', 'graph', 'structures', ',', 'enabling', 'llm', 'handle', 'graph-structured', 'data', 'independently', '.', 'demonstrate', 'effectiveness', 'proposed', 'method', 'multiple', 'datasets', '.']","recently, ,, large, language, models, (, llms, ), widely, researched, field, graph, machine, learning, due, outstanding, abilities, language, comprehension, learning, ., however, ,, significant, gap, natural, language, tasks, topological, structure, modeling, poses, nonnegligible, challenge, ., specifically, ,, since, natural, language, descriptions, sufficient, llms, understand, process, graph-structured, data, ,, fine-tuned, llms, perform, even, worse, traditional, gnn, models, graph, tasks, ,, lacking, inherent, modeling, capabilities, graph, structures, ., existing, research, overly, emphasizes, llms, ', understanding, semantic, information, captured, external, models, ,, inadequately, exploring, graph, topological, structure, modeling, ,, thereby, overlooking, genuine, capabilities, llms, lack, ., consequently, ,, paper, ,, introduce, new, framework, ,, langtopo, ,, aligns, graph, structure, modeling, natural, language, understanding, token, level, ., langtopo, quantifies, graph, structure, modeling, capabilities, gnns, llms, constructing, codebook, graph, modality, performs, consistency, maximization, ., process, aligns, text, description, llm, topological, modeling, gnn, ,, allowing, llm, learn, ability, gnn, capture, graph, structures, ,, enabling, llm, handle, graph-structured, data, independently, ., demonstrate, effectiveness, proposed, method, multiple, datasets, ."
"Towards Efficient and Robust VQA-NLE Data Generation with Large
  Vision-Language Models","Patrick Amadeus Irawan, Genta Indra Winata, Samuel Cahyawijaya, Ayu Purwarianti",2024-09-23T07:59:50Z,"  Natural Language Explanation (NLE) aims to elucidate the decision-making
process by providing detailed, human-friendly explanations in natural language.
It helps demystify the decision-making processes of large vision-language
models (LVLMs) through the use of language models. While existing methods for
creating a Vision Question-Answering with Natural Language Explanation
(VQA-NLE) datasets can provide explanations, they heavily rely on human
annotations that are time-consuming and costly. In this study, we propose a
novel approach that leverages LVLMs to efficiently generate high-quality
synthetic VQA-NLE datasets. By evaluating our synthetic data, we showcase how
advanced prompting techniques can lead to the production of high-quality
VQA-NLE data. Our findings indicate that this proposed method achieves up to
20x faster than human annotation, with only a minimal decrease in qualitative
metrics, achieving robust quality that is nearly equivalent to human-annotated
data. Furthermore, we show that incorporating visual prompts significantly
enhances the relevance of text generation. Our study paves the way for a more
efficient and robust automated generation of multi-modal NLE data, offering a
promising solution to the problem.
","['natural', 'language', 'explanation', '(', 'nle', ')', 'aims', 'elucidate', 'decision-making', 'process', 'providing', 'detailed', ',', 'human-friendly', 'explanations', 'natural', 'language', '.', 'helps', 'demystify', 'decision-making', 'processes', 'large', 'vision-language', 'models', '(', 'lvlms', ')', 'use', 'language', 'models', '.', 'existing', 'methods', 'creating', 'vision', 'question-answering', 'natural', 'language', 'explanation', '(', 'vqa-nle', ')', 'datasets', 'provide', 'explanations', ',', 'heavily', 'rely', 'human', 'annotations', 'time-consuming', 'costly', '.', 'study', ',', 'propose', 'novel', 'approach', 'leverages', 'lvlms', 'efficiently', 'generate', 'high-quality', 'synthetic', 'vqa-nle', 'datasets', '.', 'evaluating', 'synthetic', 'data', ',', 'showcase', 'advanced', 'prompting', 'techniques', 'lead', 'production', 'high-quality', 'vqa-nle', 'data', '.', 'findings', 'indicate', 'proposed', 'method', 'achieves', '20x', 'faster', 'human', 'annotation', ',', 'minimal', 'decrease', 'qualitative', 'metrics', ',', 'achieving', 'robust', 'quality', 'nearly', 'equivalent', 'human-annotated', 'data', '.', 'furthermore', ',', 'show', 'incorporating', 'visual', 'prompts', 'significantly', 'enhances', 'relevance', 'text', 'generation', '.', 'study', 'paves', 'way', 'efficient', 'robust', 'automated', 'generation', 'multi-modal', 'nle', 'data', ',', 'offering', 'promising', 'solution', 'problem', '.']","natural, language, explanation, (, nle, ), aims, elucidate, decision-making, process, providing, detailed, ,, human-friendly, explanations, natural, language, ., helps, demystify, decision-making, processes, large, vision-language, models, (, lvlms, ), use, language, models, ., existing, methods, creating, vision, question-answering, natural, language, explanation, (, vqa-nle, ), datasets, provide, explanations, ,, heavily, rely, human, annotations, time-consuming, costly, ., study, ,, propose, novel, approach, leverages, lvlms, efficiently, generate, high-quality, synthetic, vqa-nle, datasets, ., evaluating, synthetic, data, ,, showcase, advanced, prompting, techniques, lead, production, high-quality, vqa-nle, data, ., findings, indicate, proposed, method, achieves, 20x, faster, human, annotation, ,, minimal, decrease, qualitative, metrics, ,, achieving, robust, quality, nearly, equivalent, human-annotated, data, ., furthermore, ,, show, incorporating, visual, prompts, significantly, enhances, relevance, text, generation, ., study, paves, way, efficient, robust, automated, generation, multi-modal, nle, data, ,, offering, promising, solution, problem, ."
Native vs Non-Native Language Prompting: A Comparative Analysis,"Mohamed Bayan Kmainasi, Rakif Khan, Ali Ezzat Shahroor, Boushra Bendou, Maram Hasanain, Firoj Alam",2024-09-11T06:59:37Z,"  Large language models (LLMs) have shown remarkable abilities in different
fields, including standard Natural Language Processing (NLP) tasks. To elicit
knowledge from LLMs, prompts play a key role, consisting of natural language
instructions. Most open and closed source LLMs are trained on available labeled
and unlabeled resources--digital content such as text, images, audio, and
videos. Hence, these models have better knowledge for high-resourced languages
but struggle with low-resourced languages. Since prompts play a crucial role in
understanding their capabilities, the language used for prompts remains an
important research question. Although there has been significant research in
this area, it is still limited, and less has been explored for medium to
low-resourced languages. In this study, we investigate different prompting
strategies (native vs. non-native) on 11 different NLP tasks associated with 12
different Arabic datasets (9.7K data points). In total, we conducted 197
experiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our
findings suggest that, on average, the non-native prompt performs the best,
followed by mixed and native prompts.
","['large', 'language', 'models', '(', 'llms', ')', 'shown', 'remarkable', 'abilities', 'different', 'fields', ',', 'including', 'standard', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', '.', 'elicit', 'knowledge', 'llms', ',', 'prompts', 'play', 'key', 'role', ',', 'consisting', 'natural', 'language', 'instructions', '.', 'open', 'closed', 'source', 'llms', 'trained', 'available', 'labeled', 'unlabeled', 'resources', '--', 'digital', 'content', 'text', ',', 'images', ',', 'audio', ',', 'videos', '.', 'hence', ',', 'models', 'better', 'knowledge', 'high-resourced', 'languages', 'struggle', 'low-resourced', 'languages', '.', 'since', 'prompts', 'play', 'crucial', 'role', 'understanding', 'capabilities', ',', 'language', 'used', 'prompts', 'remains', 'important', 'research', 'question', '.', 'although', 'significant', 'research', 'area', ',', 'still', 'limited', ',', 'less', 'explored', 'medium', 'low-resourced', 'languages', '.', 'study', ',', 'investigate', 'different', 'prompting', 'strategies', '(', 'native', 'vs.', 'non-native', ')', '11', 'different', 'nlp', 'tasks', 'associated', '12', 'different', 'arabic', 'datasets', '(', '9.7k', 'data', 'points', ')', '.', 'total', ',', 'conducted', '197', 'experiments', 'involving', '3', 'llms', ',', '12', 'datasets', ',', '3', 'prompting', 'strategies', '.', 'findings', 'suggest', ',', 'average', ',', 'non-native', 'prompt', 'performs', 'best', ',', 'followed', 'mixed', 'native', 'prompts', '.']","large, language, models, (, llms, ), shown, remarkable, abilities, different, fields, ,, including, standard, natural, language, processing, (, nlp, ), tasks, ., elicit, knowledge, llms, ,, prompts, play, key, role, ,, consisting, natural, language, instructions, ., open, closed, source, llms, trained, available, labeled, unlabeled, resources, --, digital, content, text, ,, images, ,, audio, ,, videos, ., hence, ,, models, better, knowledge, high-resourced, languages, struggle, low-resourced, languages, ., since, prompts, play, crucial, role, understanding, capabilities, ,, language, used, prompts, remains, important, research, question, ., although, significant, research, area, ,, still, limited, ,, less, explored, medium, low-resourced, languages, ., study, ,, investigate, different, prompting, strategies, (, native, vs., non-native, ), 11, different, nlp, tasks, associated, 12, different, arabic, datasets, (, 9.7k, data, points, ), ., total, ,, conducted, 197, experiments, involving, 3, llms, ,, 12, datasets, ,, 3, prompting, strategies, ., findings, suggest, ,, average, ,, non-native, prompt, performs, best, ,, followed, mixed, native, prompts, ."
"Technical Language Supervision for Intelligent Fault Diagnosis in
  Process Industry","Karl Löwenmark, Cees Taal, Stephan Schnabel, Marcus Liwicki, Fredrik Sandin",2021-12-11T18:59:40Z,"  In the process industry, condition monitoring systems with automated fault
diagnosis methods assist human experts and thereby improve maintenance
efficiency, process sustainability, and workplace safety. Improving the
automated fault diagnosis methods using data and machine learning-based models
is a central aspect of intelligent fault diagnosis (IFD). A major challenge in
IFD is to develop realistic datasets with accurate labels needed to train and
validate models, and to transfer models trained with labeled lab data to
heterogeneous process industry environments. However, fault descriptions and
work-orders written by domain experts are increasingly digitised in modern
condition monitoring systems, for example in the context of rotating equipment
monitoring. Thus, domain-specific knowledge about fault characteristics and
severities exists as technical language annotations in industrial datasets.
Furthermore, recent advances in natural language processing enable weakly
supervised model optimisation using natural language annotations, most notably
in the form of natural language supervision (NLS). This creates a timely
opportunity to develop technical language supervision (TLS) solutions for IFD
systems grounded in industrial data, for example as a complement to
pre-training with lab data to address problems like overfitting and inaccurate
out-of-sample generalisation. We surveyed the literature and identify a
considerable improvement in the maturity of NLS over the last two years,
facilitating applications beyond natural language; a rapid development of weak
supervision methods; and transfer learning as a current trend in IFD which can
benefit from these developments. Finally we describe a general framework for
TLS and implement a TLS case study based on SentenceBERT and contrastive
learning based zero-shot inference on annotated industry data.
","['process', 'industry', ',', 'condition', 'monitoring', 'systems', 'automated', 'fault', 'diagnosis', 'methods', 'assist', 'human', 'experts', 'thereby', 'improve', 'maintenance', 'efficiency', ',', 'process', 'sustainability', ',', 'workplace', 'safety', '.', 'improving', 'automated', 'fault', 'diagnosis', 'methods', 'using', 'data', 'machine', 'learning-based', 'models', 'central', 'aspect', 'intelligent', 'fault', 'diagnosis', '(', 'ifd', ')', '.', 'major', 'challenge', 'ifd', 'develop', 'realistic', 'datasets', 'accurate', 'labels', 'needed', 'train', 'validate', 'models', ',', 'transfer', 'models', 'trained', 'labeled', 'lab', 'data', 'heterogeneous', 'process', 'industry', 'environments', '.', 'however', ',', 'fault', 'descriptions', 'work-orders', 'written', 'domain', 'experts', 'increasingly', 'digitised', 'modern', 'condition', 'monitoring', 'systems', ',', 'example', 'context', 'rotating', 'equipment', 'monitoring', '.', 'thus', ',', 'domain-specific', 'knowledge', 'fault', 'characteristics', 'severities', 'exists', 'technical', 'language', 'annotations', 'industrial', 'datasets', '.', 'furthermore', ',', 'recent', 'advances', 'natural', 'language', 'processing', 'enable', 'weakly', 'supervised', 'model', 'optimisation', 'using', 'natural', 'language', 'annotations', ',', 'notably', 'form', 'natural', 'language', 'supervision', '(', 'nls', ')', '.', 'creates', 'timely', 'opportunity', 'develop', 'technical', 'language', 'supervision', '(', 'tls', ')', 'solutions', 'ifd', 'systems', 'grounded', 'industrial', 'data', ',', 'example', 'complement', 'pre-training', 'lab', 'data', 'address', 'problems', 'like', 'overfitting', 'inaccurate', 'out-of-sample', 'generalisation', '.', 'surveyed', 'literature', 'identify', 'considerable', 'improvement', 'maturity', 'nls', 'last', 'two', 'years', ',', 'facilitating', 'applications', 'beyond', 'natural', 'language', ';', 'rapid', 'development', 'weak', 'supervision', 'methods', ';', 'transfer', 'learning', 'current', 'trend', 'ifd', 'benefit', 'developments', '.', 'finally', 'describe', 'general', 'framework', 'tls', 'implement', 'tls', 'case', 'study', 'based', 'sentencebert', 'contrastive', 'learning', 'based', 'zero-shot', 'inference', 'annotated', 'industry', 'data', '.']","process, industry, ,, condition, monitoring, systems, automated, fault, diagnosis, methods, assist, human, experts, thereby, improve, maintenance, efficiency, ,, process, sustainability, ,, workplace, safety, ., improving, automated, fault, diagnosis, methods, using, data, machine, learning-based, models, central, aspect, intelligent, fault, diagnosis, (, ifd, ), ., major, challenge, ifd, develop, realistic, datasets, accurate, labels, needed, train, validate, models, ,, transfer, models, trained, labeled, lab, data, heterogeneous, process, industry, environments, ., however, ,, fault, descriptions, work-orders, written, domain, experts, increasingly, digitised, modern, condition, monitoring, systems, ,, example, context, rotating, equipment, monitoring, ., thus, ,, domain-specific, knowledge, fault, characteristics, severities, exists, technical, language, annotations, industrial, datasets, ., furthermore, ,, recent, advances, natural, language, processing, enable, weakly, supervised, model, optimisation, using, natural, language, annotations, ,, notably, form, natural, language, supervision, (, nls, ), ., creates, timely, opportunity, develop, technical, language, supervision, (, tls, ), solutions, ifd, systems, grounded, industrial, data, ,, example, complement, pre-training, lab, data, address, problems, like, overfitting, inaccurate, out-of-sample, generalisation, ., surveyed, literature, identify, considerable, improvement, maturity, nls, last, two, years, ,, facilitating, applications, beyond, natural, language, ;, rapid, development, weak, supervision, methods, ;, transfer, learning, current, trend, ifd, benefit, developments, ., finally, describe, general, framework, tls, implement, tls, case, study, based, sentencebert, contrastive, learning, based, zero-shot, inference, annotated, industry, data, ."
"Performance Prediction of Data-Driven Knowledge summarization of High
  Entropy Alloys (HEAs) literature implementing Natural Language Processing
  algorithms","Akshansh Mishra, Vijaykumar S Jatti, Vaishnavi More, Anish Dasgupta, Devarrishi Dixit, Eyob Messele Sefene",2023-11-06T16:22:32Z,"  The ability to interpret spoken language is connected to natural language
processing. It involves teaching the AI how words relate to one another, how
they are meant to be used, and in what settings. The goal of natural language
processing (NLP) is to get a machine intelligence to process words the same way
a human brain does. This enables machine intelligence to interpret, arrange,
and comprehend textual data by processing the natural language. The technology
can comprehend what is communicated, whether it be through speech or writing
because AI pro-cesses language more quickly than humans can. In the present
study, five NLP algorithms, namely, Geneism, Sumy, Luhn, Latent Semantic
Analysis (LSA), and Kull-back-Liebler (KL) al-gorithm, are implemented for the
first time for the knowledge summarization purpose of the High Entropy Alloys
(HEAs). The performance prediction of these algorithms is made by using the
BLEU score and ROUGE score. The results showed that the Luhn algorithm has the
highest accuracy score for the knowledge summarization tasks compared to the
other used algorithms.
","['ability', 'interpret', 'spoken', 'language', 'connected', 'natural', 'language', 'processing', '.', 'involves', 'teaching', 'ai', 'words', 'relate', 'one', 'another', ',', 'meant', 'used', ',', 'settings', '.', 'goal', 'natural', 'language', 'processing', '(', 'nlp', ')', 'get', 'machine', 'intelligence', 'process', 'words', 'way', 'human', 'brain', '.', 'enables', 'machine', 'intelligence', 'interpret', ',', 'arrange', ',', 'comprehend', 'textual', 'data', 'processing', 'natural', 'language', '.', 'technology', 'comprehend', 'communicated', ',', 'whether', 'speech', 'writing', 'ai', 'pro-cesses', 'language', 'quickly', 'humans', '.', 'present', 'study', ',', 'five', 'nlp', 'algorithms', ',', 'namely', ',', 'geneism', ',', 'sumy', ',', 'luhn', ',', 'latent', 'semantic', 'analysis', '(', 'lsa', ')', ',', 'kull-back-liebler', '(', 'kl', ')', 'al-gorithm', ',', 'implemented', 'first', 'time', 'knowledge', 'summarization', 'purpose', 'high', 'entropy', 'alloys', '(', 'heas', ')', '.', 'performance', 'prediction', 'algorithms', 'made', 'using', 'bleu', 'score', 'rouge', 'score', '.', 'results', 'showed', 'luhn', 'algorithm', 'highest', 'accuracy', 'score', 'knowledge', 'summarization', 'tasks', 'compared', 'used', 'algorithms', '.']","ability, interpret, spoken, language, connected, natural, language, processing, ., involves, teaching, ai, words, relate, one, another, ,, meant, used, ,, settings, ., goal, natural, language, processing, (, nlp, ), get, machine, intelligence, process, words, way, human, brain, ., enables, machine, intelligence, interpret, ,, arrange, ,, comprehend, textual, data, processing, natural, language, ., technology, comprehend, communicated, ,, whether, speech, writing, ai, pro-cesses, language, quickly, humans, ., present, study, ,, five, nlp, algorithms, ,, namely, ,, geneism, ,, sumy, ,, luhn, ,, latent, semantic, analysis, (, lsa, ), ,, kull-back-liebler, (, kl, ), al-gorithm, ,, implemented, first, time, knowledge, summarization, purpose, high, entropy, alloys, (, heas, ), ., performance, prediction, algorithms, made, using, bleu, score, rouge, score, ., results, showed, luhn, algorithm, highest, accuracy, score, knowledge, summarization, tasks, compared, used, algorithms, ."
Federated Learning Meets Natural Language Processing: A Survey,"Ming Liu, Stella Ho, Mengqi Wang, Longxiang Gao, Yuan Jin, He Zhang",2021-07-27T05:07:48Z,"  Federated Learning aims to learn machine learning models from multiple
decentralized edge devices (e.g. mobiles) or servers without sacrificing local
data privacy. Recent Natural Language Processing techniques rely on deep
learning and large pre-trained language models. However, both big deep neural
and language models are trained with huge amounts of data which often lies on
the server side. Since text data is widely originated from end users, in this
work, we look into recent NLP models and techniques which use federated
learning as the learning framework. Our survey discusses major challenges in
federated natural language processing, including the algorithm challenges,
system challenges as well as the privacy issues. We also provide a critical
review of the existing Federated NLP evaluation methods and tools. Finally, we
highlight the current research gaps and future directions.
","['federated', 'learning', 'aims', 'learn', 'machine', 'learning', 'models', 'multiple', 'decentralized', 'edge', 'devices', '(', 'e.g', '.', 'mobiles', ')', 'servers', 'without', 'sacrificing', 'local', 'data', 'privacy', '.', 'recent', 'natural', 'language', 'processing', 'techniques', 'rely', 'deep', 'learning', 'large', 'pre-trained', 'language', 'models', '.', 'however', ',', 'big', 'deep', 'neural', 'language', 'models', 'trained', 'huge', 'amounts', 'data', 'often', 'lies', 'server', 'side', '.', 'since', 'text', 'data', 'widely', 'originated', 'end', 'users', ',', 'work', ',', 'look', 'recent', 'nlp', 'models', 'techniques', 'use', 'federated', 'learning', 'learning', 'framework', '.', 'survey', 'discusses', 'major', 'challenges', 'federated', 'natural', 'language', 'processing', ',', 'including', 'algorithm', 'challenges', ',', 'system', 'challenges', 'well', 'privacy', 'issues', '.', 'also', 'provide', 'critical', 'review', 'existing', 'federated', 'nlp', 'evaluation', 'methods', 'tools', '.', 'finally', ',', 'highlight', 'current', 'research', 'gaps', 'future', 'directions', '.']","federated, learning, aims, learn, machine, learning, models, multiple, decentralized, edge, devices, (, e.g, ., mobiles, ), servers, without, sacrificing, local, data, privacy, ., recent, natural, language, processing, techniques, rely, deep, learning, large, pre-trained, language, models, ., however, ,, big, deep, neural, language, models, trained, huge, amounts, data, often, lies, server, side, ., since, text, data, widely, originated, end, users, ,, work, ,, look, recent, nlp, models, techniques, use, federated, learning, learning, framework, ., survey, discusses, major, challenges, federated, natural, language, processing, ,, including, algorithm, challenges, ,, system, challenges, well, privacy, issues, ., also, provide, critical, review, existing, federated, nlp, evaluation, methods, tools, ., finally, ,, highlight, current, research, gaps, future, directions, ."
"LM4OPT: Unveiling the Potential of Large Language Models in Formulating
  Mathematical Optimization Problems","Tasnim Ahmed, Salimur Choudhury",2024-03-02T23:32:33Z,"  In the rapidly evolving field of natural language processing, the translation
of linguistic descriptions into mathematical formulation of optimization
problems presents a formidable challenge, demanding intricate understanding and
processing capabilities from Large Language Models (LLMs). This study compares
prominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and
one-shot settings for this task. Our findings show GPT-4's superior
performance, particularly in the one-shot scenario. A central part of this
research is the introduction of `LM4OPT,' a progressive fine-tuning framework
for Llama-2-7b that utilizes noisy embeddings and specialized datasets.
However, this research highlights a notable gap in the contextual understanding
capabilities of smaller models such as Llama-2-7b compared to larger
counterparts, especially in processing lengthy and complex input contexts. Our
empirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4
surpasses the baseline performance established by previous research, achieving
an F1-score of 0.63, solely based on the problem description in natural
language, and without relying on any additional named entity information.
GPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b. These
findings not only benchmark the current capabilities of LLMs in a novel
application area but also lay the groundwork for future improvements in
mathematical formulation of optimization problems from natural language input.
","['rapidly', 'evolving', 'field', 'natural', 'language', 'processing', ',', 'translation', 'linguistic', 'descriptions', 'mathematical', 'formulation', 'optimization', 'problems', 'presents', 'formidable', 'challenge', ',', 'demanding', 'intricate', 'understanding', 'processing', 'capabilities', 'large', 'language', 'models', '(', 'llms', ')', '.', 'study', 'compares', 'prominent', 'llms', ',', 'including', 'gpt-3.5', ',', 'gpt-4', ',', 'llama-2-7b', ',', 'zero-shot', 'one-shot', 'settings', 'task', '.', 'findings', 'show', 'gpt-4', ""'s"", 'superior', 'performance', ',', 'particularly', 'one-shot', 'scenario', '.', 'central', 'part', 'research', 'introduction', '`', 'lm4opt', ',', ""'"", 'progressive', 'fine-tuning', 'framework', 'llama-2-7b', 'utilizes', 'noisy', 'embeddings', 'specialized', 'datasets', '.', 'however', ',', 'research', 'highlights', 'notable', 'gap', 'contextual', 'understanding', 'capabilities', 'smaller', 'models', 'llama-2-7b', 'compared', 'larger', 'counterparts', ',', 'especially', 'processing', 'lengthy', 'complex', 'input', 'contexts', '.', 'empirical', 'investigation', ',', 'utilizing', 'nl4opt', 'dataset', ',', 'unveils', 'gpt-4', 'surpasses', 'baseline', 'performance', 'established', 'previous', 'research', ',', 'achieving', 'f1-score', '0.63', ',', 'solely', 'based', 'problem', 'description', 'natural', 'language', ',', 'without', 'relying', 'additional', 'named', 'entity', 'information', '.', 'gpt-3.5', 'follows', 'closely', ',', 'outperforming', 'fine-tuned', 'llama-2-7b', '.', 'findings', 'benchmark', 'current', 'capabilities', 'llms', 'novel', 'application', 'area', 'also', 'lay', 'groundwork', 'future', 'improvements', 'mathematical', 'formulation', 'optimization', 'problems', 'natural', 'language', 'input', '.']","rapidly, evolving, field, natural, language, processing, ,, translation, linguistic, descriptions, mathematical, formulation, optimization, problems, presents, formidable, challenge, ,, demanding, intricate, understanding, processing, capabilities, large, language, models, (, llms, ), ., study, compares, prominent, llms, ,, including, gpt-3.5, ,, gpt-4, ,, llama-2-7b, ,, zero-shot, one-shot, settings, task, ., findings, show, gpt-4, 's, superior, performance, ,, particularly, one-shot, scenario, ., central, part, research, introduction, `, lm4opt, ,, ', progressive, fine-tuning, framework, llama-2-7b, utilizes, noisy, embeddings, specialized, datasets, ., however, ,, research, highlights, notable, gap, contextual, understanding, capabilities, smaller, models, llama-2-7b, compared, larger, counterparts, ,, especially, processing, lengthy, complex, input, contexts, ., empirical, investigation, ,, utilizing, nl4opt, dataset, ,, unveils, gpt-4, surpasses, baseline, performance, established, previous, research, ,, achieving, f1-score, 0.63, ,, solely, based, problem, description, natural, language, ,, without, relying, additional, named, entity, information, ., gpt-3.5, follows, closely, ,, outperforming, fine-tuned, llama-2-7b, ., findings, benchmark, current, capabilities, llms, novel, application, area, also, lay, groundwork, future, improvements, mathematical, formulation, optimization, problems, natural, language, input, ."
"Accuracy of the Uzbek stop words detection: a case study on ""School
  corpus""","Khabibulla Madatov, Shukurla Bekchanov, Jernej Vičič",2022-09-15T05:14:31Z,"  Stop words are very important for information retrieval and text analysis
investigation tasks of natural language processing. Current work presents a
method to evaluate the quality of a list of stop words aimed at automatically
creating techniques. Although the method proposed in this paper was tested on
an automatically-generated list of stop words for the Uzbek language, it can
be, with some modifications, applied to similar languages either from the same
family or the ones that have an agglutinative nature. Since the Uzbek language
belongs to the family of agglutinative languages, it can be explained that the
automatic detection of stop words in the language is a more complex process
than in inflected languages. Moreover, we integrated our previous work on stop
words detection in the example of the ""School corpus"" by investigating how to
automatically analyse the detection of stop words in Uzbek texts. This work is
devoted to answering whether there is a good way of evaluating available stop
words for Uzbek texts, or whether it is possible to determine what part of the
Uzbek sentence contains the majority of the stop words by studying the
numerical characteristics of the probability of unique words. The results show
acceptable accuracy of the stop words lists.
","['stop', 'words', 'important', 'information', 'retrieval', 'text', 'analysis', 'investigation', 'tasks', 'natural', 'language', 'processing', '.', 'current', 'work', 'presents', 'method', 'evaluate', 'quality', 'list', 'stop', 'words', 'aimed', 'automatically', 'creating', 'techniques', '.', 'although', 'method', 'proposed', 'paper', 'tested', 'automatically-generated', 'list', 'stop', 'words', 'uzbek', 'language', ',', ',', 'modifications', ',', 'applied', 'similar', 'languages', 'either', 'family', 'ones', 'agglutinative', 'nature', '.', 'since', 'uzbek', 'language', 'belongs', 'family', 'agglutinative', 'languages', ',', 'explained', 'automatic', 'detection', 'stop', 'words', 'language', 'complex', 'process', 'inflected', 'languages', '.', 'moreover', ',', 'integrated', 'previous', 'work', 'stop', 'words', 'detection', 'example', '``', 'school', 'corpus', ""''"", 'investigating', 'automatically', 'analyse', 'detection', 'stop', 'words', 'uzbek', 'texts', '.', 'work', 'devoted', 'answering', 'whether', 'good', 'way', 'evaluating', 'available', 'stop', 'words', 'uzbek', 'texts', ',', 'whether', 'possible', 'determine', 'part', 'uzbek', 'sentence', 'contains', 'majority', 'stop', 'words', 'studying', 'numerical', 'characteristics', 'probability', 'unique', 'words', '.', 'results', 'show', 'acceptable', 'accuracy', 'stop', 'words', 'lists', '.']","stop, words, important, information, retrieval, text, analysis, investigation, tasks, natural, language, processing, ., current, work, presents, method, evaluate, quality, list, stop, words, aimed, automatically, creating, techniques, ., although, method, proposed, paper, tested, automatically-generated, list, stop, words, uzbek, language, ,, ,, modifications, ,, applied, similar, languages, either, family, ones, agglutinative, nature, ., since, uzbek, language, belongs, family, agglutinative, languages, ,, explained, automatic, detection, stop, words, language, complex, process, inflected, languages, ., moreover, ,, integrated, previous, work, stop, words, detection, example, ``, school, corpus, '', investigating, automatically, analyse, detection, stop, words, uzbek, texts, ., work, devoted, answering, whether, good, way, evaluating, available, stop, words, uzbek, texts, ,, whether, possible, determine, part, uzbek, sentence, contains, majority, stop, words, studying, numerical, characteristics, probability, unique, words, ., results, show, acceptable, accuracy, stop, words, lists, ."
Language is All a Graph Needs,"Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, Yongfeng Zhang",2023-08-14T13:41:09Z,"  The emergence of large-scale pre-trained language models has revolutionized
various AI research domains. Transformers-based Large Language Models (LLMs)
have gradually replaced CNNs and RNNs to unify fields of computer vision and
natural language processing. Compared with independent data samples such as
images, videos or texts, graphs usually contain rich structural and relational
information. Meanwhile, language, especially natural language, being one of the
most expressive mediums, excels in describing complex structures. However,
existing work on incorporating graph problems into the generative language
modeling framework remains very limited. Considering the rising prominence of
LLMs, it becomes essential to explore whether LLMs can also replace GNNs as the
foundation model for graphs. In this paper, we propose InstructGLM
(Instruction-finetuned Graph Language Model) with highly scalable prompts based
on natural language instructions. We use natural language to describe
multi-scale geometric structure of the graph and then instruction finetune an
LLM to perform graph tasks, which enables Generative Graph Learning. Our method
surpasses all GNN baselines on ogbn-arxiv, Cora and PubMed datasets,
underscoring its effectiveness and sheds light on generative LLMs as new
foundation model for graph machine learning. Our code is open-sourced at
https://github.com/agiresearch/InstructGLM.
","['emergence', 'large-scale', 'pre-trained', 'language', 'models', 'revolutionized', 'various', 'ai', 'research', 'domains', '.', 'transformers-based', 'large', 'language', 'models', '(', 'llms', ')', 'gradually', 'replaced', 'cnns', 'rnns', 'unify', 'fields', 'computer', 'vision', 'natural', 'language', 'processing', '.', 'compared', 'independent', 'data', 'samples', 'images', ',', 'videos', 'texts', ',', 'graphs', 'usually', 'contain', 'rich', 'structural', 'relational', 'information', '.', 'meanwhile', ',', 'language', ',', 'especially', 'natural', 'language', ',', 'one', 'expressive', 'mediums', ',', 'excels', 'describing', 'complex', 'structures', '.', 'however', ',', 'existing', 'work', 'incorporating', 'graph', 'problems', 'generative', 'language', 'modeling', 'framework', 'remains', 'limited', '.', 'considering', 'rising', 'prominence', 'llms', ',', 'becomes', 'essential', 'explore', 'whether', 'llms', 'also', 'replace', 'gnns', 'foundation', 'model', 'graphs', '.', 'paper', ',', 'propose', 'instructglm', '(', 'instruction-finetuned', 'graph', 'language', 'model', ')', 'highly', 'scalable', 'prompts', 'based', 'natural', 'language', 'instructions', '.', 'use', 'natural', 'language', 'describe', 'multi-scale', 'geometric', 'structure', 'graph', 'instruction', 'finetune', 'llm', 'perform', 'graph', 'tasks', ',', 'enables', 'generative', 'graph', 'learning', '.', 'method', 'surpasses', 'gnn', 'baselines', 'ogbn-arxiv', ',', 'cora', 'pubmed', 'datasets', ',', 'underscoring', 'effectiveness', 'sheds', 'light', 'generative', 'llms', 'new', 'foundation', 'model', 'graph', 'machine', 'learning', '.', 'code', 'open-sourced', 'https', ':', '//github.com/agiresearch/instructglm', '.']","emergence, large-scale, pre-trained, language, models, revolutionized, various, ai, research, domains, ., transformers-based, large, language, models, (, llms, ), gradually, replaced, cnns, rnns, unify, fields, computer, vision, natural, language, processing, ., compared, independent, data, samples, images, ,, videos, texts, ,, graphs, usually, contain, rich, structural, relational, information, ., meanwhile, ,, language, ,, especially, natural, language, ,, one, expressive, mediums, ,, excels, describing, complex, structures, ., however, ,, existing, work, incorporating, graph, problems, generative, language, modeling, framework, remains, limited, ., considering, rising, prominence, llms, ,, becomes, essential, explore, whether, llms, also, replace, gnns, foundation, model, graphs, ., paper, ,, propose, instructglm, (, instruction-finetuned, graph, language, model, ), highly, scalable, prompts, based, natural, language, instructions, ., use, natural, language, describe, multi-scale, geometric, structure, graph, instruction, finetune, llm, perform, graph, tasks, ,, enables, generative, graph, learning, ., method, surpasses, gnn, baselines, ogbn-arxiv, ,, cora, pubmed, datasets, ,, underscoring, effectiveness, sheds, light, generative, llms, new, foundation, model, graph, machine, learning, ., code, open-sourced, https, :, //github.com/agiresearch/instructglm, ."
word representation or word embedding in Persian text,"Siamak Sarmady, Erfan Rahmani",2017-12-18T21:06:42Z,"  Text processing is one of the sub-branches of natural language processing.
Recently, the use of machine learning and neural networks methods has been
given greater consideration. For this reason, the representation of words has
become very important. This article is about word representation or converting
words into vectors in Persian text. In this research GloVe, CBOW and skip-gram
methods are updated to produce embedded vectors for Persian words. In order to
train a neural networks, Bijankhan corpus, Hamshahri corpus and UPEC corpus
have been compound and used. Finally, we have 342,362 words that obtained
vectors in all three models for this words. These vectors have many usage for
Persian natural language processing.
","['text', 'processing', 'one', 'sub-branches', 'natural', 'language', 'processing', '.', 'recently', ',', 'use', 'machine', 'learning', 'neural', 'networks', 'methods', 'given', 'greater', 'consideration', '.', 'reason', ',', 'representation', 'words', 'become', 'important', '.', 'article', 'word', 'representation', 'converting', 'words', 'vectors', 'persian', 'text', '.', 'research', 'glove', ',', 'cbow', 'skip-gram', 'methods', 'updated', 'produce', 'embedded', 'vectors', 'persian', 'words', '.', 'order', 'train', 'neural', 'networks', ',', 'bijankhan', 'corpus', ',', 'hamshahri', 'corpus', 'upec', 'corpus', 'compound', 'used', '.', 'finally', ',', '342,362', 'words', 'obtained', 'vectors', 'three', 'models', 'words', '.', 'vectors', 'many', 'usage', 'persian', 'natural', 'language', 'processing', '.']","text, processing, one, sub-branches, natural, language, processing, ., recently, ,, use, machine, learning, neural, networks, methods, given, greater, consideration, ., reason, ,, representation, words, become, important, ., article, word, representation, converting, words, vectors, persian, text, ., research, glove, ,, cbow, skip-gram, methods, updated, produce, embedded, vectors, persian, words, ., order, train, neural, networks, ,, bijankhan, corpus, ,, hamshahri, corpus, upec, corpus, compound, used, ., finally, ,, 342,362, words, obtained, vectors, three, models, words, ., vectors, many, usage, persian, natural, language, processing, ."
Data Readiness for Natural Language Processing,"Fredrik Olsson, Magnus Sahlgren",2020-09-04T07:53:43Z,"  This document concerns data readiness in the context of machine learning and
Natural Language Processing. It describes how an organization may proceed to
identify, make available, validate, and prepare data to facilitate automated
analysis methods. The contents of the document is based on the practical
challenges and frequently asked questions we have encountered in our work as an
applied research institute with helping organizations and companies, both in
the public and private sectors, to use data in their business processes.
","['document', 'concerns', 'data', 'readiness', 'context', 'machine', 'learning', 'natural', 'language', 'processing', '.', 'describes', 'organization', 'may', 'proceed', 'identify', ',', 'make', 'available', ',', 'validate', ',', 'prepare', 'data', 'facilitate', 'automated', 'analysis', 'methods', '.', 'contents', 'document', 'based', 'practical', 'challenges', 'frequently', 'asked', 'questions', 'encountered', 'work', 'applied', 'research', 'institute', 'helping', 'organizations', 'companies', ',', 'public', 'private', 'sectors', ',', 'use', 'data', 'business', 'processes', '.']","document, concerns, data, readiness, context, machine, learning, natural, language, processing, ., describes, organization, may, proceed, identify, ,, make, available, ,, validate, ,, prepare, data, facilitate, automated, analysis, methods, ., contents, document, based, practical, challenges, frequently, asked, questions, encountered, work, applied, research, institute, helping, organizations, companies, ,, public, private, sectors, ,, use, data, business, processes, ."
Uzbek Sentiment Analysis based on local Restaurant Reviews,"Sanatbek Matlatipov, Hulkar Rahimboeva, Jaloliddin Rajabov, Elmurod Kuriyozov",2022-05-31T16:21:00Z,"  Extracting useful information for sentiment analysis and classification
problems from a big amount of user-generated feedback, such as restaurant
reviews, is a crucial task of natural language processing, which is not only
for customer satisfaction where it can give personalized services, but can also
influence the further development of a company. In this paper, we present a
work done on collecting restaurant reviews data as a sentiment analysis dataset
for the Uzbek language, a member of the Turkic family which is heavily affected
by the low-resource constraint, and provide some further analysis of the novel
dataset by evaluation using different techniques, from logistic regression
based models, to support vector machines, and even deep learning models, such
as recurrent neural networks, as well as convolutional neural networks. The
paper includes detailed information on how the data was collected, how it was
pre-processed for better quality optimization, as well as experimental setups
for the evaluation process. The overall evaluation results indicate that by
performing pre-processing steps, such as stemming for agglutinative languages,
the system yields better results, eventually achieving 91% accuracy result in
the best performing model
","['extracting', 'useful', 'information', 'sentiment', 'analysis', 'classification', 'problems', 'big', 'amount', 'user-generated', 'feedback', ',', 'restaurant', 'reviews', ',', 'crucial', 'task', 'natural', 'language', 'processing', ',', 'customer', 'satisfaction', 'give', 'personalized', 'services', ',', 'also', 'influence', 'development', 'company', '.', 'paper', ',', 'present', 'work', 'done', 'collecting', 'restaurant', 'reviews', 'data', 'sentiment', 'analysis', 'dataset', 'uzbek', 'language', ',', 'member', 'turkic', 'family', 'heavily', 'affected', 'low-resource', 'constraint', ',', 'provide', 'analysis', 'novel', 'dataset', 'evaluation', 'using', 'different', 'techniques', ',', 'logistic', 'regression', 'based', 'models', ',', 'support', 'vector', 'machines', ',', 'even', 'deep', 'learning', 'models', ',', 'recurrent', 'neural', 'networks', ',', 'well', 'convolutional', 'neural', 'networks', '.', 'paper', 'includes', 'detailed', 'information', 'data', 'collected', ',', 'pre-processed', 'better', 'quality', 'optimization', ',', 'well', 'experimental', 'setups', 'evaluation', 'process', '.', 'overall', 'evaluation', 'results', 'indicate', 'performing', 'pre-processing', 'steps', ',', 'stemming', 'agglutinative', 'languages', ',', 'system', 'yields', 'better', 'results', ',', 'eventually', 'achieving', '91', '%', 'accuracy', 'result', 'best', 'performing', 'model']","extracting, useful, information, sentiment, analysis, classification, problems, big, amount, user-generated, feedback, ,, restaurant, reviews, ,, crucial, task, natural, language, processing, ,, customer, satisfaction, give, personalized, services, ,, also, influence, development, company, ., paper, ,, present, work, done, collecting, restaurant, reviews, data, sentiment, analysis, dataset, uzbek, language, ,, member, turkic, family, heavily, affected, low-resource, constraint, ,, provide, analysis, novel, dataset, evaluation, using, different, techniques, ,, logistic, regression, based, models, ,, support, vector, machines, ,, even, deep, learning, models, ,, recurrent, neural, networks, ,, well, convolutional, neural, networks, ., paper, includes, detailed, information, data, collected, ,, pre-processed, better, quality, optimization, ,, well, experimental, setups, evaluation, process, ., overall, evaluation, results, indicate, performing, pre-processing, steps, ,, stemming, agglutinative, languages, ,, system, yields, better, results, ,, eventually, achieving, 91, %, accuracy, result, best, performing, model"
"A Comparative Study on Textual Saliency of Styles from Eye Tracking,
  Annotations, and Language Models","Karin de Langis, Dongyeop Kang",2022-12-19T21:50:36Z,"  There is growing interest in incorporating eye-tracking data and other
implicit measures of human language processing into natural language processing
(NLP) pipelines. The data from human language processing contain unique insight
into human linguistic understanding that could be exploited by language models.
However, many unanswered questions remain about the nature of this data and how
it can best be utilized in downstream NLP tasks. In this paper, we present
eyeStyliency, an eye-tracking dataset for human processing of stylistic text
(e.g., politeness). We develop a variety of methods to derive style saliency
scores over text using the collected eye dataset. We further investigate how
this saliency data compares to both human annotation methods and model-based
interpretability metrics. We find that while eye-tracking data is unique, it
also intersects with both human annotations and model-based importance scores,
providing a possible bridge between human- and machine-based perspectives. We
propose utilizing this type of data to evaluate the cognitive plausibility of
models that interpret style. Our eye-tracking data and processing code are
publicly available.
","['growing', 'interest', 'incorporating', 'eye-tracking', 'data', 'implicit', 'measures', 'human', 'language', 'processing', 'natural', 'language', 'processing', '(', 'nlp', ')', 'pipelines', '.', 'data', 'human', 'language', 'processing', 'contain', 'unique', 'insight', 'human', 'linguistic', 'understanding', 'could', 'exploited', 'language', 'models', '.', 'however', ',', 'many', 'unanswered', 'questions', 'remain', 'nature', 'data', 'best', 'utilized', 'downstream', 'nlp', 'tasks', '.', 'paper', ',', 'present', 'eyestyliency', ',', 'eye-tracking', 'dataset', 'human', 'processing', 'stylistic', 'text', '(', 'e.g.', ',', 'politeness', ')', '.', 'develop', 'variety', 'methods', 'derive', 'style', 'saliency', 'scores', 'text', 'using', 'collected', 'eye', 'dataset', '.', 'investigate', 'saliency', 'data', 'compares', 'human', 'annotation', 'methods', 'model-based', 'interpretability', 'metrics', '.', 'find', 'eye-tracking', 'data', 'unique', ',', 'also', 'intersects', 'human', 'annotations', 'model-based', 'importance', 'scores', ',', 'providing', 'possible', 'bridge', 'human-', 'machine-based', 'perspectives', '.', 'propose', 'utilizing', 'type', 'data', 'evaluate', 'cognitive', 'plausibility', 'models', 'interpret', 'style', '.', 'eye-tracking', 'data', 'processing', 'code', 'publicly', 'available', '.']","growing, interest, incorporating, eye-tracking, data, implicit, measures, human, language, processing, natural, language, processing, (, nlp, ), pipelines, ., data, human, language, processing, contain, unique, insight, human, linguistic, understanding, could, exploited, language, models, ., however, ,, many, unanswered, questions, remain, nature, data, best, utilized, downstream, nlp, tasks, ., paper, ,, present, eyestyliency, ,, eye-tracking, dataset, human, processing, stylistic, text, (, e.g., ,, politeness, ), ., develop, variety, methods, derive, style, saliency, scores, text, using, collected, eye, dataset, ., investigate, saliency, data, compares, human, annotation, methods, model-based, interpretability, metrics, ., find, eye-tracking, data, unique, ,, also, intersects, human, annotations, model-based, importance, scores, ,, providing, possible, bridge, human-, machine-based, perspectives, ., propose, utilizing, type, data, evaluate, cognitive, plausibility, models, interpret, style, ., eye-tracking, data, processing, code, publicly, available, ."
"UniPSDA: Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot
  Cross-Lingual Natural Language Understanding","Dongyang Li, Taolin Zhang, Jiali Deng, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue",2024-06-24T07:27:01Z,"  Cross-lingual representation learning transfers knowledge from resource-rich
data to resource-scarce ones to improve the semantic understanding abilities of
different languages. However, previous works rely on shallow unsupervised data
generated by token surface matching, regardless of the global context-aware
semantics of the surrounding text tokens. In this paper, we propose an
Unsupervised Pseudo Semantic Data Augmentation (UniPSDA) mechanism for
cross-lingual natural language understanding to enrich the training data
without human interventions. Specifically, to retrieve the tokens with similar
meanings for the semantic data augmentation across different languages, we
propose a sequential clustering process in 3 stages: within a single language,
across multiple languages of a language family, and across languages from
multiple language families. Meanwhile, considering the multi-lingual knowledge
infusion with context-aware semantics while alleviating computation burden, we
directly replace the key constituents of the sentences with the above-learned
multi-lingual family knowledge, viewed as pseudo-semantic. The infusion process
is further optimized via three de-biasing techniques without introducing any
neural parameters. Extensive experiments demonstrate that our model
consistently improves the performance on general zero-shot cross-lingual
natural language understanding tasks, including sequence classification,
information extraction, and question answering.
","['cross-lingual', 'representation', 'learning', 'transfers', 'knowledge', 'resource-rich', 'data', 'resource-scarce', 'ones', 'improve', 'semantic', 'understanding', 'abilities', 'different', 'languages', '.', 'however', ',', 'previous', 'works', 'rely', 'shallow', 'unsupervised', 'data', 'generated', 'token', 'surface', 'matching', ',', 'regardless', 'global', 'context-aware', 'semantics', 'surrounding', 'text', 'tokens', '.', 'paper', ',', 'propose', 'unsupervised', 'pseudo', 'semantic', 'data', 'augmentation', '(', 'unipsda', ')', 'mechanism', 'cross-lingual', 'natural', 'language', 'understanding', 'enrich', 'training', 'data', 'without', 'human', 'interventions', '.', 'specifically', ',', 'retrieve', 'tokens', 'similar', 'meanings', 'semantic', 'data', 'augmentation', 'across', 'different', 'languages', ',', 'propose', 'sequential', 'clustering', 'process', '3', 'stages', ':', 'within', 'single', 'language', ',', 'across', 'multiple', 'languages', 'language', 'family', ',', 'across', 'languages', 'multiple', 'language', 'families', '.', 'meanwhile', ',', 'considering', 'multi-lingual', 'knowledge', 'infusion', 'context-aware', 'semantics', 'alleviating', 'computation', 'burden', ',', 'directly', 'replace', 'key', 'constituents', 'sentences', 'above-learned', 'multi-lingual', 'family', 'knowledge', ',', 'viewed', 'pseudo-semantic', '.', 'infusion', 'process', 'optimized', 'via', 'three', 'de-biasing', 'techniques', 'without', 'introducing', 'neural', 'parameters', '.', 'extensive', 'experiments', 'demonstrate', 'model', 'consistently', 'improves', 'performance', 'general', 'zero-shot', 'cross-lingual', 'natural', 'language', 'understanding', 'tasks', ',', 'including', 'sequence', 'classification', ',', 'information', 'extraction', ',', 'question', 'answering', '.']","cross-lingual, representation, learning, transfers, knowledge, resource-rich, data, resource-scarce, ones, improve, semantic, understanding, abilities, different, languages, ., however, ,, previous, works, rely, shallow, unsupervised, data, generated, token, surface, matching, ,, regardless, global, context-aware, semantics, surrounding, text, tokens, ., paper, ,, propose, unsupervised, pseudo, semantic, data, augmentation, (, unipsda, ), mechanism, cross-lingual, natural, language, understanding, enrich, training, data, without, human, interventions, ., specifically, ,, retrieve, tokens, similar, meanings, semantic, data, augmentation, across, different, languages, ,, propose, sequential, clustering, process, 3, stages, :, within, single, language, ,, across, multiple, languages, language, family, ,, across, languages, multiple, language, families, ., meanwhile, ,, considering, multi-lingual, knowledge, infusion, context-aware, semantics, alleviating, computation, burden, ,, directly, replace, key, constituents, sentences, above-learned, multi-lingual, family, knowledge, ,, viewed, pseudo-semantic, ., infusion, process, optimized, via, three, de-biasing, techniques, without, introducing, neural, parameters, ., extensive, experiments, demonstrate, model, consistently, improves, performance, general, zero-shot, cross-lingual, natural, language, understanding, tasks, ,, including, sequence, classification, ,, information, extraction, ,, question, answering, ."
"Efficient neural speech synthesis for low-resource languages through
  multilingual modeling","Marcel de Korte, Jaebok Kim, Esther Klabbers",2020-08-20T14:05:28Z,"  Recent advances in neural TTS have led to models that can produce
high-quality synthetic speech. However, these models typically require large
amounts of training data, which can make it costly to produce a new voice with
the desired quality. Although multi-speaker modeling can reduce the data
requirements necessary for a new voice, this approach is usually not viable for
many low-resource languages for which abundant multi-speaker data is not
available. In this paper, we therefore investigated to what extent multilingual
multi-speaker modeling can be an alternative to monolingual multi-speaker
modeling, and explored how data from foreign languages may best be combined
with low-resource language data. We found that multilingual modeling can
increase the naturalness of low-resource language speech, showed that
multilingual models can produce speech with a naturalness comparable to
monolingual multi-speaker models, and saw that the target language naturalness
was affected by the strategy used to add foreign language data.
","['recent', 'advances', 'neural', 'tts', 'led', 'models', 'produce', 'high-quality', 'synthetic', 'speech', '.', 'however', ',', 'models', 'typically', 'require', 'large', 'amounts', 'training', 'data', ',', 'make', 'costly', 'produce', 'new', 'voice', 'desired', 'quality', '.', 'although', 'multi-speaker', 'modeling', 'reduce', 'data', 'requirements', 'necessary', 'new', 'voice', ',', 'approach', 'usually', 'viable', 'many', 'low-resource', 'languages', 'abundant', 'multi-speaker', 'data', 'available', '.', 'paper', ',', 'therefore', 'investigated', 'extent', 'multilingual', 'multi-speaker', 'modeling', 'alternative', 'monolingual', 'multi-speaker', 'modeling', ',', 'explored', 'data', 'foreign', 'languages', 'may', 'best', 'combined', 'low-resource', 'language', 'data', '.', 'found', 'multilingual', 'modeling', 'increase', 'naturalness', 'low-resource', 'language', 'speech', ',', 'showed', 'multilingual', 'models', 'produce', 'speech', 'naturalness', 'comparable', 'monolingual', 'multi-speaker', 'models', ',', 'saw', 'target', 'language', 'naturalness', 'affected', 'strategy', 'used', 'add', 'foreign', 'language', 'data', '.']","recent, advances, neural, tts, led, models, produce, high-quality, synthetic, speech, ., however, ,, models, typically, require, large, amounts, training, data, ,, make, costly, produce, new, voice, desired, quality, ., although, multi-speaker, modeling, reduce, data, requirements, necessary, new, voice, ,, approach, usually, viable, many, low-resource, languages, abundant, multi-speaker, data, available, ., paper, ,, therefore, investigated, extent, multilingual, multi-speaker, modeling, alternative, monolingual, multi-speaker, modeling, ,, explored, data, foreign, languages, may, best, combined, low-resource, language, data, ., found, multilingual, modeling, increase, naturalness, low-resource, language, speech, ,, showed, multilingual, models, produce, speech, naturalness, comparable, monolingual, multi-speaker, models, ,, saw, target, language, naturalness, affected, strategy, used, add, foreign, language, data, ."
"Testing the limits of natural language models for predicting human
  language judgments","Tal Golan, Matthew Siegelman, Nikolaus Kriegeskorte, Christopher Baldassano",2022-04-07T17:12:57Z,"  Neural network language models can serve as computational hypotheses about
how humans process language. We compared the model-human consistency of diverse
language models using a novel experimental approach: controversial sentence
pairs. For each controversial sentence pair, two language models disagree about
which sentence is more likely to occur in natural text. Considering nine
language models (including n-gram, recurrent neural networks, and transformer
models), we created hundreds of such controversial sentence pairs by either
selecting sentences from a corpus or synthetically optimizing sentence pairs to
be highly controversial. Human subjects then provided judgments indicating for
each pair which of the two sentences is more likely. Controversial sentence
pairs proved highly effective at revealing model failures and identifying
models that aligned most closely with human judgments. The most
human-consistent model tested was GPT-2, although experiments also revealed
significant shortcomings of its alignment with human perception.
","['neural', 'network', 'language', 'models', 'serve', 'computational', 'hypotheses', 'humans', 'process', 'language', '.', 'compared', 'model-human', 'consistency', 'diverse', 'language', 'models', 'using', 'novel', 'experimental', 'approach', ':', 'controversial', 'sentence', 'pairs', '.', 'controversial', 'sentence', 'pair', ',', 'two', 'language', 'models', 'disagree', 'sentence', 'likely', 'occur', 'natural', 'text', '.', 'considering', 'nine', 'language', 'models', '(', 'including', 'n-gram', ',', 'recurrent', 'neural', 'networks', ',', 'transformer', 'models', ')', ',', 'created', 'hundreds', 'controversial', 'sentence', 'pairs', 'either', 'selecting', 'sentences', 'corpus', 'synthetically', 'optimizing', 'sentence', 'pairs', 'highly', 'controversial', '.', 'human', 'subjects', 'provided', 'judgments', 'indicating', 'pair', 'two', 'sentences', 'likely', '.', 'controversial', 'sentence', 'pairs', 'proved', 'highly', 'effective', 'revealing', 'model', 'failures', 'identifying', 'models', 'aligned', 'closely', 'human', 'judgments', '.', 'human-consistent', 'model', 'tested', 'gpt-2', ',', 'although', 'experiments', 'also', 'revealed', 'significant', 'shortcomings', 'alignment', 'human', 'perception', '.']","neural, network, language, models, serve, computational, hypotheses, humans, process, language, ., compared, model-human, consistency, diverse, language, models, using, novel, experimental, approach, :, controversial, sentence, pairs, ., controversial, sentence, pair, ,, two, language, models, disagree, sentence, likely, occur, natural, text, ., considering, nine, language, models, (, including, n-gram, ,, recurrent, neural, networks, ,, transformer, models, ), ,, created, hundreds, controversial, sentence, pairs, either, selecting, sentences, corpus, synthetically, optimizing, sentence, pairs, highly, controversial, ., human, subjects, provided, judgments, indicating, pair, two, sentences, likely, ., controversial, sentence, pairs, proved, highly, effective, revealing, model, failures, identifying, models, aligned, closely, human, judgments, ., human-consistent, model, tested, gpt-2, ,, although, experiments, also, revealed, significant, shortcomings, alignment, human, perception, ."
"Is neural language acquisition similar to natural? A chronological
  probing study","Ekaterina Voloshina, Oleg Serikov, Tatiana Shavrina",2022-07-01T17:24:11Z,"  The probing methodology allows one to obtain a partial representation of
linguistic phenomena stored in the inner layers of the neural network, using
external classifiers and statistical analysis. Pre-trained transformer-based
language models are widely used both for natural language understanding (NLU)
and natural language generation (NLG) tasks making them most commonly used for
downstream applications. However, little analysis was carried out, whether the
models were pre-trained enough or contained knowledge correlated with
linguistic theory. We are presenting the chronological probing study of
transformer English models such as MultiBERT and T5. We sequentially compare
the information about the language learned by the models in the process of
training on corpora. The results show that 1) linguistic information is
acquired in the early stages of training 2) both language models demonstrate
capabilities to capture various features from various levels of language,
including morphology, syntax, and even discourse, while they also can
inconsistently fail on tasks that are perceived as easy. We also introduce the
open-source framework for chronological probing research, compatible with other
transformer-based models.
https://github.com/EkaterinaVoloshina/chronological_probing
","['probing', 'methodology', 'allows', 'one', 'obtain', 'partial', 'representation', 'linguistic', 'phenomena', 'stored', 'inner', 'layers', 'neural', 'network', ',', 'using', 'external', 'classifiers', 'statistical', 'analysis', '.', 'pre-trained', 'transformer-based', 'language', 'models', 'widely', 'used', 'natural', 'language', 'understanding', '(', 'nlu', ')', 'natural', 'language', 'generation', '(', 'nlg', ')', 'tasks', 'making', 'commonly', 'used', 'downstream', 'applications', '.', 'however', ',', 'little', 'analysis', 'carried', ',', 'whether', 'models', 'pre-trained', 'enough', 'contained', 'knowledge', 'correlated', 'linguistic', 'theory', '.', 'presenting', 'chronological', 'probing', 'study', 'transformer', 'english', 'models', 'multibert', 't5', '.', 'sequentially', 'compare', 'information', 'language', 'learned', 'models', 'process', 'training', 'corpora', '.', 'results', 'show', '1', ')', 'linguistic', 'information', 'acquired', 'early', 'stages', 'training', '2', ')', 'language', 'models', 'demonstrate', 'capabilities', 'capture', 'various', 'features', 'various', 'levels', 'language', ',', 'including', 'morphology', ',', 'syntax', ',', 'even', 'discourse', ',', 'also', 'inconsistently', 'fail', 'tasks', 'perceived', 'easy', '.', 'also', 'introduce', 'open-source', 'framework', 'chronological', 'probing', 'research', ',', 'compatible', 'transformer-based', 'models', '.', 'https', ':', '//github.com/ekaterinavoloshina/chronological_probing']","probing, methodology, allows, one, obtain, partial, representation, linguistic, phenomena, stored, inner, layers, neural, network, ,, using, external, classifiers, statistical, analysis, ., pre-trained, transformer-based, language, models, widely, used, natural, language, understanding, (, nlu, ), natural, language, generation, (, nlg, ), tasks, making, commonly, used, downstream, applications, ., however, ,, little, analysis, carried, ,, whether, models, pre-trained, enough, contained, knowledge, correlated, linguistic, theory, ., presenting, chronological, probing, study, transformer, english, models, multibert, t5, ., sequentially, compare, information, language, learned, models, process, training, corpora, ., results, show, 1, ), linguistic, information, acquired, early, stages, training, 2, ), language, models, demonstrate, capabilities, capture, various, features, various, levels, language, ,, including, morphology, ,, syntax, ,, even, discourse, ,, also, inconsistently, fail, tasks, perceived, easy, ., also, introduce, open-source, framework, chronological, probing, research, ,, compatible, transformer-based, models, ., https, :, //github.com/ekaterinavoloshina/chronological_probing"
"A No-Code Low-Code Paradigm for Authoring Business Automations Using
  Natural Language","Michael Desmond, Evelyn Duesterwald, Vatche Isahagian, Vinod Muthusamy",2022-07-15T19:17:55Z,"  Most business process automation is still developed using traditional
automation technologies such as workflow engines. These systems provide domain
specific languages that require both business knowledge and programming skills
to effectively use. As such, business users often lack adequate programming
skills to fully leverage these code oriented environments. We propose a
paradigm for the construction of business automations using natural language.
The approach applies a large language model to translate business rules and
automations described in natural language, into a domain specific language
interpretable by a business rule engine. We compare the performance of various
language model configurations, across various target domains, and explore the
use of constrained decoding to ensure syntactically correct generation of
output.
","['business', 'process', 'automation', 'still', 'developed', 'using', 'traditional', 'automation', 'technologies', 'workflow', 'engines', '.', 'systems', 'provide', 'domain', 'specific', 'languages', 'require', 'business', 'knowledge', 'programming', 'skills', 'effectively', 'use', '.', ',', 'business', 'users', 'often', 'lack', 'adequate', 'programming', 'skills', 'fully', 'leverage', 'code', 'oriented', 'environments', '.', 'propose', 'paradigm', 'construction', 'business', 'automations', 'using', 'natural', 'language', '.', 'approach', 'applies', 'large', 'language', 'model', 'translate', 'business', 'rules', 'automations', 'described', 'natural', 'language', ',', 'domain', 'specific', 'language', 'interpretable', 'business', 'rule', 'engine', '.', 'compare', 'performance', 'various', 'language', 'model', 'configurations', ',', 'across', 'various', 'target', 'domains', ',', 'explore', 'use', 'constrained', 'decoding', 'ensure', 'syntactically', 'correct', 'generation', 'output', '.']","business, process, automation, still, developed, using, traditional, automation, technologies, workflow, engines, ., systems, provide, domain, specific, languages, require, business, knowledge, programming, skills, effectively, use, ., ,, business, users, often, lack, adequate, programming, skills, fully, leverage, code, oriented, environments, ., propose, paradigm, construction, business, automations, using, natural, language, ., approach, applies, large, language, model, translate, business, rules, automations, described, natural, language, ,, domain, specific, language, interpretable, business, rule, engine, ., compare, performance, various, language, model, configurations, ,, across, various, target, domains, ,, explore, use, constrained, decoding, ensure, syntactically, correct, generation, output, ."
"Enhancing Language Representation with Constructional Information for
  Natural Language Understanding","Lvxiaowei Xu, Jianwang Wu, Jiawei Peng, Zhilin Gong, Ming Cai, Tianxiang Wang",2023-06-05T12:15:12Z,"  Natural language understanding (NLU) is an essential branch of natural
language processing, which relies on representations generated by pre-trained
language models (PLMs). However, PLMs primarily focus on acquiring
lexico-semantic information, while they may be unable to adequately handle the
meaning of constructions. To address this issue, we introduce construction
grammar (CxG), which highlights the pairings of form and meaning, to enrich
language representation. We adopt usage-based construction grammar as the basis
of our work, which is highly compatible with statistical models such as PLMs.
Then a HyCxG framework is proposed to enhance language representation through a
three-stage solution. First, all constructions are extracted from sentences via
a slot-constraints approach. As constructions can overlap with each other,
bringing redundancy and imbalance, we formulate the conditional max coverage
problem for selecting the discriminative constructions. Finally, we propose a
relational hypergraph attention network to acquire representation from
constructional information by capturing high-order word interactions among
constructions. Extensive experiments demonstrate the superiority of the
proposed model on a variety of NLU tasks.
","['natural', 'language', 'understanding', '(', 'nlu', ')', 'essential', 'branch', 'natural', 'language', 'processing', ',', 'relies', 'representations', 'generated', 'pre-trained', 'language', 'models', '(', 'plms', ')', '.', 'however', ',', 'plms', 'primarily', 'focus', 'acquiring', 'lexico-semantic', 'information', ',', 'may', 'unable', 'adequately', 'handle', 'meaning', 'constructions', '.', 'address', 'issue', ',', 'introduce', 'construction', 'grammar', '(', 'cxg', ')', ',', 'highlights', 'pairings', 'form', 'meaning', ',', 'enrich', 'language', 'representation', '.', 'adopt', 'usage-based', 'construction', 'grammar', 'basis', 'work', ',', 'highly', 'compatible', 'statistical', 'models', 'plms', '.', 'hycxg', 'framework', 'proposed', 'enhance', 'language', 'representation', 'three-stage', 'solution', '.', 'first', ',', 'constructions', 'extracted', 'sentences', 'via', 'slot-constraints', 'approach', '.', 'constructions', 'overlap', ',', 'bringing', 'redundancy', 'imbalance', ',', 'formulate', 'conditional', 'max', 'coverage', 'problem', 'selecting', 'discriminative', 'constructions', '.', 'finally', ',', 'propose', 'relational', 'hypergraph', 'attention', 'network', 'acquire', 'representation', 'constructional', 'information', 'capturing', 'high-order', 'word', 'interactions', 'among', 'constructions', '.', 'extensive', 'experiments', 'demonstrate', 'superiority', 'proposed', 'model', 'variety', 'nlu', 'tasks', '.']","natural, language, understanding, (, nlu, ), essential, branch, natural, language, processing, ,, relies, representations, generated, pre-trained, language, models, (, plms, ), ., however, ,, plms, primarily, focus, acquiring, lexico-semantic, information, ,, may, unable, adequately, handle, meaning, constructions, ., address, issue, ,, introduce, construction, grammar, (, cxg, ), ,, highlights, pairings, form, meaning, ,, enrich, language, representation, ., adopt, usage-based, construction, grammar, basis, work, ,, highly, compatible, statistical, models, plms, ., hycxg, framework, proposed, enhance, language, representation, three-stage, solution, ., first, ,, constructions, extracted, sentences, via, slot-constraints, approach, ., constructions, overlap, ,, bringing, redundancy, imbalance, ,, formulate, conditional, max, coverage, problem, selecting, discriminative, constructions, ., finally, ,, propose, relational, hypergraph, attention, network, acquire, representation, constructional, information, capturing, high-order, word, interactions, among, constructions, ., extensive, experiments, demonstrate, superiority, proposed, model, variety, nlu, tasks, ."
"Lean Workbook: A large-scale Lean problem set formalized from natural
  language math problems","Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, Kai Chen",2024-06-06T08:25:43Z,"  Large language models have demonstrated impressive capabilities across
various natural language processing tasks, especially in solving mathematical
problems. However, large language models are not good at math theorem proving
using formal languages like Lean. A significant challenge in this area is the
scarcity of training data available in these formal languages. To address this
issue, we propose a novel pipeline that iteratively generates and filters
synthetic data to translate natural language mathematical problems into Lean 4
statements, and vice versa. Our results indicate that the synthetic data
pipeline can provide useful training data and improve the performance of LLMs
in translating and understanding complex mathematical problems and proofs. Our
final dataset contains about 57K formal-informal question pairs along with
searched proof from the math contest forum and 21 new IMO questions. We
open-source our code at https://github.com/InternLM/InternLM-Math and our data
at https://huggingface.co/datasets/InternLM/Lean-Workbook.
","['large', 'language', 'models', 'demonstrated', 'impressive', 'capabilities', 'across', 'various', 'natural', 'language', 'processing', 'tasks', ',', 'especially', 'solving', 'mathematical', 'problems', '.', 'however', ',', 'large', 'language', 'models', 'good', 'math', 'theorem', 'proving', 'using', 'formal', 'languages', 'like', 'lean', '.', 'significant', 'challenge', 'area', 'scarcity', 'training', 'data', 'available', 'formal', 'languages', '.', 'address', 'issue', ',', 'propose', 'novel', 'pipeline', 'iteratively', 'generates', 'filters', 'synthetic', 'data', 'translate', 'natural', 'language', 'mathematical', 'problems', 'lean', '4', 'statements', ',', 'vice', 'versa', '.', 'results', 'indicate', 'synthetic', 'data', 'pipeline', 'provide', 'useful', 'training', 'data', 'improve', 'performance', 'llms', 'translating', 'understanding', 'complex', 'mathematical', 'problems', 'proofs', '.', 'final', 'dataset', 'contains', '57k', 'formal-informal', 'question', 'pairs', 'along', 'searched', 'proof', 'math', 'contest', 'forum', '21', 'new', 'imo', 'questions', '.', 'open-source', 'code', 'https', ':', '//github.com/internlm/internlm-math', 'data', 'https', ':', '//huggingface.co/datasets/internlm/lean-workbook', '.']","large, language, models, demonstrated, impressive, capabilities, across, various, natural, language, processing, tasks, ,, especially, solving, mathematical, problems, ., however, ,, large, language, models, good, math, theorem, proving, using, formal, languages, like, lean, ., significant, challenge, area, scarcity, training, data, available, formal, languages, ., address, issue, ,, propose, novel, pipeline, iteratively, generates, filters, synthetic, data, translate, natural, language, mathematical, problems, lean, 4, statements, ,, vice, versa, ., results, indicate, synthetic, data, pipeline, provide, useful, training, data, improve, performance, llms, translating, understanding, complex, mathematical, problems, proofs, ., final, dataset, contains, 57k, formal-informal, question, pairs, along, searched, proof, math, contest, forum, 21, new, imo, questions, ., open-source, code, https, :, //github.com/internlm/internlm-math, data, https, :, //huggingface.co/datasets/internlm/lean-workbook, ."
"Is English the New Programming Language? How About Pseudo-code
  Engineering?","Gian Alexandre Michaelsen, Renato P. dos Santos",2024-04-08T16:28:52Z,"  Background: The integration of artificial intelligence (AI) into daily life,
particularly through chatbots utilizing natural language processing (NLP),
presents both revolutionary potential and unique challenges. This intended to
investigate how different input forms impact ChatGPT, a leading language model
by OpenAI, performance in understanding and executing complex, multi-intention
tasks. Design: Employing a case study methodology supplemented by discourse
analysis, the research analyzes ChatGPT's responses to inputs varying from
natural language to pseudo-code engineering. The study specifically examines
the model's proficiency across four categories: understanding of intentions,
interpretability, completeness, and creativity. Setting and Participants: As a
theoretical exploration of AI interaction, this study focuses on the analysis
of structured and unstructured inputs processed by ChatGPT, without direct
human participants. Data collection and analysis: The research utilizes
synthetic case scenarios, including the organization of a ""weekly meal plan""
and a ""shopping list,"" to assess ChatGPT's response to prompts in both natural
language and pseudo-code engineering. The analysis is grounded in the
identification of patterns, contradictions, and unique response elements across
different input formats. Results: Findings reveal that pseudo-code engineering
inputs significantly enhance the clarity and determinism of ChatGPT's
responses, reducing ambiguity inherent in natural language. Enhanced natural
language, structured through prompt engineering techniques, similarly improves
the model's interpretability and creativity. Conclusions: The study underscores
the potential of pseudo-code engineering in refining human-AI interaction and
achieving more deterministic, concise, and direct outcomes, advocating for its
broader application across disciplines requiring precise AI responses.
","['background', ':', 'integration', 'artificial', 'intelligence', '(', 'ai', ')', 'daily', 'life', ',', 'particularly', 'chatbots', 'utilizing', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'presents', 'revolutionary', 'potential', 'unique', 'challenges', '.', 'intended', 'investigate', 'different', 'input', 'forms', 'impact', 'chatgpt', ',', 'leading', 'language', 'model', 'openai', ',', 'performance', 'understanding', 'executing', 'complex', ',', 'multi-intention', 'tasks', '.', 'design', ':', 'employing', 'case', 'study', 'methodology', 'supplemented', 'discourse', 'analysis', ',', 'research', 'analyzes', 'chatgpt', ""'s"", 'responses', 'inputs', 'varying', 'natural', 'language', 'pseudo-code', 'engineering', '.', 'study', 'specifically', 'examines', 'model', ""'s"", 'proficiency', 'across', 'four', 'categories', ':', 'understanding', 'intentions', ',', 'interpretability', ',', 'completeness', ',', 'creativity', '.', 'setting', 'participants', ':', 'theoretical', 'exploration', 'ai', 'interaction', ',', 'study', 'focuses', 'analysis', 'structured', 'unstructured', 'inputs', 'processed', 'chatgpt', ',', 'without', 'direct', 'human', 'participants', '.', 'data', 'collection', 'analysis', ':', 'research', 'utilizes', 'synthetic', 'case', 'scenarios', ',', 'including', 'organization', '``', 'weekly', 'meal', 'plan', ""''"", '``', 'shopping', 'list', ',', ""''"", 'assess', 'chatgpt', ""'s"", 'response', 'prompts', 'natural', 'language', 'pseudo-code', 'engineering', '.', 'analysis', 'grounded', 'identification', 'patterns', ',', 'contradictions', ',', 'unique', 'response', 'elements', 'across', 'different', 'input', 'formats', '.', 'results', ':', 'findings', 'reveal', 'pseudo-code', 'engineering', 'inputs', 'significantly', 'enhance', 'clarity', 'determinism', 'chatgpt', ""'s"", 'responses', ',', 'reducing', 'ambiguity', 'inherent', 'natural', 'language', '.', 'enhanced', 'natural', 'language', ',', 'structured', 'prompt', 'engineering', 'techniques', ',', 'similarly', 'improves', 'model', ""'s"", 'interpretability', 'creativity', '.', 'conclusions', ':', 'study', 'underscores', 'potential', 'pseudo-code', 'engineering', 'refining', 'human-ai', 'interaction', 'achieving', 'deterministic', ',', 'concise', ',', 'direct', 'outcomes', ',', 'advocating', 'broader', 'application', 'across', 'disciplines', 'requiring', 'precise', 'ai', 'responses', '.']","background, :, integration, artificial, intelligence, (, ai, ), daily, life, ,, particularly, chatbots, utilizing, natural, language, processing, (, nlp, ), ,, presents, revolutionary, potential, unique, challenges, ., intended, investigate, different, input, forms, impact, chatgpt, ,, leading, language, model, openai, ,, performance, understanding, executing, complex, ,, multi-intention, tasks, ., design, :, employing, case, study, methodology, supplemented, discourse, analysis, ,, research, analyzes, chatgpt, 's, responses, inputs, varying, natural, language, pseudo-code, engineering, ., study, specifically, examines, model, 's, proficiency, across, four, categories, :, understanding, intentions, ,, interpretability, ,, completeness, ,, creativity, ., setting, participants, :, theoretical, exploration, ai, interaction, ,, study, focuses, analysis, structured, unstructured, inputs, processed, chatgpt, ,, without, direct, human, participants, ., data, collection, analysis, :, research, utilizes, synthetic, case, scenarios, ,, including, organization, ``, weekly, meal, plan, '', ``, shopping, list, ,, '', assess, chatgpt, 's, response, prompts, natural, language, pseudo-code, engineering, ., analysis, grounded, identification, patterns, ,, contradictions, ,, unique, response, elements, across, different, input, formats, ., results, :, findings, reveal, pseudo-code, engineering, inputs, significantly, enhance, clarity, determinism, chatgpt, 's, responses, ,, reducing, ambiguity, inherent, natural, language, ., enhanced, natural, language, ,, structured, prompt, engineering, techniques, ,, similarly, improves, model, 's, interpretability, creativity, ., conclusions, :, study, underscores, potential, pseudo-code, engineering, refining, human-ai, interaction, achieving, deterministic, ,, concise, ,, direct, outcomes, ,, advocating, broader, application, across, disciplines, requiring, precise, ai, responses, ."
"AI-based Question Answering Assistance for Analyzing Natural-language
  Requirements","Saad Ezzini, Sallam Abualhaija, Chetan Arora, Mehrdad Sabetzadeh",2023-02-09T17:31:46Z,"  By virtue of being prevalently written in natural language (NL), requirements
are prone to various defects, e.g., inconsistency and incompleteness. As such,
requirements are frequently subject to quality assurance processes. These
processes, when carried out entirely manually, are tedious and may further
overlook important quality issues due to time and budget pressures. In this
paper, we propose QAssist -- a question-answering (QA) approach that provides
automated assistance to stakeholders, including requirements engineers, during
the analysis of NL requirements. Posing a question and getting an instant
answer is beneficial in various quality-assurance scenarios, e.g.,
incompleteness detection. Answering requirements-related questions
automatically is challenging since the scope of the search for answers can go
beyond the given requirements specification. To that end, QAssist provides
support for mining external domain-knowledge resources. Our work is one of the
first initiatives to bring together QA and external domain knowledge for
addressing requirements engineering challenges. We evaluate QAssist on a
dataset covering three application domains and containing a total of 387
question-answer pairs. We experiment with state-of-the-art QA methods, based
primarily on recent large-scale language models. In our empirical study,
QAssist localizes the answer to a question to three passages within the
requirements specification and within the external domain-knowledge resource
with an average recall of 90.1% and 96.5%, respectively. QAssist extracts the
actual answer to the posed question with an average accuracy of 84.2%.
  Keywords: Natural-language Requirements, Question Answering (QA), Language
Models, Natural Language Processing (NLP), Natural Language Generation (NLG),
BERT, T5.
","['virtue', 'prevalently', 'written', 'natural', 'language', '(', 'nl', ')', ',', 'requirements', 'prone', 'various', 'defects', ',', 'e.g.', ',', 'inconsistency', 'incompleteness', '.', ',', 'requirements', 'frequently', 'subject', 'quality', 'assurance', 'processes', '.', 'processes', ',', 'carried', 'entirely', 'manually', ',', 'tedious', 'may', 'overlook', 'important', 'quality', 'issues', 'due', 'time', 'budget', 'pressures', '.', 'paper', ',', 'propose', 'qassist', '--', 'question-answering', '(', 'qa', ')', 'approach', 'provides', 'automated', 'assistance', 'stakeholders', ',', 'including', 'requirements', 'engineers', ',', 'analysis', 'nl', 'requirements', '.', 'posing', 'question', 'getting', 'instant', 'answer', 'beneficial', 'various', 'quality-assurance', 'scenarios', ',', 'e.g.', ',', 'incompleteness', 'detection', '.', 'answering', 'requirements-related', 'questions', 'automatically', 'challenging', 'since', 'scope', 'search', 'answers', 'go', 'beyond', 'given', 'requirements', 'specification', '.', 'end', ',', 'qassist', 'provides', 'support', 'mining', 'external', 'domain-knowledge', 'resources', '.', 'work', 'one', 'first', 'initiatives', 'bring', 'together', 'qa', 'external', 'domain', 'knowledge', 'addressing', 'requirements', 'engineering', 'challenges', '.', 'evaluate', 'qassist', 'dataset', 'covering', 'three', 'application', 'domains', 'containing', 'total', '387', 'question-answer', 'pairs', '.', 'experiment', 'state-of-the-art', 'qa', 'methods', ',', 'based', 'primarily', 'recent', 'large-scale', 'language', 'models', '.', 'empirical', 'study', ',', 'qassist', 'localizes', 'answer', 'question', 'three', 'passages', 'within', 'requirements', 'specification', 'within', 'external', 'domain-knowledge', 'resource', 'average', 'recall', '90.1', '%', '96.5', '%', ',', 'respectively', '.', 'qassist', 'extracts', 'actual', 'answer', 'posed', 'question', 'average', 'accuracy', '84.2', '%', '.', 'keywords', ':', 'natural-language', 'requirements', ',', 'question', 'answering', '(', 'qa', ')', ',', 'language', 'models', ',', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'natural', 'language', 'generation', '(', 'nlg', ')', ',', 'bert', ',', 't5', '.']","virtue, prevalently, written, natural, language, (, nl, ), ,, requirements, prone, various, defects, ,, e.g., ,, inconsistency, incompleteness, ., ,, requirements, frequently, subject, quality, assurance, processes, ., processes, ,, carried, entirely, manually, ,, tedious, may, overlook, important, quality, issues, due, time, budget, pressures, ., paper, ,, propose, qassist, --, question-answering, (, qa, ), approach, provides, automated, assistance, stakeholders, ,, including, requirements, engineers, ,, analysis, nl, requirements, ., posing, question, getting, instant, answer, beneficial, various, quality-assurance, scenarios, ,, e.g., ,, incompleteness, detection, ., answering, requirements-related, questions, automatically, challenging, since, scope, search, answers, go, beyond, given, requirements, specification, ., end, ,, qassist, provides, support, mining, external, domain-knowledge, resources, ., work, one, first, initiatives, bring, together, qa, external, domain, knowledge, addressing, requirements, engineering, challenges, ., evaluate, qassist, dataset, covering, three, application, domains, containing, total, 387, question-answer, pairs, ., experiment, state-of-the-art, qa, methods, ,, based, primarily, recent, large-scale, language, models, ., empirical, study, ,, qassist, localizes, answer, question, three, passages, within, requirements, specification, within, external, domain-knowledge, resource, average, recall, 90.1, %, 96.5, %, ,, respectively, ., qassist, extracts, actual, answer, posed, question, average, accuracy, 84.2, %, ., keywords, :, natural-language, requirements, ,, question, answering, (, qa, ), ,, language, models, ,, natural, language, processing, (, nlp, ), ,, natural, language, generation, (, nlg, ), ,, bert, ,, t5, ."
Learning to Compress Prompt in Natural Language Formats,"Yu-Neng Chuang, Tianwei Xing, Chia-Yuan Chang, Zirui Liu, Xun Chen, Xia Hu",2024-02-28T20:41:21Z,"  Large language models (LLMs) are great at processing multiple natural
language processing tasks, but their abilities are constrained by inferior
performance with long context, slow inference speed, and the high cost of
computing the results. Deploying LLMs with precise and informative context
helps users process large-scale datasets more effectively and cost-efficiently.
Existing works rely on compressing long prompt contexts into soft prompts.
However, soft prompt compression encounters limitations in transferability
across different LLMs, especially API-based LLMs. To this end, this work aims
to compress lengthy prompts in the form of natural language with LLM
transferability. This poses two challenges: (i) Natural Language (NL) prompts
are incompatible with back-propagation, and (ii) NL prompts lack flexibility in
imposing length constraints. In this work, we propose a Natural Language Prompt
Encapsulation (Nano-Capsulator) framework compressing original prompts into NL
formatted Capsule Prompt while maintaining the prompt utility and
transferability. Specifically, to tackle the first challenge, the
Nano-Capsulator is optimized by a reward function that interacts with the
proposed semantics preserving loss. To address the second question, the
Nano-Capsulator is optimized by a reward function featuring length constraints.
Experimental results demonstrate that the Capsule Prompt can reduce 81.4% of
the original length, decrease inference latency up to 4.5x, and save 80.1% of
budget overheads while providing transferability across diverse LLMs and
different datasets.
","['large', 'language', 'models', '(', 'llms', ')', 'great', 'processing', 'multiple', 'natural', 'language', 'processing', 'tasks', ',', 'abilities', 'constrained', 'inferior', 'performance', 'long', 'context', ',', 'slow', 'inference', 'speed', ',', 'high', 'cost', 'computing', 'results', '.', 'deploying', 'llms', 'precise', 'informative', 'context', 'helps', 'users', 'process', 'large-scale', 'datasets', 'effectively', 'cost-efficiently', '.', 'existing', 'works', 'rely', 'compressing', 'long', 'prompt', 'contexts', 'soft', 'prompts', '.', 'however', ',', 'soft', 'prompt', 'compression', 'encounters', 'limitations', 'transferability', 'across', 'different', 'llms', ',', 'especially', 'api-based', 'llms', '.', 'end', ',', 'work', 'aims', 'compress', 'lengthy', 'prompts', 'form', 'natural', 'language', 'llm', 'transferability', '.', 'poses', 'two', 'challenges', ':', '(', ')', 'natural', 'language', '(', 'nl', ')', 'prompts', 'incompatible', 'back-propagation', ',', '(', 'ii', ')', 'nl', 'prompts', 'lack', 'flexibility', 'imposing', 'length', 'constraints', '.', 'work', ',', 'propose', 'natural', 'language', 'prompt', 'encapsulation', '(', 'nano-capsulator', ')', 'framework', 'compressing', 'original', 'prompts', 'nl', 'formatted', 'capsule', 'prompt', 'maintaining', 'prompt', 'utility', 'transferability', '.', 'specifically', ',', 'tackle', 'first', 'challenge', ',', 'nano-capsulator', 'optimized', 'reward', 'function', 'interacts', 'proposed', 'semantics', 'preserving', 'loss', '.', 'address', 'second', 'question', ',', 'nano-capsulator', 'optimized', 'reward', 'function', 'featuring', 'length', 'constraints', '.', 'experimental', 'results', 'demonstrate', 'capsule', 'prompt', 'reduce', '81.4', '%', 'original', 'length', ',', 'decrease', 'inference', 'latency', '4.5x', ',', 'save', '80.1', '%', 'budget', 'overheads', 'providing', 'transferability', 'across', 'diverse', 'llms', 'different', 'datasets', '.']","large, language, models, (, llms, ), great, processing, multiple, natural, language, processing, tasks, ,, abilities, constrained, inferior, performance, long, context, ,, slow, inference, speed, ,, high, cost, computing, results, ., deploying, llms, precise, informative, context, helps, users, process, large-scale, datasets, effectively, cost-efficiently, ., existing, works, rely, compressing, long, prompt, contexts, soft, prompts, ., however, ,, soft, prompt, compression, encounters, limitations, transferability, across, different, llms, ,, especially, api-based, llms, ., end, ,, work, aims, compress, lengthy, prompts, form, natural, language, llm, transferability, ., poses, two, challenges, :, (, ), natural, language, (, nl, ), prompts, incompatible, back-propagation, ,, (, ii, ), nl, prompts, lack, flexibility, imposing, length, constraints, ., work, ,, propose, natural, language, prompt, encapsulation, (, nano-capsulator, ), framework, compressing, original, prompts, nl, formatted, capsule, prompt, maintaining, prompt, utility, transferability, ., specifically, ,, tackle, first, challenge, ,, nano-capsulator, optimized, reward, function, interacts, proposed, semantics, preserving, loss, ., address, second, question, ,, nano-capsulator, optimized, reward, function, featuring, length, constraints, ., experimental, results, demonstrate, capsule, prompt, reduce, 81.4, %, original, length, ,, decrease, inference, latency, 4.5x, ,, save, 80.1, %, budget, overheads, providing, transferability, across, diverse, llms, different, datasets, ."
"ScispaCy: Fast and Robust Models for Biomedical Natural Language
  Processing","Mark Neumann, Daniel King, Iz Beltagy, Waleed Ammar",2019-02-20T17:28:51Z,"  Despite recent advances in natural language processing, many statistical
models for processing text perform extremely poorly under domain shift.
Processing biomedical and clinical text is a critically important application
area of natural language processing, for which there are few robust, practical,
publicly available models. This paper describes scispaCy, a new tool for
practical biomedical/scientific text processing, which heavily leverages the
spaCy library. We detail the performance of two packages of models released in
scispaCy and demonstrate their robustness on several tasks and datasets. Models
and code are available at https://allenai.github.io/scispacy/
","['despite', 'recent', 'advances', 'natural', 'language', 'processing', ',', 'many', 'statistical', 'models', 'processing', 'text', 'perform', 'extremely', 'poorly', 'domain', 'shift', '.', 'processing', 'biomedical', 'clinical', 'text', 'critically', 'important', 'application', 'area', 'natural', 'language', 'processing', ',', 'robust', ',', 'practical', ',', 'publicly', 'available', 'models', '.', 'paper', 'describes', 'scispacy', ',', 'new', 'tool', 'practical', 'biomedical/scientific', 'text', 'processing', ',', 'heavily', 'leverages', 'spacy', 'library', '.', 'detail', 'performance', 'two', 'packages', 'models', 'released', 'scispacy', 'demonstrate', 'robustness', 'several', 'tasks', 'datasets', '.', 'models', 'code', 'available', 'https', ':', '//allenai.github.io/scispacy/']","despite, recent, advances, natural, language, processing, ,, many, statistical, models, processing, text, perform, extremely, poorly, domain, shift, ., processing, biomedical, clinical, text, critically, important, application, area, natural, language, processing, ,, robust, ,, practical, ,, publicly, available, models, ., paper, describes, scispacy, ,, new, tool, practical, biomedical/scientific, text, processing, ,, heavily, leverages, spacy, library, ., detail, performance, two, packages, models, released, scispacy, demonstrate, robustness, several, tasks, datasets, ., models, code, available, https, :, //allenai.github.io/scispacy/"
Large-scale photonic natural language processing,"Carlo Michele Valensise, Ivana Grecco, Davide Pierangeli, Claudio Conti",2022-08-29T14:52:05Z,"  Modern machine learning applications require huge artificial networks
demanding in computational power and memory. Light-based platforms promise
ultra-fast and energy-efficient hardware, which may help in realizing
next-generation data processing devices. However, current photonic networks are
limited by the number of input-output nodes that can be processed in a single
shot. This restricted network capacity prevents their application to relevant
large-scale problems such as natural language processing. Here, we realize a
photonic processor with a capacity exceeding $1.5 \times 10^{10}$ optical
nodes, more than one order of magnitude larger than any previous
implementation, which enables photonic large-scale text encoding and
classification. By exploiting the full three-dimensional structure of the
optical field propagating in free space, we overcome the interpolation
threshold and reach the over-parametrized region of machine learning, a
condition that allows high-performance natural language processing with a
minimal fraction of training points. Our results provide a novel solution to
scale-up light-driven computing and open the route to photonic language
processing.
","['modern', 'machine', 'learning', 'applications', 'require', 'huge', 'artificial', 'networks', 'demanding', 'computational', 'power', 'memory', '.', 'light-based', 'platforms', 'promise', 'ultra-fast', 'energy-efficient', 'hardware', ',', 'may', 'help', 'realizing', 'next-generation', 'data', 'processing', 'devices', '.', 'however', ',', 'current', 'photonic', 'networks', 'limited', 'number', 'input-output', 'nodes', 'processed', 'single', 'shot', '.', 'restricted', 'network', 'capacity', 'prevents', 'application', 'relevant', 'large-scale', 'problems', 'natural', 'language', 'processing', '.', ',', 'realize', 'photonic', 'processor', 'capacity', 'exceeding', '$', '1.5', '\\times', '10^', '{', '10', '}', '$', 'optical', 'nodes', ',', 'one', 'order', 'magnitude', 'larger', 'previous', 'implementation', ',', 'enables', 'photonic', 'large-scale', 'text', 'encoding', 'classification', '.', 'exploiting', 'full', 'three-dimensional', 'structure', 'optical', 'field', 'propagating', 'free', 'space', ',', 'overcome', 'interpolation', 'threshold', 'reach', 'over-parametrized', 'region', 'machine', 'learning', ',', 'condition', 'allows', 'high-performance', 'natural', 'language', 'processing', 'minimal', 'fraction', 'training', 'points', '.', 'results', 'provide', 'novel', 'solution', 'scale-up', 'light-driven', 'computing', 'open', 'route', 'photonic', 'language', 'processing', '.']","modern, machine, learning, applications, require, huge, artificial, networks, demanding, computational, power, memory, ., light-based, platforms, promise, ultra-fast, energy-efficient, hardware, ,, may, help, realizing, next-generation, data, processing, devices, ., however, ,, current, photonic, networks, limited, number, input-output, nodes, processed, single, shot, ., restricted, network, capacity, prevents, application, relevant, large-scale, problems, natural, language, processing, ., ,, realize, photonic, processor, capacity, exceeding, $, 1.5, \times, 10^, {, 10, }, $, optical, nodes, ,, one, order, magnitude, larger, previous, implementation, ,, enables, photonic, large-scale, text, encoding, classification, ., exploiting, full, three-dimensional, structure, optical, field, propagating, free, space, ,, overcome, interpolation, threshold, reach, over-parametrized, region, machine, learning, ,, condition, allows, high-performance, natural, language, processing, minimal, fraction, training, points, ., results, provide, novel, solution, scale-up, light-driven, computing, open, route, photonic, language, processing, ."
Deep Learning Models to Study Sentence Comprehension in the Human Brain,"Sophie Arana, Jacques Pesnot Lerousseau, Peter Hagoort",2023-01-16T10:31:25Z,"  Recent artificial neural networks that process natural language achieve
unprecedented performance in tasks requiring sentence-level understanding. As
such, they could be interesting models of the integration of linguistic
information in the human brain. We review works that compare these artificial
language models with human brain activity and we assess the extent to which
this approach has improved our understanding of the neural processes involved
in natural language comprehension. Two main results emerge. First, the neural
representation of word meaning aligns with the context-dependent, dense word
vectors used by the artificial neural networks. Second, the processing
hierarchy that emerges within artificial neural networks broadly matches the
brain, but is surprisingly inconsistent across studies. We discuss current
challenges in establishing artificial neural networks as process models of
natural language comprehension. We suggest exploiting the highly structured
representational geometry of artificial neural networks when mapping
representations to brain data.
","['recent', 'artificial', 'neural', 'networks', 'process', 'natural', 'language', 'achieve', 'unprecedented', 'performance', 'tasks', 'requiring', 'sentence-level', 'understanding', '.', ',', 'could', 'interesting', 'models', 'integration', 'linguistic', 'information', 'human', 'brain', '.', 'review', 'works', 'compare', 'artificial', 'language', 'models', 'human', 'brain', 'activity', 'assess', 'extent', 'approach', 'improved', 'understanding', 'neural', 'processes', 'involved', 'natural', 'language', 'comprehension', '.', 'two', 'main', 'results', 'emerge', '.', 'first', ',', 'neural', 'representation', 'word', 'meaning', 'aligns', 'context-dependent', ',', 'dense', 'word', 'vectors', 'used', 'artificial', 'neural', 'networks', '.', 'second', ',', 'processing', 'hierarchy', 'emerges', 'within', 'artificial', 'neural', 'networks', 'broadly', 'matches', 'brain', ',', 'surprisingly', 'inconsistent', 'across', 'studies', '.', 'discuss', 'current', 'challenges', 'establishing', 'artificial', 'neural', 'networks', 'process', 'models', 'natural', 'language', 'comprehension', '.', 'suggest', 'exploiting', 'highly', 'structured', 'representational', 'geometry', 'artificial', 'neural', 'networks', 'mapping', 'representations', 'brain', 'data', '.']","recent, artificial, neural, networks, process, natural, language, achieve, unprecedented, performance, tasks, requiring, sentence-level, understanding, ., ,, could, interesting, models, integration, linguistic, information, human, brain, ., review, works, compare, artificial, language, models, human, brain, activity, assess, extent, approach, improved, understanding, neural, processes, involved, natural, language, comprehension, ., two, main, results, emerge, ., first, ,, neural, representation, word, meaning, aligns, context-dependent, ,, dense, word, vectors, used, artificial, neural, networks, ., second, ,, processing, hierarchy, emerges, within, artificial, neural, networks, broadly, matches, brain, ,, surprisingly, inconsistent, across, studies, ., discuss, current, challenges, establishing, artificial, neural, networks, process, models, natural, language, comprehension, ., suggest, exploiting, highly, structured, representational, geometry, artificial, neural, networks, mapping, representations, brain, data, ."
Exploring Language Similarities with Dimensionality Reduction Technique,Sangarshanan Veeraraghavan,2019-02-16T11:27:21Z,"  In recent years several novel models were developed to process natural
language, development of accurate language translation systems have helped us
overcome geographical barriers and communicate ideas effectively. These models
are developed mostly for a few languages that are widely used while other
languages are ignored. Most of the languages that are spoken share lexical,
syntactic and sematic similarity with several other languages and knowing this
can help us leverage the existing model to build more specific and accurate
models that can be used for other languages, so here I have explored the idea
of representing several known popular languages in a lower dimension such that
their similarities can be visualized using simple 2 dimensional plots. This can
even help us understand newly discovered languages that may not share its
vocabulary with any of the existing languages.
","['recent', 'years', 'several', 'novel', 'models', 'developed', 'process', 'natural', 'language', ',', 'development', 'accurate', 'language', 'translation', 'systems', 'helped', 'us', 'overcome', 'geographical', 'barriers', 'communicate', 'ideas', 'effectively', '.', 'models', 'developed', 'mostly', 'languages', 'widely', 'used', 'languages', 'ignored', '.', 'languages', 'spoken', 'share', 'lexical', ',', 'syntactic', 'sematic', 'similarity', 'several', 'languages', 'knowing', 'help', 'us', 'leverage', 'existing', 'model', 'build', 'specific', 'accurate', 'models', 'used', 'languages', ',', 'explored', 'idea', 'representing', 'several', 'known', 'popular', 'languages', 'lower', 'dimension', 'similarities', 'visualized', 'using', 'simple', '2', 'dimensional', 'plots', '.', 'even', 'help', 'us', 'understand', 'newly', 'discovered', 'languages', 'may', 'share', 'vocabulary', 'existing', 'languages', '.']","recent, years, several, novel, models, developed, process, natural, language, ,, development, accurate, language, translation, systems, helped, us, overcome, geographical, barriers, communicate, ideas, effectively, ., models, developed, mostly, languages, widely, used, languages, ignored, ., languages, spoken, share, lexical, ,, syntactic, sematic, similarity, several, languages, knowing, help, us, leverage, existing, model, build, specific, accurate, models, used, languages, ,, explored, idea, representing, several, known, popular, languages, lower, dimension, similarities, visualized, using, simple, 2, dimensional, plots, ., even, help, us, understand, newly, discovered, languages, may, share, vocabulary, existing, languages, ."
"On the Language-specificity of Multilingual BERT and the Impact of
  Fine-tuning","Marc Tanti, Lonneke van der Plas, Claudia Borg, Albert Gatt",2021-09-14T19:28:31Z,"  Recent work has shown evidence that the knowledge acquired by multilingual
BERT (mBERT) has two components: a language-specific and a language-neutral
one. This paper analyses the relationship between them, in the context of
fine-tuning on two tasks -- POS tagging and natural language inference -- which
require the model to bring to bear different degrees of language-specific
knowledge. Visualisations reveal that mBERT loses the ability to cluster
representations by language after fine-tuning, a result that is supported by
evidence from language identification experiments. However, further experiments
on 'unlearning' language-specific representations using gradient reversal and
iterative adversarial learning are shown not to add further improvement to the
language-independent component over and above the effect of fine-tuning. The
results presented here suggest that the process of fine-tuning causes a
reorganisation of the model's limited representational capacity, enhancing
language-independent representations at the expense of language-specific ones.
","['recent', 'work', 'shown', 'evidence', 'knowledge', 'acquired', 'multilingual', 'bert', '(', 'mbert', ')', 'two', 'components', ':', 'language-specific', 'language-neutral', 'one', '.', 'paper', 'analyses', 'relationship', ',', 'context', 'fine-tuning', 'two', 'tasks', '--', 'pos', 'tagging', 'natural', 'language', 'inference', '--', 'require', 'model', 'bring', 'bear', 'different', 'degrees', 'language-specific', 'knowledge', '.', 'visualisations', 'reveal', 'mbert', 'loses', 'ability', 'cluster', 'representations', 'language', 'fine-tuning', ',', 'result', 'supported', 'evidence', 'language', 'identification', 'experiments', '.', 'however', ',', 'experiments', ""'unlearning"", ""'"", 'language-specific', 'representations', 'using', 'gradient', 'reversal', 'iterative', 'adversarial', 'learning', 'shown', 'add', 'improvement', 'language-independent', 'component', 'effect', 'fine-tuning', '.', 'results', 'presented', 'suggest', 'process', 'fine-tuning', 'causes', 'reorganisation', 'model', ""'s"", 'limited', 'representational', 'capacity', ',', 'enhancing', 'language-independent', 'representations', 'expense', 'language-specific', 'ones', '.']","recent, work, shown, evidence, knowledge, acquired, multilingual, bert, (, mbert, ), two, components, :, language-specific, language-neutral, one, ., paper, analyses, relationship, ,, context, fine-tuning, two, tasks, --, pos, tagging, natural, language, inference, --, require, model, bring, bear, different, degrees, language-specific, knowledge, ., visualisations, reveal, mbert, loses, ability, cluster, representations, language, fine-tuning, ,, result, supported, evidence, language, identification, experiments, ., however, ,, experiments, 'unlearning, ', language-specific, representations, using, gradient, reversal, iterative, adversarial, learning, shown, add, improvement, language-independent, component, effect, fine-tuning, ., results, presented, suggest, process, fine-tuning, causes, reorganisation, model, 's, limited, representational, capacity, ,, enhancing, language-independent, representations, expense, language-specific, ones, ."
"What a Creole Wants, What a Creole Needs","Heather Lent, Kelechi Ogueji, Miryam de Lhoneux, Orevaoghene Ahia, Anders Søgaard",2022-06-01T12:22:34Z,"  In recent years, the natural language processing (NLP) community has given
increased attention to the disparity of efforts directed towards high-resource
languages over low-resource ones. Efforts to remedy this delta often begin with
translations of existing English datasets into other languages. However, this
approach ignores that different language communities have different needs. We
consider a group of low-resource languages, Creole languages. Creoles are both
largely absent from the NLP literature, and also often ignored by society at
large due to stigma, despite these languages having sizable and vibrant
communities. We demonstrate, through conversations with Creole experts and
surveys of Creole-speaking communities, how the things needed from language
technology can change dramatically from one language to another, even when the
languages are considered to be very similar to each other, as with Creoles. We
discuss the prominent themes arising from these conversations, and ultimately
demonstrate that useful language technology cannot be built without involving
the relevant community.
","['recent', 'years', ',', 'natural', 'language', 'processing', '(', 'nlp', ')', 'community', 'given', 'increased', 'attention', 'disparity', 'efforts', 'directed', 'towards', 'high-resource', 'languages', 'low-resource', 'ones', '.', 'efforts', 'remedy', 'delta', 'often', 'begin', 'translations', 'existing', 'english', 'datasets', 'languages', '.', 'however', ',', 'approach', 'ignores', 'different', 'language', 'communities', 'different', 'needs', '.', 'consider', 'group', 'low-resource', 'languages', ',', 'creole', 'languages', '.', 'creoles', 'largely', 'absent', 'nlp', 'literature', ',', 'also', 'often', 'ignored', 'society', 'large', 'due', 'stigma', ',', 'despite', 'languages', 'sizable', 'vibrant', 'communities', '.', 'demonstrate', ',', 'conversations', 'creole', 'experts', 'surveys', 'creole-speaking', 'communities', ',', 'things', 'needed', 'language', 'technology', 'change', 'dramatically', 'one', 'language', 'another', ',', 'even', 'languages', 'considered', 'similar', ',', 'creoles', '.', 'discuss', 'prominent', 'themes', 'arising', 'conversations', ',', 'ultimately', 'demonstrate', 'useful', 'language', 'technology', 'built', 'without', 'involving', 'relevant', 'community', '.']","recent, years, ,, natural, language, processing, (, nlp, ), community, given, increased, attention, disparity, efforts, directed, towards, high-resource, languages, low-resource, ones, ., efforts, remedy, delta, often, begin, translations, existing, english, datasets, languages, ., however, ,, approach, ignores, different, language, communities, different, needs, ., consider, group, low-resource, languages, ,, creole, languages, ., creoles, largely, absent, nlp, literature, ,, also, often, ignored, society, large, due, stigma, ,, despite, languages, sizable, vibrant, communities, ., demonstrate, ,, conversations, creole, experts, surveys, creole-speaking, communities, ,, things, needed, language, technology, change, dramatically, one, language, another, ,, even, languages, considered, similar, ,, creoles, ., discuss, prominent, themes, arising, conversations, ,, ultimately, demonstrate, useful, language, technology, built, without, involving, relevant, community, ."
"LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine
  Translation","Hongcheng Guo, Jiaheng Liu, Haoyang Huang, Jian Yang, Zhoujun Li, Dongdong Zhang, Zheng Cui, Furu Wei",2022-10-19T12:21:39Z,"  Multimodal Machine Translation (MMT) focuses on enhancing text-only
translation with visual features, which has attracted considerable attention
from both natural language processing and computer vision communities. Recent
advances still struggle to train a separate model for each language pair, which
is costly and unaffordable when the number of languages increases in the real
world. In other words, the multilingual multimodal machine translation
(Multilingual MMT) task has not been investigated, which aims to handle the
aforementioned issues by providing a shared semantic space for multiple
languages. Besides, the image modality has no language boundaries, which is
superior to bridging the semantic gap between languages. To this end, we first
propose the Multilingual MMT task by establishing two new Multilingual MMT
benchmark datasets covering seven languages. Then, an effective baseline LVP-M3
using visual prompts is proposed to support translations between different
languages, which includes three stages (token encoding, language-aware visual
prompt generation, and language translation). Extensive experimental results on
our constructed benchmark datasets demonstrate the effectiveness of LVP-M3
method for Multilingual MMT.
","['multimodal', 'machine', 'translation', '(', 'mmt', ')', 'focuses', 'enhancing', 'text-only', 'translation', 'visual', 'features', ',', 'attracted', 'considerable', 'attention', 'natural', 'language', 'processing', 'computer', 'vision', 'communities', '.', 'recent', 'advances', 'still', 'struggle', 'train', 'separate', 'model', 'language', 'pair', ',', 'costly', 'unaffordable', 'number', 'languages', 'increases', 'real', 'world', '.', 'words', ',', 'multilingual', 'multimodal', 'machine', 'translation', '(', 'multilingual', 'mmt', ')', 'task', 'investigated', ',', 'aims', 'handle', 'aforementioned', 'issues', 'providing', 'shared', 'semantic', 'space', 'multiple', 'languages', '.', 'besides', ',', 'image', 'modality', 'language', 'boundaries', ',', 'superior', 'bridging', 'semantic', 'gap', 'languages', '.', 'end', ',', 'first', 'propose', 'multilingual', 'mmt', 'task', 'establishing', 'two', 'new', 'multilingual', 'mmt', 'benchmark', 'datasets', 'covering', 'seven', 'languages', '.', ',', 'effective', 'baseline', 'lvp-m3', 'using', 'visual', 'prompts', 'proposed', 'support', 'translations', 'different', 'languages', ',', 'includes', 'three', 'stages', '(', 'token', 'encoding', ',', 'language-aware', 'visual', 'prompt', 'generation', ',', 'language', 'translation', ')', '.', 'extensive', 'experimental', 'results', 'constructed', 'benchmark', 'datasets', 'demonstrate', 'effectiveness', 'lvp-m3', 'method', 'multilingual', 'mmt', '.']","multimodal, machine, translation, (, mmt, ), focuses, enhancing, text-only, translation, visual, features, ,, attracted, considerable, attention, natural, language, processing, computer, vision, communities, ., recent, advances, still, struggle, train, separate, model, language, pair, ,, costly, unaffordable, number, languages, increases, real, world, ., words, ,, multilingual, multimodal, machine, translation, (, multilingual, mmt, ), task, investigated, ,, aims, handle, aforementioned, issues, providing, shared, semantic, space, multiple, languages, ., besides, ,, image, modality, language, boundaries, ,, superior, bridging, semantic, gap, languages, ., end, ,, first, propose, multilingual, mmt, task, establishing, two, new, multilingual, mmt, benchmark, datasets, covering, seven, languages, ., ,, effective, baseline, lvp-m3, using, visual, prompts, proposed, support, translations, different, languages, ,, includes, three, stages, (, token, encoding, ,, language-aware, visual, prompt, generation, ,, language, translation, ), ., extensive, experimental, results, constructed, benchmark, datasets, demonstrate, effectiveness, lvp-m3, method, multilingual, mmt, ."
Improve Bilingual TTS Using Dynamic Language and Phonology Embedding,"Fengyu Yang, Jian Luan, Yujun Wang",2022-12-07T03:46:18Z,"  In most cases, bilingual TTS needs to handle three types of input scripts:
first language only, second language only, and second language embedded in the
first language. In the latter two situations, the pronunciation and intonation
of the second language are usually quite different due to the influence of the
first language. Therefore, it is a big challenge to accurately model the
pronunciation and intonation of the second language in different contexts
without mutual interference. This paper builds a Mandarin-English TTS system to
acquire more standard spoken English speech from a monolingual Chinese speaker.
We introduce phonology embedding to capture the English differences between
different phonology. Embedding mask is applied to language embedding for
distinguishing information between different languages and to phonology
embedding for focusing on English expression. We specially design an embedding
strength modulator to capture the dynamic strength of language and phonology.
Experiments show that our approach can produce significantly more natural and
standard spoken English speech of the monolingual Chinese speaker. From
analysis, we find that suitable phonology control contributes to better
performance in different scenarios.
","['cases', ',', 'bilingual', 'tts', 'needs', 'handle', 'three', 'types', 'input', 'scripts', ':', 'first', 'language', ',', 'second', 'language', ',', 'second', 'language', 'embedded', 'first', 'language', '.', 'latter', 'two', 'situations', ',', 'pronunciation', 'intonation', 'second', 'language', 'usually', 'quite', 'different', 'due', 'influence', 'first', 'language', '.', 'therefore', ',', 'big', 'challenge', 'accurately', 'model', 'pronunciation', 'intonation', 'second', 'language', 'different', 'contexts', 'without', 'mutual', 'interference', '.', 'paper', 'builds', 'mandarin-english', 'tts', 'system', 'acquire', 'standard', 'spoken', 'english', 'speech', 'monolingual', 'chinese', 'speaker', '.', 'introduce', 'phonology', 'embedding', 'capture', 'english', 'differences', 'different', 'phonology', '.', 'embedding', 'mask', 'applied', 'language', 'embedding', 'distinguishing', 'information', 'different', 'languages', 'phonology', 'embedding', 'focusing', 'english', 'expression', '.', 'specially', 'design', 'embedding', 'strength', 'modulator', 'capture', 'dynamic', 'strength', 'language', 'phonology', '.', 'experiments', 'show', 'approach', 'produce', 'significantly', 'natural', 'standard', 'spoken', 'english', 'speech', 'monolingual', 'chinese', 'speaker', '.', 'analysis', ',', 'find', 'suitable', 'phonology', 'control', 'contributes', 'better', 'performance', 'different', 'scenarios', '.']","cases, ,, bilingual, tts, needs, handle, three, types, input, scripts, :, first, language, ,, second, language, ,, second, language, embedded, first, language, ., latter, two, situations, ,, pronunciation, intonation, second, language, usually, quite, different, due, influence, first, language, ., therefore, ,, big, challenge, accurately, model, pronunciation, intonation, second, language, different, contexts, without, mutual, interference, ., paper, builds, mandarin-english, tts, system, acquire, standard, spoken, english, speech, monolingual, chinese, speaker, ., introduce, phonology, embedding, capture, english, differences, different, phonology, ., embedding, mask, applied, language, embedding, distinguishing, information, different, languages, phonology, embedding, focusing, english, expression, ., specially, design, embedding, strength, modulator, capture, dynamic, strength, language, phonology, ., experiments, show, approach, produce, significantly, natural, standard, spoken, english, speech, monolingual, chinese, speaker, ., analysis, ,, find, suitable, phonology, control, contributes, better, performance, different, scenarios, ."
On the Applicability of Language Models to Block-Based Programs,"Elisabeth Griebl, Benedikt Fein, Florian Obermüller, Gordon Fraser, René Just",2023-02-08T07:54:25Z,"  Block-based programming languages like Scratch are increasingly popular for
programming education and end-user programming. Recent program analyses build
on the insight that source code can be modelled using techniques from natural
language processing. Many of the regularities of source code that support this
approach are due to the syntactic overhead imposed by textual programming
languages. This syntactic overhead, however, is precisely what block-based
languages remove in order to simplify programming. Consequently, it is unclear
how well this modelling approach performs on block-based programming languages.
In this paper, we investigate the applicability of language models for the
popular block-based programming language Scratch. We model Scratch programs
using n-gram models, the most essential type of language model, and
transformers, a popular deep learning model. Evaluation on the example tasks of
code completion and bug finding confirm that blocks inhibit predictability, but
the use of language models is nevertheless feasible. Our findings serve as
foundation for improving tooling and analyses for block-based languages.
","['block-based', 'programming', 'languages', 'like', 'scratch', 'increasingly', 'popular', 'programming', 'education', 'end-user', 'programming', '.', 'recent', 'program', 'analyses', 'build', 'insight', 'source', 'code', 'modelled', 'using', 'techniques', 'natural', 'language', 'processing', '.', 'many', 'regularities', 'source', 'code', 'support', 'approach', 'due', 'syntactic', 'overhead', 'imposed', 'textual', 'programming', 'languages', '.', 'syntactic', 'overhead', ',', 'however', ',', 'precisely', 'block-based', 'languages', 'remove', 'order', 'simplify', 'programming', '.', 'consequently', ',', 'unclear', 'well', 'modelling', 'approach', 'performs', 'block-based', 'programming', 'languages', '.', 'paper', ',', 'investigate', 'applicability', 'language', 'models', 'popular', 'block-based', 'programming', 'language', 'scratch', '.', 'model', 'scratch', 'programs', 'using', 'n-gram', 'models', ',', 'essential', 'type', 'language', 'model', ',', 'transformers', ',', 'popular', 'deep', 'learning', 'model', '.', 'evaluation', 'example', 'tasks', 'code', 'completion', 'bug', 'finding', 'confirm', 'blocks', 'inhibit', 'predictability', ',', 'use', 'language', 'models', 'nevertheless', 'feasible', '.', 'findings', 'serve', 'foundation', 'improving', 'tooling', 'analyses', 'block-based', 'languages', '.']","block-based, programming, languages, like, scratch, increasingly, popular, programming, education, end-user, programming, ., recent, program, analyses, build, insight, source, code, modelled, using, techniques, natural, language, processing, ., many, regularities, source, code, support, approach, due, syntactic, overhead, imposed, textual, programming, languages, ., syntactic, overhead, ,, however, ,, precisely, block-based, languages, remove, order, simplify, programming, ., consequently, ,, unclear, well, modelling, approach, performs, block-based, programming, languages, ., paper, ,, investigate, applicability, language, models, popular, block-based, programming, language, scratch, ., model, scratch, programs, using, n-gram, models, ,, essential, type, language, model, ,, transformers, ,, popular, deep, learning, model, ., evaluation, example, tasks, code, completion, bug, finding, confirm, blocks, inhibit, predictability, ,, use, language, models, nevertheless, feasible, ., findings, serve, foundation, improving, tooling, analyses, block-based, languages, ."
"GradSim: Gradient-Based Language Grouping for Effective Multilingual
  Training","Mingyang Wang, Heike Adel, Lukas Lange, Jannik Strötgen, Hinrich Schütze",2023-10-23T18:13:37Z,"  Most languages of the world pose low-resource challenges to natural language
processing models. With multilingual training, knowledge can be shared among
languages. However, not all languages positively influence each other and it is
an open research question how to select the most suitable set of languages for
multilingual training and avoid negative interference among languages whose
characteristics or data distributions are not compatible. In this paper, we
propose GradSim, a language grouping method based on gradient similarity. Our
experiments on three diverse multilingual benchmark datasets show that it leads
to the largest performance gains compared to other similarity measures and it
is better correlated with cross-lingual model performance. As a result, we set
the new state of the art on AfriSenti, a benchmark dataset for sentiment
analysis on low-resource African languages. In our extensive analysis, we
further reveal that besides linguistic features, the topics of the datasets
play an important role for language grouping and that lower layers of
transformer models encode language-specific features while higher layers
capture task-specific information.
","['languages', 'world', 'pose', 'low-resource', 'challenges', 'natural', 'language', 'processing', 'models', '.', 'multilingual', 'training', ',', 'knowledge', 'shared', 'among', 'languages', '.', 'however', ',', 'languages', 'positively', 'influence', 'open', 'research', 'question', 'select', 'suitable', 'set', 'languages', 'multilingual', 'training', 'avoid', 'negative', 'interference', 'among', 'languages', 'whose', 'characteristics', 'data', 'distributions', 'compatible', '.', 'paper', ',', 'propose', 'gradsim', ',', 'language', 'grouping', 'method', 'based', 'gradient', 'similarity', '.', 'experiments', 'three', 'diverse', 'multilingual', 'benchmark', 'datasets', 'show', 'leads', 'largest', 'performance', 'gains', 'compared', 'similarity', 'measures', 'better', 'correlated', 'cross-lingual', 'model', 'performance', '.', 'result', ',', 'set', 'new', 'state', 'art', 'afrisenti', ',', 'benchmark', 'dataset', 'sentiment', 'analysis', 'low-resource', 'african', 'languages', '.', 'extensive', 'analysis', ',', 'reveal', 'besides', 'linguistic', 'features', ',', 'topics', 'datasets', 'play', 'important', 'role', 'language', 'grouping', 'lower', 'layers', 'transformer', 'models', 'encode', 'language-specific', 'features', 'higher', 'layers', 'capture', 'task-specific', 'information', '.']","languages, world, pose, low-resource, challenges, natural, language, processing, models, ., multilingual, training, ,, knowledge, shared, among, languages, ., however, ,, languages, positively, influence, open, research, question, select, suitable, set, languages, multilingual, training, avoid, negative, interference, among, languages, whose, characteristics, data, distributions, compatible, ., paper, ,, propose, gradsim, ,, language, grouping, method, based, gradient, similarity, ., experiments, three, diverse, multilingual, benchmark, datasets, show, leads, largest, performance, gains, compared, similarity, measures, better, correlated, cross-lingual, model, performance, ., result, ,, set, new, state, art, afrisenti, ,, benchmark, dataset, sentiment, analysis, low-resource, african, languages, ., extensive, analysis, ,, reveal, besides, linguistic, features, ,, topics, datasets, play, important, role, language, grouping, lower, layers, transformer, models, encode, language-specific, features, higher, layers, capture, task-specific, information, ."
On Languaging a Simulation Engine,"Han Liu, Liantang Li",2024-02-26T11:01:54Z,"  Language model intelligence is revolutionizing the way we program materials
simulations. However, the diversity of simulation scenarios renders it
challenging to precisely transform human language into a tailored simulator.
Here, using three functionalized types of language model, we propose a
language-to-simulation (Lang2Sim) framework that enables interactive navigation
on languaging a simulation engine, by taking a scenario instance of water
sorption in porous matrices. Unlike line-by-line coding of a target simulator,
the language models interpret each simulator as an assembly of invariant tool
function and its variant input-output pair. Lang2Sim enables the precise
transform of textual description by functionalizing and sequentializing the
language models of, respectively, rationalizing the tool categorization,
customizing its input-output combinations, and distilling the simulator input
into executable format. Importantly, depending on its functionalized type, each
language model features a distinct processing of chat history to best balance
its memory limit and information completeness, thus leveraging the model
intelligence to unstructured nature of human request. Overall, this work
establishes language model as an intelligent platform to unlock the era of
languaging a simulation engine.
","['language', 'model', 'intelligence', 'revolutionizing', 'way', 'program', 'materials', 'simulations', '.', 'however', ',', 'diversity', 'simulation', 'scenarios', 'renders', 'challenging', 'precisely', 'transform', 'human', 'language', 'tailored', 'simulator', '.', ',', 'using', 'three', 'functionalized', 'types', 'language', 'model', ',', 'propose', 'language-to-simulation', '(', 'lang2sim', ')', 'framework', 'enables', 'interactive', 'navigation', 'languaging', 'simulation', 'engine', ',', 'taking', 'scenario', 'instance', 'water', 'sorption', 'porous', 'matrices', '.', 'unlike', 'line-by-line', 'coding', 'target', 'simulator', ',', 'language', 'models', 'interpret', 'simulator', 'assembly', 'invariant', 'tool', 'function', 'variant', 'input-output', 'pair', '.', 'lang2sim', 'enables', 'precise', 'transform', 'textual', 'description', 'functionalizing', 'sequentializing', 'language', 'models', ',', 'respectively', ',', 'rationalizing', 'tool', 'categorization', ',', 'customizing', 'input-output', 'combinations', ',', 'distilling', 'simulator', 'input', 'executable', 'format', '.', 'importantly', ',', 'depending', 'functionalized', 'type', ',', 'language', 'model', 'features', 'distinct', 'processing', 'chat', 'history', 'best', 'balance', 'memory', 'limit', 'information', 'completeness', ',', 'thus', 'leveraging', 'model', 'intelligence', 'unstructured', 'nature', 'human', 'request', '.', 'overall', ',', 'work', 'establishes', 'language', 'model', 'intelligent', 'platform', 'unlock', 'era', 'languaging', 'simulation', 'engine', '.']","language, model, intelligence, revolutionizing, way, program, materials, simulations, ., however, ,, diversity, simulation, scenarios, renders, challenging, precisely, transform, human, language, tailored, simulator, ., ,, using, three, functionalized, types, language, model, ,, propose, language-to-simulation, (, lang2sim, ), framework, enables, interactive, navigation, languaging, simulation, engine, ,, taking, scenario, instance, water, sorption, porous, matrices, ., unlike, line-by-line, coding, target, simulator, ,, language, models, interpret, simulator, assembly, invariant, tool, function, variant, input-output, pair, ., lang2sim, enables, precise, transform, textual, description, functionalizing, sequentializing, language, models, ,, respectively, ,, rationalizing, tool, categorization, ,, customizing, input-output, combinations, ,, distilling, simulator, input, executable, format, ., importantly, ,, depending, functionalized, type, ,, language, model, features, distinct, processing, chat, history, best, balance, memory, limit, information, completeness, ,, thus, leveraging, model, intelligence, unstructured, nature, human, request, ., overall, ,, work, establishes, language, model, intelligent, platform, unlock, era, languaging, simulation, engine, ."
EthioMT: Parallel Corpus for Low-resource Ethiopian Languages,"Atnafu Lambebo Tonja, Olga Kolesnikova, Alexander Gelbukh, Jugal Kalita",2024-03-28T12:26:45Z,"  Recent research in natural language processing (NLP) has achieved impressive
performance in tasks such as machine translation (MT), news classification, and
question-answering in high-resource languages. However, the performance of MT
leaves much to be desired for low-resource languages. This is due to the
smaller size of available parallel corpora in these languages, if such corpora
are available at all. NLP in Ethiopian languages suffers from the same issues
due to the unavailability of publicly accessible datasets for NLP tasks,
including MT. To help the research community and foster research for Ethiopian
languages, we introduce EthioMT -- a new parallel corpus for 15 languages. We
also create a new benchmark by collecting a dataset for better-researched
languages in Ethiopia. We evaluate the newly collected corpus and the benchmark
dataset for 23 Ethiopian languages using transformer and fine-tuning
approaches.
","['recent', 'research', 'natural', 'language', 'processing', '(', 'nlp', ')', 'achieved', 'impressive', 'performance', 'tasks', 'machine', 'translation', '(', 'mt', ')', ',', 'news', 'classification', ',', 'question-answering', 'high-resource', 'languages', '.', 'however', ',', 'performance', 'mt', 'leaves', 'much', 'desired', 'low-resource', 'languages', '.', 'due', 'smaller', 'size', 'available', 'parallel', 'corpora', 'languages', ',', 'corpora', 'available', '.', 'nlp', 'ethiopian', 'languages', 'suffers', 'issues', 'due', 'unavailability', 'publicly', 'accessible', 'datasets', 'nlp', 'tasks', ',', 'including', 'mt', '.', 'help', 'research', 'community', 'foster', 'research', 'ethiopian', 'languages', ',', 'introduce', 'ethiomt', '--', 'new', 'parallel', 'corpus', '15', 'languages', '.', 'also', 'create', 'new', 'benchmark', 'collecting', 'dataset', 'better-researched', 'languages', 'ethiopia', '.', 'evaluate', 'newly', 'collected', 'corpus', 'benchmark', 'dataset', '23', 'ethiopian', 'languages', 'using', 'transformer', 'fine-tuning', 'approaches', '.']","recent, research, natural, language, processing, (, nlp, ), achieved, impressive, performance, tasks, machine, translation, (, mt, ), ,, news, classification, ,, question-answering, high-resource, languages, ., however, ,, performance, mt, leaves, much, desired, low-resource, languages, ., due, smaller, size, available, parallel, corpora, languages, ,, corpora, available, ., nlp, ethiopian, languages, suffers, issues, due, unavailability, publicly, accessible, datasets, nlp, tasks, ,, including, mt, ., help, research, community, foster, research, ethiopian, languages, ,, introduce, ethiomt, --, new, parallel, corpus, 15, languages, ., also, create, new, benchmark, collecting, dataset, better-researched, languages, ethiopia, ., evaluate, newly, collected, corpus, benchmark, dataset, 23, ethiopian, languages, using, transformer, fine-tuning, approaches, ."
"Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language
  Translation","Ryan Wong, Necati Cihan Camgoz, Richard Bowden",2024-05-07T10:00:38Z,"  Automatic Sign Language Translation requires the integration of both computer
vision and natural language processing to effectively bridge the communication
gap between sign and spoken languages. However, the deficiency in large-scale
training data to support sign language translation means we need to leverage
resources from spoken language. We introduce, Sign2GPT, a novel framework for
sign language translation that utilizes large-scale pretrained vision and
language models via lightweight adapters for gloss-free sign language
translation. The lightweight adapters are crucial for sign language
translation, due to the constraints imposed by limited dataset sizes and the
computational requirements when training with long sign videos. We also propose
a novel pretraining strategy that directs our encoder to learn sign
representations from automatically extracted pseudo-glosses without requiring
gloss order information or annotations. We evaluate our approach on two public
benchmark sign language translation datasets, namely RWTH-PHOENIX-Weather 2014T
and CSL-Daily, and improve on state-of-the-art gloss-free translation
performance with a significant margin.
","['automatic', 'sign', 'language', 'translation', 'requires', 'integration', 'computer', 'vision', 'natural', 'language', 'processing', 'effectively', 'bridge', 'communication', 'gap', 'sign', 'spoken', 'languages', '.', 'however', ',', 'deficiency', 'large-scale', 'training', 'data', 'support', 'sign', 'language', 'translation', 'means', 'need', 'leverage', 'resources', 'spoken', 'language', '.', 'introduce', ',', 'sign2gpt', ',', 'novel', 'framework', 'sign', 'language', 'translation', 'utilizes', 'large-scale', 'pretrained', 'vision', 'language', 'models', 'via', 'lightweight', 'adapters', 'gloss-free', 'sign', 'language', 'translation', '.', 'lightweight', 'adapters', 'crucial', 'sign', 'language', 'translation', ',', 'due', 'constraints', 'imposed', 'limited', 'dataset', 'sizes', 'computational', 'requirements', 'training', 'long', 'sign', 'videos', '.', 'also', 'propose', 'novel', 'pretraining', 'strategy', 'directs', 'encoder', 'learn', 'sign', 'representations', 'automatically', 'extracted', 'pseudo-glosses', 'without', 'requiring', 'gloss', 'order', 'information', 'annotations', '.', 'evaluate', 'approach', 'two', 'public', 'benchmark', 'sign', 'language', 'translation', 'datasets', ',', 'namely', 'rwth-phoenix-weather', '2014t', 'csl-daily', ',', 'improve', 'state-of-the-art', 'gloss-free', 'translation', 'performance', 'significant', 'margin', '.']","automatic, sign, language, translation, requires, integration, computer, vision, natural, language, processing, effectively, bridge, communication, gap, sign, spoken, languages, ., however, ,, deficiency, large-scale, training, data, support, sign, language, translation, means, need, leverage, resources, spoken, language, ., introduce, ,, sign2gpt, ,, novel, framework, sign, language, translation, utilizes, large-scale, pretrained, vision, language, models, via, lightweight, adapters, gloss-free, sign, language, translation, ., lightweight, adapters, crucial, sign, language, translation, ,, due, constraints, imposed, limited, dataset, sizes, computational, requirements, training, long, sign, videos, ., also, propose, novel, pretraining, strategy, directs, encoder, learn, sign, representations, automatically, extracted, pseudo-glosses, without, requiring, gloss, order, information, annotations, ., evaluate, approach, two, public, benchmark, sign, language, translation, datasets, ,, namely, rwth-phoenix-weather, 2014t, csl-daily, ,, improve, state-of-the-art, gloss-free, translation, performance, significant, margin, ."
"NL4DV: A Toolkit for Generating Analytic Specifications for Data
  Visualization from Natural Language Queries","Arpit Narechania, Arjun Srinivasan, John Stasko",2020-08-24T21:54:43Z,"  Natural language interfaces (NLIs) have shown great promise for visual data
analysis, allowing people to flexibly specify and interact with visualizations.
However, developing visualization NLIs remains a challenging task, requiring
low-level implementation of natural language processing (NLP) techniques as
well as knowledge of visual analytic tasks and visualization design. We present
NL4DV, a toolkit for natural language-driven data visualization. NL4DV is a
Python package that takes as input a tabular dataset and a natural language
query about that dataset. In response, the toolkit returns an analytic
specification modeled as a JSON object containing data attributes, analytic
tasks, and a list of Vega-Lite specifications relevant to the input query. In
doing so, NL4DV aids visualization developers who may not have a background in
NLP, enabling them to create new visualization NLIs or incorporate natural
language input within their existing systems. We demonstrate NL4DV's usage and
capabilities through four examples: 1) rendering visualizations using natural
language in a Jupyter notebook, 2) developing a NLI to specify and edit
Vega-Lite charts, 3) recreating data ambiguity widgets from the DataTone
system, and 4) incorporating speech input to create a multimodal visualization
system.
","['natural', 'language', 'interfaces', '(', 'nlis', ')', 'shown', 'great', 'promise', 'visual', 'data', 'analysis', ',', 'allowing', 'people', 'flexibly', 'specify', 'interact', 'visualizations', '.', 'however', ',', 'developing', 'visualization', 'nlis', 'remains', 'challenging', 'task', ',', 'requiring', 'low-level', 'implementation', 'natural', 'language', 'processing', '(', 'nlp', ')', 'techniques', 'well', 'knowledge', 'visual', 'analytic', 'tasks', 'visualization', 'design', '.', 'present', 'nl4dv', ',', 'toolkit', 'natural', 'language-driven', 'data', 'visualization', '.', 'nl4dv', 'python', 'package', 'takes', 'input', 'tabular', 'dataset', 'natural', 'language', 'query', 'dataset', '.', 'response', ',', 'toolkit', 'returns', 'analytic', 'specification', 'modeled', 'json', 'object', 'containing', 'data', 'attributes', ',', 'analytic', 'tasks', ',', 'list', 'vega-lite', 'specifications', 'relevant', 'input', 'query', '.', ',', 'nl4dv', 'aids', 'visualization', 'developers', 'may', 'background', 'nlp', ',', 'enabling', 'create', 'new', 'visualization', 'nlis', 'incorporate', 'natural', 'language', 'input', 'within', 'existing', 'systems', '.', 'demonstrate', 'nl4dv', ""'s"", 'usage', 'capabilities', 'four', 'examples', ':', '1', ')', 'rendering', 'visualizations', 'using', 'natural', 'language', 'jupyter', 'notebook', ',', '2', ')', 'developing', 'nli', 'specify', 'edit', 'vega-lite', 'charts', ',', '3', ')', 'recreating', 'data', 'ambiguity', 'widgets', 'datatone', 'system', ',', '4', ')', 'incorporating', 'speech', 'input', 'create', 'multimodal', 'visualization', 'system', '.']","natural, language, interfaces, (, nlis, ), shown, great, promise, visual, data, analysis, ,, allowing, people, flexibly, specify, interact, visualizations, ., however, ,, developing, visualization, nlis, remains, challenging, task, ,, requiring, low-level, implementation, natural, language, processing, (, nlp, ), techniques, well, knowledge, visual, analytic, tasks, visualization, design, ., present, nl4dv, ,, toolkit, natural, language-driven, data, visualization, ., nl4dv, python, package, takes, input, tabular, dataset, natural, language, query, dataset, ., response, ,, toolkit, returns, analytic, specification, modeled, json, object, containing, data, attributes, ,, analytic, tasks, ,, list, vega-lite, specifications, relevant, input, query, ., ,, nl4dv, aids, visualization, developers, may, background, nlp, ,, enabling, create, new, visualization, nlis, incorporate, natural, language, input, within, existing, systems, ., demonstrate, nl4dv, 's, usage, capabilities, four, examples, :, 1, ), rendering, visualizations, using, natural, language, jupyter, notebook, ,, 2, ), developing, nli, specify, edit, vega-lite, charts, ,, 3, ), recreating, data, ambiguity, widgets, datatone, system, ,, 4, ), incorporating, speech, input, create, multimodal, visualization, system, ."
"A Catalog of Transformations to Remove Smells From Natural Language
  Tests","Manoel Aranda, Naelson Oliveira, Elvys Soares, Márcio Ribeiro, Davi Romão, Ullyanne Patriota, Rohit Gheyi, Emerson Souza, Ivan Machado",2024-04-25T19:23:24Z,"  Test smells can pose difficulties during testing activities, such as poor
maintainability, non-deterministic behavior, and incomplete verification.
Existing research has extensively addressed test smells in automated software
tests but little attention has been given to smells in natural language tests.
While some research has identified and catalogued such smells, there is a lack
of systematic approaches for their removal. Consequently, there is also a lack
of tools to automatically identify and remove natural language test smells.
This paper introduces a catalog of transformations designed to remove seven
natural language test smells and a companion tool implemented using Natural
Language Processing (NLP) techniques. Our work aims to enhance the quality and
reliability of natural language tests during software development. The research
employs a two-fold empirical strategy to evaluate its contributions. First, a
survey involving 15 software testing professionals assesses the acceptance and
usefulness of the catalog's transformations. Second, an empirical study
evaluates our tool to remove natural language test smells by analyzing a sample
of real-practice tests from the Ubuntu OS. The results indicate that software
testing professionals find the transformations valuable. Additionally, the
automated tool demonstrates a good level of precision, as evidenced by a
F-Measure rate of 83.70%
","['test', 'smells', 'pose', 'difficulties', 'testing', 'activities', ',', 'poor', 'maintainability', ',', 'non-deterministic', 'behavior', ',', 'incomplete', 'verification', '.', 'existing', 'research', 'extensively', 'addressed', 'test', 'smells', 'automated', 'software', 'tests', 'little', 'attention', 'given', 'smells', 'natural', 'language', 'tests', '.', 'research', 'identified', 'catalogued', 'smells', ',', 'lack', 'systematic', 'approaches', 'removal', '.', 'consequently', ',', 'also', 'lack', 'tools', 'automatically', 'identify', 'remove', 'natural', 'language', 'test', 'smells', '.', 'paper', 'introduces', 'catalog', 'transformations', 'designed', 'remove', 'seven', 'natural', 'language', 'test', 'smells', 'companion', 'tool', 'implemented', 'using', 'natural', 'language', 'processing', '(', 'nlp', ')', 'techniques', '.', 'work', 'aims', 'enhance', 'quality', 'reliability', 'natural', 'language', 'tests', 'software', 'development', '.', 'research', 'employs', 'two-fold', 'empirical', 'strategy', 'evaluate', 'contributions', '.', 'first', ',', 'survey', 'involving', '15', 'software', 'testing', 'professionals', 'assesses', 'acceptance', 'usefulness', 'catalog', ""'s"", 'transformations', '.', 'second', ',', 'empirical', 'study', 'evaluates', 'tool', 'remove', 'natural', 'language', 'test', 'smells', 'analyzing', 'sample', 'real-practice', 'tests', 'ubuntu', 'os', '.', 'results', 'indicate', 'software', 'testing', 'professionals', 'find', 'transformations', 'valuable', '.', 'additionally', ',', 'automated', 'tool', 'demonstrates', 'good', 'level', 'precision', ',', 'evidenced', 'f-measure', 'rate', '83.70', '%']","test, smells, pose, difficulties, testing, activities, ,, poor, maintainability, ,, non-deterministic, behavior, ,, incomplete, verification, ., existing, research, extensively, addressed, test, smells, automated, software, tests, little, attention, given, smells, natural, language, tests, ., research, identified, catalogued, smells, ,, lack, systematic, approaches, removal, ., consequently, ,, also, lack, tools, automatically, identify, remove, natural, language, test, smells, ., paper, introduces, catalog, transformations, designed, remove, seven, natural, language, test, smells, companion, tool, implemented, using, natural, language, processing, (, nlp, ), techniques, ., work, aims, enhance, quality, reliability, natural, language, tests, software, development, ., research, employs, two-fold, empirical, strategy, evaluate, contributions, ., first, ,, survey, involving, 15, software, testing, professionals, assesses, acceptance, usefulness, catalog, 's, transformations, ., second, ,, empirical, study, evaluates, tool, remove, natural, language, test, smells, analyzing, sample, real-practice, tests, ubuntu, os, ., results, indicate, software, testing, professionals, find, transformations, valuable, ., additionally, ,, automated, tool, demonstrates, good, level, precision, ,, evidenced, f-measure, rate, 83.70, %"
"Considerations for meaningful sign language machine translation based on
  glosses","Mathias Müller, Zifan Jiang, Amit Moryossef, Annette Rios, Sarah Ebling",2022-11-28T15:51:58Z,"  Automatic sign language processing is gaining popularity in Natural Language
Processing (NLP) research (Yin et al., 2021). In machine translation (MT) in
particular, sign language translation based on glosses is a prominent approach.
In this paper, we review recent works on neural gloss translation. We find that
limitations of glosses in general and limitations of specific datasets are not
discussed in a transparent manner and that there is no common standard for
evaluation.
  To address these issues, we put forward concrete recommendations for future
research on gloss translation. Our suggestions advocate awareness of the
inherent limitations of gloss-based approaches, realistic datasets, stronger
baselines and convincing evaluation.
","['automatic', 'sign', 'language', 'processing', 'gaining', 'popularity', 'natural', 'language', 'processing', '(', 'nlp', ')', 'research', '(', 'yin', 'et', 'al.', ',', '2021', ')', '.', 'machine', 'translation', '(', 'mt', ')', 'particular', ',', 'sign', 'language', 'translation', 'based', 'glosses', 'prominent', 'approach', '.', 'paper', ',', 'review', 'recent', 'works', 'neural', 'gloss', 'translation', '.', 'find', 'limitations', 'glosses', 'general', 'limitations', 'specific', 'datasets', 'discussed', 'transparent', 'manner', 'common', 'standard', 'evaluation', '.', 'address', 'issues', ',', 'put', 'forward', 'concrete', 'recommendations', 'future', 'research', 'gloss', 'translation', '.', 'suggestions', 'advocate', 'awareness', 'inherent', 'limitations', 'gloss-based', 'approaches', ',', 'realistic', 'datasets', ',', 'stronger', 'baselines', 'convincing', 'evaluation', '.']","automatic, sign, language, processing, gaining, popularity, natural, language, processing, (, nlp, ), research, (, yin, et, al., ,, 2021, ), ., machine, translation, (, mt, ), particular, ,, sign, language, translation, based, glosses, prominent, approach, ., paper, ,, review, recent, works, neural, gloss, translation, ., find, limitations, glosses, general, limitations, specific, datasets, discussed, transparent, manner, common, standard, evaluation, ., address, issues, ,, put, forward, concrete, recommendations, future, research, gloss, translation, ., suggestions, advocate, awareness, inherent, limitations, gloss-based, approaches, ,, realistic, datasets, ,, stronger, baselines, convincing, evaluation, ."
ViANLI: Adversarial Natural Language Inference for Vietnamese,"Tin Van Huynh, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen",2024-06-25T16:58:19Z,"  The development of Natural Language Processing (NLI) datasets and models has
been inspired by innovations in annotation design. With the rapid development
of machine learning models today, the performance of existing machine learning
models has quickly reached state-of-the-art results on a variety of tasks
related to natural language processing, including natural language inference
tasks. By using a pre-trained model during the annotation process, it is
possible to challenge current NLI models by having humans produce
premise-hypothesis combinations that the machine model cannot correctly
predict. To remain attractive and challenging in the research of natural
language inference for Vietnamese, in this paper, we introduce the adversarial
NLI dataset to the NLP research community with the name ViANLI. This data set
contains more than 10K premise-hypothesis pairs and is built by a continuously
adjusting process to obtain the most out of the patterns generated by the
annotators. ViANLI dataset has brought many difficulties to many current SOTA
models when the accuracy of the most powerful model on the test set only
reached 48.4%. Additionally, the experimental results show that the models
trained on our dataset have significantly improved the results on other
Vietnamese NLI datasets.
","['development', 'natural', 'language', 'processing', '(', 'nli', ')', 'datasets', 'models', 'inspired', 'innovations', 'annotation', 'design', '.', 'rapid', 'development', 'machine', 'learning', 'models', 'today', ',', 'performance', 'existing', 'machine', 'learning', 'models', 'quickly', 'reached', 'state-of-the-art', 'results', 'variety', 'tasks', 'related', 'natural', 'language', 'processing', ',', 'including', 'natural', 'language', 'inference', 'tasks', '.', 'using', 'pre-trained', 'model', 'annotation', 'process', ',', 'possible', 'challenge', 'current', 'nli', 'models', 'humans', 'produce', 'premise-hypothesis', 'combinations', 'machine', 'model', 'correctly', 'predict', '.', 'remain', 'attractive', 'challenging', 'research', 'natural', 'language', 'inference', 'vietnamese', ',', 'paper', ',', 'introduce', 'adversarial', 'nli', 'dataset', 'nlp', 'research', 'community', 'name', 'vianli', '.', 'data', 'set', 'contains', '10k', 'premise-hypothesis', 'pairs', 'built', 'continuously', 'adjusting', 'process', 'obtain', 'patterns', 'generated', 'annotators', '.', 'vianli', 'dataset', 'brought', 'many', 'difficulties', 'many', 'current', 'sota', 'models', 'accuracy', 'powerful', 'model', 'test', 'set', 'reached', '48.4', '%', '.', 'additionally', ',', 'experimental', 'results', 'show', 'models', 'trained', 'dataset', 'significantly', 'improved', 'results', 'vietnamese', 'nli', 'datasets', '.']","development, natural, language, processing, (, nli, ), datasets, models, inspired, innovations, annotation, design, ., rapid, development, machine, learning, models, today, ,, performance, existing, machine, learning, models, quickly, reached, state-of-the-art, results, variety, tasks, related, natural, language, processing, ,, including, natural, language, inference, tasks, ., using, pre-trained, model, annotation, process, ,, possible, challenge, current, nli, models, humans, produce, premise-hypothesis, combinations, machine, model, correctly, predict, ., remain, attractive, challenging, research, natural, language, inference, vietnamese, ,, paper, ,, introduce, adversarial, nli, dataset, nlp, research, community, name, vianli, ., data, set, contains, 10k, premise-hypothesis, pairs, built, continuously, adjusting, process, obtain, patterns, generated, annotators, ., vianli, dataset, brought, many, difficulties, many, current, sota, models, accuracy, powerful, model, test, set, reached, 48.4, %, ., additionally, ,, experimental, results, show, models, trained, dataset, significantly, improved, results, vietnamese, nli, datasets, ."
"Stanza: A Python Natural Language Processing Toolkit for Many Human
  Languages","Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher D. Manning",2020-03-16T09:05:53Z,"  We introduce Stanza, an open-source Python natural language processing
toolkit supporting 66 human languages. Compared to existing widely used
toolkits, Stanza features a language-agnostic fully neural pipeline for text
analysis, including tokenization, multi-word token expansion, lemmatization,
part-of-speech and morphological feature tagging, dependency parsing, and named
entity recognition. We have trained Stanza on a total of 112 datasets,
including the Universal Dependencies treebanks and other multilingual corpora,
and show that the same neural architecture generalizes well and achieves
competitive performance on all languages tested. Additionally, Stanza includes
a native Python interface to the widely used Java Stanford CoreNLP software,
which further extends its functionality to cover other tasks such as
coreference resolution and relation extraction. Source code, documentation, and
pretrained models for 66 languages are available at
https://stanfordnlp.github.io/stanza.
","['introduce', 'stanza', ',', 'open-source', 'python', 'natural', 'language', 'processing', 'toolkit', 'supporting', '66', 'human', 'languages', '.', 'compared', 'existing', 'widely', 'used', 'toolkits', ',', 'stanza', 'features', 'language-agnostic', 'fully', 'neural', 'pipeline', 'text', 'analysis', ',', 'including', 'tokenization', ',', 'multi-word', 'token', 'expansion', ',', 'lemmatization', ',', 'part-of-speech', 'morphological', 'feature', 'tagging', ',', 'dependency', 'parsing', ',', 'named', 'entity', 'recognition', '.', 'trained', 'stanza', 'total', '112', 'datasets', ',', 'including', 'universal', 'dependencies', 'treebanks', 'multilingual', 'corpora', ',', 'show', 'neural', 'architecture', 'generalizes', 'well', 'achieves', 'competitive', 'performance', 'languages', 'tested', '.', 'additionally', ',', 'stanza', 'includes', 'native', 'python', 'interface', 'widely', 'used', 'java', 'stanford', 'corenlp', 'software', ',', 'extends', 'functionality', 'cover', 'tasks', 'coreference', 'resolution', 'relation', 'extraction', '.', 'source', 'code', ',', 'documentation', ',', 'pretrained', 'models', '66', 'languages', 'available', 'https', ':', '//stanfordnlp.github.io/stanza', '.']","introduce, stanza, ,, open-source, python, natural, language, processing, toolkit, supporting, 66, human, languages, ., compared, existing, widely, used, toolkits, ,, stanza, features, language-agnostic, fully, neural, pipeline, text, analysis, ,, including, tokenization, ,, multi-word, token, expansion, ,, lemmatization, ,, part-of-speech, morphological, feature, tagging, ,, dependency, parsing, ,, named, entity, recognition, ., trained, stanza, total, 112, datasets, ,, including, universal, dependencies, treebanks, multilingual, corpora, ,, show, neural, architecture, generalizes, well, achieves, competitive, performance, languages, tested, ., additionally, ,, stanza, includes, native, python, interface, widely, used, java, stanford, corenlp, software, ,, extends, functionality, cover, tasks, coreference, resolution, relation, extraction, ., source, code, ,, documentation, ,, pretrained, models, 66, languages, available, https, :, //stanfordnlp.github.io/stanza, ."
"Natural Language Processing in Ethiopian Languages: Current State,
  Challenges, and Opportunities","Atnafu Lambebo Tonja, Tadesse Destaw Belay, Israel Abebe Azime, Abinew Ali Ayele, Moges Ahmed Mehamed, Olga Kolesnikova, Seid Muhie Yimam",2023-03-25T09:04:29Z,"  This survey delves into the current state of natural language processing
(NLP) for four Ethiopian languages: Amharic, Afaan Oromo, Tigrinya, and
Wolaytta. Through this paper, we identify key challenges and opportunities for
NLP research in Ethiopia. Furthermore, we provide a centralized repository on
GitHub that contains publicly available resources for various NLP tasks in
these languages. This repository can be updated periodically with contributions
from other researchers. Our objective is to identify research gaps and
disseminate the information to NLP researchers interested in Ethiopian
languages and encourage future research in this domain.
","['survey', 'delves', 'current', 'state', 'natural', 'language', 'processing', '(', 'nlp', ')', 'four', 'ethiopian', 'languages', ':', 'amharic', ',', 'afaan', 'oromo', ',', 'tigrinya', ',', 'wolaytta', '.', 'paper', ',', 'identify', 'key', 'challenges', 'opportunities', 'nlp', 'research', 'ethiopia', '.', 'furthermore', ',', 'provide', 'centralized', 'repository', 'github', 'contains', 'publicly', 'available', 'resources', 'various', 'nlp', 'tasks', 'languages', '.', 'repository', 'updated', 'periodically', 'contributions', 'researchers', '.', 'objective', 'identify', 'research', 'gaps', 'disseminate', 'information', 'nlp', 'researchers', 'interested', 'ethiopian', 'languages', 'encourage', 'future', 'research', 'domain', '.']","survey, delves, current, state, natural, language, processing, (, nlp, ), four, ethiopian, languages, :, amharic, ,, afaan, oromo, ,, tigrinya, ,, wolaytta, ., paper, ,, identify, key, challenges, opportunities, nlp, research, ethiopia, ., furthermore, ,, provide, centralized, repository, github, contains, publicly, available, resources, various, nlp, tasks, languages, ., repository, updated, periodically, contributions, researchers, ., objective, identify, research, gaps, disseminate, information, nlp, researchers, interested, ethiopian, languages, encourage, future, research, domain, ."
Several categories of Large Language Models (LLMs): A Short Survey,"Saurabh Pahune, Manoj Chandrasekharan",2023-07-05T18:18:23Z,"  Large Language Models(LLMs)have become effective tools for natural language
processing and have been used in many different fields. This essay offers a
succinct summary of various LLM subcategories. The survey emphasizes recent
developments and efforts made for various LLM kinds, including task-based
financial LLMs, multilingual language LLMs, biomedical and clinical LLMs,
vision language LLMs, and code language models. The survey gives a general
summary of the methods, attributes, datasets, transformer models, and
comparison metrics applied in each category of LLMs. Furthermore, it highlights
unresolved problems in the field of developing chatbots and virtual assistants,
such as boosting natural language processing, enhancing chatbot intelligence,
and resolving moral and legal dilemmas. The purpose of this study is to provide
readers, developers, academics, and users interested in LLM-based chatbots and
virtual intelligent assistant technologies with useful information and future
directions.
","['large', 'language', 'models', '(', 'llms', ')', 'become', 'effective', 'tools', 'natural', 'language', 'processing', 'used', 'many', 'different', 'fields', '.', 'essay', 'offers', 'succinct', 'summary', 'various', 'llm', 'subcategories', '.', 'survey', 'emphasizes', 'recent', 'developments', 'efforts', 'made', 'various', 'llm', 'kinds', ',', 'including', 'task-based', 'financial', 'llms', ',', 'multilingual', 'language', 'llms', ',', 'biomedical', 'clinical', 'llms', ',', 'vision', 'language', 'llms', ',', 'code', 'language', 'models', '.', 'survey', 'gives', 'general', 'summary', 'methods', ',', 'attributes', ',', 'datasets', ',', 'transformer', 'models', ',', 'comparison', 'metrics', 'applied', 'category', 'llms', '.', 'furthermore', ',', 'highlights', 'unresolved', 'problems', 'field', 'developing', 'chatbots', 'virtual', 'assistants', ',', 'boosting', 'natural', 'language', 'processing', ',', 'enhancing', 'chatbot', 'intelligence', ',', 'resolving', 'moral', 'legal', 'dilemmas', '.', 'purpose', 'study', 'provide', 'readers', ',', 'developers', ',', 'academics', ',', 'users', 'interested', 'llm-based', 'chatbots', 'virtual', 'intelligent', 'assistant', 'technologies', 'useful', 'information', 'future', 'directions', '.']","large, language, models, (, llms, ), become, effective, tools, natural, language, processing, used, many, different, fields, ., essay, offers, succinct, summary, various, llm, subcategories, ., survey, emphasizes, recent, developments, efforts, made, various, llm, kinds, ,, including, task-based, financial, llms, ,, multilingual, language, llms, ,, biomedical, clinical, llms, ,, vision, language, llms, ,, code, language, models, ., survey, gives, general, summary, methods, ,, attributes, ,, datasets, ,, transformer, models, ,, comparison, metrics, applied, category, llms, ., furthermore, ,, highlights, unresolved, problems, field, developing, chatbots, virtual, assistants, ,, boosting, natural, language, processing, ,, enhancing, chatbot, intelligence, ,, resolving, moral, legal, dilemmas, ., purpose, study, provide, readers, ,, developers, ,, academics, ,, users, interested, llm-based, chatbots, virtual, intelligent, assistant, technologies, useful, information, future, directions, ."
"ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text
  Processing","Quoc-Nam Nguyen, Thang Chau Phan, Duc-Vu Nguyen, Kiet Van Nguyen",2023-10-17T11:34:50Z,"  English and Chinese, known as resource-rich languages, have witnessed the
strong development of transformer-based language models for natural language
processing tasks. Although Vietnam has approximately 100M people speaking
Vietnamese, several pre-trained models, e.g., PhoBERT, ViBERT, and vELECTRA,
performed well on general Vietnamese NLP tasks, including POS tagging and named
entity recognition. These pre-trained language models are still limited to
Vietnamese social media tasks. In this paper, we present the first monolingual
pre-trained language model for Vietnamese social media texts, ViSoBERT, which
is pre-trained on a large-scale corpus of high-quality and diverse Vietnamese
social media texts using XLM-R architecture. Moreover, we explored our
pre-trained model on five important natural language downstream tasks on
Vietnamese social media texts: emotion recognition, hate speech detection,
sentiment analysis, spam reviews detection, and hate speech spans detection.
Our experiments demonstrate that ViSoBERT, with far fewer parameters, surpasses
the previous state-of-the-art models on multiple Vietnamese social media tasks.
Our ViSoBERT model is available only for research purposes.
","['english', 'chinese', ',', 'known', 'resource-rich', 'languages', ',', 'witnessed', 'strong', 'development', 'transformer-based', 'language', 'models', 'natural', 'language', 'processing', 'tasks', '.', 'although', 'vietnam', 'approximately', '100m', 'people', 'speaking', 'vietnamese', ',', 'several', 'pre-trained', 'models', ',', 'e.g.', ',', 'phobert', ',', 'vibert', ',', 'velectra', ',', 'performed', 'well', 'general', 'vietnamese', 'nlp', 'tasks', ',', 'including', 'pos', 'tagging', 'named', 'entity', 'recognition', '.', 'pre-trained', 'language', 'models', 'still', 'limited', 'vietnamese', 'social', 'media', 'tasks', '.', 'paper', ',', 'present', 'first', 'monolingual', 'pre-trained', 'language', 'model', 'vietnamese', 'social', 'media', 'texts', ',', 'visobert', ',', 'pre-trained', 'large-scale', 'corpus', 'high-quality', 'diverse', 'vietnamese', 'social', 'media', 'texts', 'using', 'xlm-r', 'architecture', '.', 'moreover', ',', 'explored', 'pre-trained', 'model', 'five', 'important', 'natural', 'language', 'downstream', 'tasks', 'vietnamese', 'social', 'media', 'texts', ':', 'emotion', 'recognition', ',', 'hate', 'speech', 'detection', ',', 'sentiment', 'analysis', ',', 'spam', 'reviews', 'detection', ',', 'hate', 'speech', 'spans', 'detection', '.', 'experiments', 'demonstrate', 'visobert', ',', 'far', 'fewer', 'parameters', ',', 'surpasses', 'previous', 'state-of-the-art', 'models', 'multiple', 'vietnamese', 'social', 'media', 'tasks', '.', 'visobert', 'model', 'available', 'research', 'purposes', '.']","english, chinese, ,, known, resource-rich, languages, ,, witnessed, strong, development, transformer-based, language, models, natural, language, processing, tasks, ., although, vietnam, approximately, 100m, people, speaking, vietnamese, ,, several, pre-trained, models, ,, e.g., ,, phobert, ,, vibert, ,, velectra, ,, performed, well, general, vietnamese, nlp, tasks, ,, including, pos, tagging, named, entity, recognition, ., pre-trained, language, models, still, limited, vietnamese, social, media, tasks, ., paper, ,, present, first, monolingual, pre-trained, language, model, vietnamese, social, media, texts, ,, visobert, ,, pre-trained, large-scale, corpus, high-quality, diverse, vietnamese, social, media, texts, using, xlm-r, architecture, ., moreover, ,, explored, pre-trained, model, five, important, natural, language, downstream, tasks, vietnamese, social, media, texts, :, emotion, recognition, ,, hate, speech, detection, ,, sentiment, analysis, ,, spam, reviews, detection, ,, hate, speech, spans, detection, ., experiments, demonstrate, visobert, ,, far, fewer, parameters, ,, surpasses, previous, state-of-the-art, models, multiple, vietnamese, social, media, tasks, ., visobert, model, available, research, purposes, ."
"GeoLM: Empowering Language Models for Geospatially Grounded Language
  Understanding","Zekun Li, Wenxuan Zhou, Yao-Yi Chiang, Muhao Chen",2023-10-23T01:20:01Z,"  Humans subconsciously engage in geospatial reasoning when reading articles.
We recognize place names and their spatial relations in text and mentally
associate them with their physical locations on Earth. Although pretrained
language models can mimic this cognitive process using linguistic context, they
do not utilize valuable geospatial information in large, widely available
geographical databases, e.g., OpenStreetMap. This paper introduces GeoLM, a
geospatially grounded language model that enhances the understanding of
geo-entities in natural language. GeoLM leverages geo-entity mentions as
anchors to connect linguistic information in text corpora with geospatial
information extracted from geographical databases. GeoLM connects the two types
of context through contrastive learning and masked language modeling. It also
incorporates a spatial coordinate embedding mechanism to encode distance and
direction relations to capture geospatial context. In the experiment, we
demonstrate that GeoLM exhibits promising capabilities in supporting toponym
recognition, toponym linking, relation extraction, and geo-entity typing, which
bridge the gap between natural language processing and geospatial sciences. The
code is publicly available at https://github.com/knowledge-computing/geolm.
","['humans', 'subconsciously', 'engage', 'geospatial', 'reasoning', 'reading', 'articles', '.', 'recognize', 'place', 'names', 'spatial', 'relations', 'text', 'mentally', 'associate', 'physical', 'locations', 'earth', '.', 'although', 'pretrained', 'language', 'models', 'mimic', 'cognitive', 'process', 'using', 'linguistic', 'context', ',', 'utilize', 'valuable', 'geospatial', 'information', 'large', ',', 'widely', 'available', 'geographical', 'databases', ',', 'e.g.', ',', 'openstreetmap', '.', 'paper', 'introduces', 'geolm', ',', 'geospatially', 'grounded', 'language', 'model', 'enhances', 'understanding', 'geo-entities', 'natural', 'language', '.', 'geolm', 'leverages', 'geo-entity', 'mentions', 'anchors', 'connect', 'linguistic', 'information', 'text', 'corpora', 'geospatial', 'information', 'extracted', 'geographical', 'databases', '.', 'geolm', 'connects', 'two', 'types', 'context', 'contrastive', 'learning', 'masked', 'language', 'modeling', '.', 'also', 'incorporates', 'spatial', 'coordinate', 'embedding', 'mechanism', 'encode', 'distance', 'direction', 'relations', 'capture', 'geospatial', 'context', '.', 'experiment', ',', 'demonstrate', 'geolm', 'exhibits', 'promising', 'capabilities', 'supporting', 'toponym', 'recognition', ',', 'toponym', 'linking', ',', 'relation', 'extraction', ',', 'geo-entity', 'typing', ',', 'bridge', 'gap', 'natural', 'language', 'processing', 'geospatial', 'sciences', '.', 'code', 'publicly', 'available', 'https', ':', '//github.com/knowledge-computing/geolm', '.']","humans, subconsciously, engage, geospatial, reasoning, reading, articles, ., recognize, place, names, spatial, relations, text, mentally, associate, physical, locations, earth, ., although, pretrained, language, models, mimic, cognitive, process, using, linguistic, context, ,, utilize, valuable, geospatial, information, large, ,, widely, available, geographical, databases, ,, e.g., ,, openstreetmap, ., paper, introduces, geolm, ,, geospatially, grounded, language, model, enhances, understanding, geo-entities, natural, language, ., geolm, leverages, geo-entity, mentions, anchors, connect, linguistic, information, text, corpora, geospatial, information, extracted, geographical, databases, ., geolm, connects, two, types, context, contrastive, learning, masked, language, modeling, ., also, incorporates, spatial, coordinate, embedding, mechanism, encode, distance, direction, relations, capture, geospatial, context, ., experiment, ,, demonstrate, geolm, exhibits, promising, capabilities, supporting, toponym, recognition, ,, toponym, linking, ,, relation, extraction, ,, geo-entity, typing, ,, bridge, gap, natural, language, processing, geospatial, sciences, ., code, publicly, available, https, :, //github.com/knowledge-computing/geolm, ."
"Analyzing Language Bias Between French and English in Conventional
  Multilingual Sentiment Analysis Models","Ethan Parker Wong, Faten M'hiri",2024-05-07T17:46:36Z,"  Inspired by the 'Bias Considerations in Bilingual Natural Language
Processing' report by Statistics Canada, this study delves into potential
biases in multilingual sentiment analysis between English and French. Given a
50-50 dataset of French and English, we aim to determine if there exists a
language bias and explore how the incorporation of more diverse datasets in the
future might affect the equity of multilingual Natural Language Processing
(NLP) systems. By employing Support Vector Machine (SVM) and Naive Bayes models
on three balanced datasets, we reveal potential biases in multilingual
sentiment classification. Utilizing Fairlearn, a tool for assessing bias in
machine learning models, our findings indicate nuanced outcomes. With French
data outperforming English across accuracy, recall, and F1 score metrics in
both models, hinting at a language bias favoring French. However, Fairlearn's
metrics suggest that the SVM approaches equitable levels with a demographic
parity ratio of 0.963, 0.989, and 0.985 for the three separate datasets,
indicating near-equitable treatment across languages. In contrast, Naive Bayes
demonstrates greater disparities, evidenced by a demographic parity ratio of
0.813, 0.908, and 0.961. These findings reveal the importance of developing
equitable multilingual NLP systems, particularly as we anticipate the inclusion
of more datasets in various languages in the future.
","['inspired', ""'bias"", 'considerations', 'bilingual', 'natural', 'language', 'processing', ""'"", 'report', 'statistics', 'canada', ',', 'study', 'delves', 'potential', 'biases', 'multilingual', 'sentiment', 'analysis', 'english', 'french', '.', 'given', '50-50', 'dataset', 'french', 'english', ',', 'aim', 'determine', 'exists', 'language', 'bias', 'explore', 'incorporation', 'diverse', 'datasets', 'future', 'might', 'affect', 'equity', 'multilingual', 'natural', 'language', 'processing', '(', 'nlp', ')', 'systems', '.', 'employing', 'support', 'vector', 'machine', '(', 'svm', ')', 'naive', 'bayes', 'models', 'three', 'balanced', 'datasets', ',', 'reveal', 'potential', 'biases', 'multilingual', 'sentiment', 'classification', '.', 'utilizing', 'fairlearn', ',', 'tool', 'assessing', 'bias', 'machine', 'learning', 'models', ',', 'findings', 'indicate', 'nuanced', 'outcomes', '.', 'french', 'data', 'outperforming', 'english', 'across', 'accuracy', ',', 'recall', ',', 'f1', 'score', 'metrics', 'models', ',', 'hinting', 'language', 'bias', 'favoring', 'french', '.', 'however', ',', 'fairlearn', ""'s"", 'metrics', 'suggest', 'svm', 'approaches', 'equitable', 'levels', 'demographic', 'parity', 'ratio', '0.963', ',', '0.989', ',', '0.985', 'three', 'separate', 'datasets', ',', 'indicating', 'near-equitable', 'treatment', 'across', 'languages', '.', 'contrast', ',', 'naive', 'bayes', 'demonstrates', 'greater', 'disparities', ',', 'evidenced', 'demographic', 'parity', 'ratio', '0.813', ',', '0.908', ',', '0.961.', 'findings', 'reveal', 'importance', 'developing', 'equitable', 'multilingual', 'nlp', 'systems', ',', 'particularly', 'anticipate', 'inclusion', 'datasets', 'various', 'languages', 'future', '.']","inspired, 'bias, considerations, bilingual, natural, language, processing, ', report, statistics, canada, ,, study, delves, potential, biases, multilingual, sentiment, analysis, english, french, ., given, 50-50, dataset, french, english, ,, aim, determine, exists, language, bias, explore, incorporation, diverse, datasets, future, might, affect, equity, multilingual, natural, language, processing, (, nlp, ), systems, ., employing, support, vector, machine, (, svm, ), naive, bayes, models, three, balanced, datasets, ,, reveal, potential, biases, multilingual, sentiment, classification, ., utilizing, fairlearn, ,, tool, assessing, bias, machine, learning, models, ,, findings, indicate, nuanced, outcomes, ., french, data, outperforming, english, across, accuracy, ,, recall, ,, f1, score, metrics, models, ,, hinting, language, bias, favoring, french, ., however, ,, fairlearn, 's, metrics, suggest, svm, approaches, equitable, levels, demographic, parity, ratio, 0.963, ,, 0.989, ,, 0.985, three, separate, datasets, ,, indicating, near-equitable, treatment, across, languages, ., contrast, ,, naive, bayes, demonstrates, greater, disparities, ,, evidenced, demographic, parity, ratio, 0.813, ,, 0.908, ,, 0.961., findings, reveal, importance, developing, equitable, multilingual, nlp, systems, ,, particularly, anticipate, inclusion, datasets, various, languages, future, ."
"Translating Natural Language to Planning Goals with Large-Language
  Models","Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, Harold Soh",2023-02-10T09:17:52Z,"  Recent large language models (LLMs) have demonstrated remarkable performance
on a variety of natural language processing (NLP) tasks, leading to intense
excitement about their applicability across various domains. Unfortunately,
recent work has also shown that LLMs are unable to perform accurate reasoning
nor solve planning problems, which may limit their usefulness for
robotics-related tasks. In this work, our central question is whether LLMs are
able to translate goals specified in natural language to a structured planning
language. If so, LLM can act as a natural interface between the planner and
human users; the translated goal can be handed to domain-independent AI
planners that are very effective at planning. Our empirical results on GPT 3.5
variants show that LLMs are much better suited towards translation rather than
planning. We find that LLMs are able to leverage commonsense knowledge and
reasoning to furnish missing details from under-specified goals (as is often
the case in natural language). However, our experiments also reveal that LLMs
can fail to generate goals in tasks that involve numerical or physical (e.g.,
spatial) reasoning, and that LLMs are sensitive to the prompts used. As such,
these models are promising for translation to structured planning languages,
but care should be taken in their use.
","['recent', 'large', 'language', 'models', '(', 'llms', ')', 'demonstrated', 'remarkable', 'performance', 'variety', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', ',', 'leading', 'intense', 'excitement', 'applicability', 'across', 'various', 'domains', '.', 'unfortunately', ',', 'recent', 'work', 'also', 'shown', 'llms', 'unable', 'perform', 'accurate', 'reasoning', 'solve', 'planning', 'problems', ',', 'may', 'limit', 'usefulness', 'robotics-related', 'tasks', '.', 'work', ',', 'central', 'question', 'whether', 'llms', 'able', 'translate', 'goals', 'specified', 'natural', 'language', 'structured', 'planning', 'language', '.', ',', 'llm', 'act', 'natural', 'interface', 'planner', 'human', 'users', ';', 'translated', 'goal', 'handed', 'domain-independent', 'ai', 'planners', 'effective', 'planning', '.', 'empirical', 'results', 'gpt', '3.5', 'variants', 'show', 'llms', 'much', 'better', 'suited', 'towards', 'translation', 'rather', 'planning', '.', 'find', 'llms', 'able', 'leverage', 'commonsense', 'knowledge', 'reasoning', 'furnish', 'missing', 'details', 'under-specified', 'goals', '(', 'often', 'case', 'natural', 'language', ')', '.', 'however', ',', 'experiments', 'also', 'reveal', 'llms', 'fail', 'generate', 'goals', 'tasks', 'involve', 'numerical', 'physical', '(', 'e.g.', ',', 'spatial', ')', 'reasoning', ',', 'llms', 'sensitive', 'prompts', 'used', '.', ',', 'models', 'promising', 'translation', 'structured', 'planning', 'languages', ',', 'care', 'taken', 'use', '.']","recent, large, language, models, (, llms, ), demonstrated, remarkable, performance, variety, natural, language, processing, (, nlp, ), tasks, ,, leading, intense, excitement, applicability, across, various, domains, ., unfortunately, ,, recent, work, also, shown, llms, unable, perform, accurate, reasoning, solve, planning, problems, ,, may, limit, usefulness, robotics-related, tasks, ., work, ,, central, question, whether, llms, able, translate, goals, specified, natural, language, structured, planning, language, ., ,, llm, act, natural, interface, planner, human, users, ;, translated, goal, handed, domain-independent, ai, planners, effective, planning, ., empirical, results, gpt, 3.5, variants, show, llms, much, better, suited, towards, translation, rather, planning, ., find, llms, able, leverage, commonsense, knowledge, reasoning, furnish, missing, details, under-specified, goals, (, often, case, natural, language, ), ., however, ,, experiments, also, reveal, llms, fail, generate, goals, tasks, involve, numerical, physical, (, e.g., ,, spatial, ), reasoning, ,, llms, sensitive, prompts, used, ., ,, models, promising, translation, structured, planning, languages, ,, care, taken, use, ."
"Self Generated Wargame AI: Double Layer Agent Task Planning Based on
  Large Language Model","Y. Sun, J. Zhao, C. Yu, W. Wang, X. Zhou",2023-12-02T09:45:45Z,"  The large language models represented by ChatGPT have a disruptive impact on
the field of artificial intelligence. But it mainly focuses on natural language
processing, speech recognition, machine learning and natural language
understanding. This paper innovatively applies the large language model to the
field of intelligent decision-making, places the large language model in the
decision-making center, and constructs an agent architecture with the large
language model as the core. Based on this, it further proposes a two-layer
agent task planning, issues and executes decision commands through the
interaction of natural language, and carries out simulation verification
through the wargame simulation environment. Through the game confrontation
simulation experiment, it is found that the intelligent decision-making ability
of the large language model is significantly stronger than the commonly used
reinforcement learning AI and rule AI, and the intelligence, understandability
and generalization are all better. And through experiments, it was found that
the intelligence of the large language model is closely related to prompt. This
work also extends the large language model from previous human-computer
interaction to the field of intelligent decision-making, which has important
reference value and significance for the development of intelligent
decision-making.
","['large', 'language', 'models', 'represented', 'chatgpt', 'disruptive', 'impact', 'field', 'artificial', 'intelligence', '.', 'mainly', 'focuses', 'natural', 'language', 'processing', ',', 'speech', 'recognition', ',', 'machine', 'learning', 'natural', 'language', 'understanding', '.', 'paper', 'innovatively', 'applies', 'large', 'language', 'model', 'field', 'intelligent', 'decision-making', ',', 'places', 'large', 'language', 'model', 'decision-making', 'center', ',', 'constructs', 'agent', 'architecture', 'large', 'language', 'model', 'core', '.', 'based', ',', 'proposes', 'two-layer', 'agent', 'task', 'planning', ',', 'issues', 'executes', 'decision', 'commands', 'interaction', 'natural', 'language', ',', 'carries', 'simulation', 'verification', 'wargame', 'simulation', 'environment', '.', 'game', 'confrontation', 'simulation', 'experiment', ',', 'found', 'intelligent', 'decision-making', 'ability', 'large', 'language', 'model', 'significantly', 'stronger', 'commonly', 'used', 'reinforcement', 'learning', 'ai', 'rule', 'ai', ',', 'intelligence', ',', 'understandability', 'generalization', 'better', '.', 'experiments', ',', 'found', 'intelligence', 'large', 'language', 'model', 'closely', 'related', 'prompt', '.', 'work', 'also', 'extends', 'large', 'language', 'model', 'previous', 'human-computer', 'interaction', 'field', 'intelligent', 'decision-making', ',', 'important', 'reference', 'value', 'significance', 'development', 'intelligent', 'decision-making', '.']","large, language, models, represented, chatgpt, disruptive, impact, field, artificial, intelligence, ., mainly, focuses, natural, language, processing, ,, speech, recognition, ,, machine, learning, natural, language, understanding, ., paper, innovatively, applies, large, language, model, field, intelligent, decision-making, ,, places, large, language, model, decision-making, center, ,, constructs, agent, architecture, large, language, model, core, ., based, ,, proposes, two-layer, agent, task, planning, ,, issues, executes, decision, commands, interaction, natural, language, ,, carries, simulation, verification, wargame, simulation, environment, ., game, confrontation, simulation, experiment, ,, found, intelligent, decision-making, ability, large, language, model, significantly, stronger, commonly, used, reinforcement, learning, ai, rule, ai, ,, intelligence, ,, understandability, generalization, better, ., experiments, ,, found, intelligence, large, language, model, closely, related, prompt, ., work, also, extends, large, language, model, previous, human-computer, interaction, field, intelligent, decision-making, ,, important, reference, value, significance, development, intelligent, decision-making, ."
"Construction contract risk identification based on knowledge-augmented
  language model","Saika Wong, Chunmo Zheng, Xing Su, Yinqiu Tang",2023-09-22T05:27:06Z,"  Contract review is an essential step in construction projects to prevent
potential losses. However, the current methods for reviewing construction
contracts lack effectiveness and reliability, leading to time-consuming and
error-prone processes. While large language models (LLMs) have shown promise in
revolutionizing natural language processing (NLP) tasks, they struggle with
domain-specific knowledge and addressing specialized issues. This paper
presents a novel approach that leverages LLMs with construction contract
knowledge to emulate the process of contract review by human experts. Our
tuning-free approach incorporates construction contract domain knowledge to
enhance language models for identifying construction contract risks. The use of
a natural language when building the domain knowledge base facilitates
practical implementation. We evaluated our method on real construction
contracts and achieved solid performance. Additionally, we investigated how
large language models employ logical thinking during the task and provide
insights and recommendations for future research.
","['contract', 'review', 'essential', 'step', 'construction', 'projects', 'prevent', 'potential', 'losses', '.', 'however', ',', 'current', 'methods', 'reviewing', 'construction', 'contracts', 'lack', 'effectiveness', 'reliability', ',', 'leading', 'time-consuming', 'error-prone', 'processes', '.', 'large', 'language', 'models', '(', 'llms', ')', 'shown', 'promise', 'revolutionizing', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', ',', 'struggle', 'domain-specific', 'knowledge', 'addressing', 'specialized', 'issues', '.', 'paper', 'presents', 'novel', 'approach', 'leverages', 'llms', 'construction', 'contract', 'knowledge', 'emulate', 'process', 'contract', 'review', 'human', 'experts', '.', 'tuning-free', 'approach', 'incorporates', 'construction', 'contract', 'domain', 'knowledge', 'enhance', 'language', 'models', 'identifying', 'construction', 'contract', 'risks', '.', 'use', 'natural', 'language', 'building', 'domain', 'knowledge', 'base', 'facilitates', 'practical', 'implementation', '.', 'evaluated', 'method', 'real', 'construction', 'contracts', 'achieved', 'solid', 'performance', '.', 'additionally', ',', 'investigated', 'large', 'language', 'models', 'employ', 'logical', 'thinking', 'task', 'provide', 'insights', 'recommendations', 'future', 'research', '.']","contract, review, essential, step, construction, projects, prevent, potential, losses, ., however, ,, current, methods, reviewing, construction, contracts, lack, effectiveness, reliability, ,, leading, time-consuming, error-prone, processes, ., large, language, models, (, llms, ), shown, promise, revolutionizing, natural, language, processing, (, nlp, ), tasks, ,, struggle, domain-specific, knowledge, addressing, specialized, issues, ., paper, presents, novel, approach, leverages, llms, construction, contract, knowledge, emulate, process, contract, review, human, experts, ., tuning-free, approach, incorporates, construction, contract, domain, knowledge, enhance, language, models, identifying, construction, contract, risks, ., use, natural, language, building, domain, knowledge, base, facilitates, practical, implementation, ., evaluated, method, real, construction, contracts, achieved, solid, performance, ., additionally, ,, investigated, large, language, models, employ, logical, thinking, task, provide, insights, recommendations, future, research, ."
"Exploring the Effectiveness of Instruction Tuning in Biomedical Language
  Processing","Omid Rohanian, Mohammadmahdi Nouriborji, David A. Clifton",2023-12-31T20:02:10Z,"  Large Language Models (LLMs), particularly those similar to ChatGPT, have
significantly influenced the field of Natural Language Processing (NLP). While
these models excel in general language tasks, their performance in
domain-specific downstream tasks such as biomedical and clinical Named Entity
Recognition (NER), Relation Extraction (RE), and Medical Natural Language
Inference (NLI) is still evolving. In this context, our study investigates the
potential of instruction tuning for biomedical language processing, applying
this technique to two general LLMs of substantial scale. We present a
comprehensive, instruction-based model trained on a dataset that consists of
approximately $200,000$ instruction-focused samples. This dataset represents a
carefully curated compilation of existing data, meticulously adapted and
reformatted to align with the specific requirements of our instruction-based
tasks. This initiative represents an important step in utilising such models to
achieve results on par with specialised encoder-only models like BioBERT and
BioClinicalBERT for various classical biomedical NLP tasks. Our work includes
an analysis of the dataset's composition and its impact on model performance,
providing insights into the intricacies of instruction tuning. By sharing our
codes, models, and the distinctively assembled instruction-based dataset, we
seek to encourage ongoing research and development in this area.
","['large', 'language', 'models', '(', 'llms', ')', ',', 'particularly', 'similar', 'chatgpt', ',', 'significantly', 'influenced', 'field', 'natural', 'language', 'processing', '(', 'nlp', ')', '.', 'models', 'excel', 'general', 'language', 'tasks', ',', 'performance', 'domain-specific', 'downstream', 'tasks', 'biomedical', 'clinical', 'named', 'entity', 'recognition', '(', 'ner', ')', ',', 'relation', 'extraction', '(', ')', ',', 'medical', 'natural', 'language', 'inference', '(', 'nli', ')', 'still', 'evolving', '.', 'context', ',', 'study', 'investigates', 'potential', 'instruction', 'tuning', 'biomedical', 'language', 'processing', ',', 'applying', 'technique', 'two', 'general', 'llms', 'substantial', 'scale', '.', 'present', 'comprehensive', ',', 'instruction-based', 'model', 'trained', 'dataset', 'consists', 'approximately', '$', '200,000', '$', 'instruction-focused', 'samples', '.', 'dataset', 'represents', 'carefully', 'curated', 'compilation', 'existing', 'data', ',', 'meticulously', 'adapted', 'reformatted', 'align', 'specific', 'requirements', 'instruction-based', 'tasks', '.', 'initiative', 'represents', 'important', 'step', 'utilising', 'models', 'achieve', 'results', 'par', 'specialised', 'encoder-only', 'models', 'like', 'biobert', 'bioclinicalbert', 'various', 'classical', 'biomedical', 'nlp', 'tasks', '.', 'work', 'includes', 'analysis', 'dataset', ""'s"", 'composition', 'impact', 'model', 'performance', ',', 'providing', 'insights', 'intricacies', 'instruction', 'tuning', '.', 'sharing', 'codes', ',', 'models', ',', 'distinctively', 'assembled', 'instruction-based', 'dataset', ',', 'seek', 'encourage', 'ongoing', 'research', 'development', 'area', '.']","large, language, models, (, llms, ), ,, particularly, similar, chatgpt, ,, significantly, influenced, field, natural, language, processing, (, nlp, ), ., models, excel, general, language, tasks, ,, performance, domain-specific, downstream, tasks, biomedical, clinical, named, entity, recognition, (, ner, ), ,, relation, extraction, (, ), ,, medical, natural, language, inference, (, nli, ), still, evolving, ., context, ,, study, investigates, potential, instruction, tuning, biomedical, language, processing, ,, applying, technique, two, general, llms, substantial, scale, ., present, comprehensive, ,, instruction-based, model, trained, dataset, consists, approximately, $, 200,000, $, instruction-focused, samples, ., dataset, represents, carefully, curated, compilation, existing, data, ,, meticulously, adapted, reformatted, align, specific, requirements, instruction-based, tasks, ., initiative, represents, important, step, utilising, models, achieve, results, par, specialised, encoder-only, models, like, biobert, bioclinicalbert, various, classical, biomedical, nlp, tasks, ., work, includes, analysis, dataset, 's, composition, impact, model, performance, ,, providing, insights, intricacies, instruction, tuning, ., sharing, codes, ,, models, ,, distinctively, assembled, instruction-based, dataset, ,, seek, encourage, ongoing, research, development, area, ."
Endangered Languages are not Low-Resourced!,Mika Hämäläinen,2021-03-17T11:05:29Z,"  The term low-resourced has been tossed around in the field of natural
language processing to a degree that almost any language that is not English
can be called ""low-resourced""; sometimes even just for the sake of making a
mundane or mediocre paper appear more interesting and insightful. In a field
where English is a synonym for language and low-resourced is a synonym for
anything not English, calling endangered languages low-resourced is a bit of an
overstatement. In this paper, I inspect the relation of the endangered with the
low-resourced from my own experiences.
","['term', 'low-resourced', 'tossed', 'around', 'field', 'natural', 'language', 'processing', 'degree', 'almost', 'language', 'english', 'called', '``', 'low-resourced', ""''"", ';', 'sometimes', 'even', 'sake', 'making', 'mundane', 'mediocre', 'paper', 'appear', 'interesting', 'insightful', '.', 'field', 'english', 'synonym', 'language', 'low-resourced', 'synonym', 'anything', 'english', ',', 'calling', 'endangered', 'languages', 'low-resourced', 'bit', 'overstatement', '.', 'paper', ',', 'inspect', 'relation', 'endangered', 'low-resourced', 'experiences', '.']","term, low-resourced, tossed, around, field, natural, language, processing, degree, almost, language, english, called, ``, low-resourced, '', ;, sometimes, even, sake, making, mundane, mediocre, paper, appear, interesting, insightful, ., field, english, synonym, language, low-resourced, synonym, anything, english, ,, calling, endangered, languages, low-resourced, bit, overstatement, ., paper, ,, inspect, relation, endangered, low-resourced, experiences, ."
UzBERT: pretraining a BERT model for Uzbek,"B. Mansurov, A. Mansurov",2021-08-22T18:28:22Z,"  Pretrained language models based on the Transformer architecture have
achieved state-of-the-art results in various natural language processing tasks
such as part-of-speech tagging, named entity recognition, and question
answering. However, no such monolingual model for the Uzbek language is
publicly available. In this paper, we introduce UzBERT, a pretrained Uzbek
language model based on the BERT architecture. Our model greatly outperforms
multilingual BERT on masked language model accuracy. We make the model publicly
available under the MIT open-source license.
","['pretrained', 'language', 'models', 'based', 'transformer', 'architecture', 'achieved', 'state-of-the-art', 'results', 'various', 'natural', 'language', 'processing', 'tasks', 'part-of-speech', 'tagging', ',', 'named', 'entity', 'recognition', ',', 'question', 'answering', '.', 'however', ',', 'monolingual', 'model', 'uzbek', 'language', 'publicly', 'available', '.', 'paper', ',', 'introduce', 'uzbert', ',', 'pretrained', 'uzbek', 'language', 'model', 'based', 'bert', 'architecture', '.', 'model', 'greatly', 'outperforms', 'multilingual', 'bert', 'masked', 'language', 'model', 'accuracy', '.', 'make', 'model', 'publicly', 'available', 'mit', 'open-source', 'license', '.']","pretrained, language, models, based, transformer, architecture, achieved, state-of-the-art, results, various, natural, language, processing, tasks, part-of-speech, tagging, ,, named, entity, recognition, ,, question, answering, ., however, ,, monolingual, model, uzbek, language, publicly, available, ., paper, ,, introduce, uzbert, ,, pretrained, uzbek, language, model, based, bert, architecture, ., model, greatly, outperforms, multilingual, bert, masked, language, model, accuracy, ., make, model, publicly, available, mit, open-source, license, ."
"The Role of AI in Human-AI Creative Writing for Hong Kong Secondary
  Students","Hengky Susanto, David James Woo, Kai Guo",2023-04-21T23:50:09Z,"  The recent advancement in Natural Language Processing (NLP) capability has
led to the development of language models (e.g., ChatGPT) that is capable of
generating human-like language. In this study, we explore how language models
can be utilized to help the ideation aspect of creative writing. Our empirical
findings show that language models play different roles in helping student
writers to be more creative, such as the role of a collaborator, a provocateur,
etc
","['recent', 'advancement', 'natural', 'language', 'processing', '(', 'nlp', ')', 'capability', 'led', 'development', 'language', 'models', '(', 'e.g.', ',', 'chatgpt', ')', 'capable', 'generating', 'human-like', 'language', '.', 'study', ',', 'explore', 'language', 'models', 'utilized', 'help', 'ideation', 'aspect', 'creative', 'writing', '.', 'empirical', 'findings', 'show', 'language', 'models', 'play', 'different', 'roles', 'helping', 'student', 'writers', 'creative', ',', 'role', 'collaborator', ',', 'provocateur', ',', 'etc']","recent, advancement, natural, language, processing, (, nlp, ), capability, led, development, language, models, (, e.g., ,, chatgpt, ), capable, generating, human-like, language, ., study, ,, explore, language, models, utilized, help, ideation, aspect, creative, writing, ., empirical, findings, show, language, models, play, different, roles, helping, student, writers, creative, ,, role, collaborator, ,, provocateur, ,, etc"
A Language Model for Grammatical Error Correction in L2 Russian,"Nikita Remnev, Sergei Obiedkov, Ekaterina Rakhilina, Ivan Smirnov, Anastasia Vyrenkova",2023-07-04T09:50:13Z,"  Grammatical error correction is one of the fundamental tasks in Natural
Language Processing. For the Russian language, most of the spellcheckers
available correct typos and other simple errors with high accuracy, but often
fail when faced with non-native (L2) writing, since the latter contains errors
that are not typical for native speakers. In this paper, we propose a pipeline
involving a language model intended for correcting errors in L2 Russian
writing. The language model proposed is trained on untagged texts of the
Newspaper subcorpus of the Russian National Corpus, and the quality of the
model is validated against the RULEC-GEC corpus.
","['grammatical', 'error', 'correction', 'one', 'fundamental', 'tasks', 'natural', 'language', 'processing', '.', 'russian', 'language', ',', 'spellcheckers', 'available', 'correct', 'typos', 'simple', 'errors', 'high', 'accuracy', ',', 'often', 'fail', 'faced', 'non-native', '(', 'l2', ')', 'writing', ',', 'since', 'latter', 'contains', 'errors', 'typical', 'native', 'speakers', '.', 'paper', ',', 'propose', 'pipeline', 'involving', 'language', 'model', 'intended', 'correcting', 'errors', 'l2', 'russian', 'writing', '.', 'language', 'model', 'proposed', 'trained', 'untagged', 'texts', 'newspaper', 'subcorpus', 'russian', 'national', 'corpus', ',', 'quality', 'model', 'validated', 'rulec-gec', 'corpus', '.']","grammatical, error, correction, one, fundamental, tasks, natural, language, processing, ., russian, language, ,, spellcheckers, available, correct, typos, simple, errors, high, accuracy, ,, often, fail, faced, non-native, (, l2, ), writing, ,, since, latter, contains, errors, typical, native, speakers, ., paper, ,, propose, pipeline, involving, language, model, intended, correcting, errors, l2, russian, writing, ., language, model, proposed, trained, untagged, texts, newspaper, subcorpus, russian, national, corpus, ,, quality, model, validated, rulec-gec, corpus, ."
The Ghanaian NLP Landscape: A First Look,"Sheriff Issaka, Zhaoyi Zhang, Mihir Heda, Keyi Wang, Yinka Ajibola, Ryan DeMar, Xuefeng Du",2024-05-10T21:39:09Z,"  Despite comprising one-third of global languages, African languages are
critically underrepresented in Artificial Intelligence (AI), threatening
linguistic diversity and cultural heritage. Ghanaian languages, in particular,
face an alarming decline, with documented extinction and several at risk. This
study pioneers a comprehensive survey of Natural Language Processing (NLP)
research focused on Ghanaian languages, identifying methodologies, datasets,
and techniques employed. Additionally, we create a detailed roadmap outlining
challenges, best practices, and future directions, aiming to improve
accessibility for researchers. This work serves as a foundational resource for
Ghanaian NLP research and underscores the critical need for integrating global
linguistic diversity into AI development.
","['despite', 'comprising', 'one-third', 'global', 'languages', ',', 'african', 'languages', 'critically', 'underrepresented', 'artificial', 'intelligence', '(', 'ai', ')', ',', 'threatening', 'linguistic', 'diversity', 'cultural', 'heritage', '.', 'ghanaian', 'languages', ',', 'particular', ',', 'face', 'alarming', 'decline', ',', 'documented', 'extinction', 'several', 'risk', '.', 'study', 'pioneers', 'comprehensive', 'survey', 'natural', 'language', 'processing', '(', 'nlp', ')', 'research', 'focused', 'ghanaian', 'languages', ',', 'identifying', 'methodologies', ',', 'datasets', ',', 'techniques', 'employed', '.', 'additionally', ',', 'create', 'detailed', 'roadmap', 'outlining', 'challenges', ',', 'best', 'practices', ',', 'future', 'directions', ',', 'aiming', 'improve', 'accessibility', 'researchers', '.', 'work', 'serves', 'foundational', 'resource', 'ghanaian', 'nlp', 'research', 'underscores', 'critical', 'need', 'integrating', 'global', 'linguistic', 'diversity', 'ai', 'development', '.']","despite, comprising, one-third, global, languages, ,, african, languages, critically, underrepresented, artificial, intelligence, (, ai, ), ,, threatening, linguistic, diversity, cultural, heritage, ., ghanaian, languages, ,, particular, ,, face, alarming, decline, ,, documented, extinction, several, risk, ., study, pioneers, comprehensive, survey, natural, language, processing, (, nlp, ), research, focused, ghanaian, languages, ,, identifying, methodologies, ,, datasets, ,, techniques, employed, ., additionally, ,, create, detailed, roadmap, outlining, challenges, ,, best, practices, ,, future, directions, ,, aiming, improve, accessibility, researchers, ., work, serves, foundational, resource, ghanaian, nlp, research, underscores, critical, need, integrating, global, linguistic, diversity, ai, development, ."
"Strategies for Language Identification in Code-Mixed Low Resource
  Languages","Soumil Mandal, Sankalp Sanand",2018-10-16T17:35:31Z,"  In recent years, substantial work has been done on language tagging of
code-mixed data, but most of them use large amounts of data to build their
models. In this article, we present three strategies to build a word level
language tagger for code-mixed data using very low resources. Each of them
secured an accuracy higher than our baseline model, and the best performing
system got an accuracy around 91%. Combining all, the ensemble system achieved
an accuracy of around 92.6%.
","['recent', 'years', ',', 'substantial', 'work', 'done', 'language', 'tagging', 'code-mixed', 'data', ',', 'use', 'large', 'amounts', 'data', 'build', 'models', '.', 'article', ',', 'present', 'three', 'strategies', 'build', 'word', 'level', 'language', 'tagger', 'code-mixed', 'data', 'using', 'low', 'resources', '.', 'secured', 'accuracy', 'higher', 'baseline', 'model', ',', 'best', 'performing', 'system', 'got', 'accuracy', 'around', '91', '%', '.', 'combining', ',', 'ensemble', 'system', 'achieved', 'accuracy', 'around', '92.6', '%', '.']","recent, years, ,, substantial, work, done, language, tagging, code-mixed, data, ,, use, large, amounts, data, build, models, ., article, ,, present, three, strategies, build, word, level, language, tagger, code-mixed, data, using, low, resources, ., secured, accuracy, higher, baseline, model, ,, best, performing, system, got, accuracy, around, 91, %, ., combining, ,, ensemble, system, achieved, accuracy, around, 92.6, %, ."
Energy-Based Models with Applications to Speech and Language Processing,Zhijian Ou,2024-03-16T16:16:31Z,"  Energy-Based Models (EBMs) are an important class of probabilistic models,
also known as random fields and undirected graphical models. EBMs are
un-normalized and thus radically different from other popular self-normalized
probabilistic models such as hidden Markov models (HMMs), autoregressive
models, generative adversarial nets (GANs) and variational auto-encoders
(VAEs). Over the past years, EBMs have attracted increasing interest not only
from the core machine learning community, but also from application domains
such as speech, vision, natural language processing (NLP) and so on, due to
significant theoretical and algorithmic progress. The sequential nature of
speech and language also presents special challenges and needs a different
treatment from processing fix-dimensional data (e.g., images). Therefore, the
purpose of this monograph is to present a systematic introduction to
energy-based models, including both algorithmic progress and applications in
speech and language processing. First, the basics of EBMs are introduced,
including classic models, recent models parameterized by neural networks,
sampling methods, and various learning methods from the classic learning
algorithms to the most advanced ones. Then, the application of EBMs in three
different scenarios is presented, i.e., for modeling marginal, conditional and
joint distributions, respectively. 1) EBMs for sequential data with
applications in language modeling, where the main focus is on the marginal
distribution of a sequence itself; 2) EBMs for modeling conditional
distributions of target sequences given observation sequences, with
applications in speech recognition, sequence labeling and text generation; 3)
EBMs for modeling joint distributions of both sequences of observations and
targets, and their applications in semi-supervised learning and calibrated
natural language understanding.
","['energy-based', 'models', '(', 'ebms', ')', 'important', 'class', 'probabilistic', 'models', ',', 'also', 'known', 'random', 'fields', 'undirected', 'graphical', 'models', '.', 'ebms', 'un-normalized', 'thus', 'radically', 'different', 'popular', 'self-normalized', 'probabilistic', 'models', 'hidden', 'markov', 'models', '(', 'hmms', ')', ',', 'autoregressive', 'models', ',', 'generative', 'adversarial', 'nets', '(', 'gans', ')', 'variational', 'auto-encoders', '(', 'vaes', ')', '.', 'past', 'years', ',', 'ebms', 'attracted', 'increasing', 'interest', 'core', 'machine', 'learning', 'community', ',', 'also', 'application', 'domains', 'speech', ',', 'vision', ',', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'due', 'significant', 'theoretical', 'algorithmic', 'progress', '.', 'sequential', 'nature', 'speech', 'language', 'also', 'presents', 'special', 'challenges', 'needs', 'different', 'treatment', 'processing', 'fix-dimensional', 'data', '(', 'e.g.', ',', 'images', ')', '.', 'therefore', ',', 'purpose', 'monograph', 'present', 'systematic', 'introduction', 'energy-based', 'models', ',', 'including', 'algorithmic', 'progress', 'applications', 'speech', 'language', 'processing', '.', 'first', ',', 'basics', 'ebms', 'introduced', ',', 'including', 'classic', 'models', ',', 'recent', 'models', 'parameterized', 'neural', 'networks', ',', 'sampling', 'methods', ',', 'various', 'learning', 'methods', 'classic', 'learning', 'algorithms', 'advanced', 'ones', '.', ',', 'application', 'ebms', 'three', 'different', 'scenarios', 'presented', ',', 'i.e.', ',', 'modeling', 'marginal', ',', 'conditional', 'joint', 'distributions', ',', 'respectively', '.', '1', ')', 'ebms', 'sequential', 'data', 'applications', 'language', 'modeling', ',', 'main', 'focus', 'marginal', 'distribution', 'sequence', ';', '2', ')', 'ebms', 'modeling', 'conditional', 'distributions', 'target', 'sequences', 'given', 'observation', 'sequences', ',', 'applications', 'speech', 'recognition', ',', 'sequence', 'labeling', 'text', 'generation', ';', '3', ')', 'ebms', 'modeling', 'joint', 'distributions', 'sequences', 'observations', 'targets', ',', 'applications', 'semi-supervised', 'learning', 'calibrated', 'natural', 'language', 'understanding', '.']","energy-based, models, (, ebms, ), important, class, probabilistic, models, ,, also, known, random, fields, undirected, graphical, models, ., ebms, un-normalized, thus, radically, different, popular, self-normalized, probabilistic, models, hidden, markov, models, (, hmms, ), ,, autoregressive, models, ,, generative, adversarial, nets, (, gans, ), variational, auto-encoders, (, vaes, ), ., past, years, ,, ebms, attracted, increasing, interest, core, machine, learning, community, ,, also, application, domains, speech, ,, vision, ,, natural, language, processing, (, nlp, ), ,, due, significant, theoretical, algorithmic, progress, ., sequential, nature, speech, language, also, presents, special, challenges, needs, different, treatment, processing, fix-dimensional, data, (, e.g., ,, images, ), ., therefore, ,, purpose, monograph, present, systematic, introduction, energy-based, models, ,, including, algorithmic, progress, applications, speech, language, processing, ., first, ,, basics, ebms, introduced, ,, including, classic, models, ,, recent, models, parameterized, neural, networks, ,, sampling, methods, ,, various, learning, methods, classic, learning, algorithms, advanced, ones, ., ,, application, ebms, three, different, scenarios, presented, ,, i.e., ,, modeling, marginal, ,, conditional, joint, distributions, ,, respectively, ., 1, ), ebms, sequential, data, applications, language, modeling, ,, main, focus, marginal, distribution, sequence, ;, 2, ), ebms, modeling, conditional, distributions, target, sequences, given, observation, sequences, ,, applications, speech, recognition, ,, sequence, labeling, text, generation, ;, 3, ), ebms, modeling, joint, distributions, sequences, observations, targets, ,, applications, semi-supervised, learning, calibrated, natural, language, understanding, ."
ECG Language Processing (ELP): a New Technique to Analyze ECG Signals,"Sajad Mousavi, Fatemeh Afghah, Fatemeh Khadem, U. Rajendra Acharya",2020-06-13T01:42:05Z,"  A language is constructed of a finite/infinite set of sentences composing of
words. Similar to natural languages, Electrocardiogram (ECG) signal, the most
common noninvasive tool to study the functionality of the heart and diagnose
several abnormal arrhythmias, is made up of sequences of three or four distinct
waves including the P-wave, QRS complex, T-wave and U-wave. An ECG signal may
contain several different varieties of each wave (e.g., the QRS complex can
have various appearances). For this reason, the ECG signal is a sequence of
heartbeats similar to sentences in natural languages) and each heartbeat is
composed of a set of waves (similar to words in a sentence) of different
morphologies. Analogous to natural language processing (NLP) which is used to
help computers understand and interpret the human's natural language, it is
possible to develop methods inspired by NLP to aid computers to gain a deeper
understanding of Electrocardiogram signals. In this work, our goal is to
propose a novel ECG analysis technique, \textit{ECG language processing (ELP)},
focusing on empowering computers to understand ECG signals in a way physicians
do. We evaluated the proposed method on two tasks including the classification
of heartbeats and the detection of atrial fibrillation in the ECG signals.
Experimental results on three databases (i.e., PhysionNet's MIT-BIH, MIT-BIH
AFIB and PhysioNet Challenge 2017 AFIB Dataset databases) reveal that the
proposed method is a general idea that can be applied to a variety of
biomedical applications and is able to achieve remarkable performance.
","['language', 'constructed', 'finite/infinite', 'set', 'sentences', 'composing', 'words', '.', 'similar', 'natural', 'languages', ',', 'electrocardiogram', '(', 'ecg', ')', 'signal', ',', 'common', 'noninvasive', 'tool', 'study', 'functionality', 'heart', 'diagnose', 'several', 'abnormal', 'arrhythmias', ',', 'made', 'sequences', 'three', 'four', 'distinct', 'waves', 'including', 'p-wave', ',', 'qrs', 'complex', ',', 't-wave', 'u-wave', '.', 'ecg', 'signal', 'may', 'contain', 'several', 'different', 'varieties', 'wave', '(', 'e.g.', ',', 'qrs', 'complex', 'various', 'appearances', ')', '.', 'reason', ',', 'ecg', 'signal', 'sequence', 'heartbeats', 'similar', 'sentences', 'natural', 'languages', ')', 'heartbeat', 'composed', 'set', 'waves', '(', 'similar', 'words', 'sentence', ')', 'different', 'morphologies', '.', 'analogous', 'natural', 'language', 'processing', '(', 'nlp', ')', 'used', 'help', 'computers', 'understand', 'interpret', 'human', ""'s"", 'natural', 'language', ',', 'possible', 'develop', 'methods', 'inspired', 'nlp', 'aid', 'computers', 'gain', 'deeper', 'understanding', 'electrocardiogram', 'signals', '.', 'work', ',', 'goal', 'propose', 'novel', 'ecg', 'analysis', 'technique', ',', '\\textit', '{', 'ecg', 'language', 'processing', '(', 'elp', ')', '}', ',', 'focusing', 'empowering', 'computers', 'understand', 'ecg', 'signals', 'way', 'physicians', '.', 'evaluated', 'proposed', 'method', 'two', 'tasks', 'including', 'classification', 'heartbeats', 'detection', 'atrial', 'fibrillation', 'ecg', 'signals', '.', 'experimental', 'results', 'three', 'databases', '(', 'i.e.', ',', 'physionnet', ""'s"", 'mit-bih', ',', 'mit-bih', 'afib', 'physionet', 'challenge', '2017', 'afib', 'dataset', 'databases', ')', 'reveal', 'proposed', 'method', 'general', 'idea', 'applied', 'variety', 'biomedical', 'applications', 'able', 'achieve', 'remarkable', 'performance', '.']","language, constructed, finite/infinite, set, sentences, composing, words, ., similar, natural, languages, ,, electrocardiogram, (, ecg, ), signal, ,, common, noninvasive, tool, study, functionality, heart, diagnose, several, abnormal, arrhythmias, ,, made, sequences, three, four, distinct, waves, including, p-wave, ,, qrs, complex, ,, t-wave, u-wave, ., ecg, signal, may, contain, several, different, varieties, wave, (, e.g., ,, qrs, complex, various, appearances, ), ., reason, ,, ecg, signal, sequence, heartbeats, similar, sentences, natural, languages, ), heartbeat, composed, set, waves, (, similar, words, sentence, ), different, morphologies, ., analogous, natural, language, processing, (, nlp, ), used, help, computers, understand, interpret, human, 's, natural, language, ,, possible, develop, methods, inspired, nlp, aid, computers, gain, deeper, understanding, electrocardiogram, signals, ., work, ,, goal, propose, novel, ecg, analysis, technique, ,, \textit, {, ecg, language, processing, (, elp, ), }, ,, focusing, empowering, computers, understand, ecg, signals, way, physicians, ., evaluated, proposed, method, two, tasks, including, classification, heartbeats, detection, atrial, fibrillation, ecg, signals, ., experimental, results, three, databases, (, i.e., ,, physionnet, 's, mit-bih, ,, mit-bih, afib, physionet, challenge, 2017, afib, dataset, databases, ), reveal, proposed, method, general, idea, applied, variety, biomedical, applications, able, achieve, remarkable, performance, ."
"The Less the Merrier? Investigating Language Representation in
  Multilingual Models","Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Jugal Kalita",2023-10-20T02:26:34Z,"  Multilingual Language Models offer a way to incorporate multiple languages in
one model and utilize cross-language transfer learning to improve performance
for different Natural Language Processing (NLP) tasks. Despite progress in
multilingual models, not all languages are supported as well, particularly in
low-resource settings. In this work, we investigate the linguistic
representation of different languages in multilingual models. We start by
asking the question which languages are supported in popular multilingual
models and which languages are left behind. Then, for included languages, we
look at models' learned representations based on language family and dialect
and try to understand how models' learned representations for~(1) seen and~(2)
unseen languages vary across different language groups. In addition, we test
and analyze performance on downstream tasks such as text generation and Named
Entity Recognition. We observe from our experiments that community-centered
models -- models that focus on languages of a given family or geographical
location and are built by communities who speak them -- perform better at
distinguishing between languages in the same family for low-resource languages.
Our paper contributes to the literature in understanding multilingual models
and their shortcomings and offers insights on potential ways to improve them.
","['multilingual', 'language', 'models', 'offer', 'way', 'incorporate', 'multiple', 'languages', 'one', 'model', 'utilize', 'cross-language', 'transfer', 'learning', 'improve', 'performance', 'different', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', '.', 'despite', 'progress', 'multilingual', 'models', ',', 'languages', 'supported', 'well', ',', 'particularly', 'low-resource', 'settings', '.', 'work', ',', 'investigate', 'linguistic', 'representation', 'different', 'languages', 'multilingual', 'models', '.', 'start', 'asking', 'question', 'languages', 'supported', 'popular', 'multilingual', 'models', 'languages', 'left', 'behind', '.', ',', 'included', 'languages', ',', 'look', 'models', ""'"", 'learned', 'representations', 'based', 'language', 'family', 'dialect', 'try', 'understand', 'models', ""'"", 'learned', 'representations', 'for~', '(', '1', ')', 'seen', 'and~', '(', '2', ')', 'unseen', 'languages', 'vary', 'across', 'different', 'language', 'groups', '.', 'addition', ',', 'test', 'analyze', 'performance', 'downstream', 'tasks', 'text', 'generation', 'named', 'entity', 'recognition', '.', 'observe', 'experiments', 'community-centered', 'models', '--', 'models', 'focus', 'languages', 'given', 'family', 'geographical', 'location', 'built', 'communities', 'speak', '--', 'perform', 'better', 'distinguishing', 'languages', 'family', 'low-resource', 'languages', '.', 'paper', 'contributes', 'literature', 'understanding', 'multilingual', 'models', 'shortcomings', 'offers', 'insights', 'potential', 'ways', 'improve', '.']","multilingual, language, models, offer, way, incorporate, multiple, languages, one, model, utilize, cross-language, transfer, learning, improve, performance, different, natural, language, processing, (, nlp, ), tasks, ., despite, progress, multilingual, models, ,, languages, supported, well, ,, particularly, low-resource, settings, ., work, ,, investigate, linguistic, representation, different, languages, multilingual, models, ., start, asking, question, languages, supported, popular, multilingual, models, languages, left, behind, ., ,, included, languages, ,, look, models, ', learned, representations, based, language, family, dialect, try, understand, models, ', learned, representations, for~, (, 1, ), seen, and~, (, 2, ), unseen, languages, vary, across, different, language, groups, ., addition, ,, test, analyze, performance, downstream, tasks, text, generation, named, entity, recognition, ., observe, experiments, community-centered, models, --, models, focus, languages, given, family, geographical, location, built, communities, speak, --, perform, better, distinguishing, languages, family, low-resource, languages, ., paper, contributes, literature, understanding, multilingual, models, shortcomings, offers, insights, potential, ways, improve, ."
Towards Machine Translation for the Kurdish Language,"Sina Ahmadi, Mariam Masoud",2020-10-12T21:28:57Z,"  Machine translation is the task of translating texts from one language to
another using computers. It has been one of the major tasks in natural language
processing and computational linguistics and has been motivating to facilitate
human communication. Kurdish, an Indo-European language, has received little
attention in this realm due to the language being less-resourced. Therefore, in
this paper, we are addressing the main issues in creating a machine translation
system for the Kurdish language, with a focus on the Sorani dialect. We
describe the available scarce parallel data suitable for training a neural
machine translation model for Sorani Kurdish-English translation. We also
discuss some of the major challenges in Kurdish language translation and
demonstrate how fundamental text processing tasks, such as tokenization, can
improve translation performance.
","['machine', 'translation', 'task', 'translating', 'texts', 'one', 'language', 'another', 'using', 'computers', '.', 'one', 'major', 'tasks', 'natural', 'language', 'processing', 'computational', 'linguistics', 'motivating', 'facilitate', 'human', 'communication', '.', 'kurdish', ',', 'indo-european', 'language', ',', 'received', 'little', 'attention', 'realm', 'due', 'language', 'less-resourced', '.', 'therefore', ',', 'paper', ',', 'addressing', 'main', 'issues', 'creating', 'machine', 'translation', 'system', 'kurdish', 'language', ',', 'focus', 'sorani', 'dialect', '.', 'describe', 'available', 'scarce', 'parallel', 'data', 'suitable', 'training', 'neural', 'machine', 'translation', 'model', 'sorani', 'kurdish-english', 'translation', '.', 'also', 'discuss', 'major', 'challenges', 'kurdish', 'language', 'translation', 'demonstrate', 'fundamental', 'text', 'processing', 'tasks', ',', 'tokenization', ',', 'improve', 'translation', 'performance', '.']","machine, translation, task, translating, texts, one, language, another, using, computers, ., one, major, tasks, natural, language, processing, computational, linguistics, motivating, facilitate, human, communication, ., kurdish, ,, indo-european, language, ,, received, little, attention, realm, due, language, less-resourced, ., therefore, ,, paper, ,, addressing, main, issues, creating, machine, translation, system, kurdish, language, ,, focus, sorani, dialect, ., describe, available, scarce, parallel, data, suitable, training, neural, machine, translation, model, sorani, kurdish-english, translation, ., also, discuss, major, challenges, kurdish, language, translation, demonstrate, fundamental, text, processing, tasks, ,, tokenization, ,, improve, translation, performance, ."
"Accelerating Neural Networks for Large Language Models and Graph
  Processing with Silicon Photonics","Salma Afifi, Febin Sunny, Mahdi Nikdast, Sudeep Pasricha",2024-01-12T20:32:38Z,"  In the rapidly evolving landscape of artificial intelligence, large language
models (LLMs) and graph processing have emerged as transformative technologies
for natural language processing (NLP), computer vision, and graph-structured
data applications. However, the complex structures of these models pose
challenges for acceleration on conventional electronic platforms. In this
paper, we describe novel hardware accelerators based on silicon photonics to
accelerate transformer neural networks that are used in LLMs and graph neural
networks for graph data processing. Our analysis demonstrates that both
hardware accelerators achieve at least 10.2x throughput improvement and 3.8x
better energy efficiency over multiple state-of-the-art electronic hardware
accelerators designed for LLMs and graph processing.
","['rapidly', 'evolving', 'landscape', 'artificial', 'intelligence', ',', 'large', 'language', 'models', '(', 'llms', ')', 'graph', 'processing', 'emerged', 'transformative', 'technologies', 'natural', 'language', 'processing', '(', 'nlp', ')', ',', 'computer', 'vision', ',', 'graph-structured', 'data', 'applications', '.', 'however', ',', 'complex', 'structures', 'models', 'pose', 'challenges', 'acceleration', 'conventional', 'electronic', 'platforms', '.', 'paper', ',', 'describe', 'novel', 'hardware', 'accelerators', 'based', 'silicon', 'photonics', 'accelerate', 'transformer', 'neural', 'networks', 'used', 'llms', 'graph', 'neural', 'networks', 'graph', 'data', 'processing', '.', 'analysis', 'demonstrates', 'hardware', 'accelerators', 'achieve', 'least', '10.2x', 'throughput', 'improvement', '3.8x', 'better', 'energy', 'efficiency', 'multiple', 'state-of-the-art', 'electronic', 'hardware', 'accelerators', 'designed', 'llms', 'graph', 'processing', '.']","rapidly, evolving, landscape, artificial, intelligence, ,, large, language, models, (, llms, ), graph, processing, emerged, transformative, technologies, natural, language, processing, (, nlp, ), ,, computer, vision, ,, graph-structured, data, applications, ., however, ,, complex, structures, models, pose, challenges, acceleration, conventional, electronic, platforms, ., paper, ,, describe, novel, hardware, accelerators, based, silicon, photonics, accelerate, transformer, neural, networks, used, llms, graph, neural, networks, graph, data, processing, ., analysis, demonstrates, hardware, accelerators, achieve, least, 10.2x, throughput, improvement, 3.8x, better, energy, efficiency, multiple, state-of-the-art, electronic, hardware, accelerators, designed, llms, graph, processing, ."
"Image-based Natural Language Understanding Using 2D Convolutional Neural
  Networks","Erinc Merdivan, Anastasios Vafeiadis, Dimitrios Kalatzis, Sten Hanke, Johannes Kropf, Konstantinos Votis, Dimitrios Giakoumis, Dimitrios Tzovaras, Liming Chen, Raouf Hamzaoui, Matthieu Geist",2018-10-24T13:46:58Z,"  We propose a new approach to natural language understanding in which we
consider the input text as an image and apply 2D Convolutional Neural Networks
to learn the local and global semantics of the sentences from the variations
ofthe visual patterns of words. Our approach demonstrates that it is possible
to get semantically meaningful features from images with text without using
optical character recognition and sequential processing pipelines, techniques
that traditional Natural Language Understanding algorithms require. To validate
our approach, we present results for two applications: text classification and
dialog modeling. Using a 2D Convolutional Neural Network, we were able to
outperform the state-of-art accuracy results of non-Latin alphabet-based text
classification and achieved promising results for eight text classification
datasets. Furthermore, our approach outperformed the memory networks when using
out of vocabulary entities fromtask 4 of the bAbI dialog dataset.
","['propose', 'new', 'approach', 'natural', 'language', 'understanding', 'consider', 'input', 'text', 'image', 'apply', '2d', 'convolutional', 'neural', 'networks', 'learn', 'local', 'global', 'semantics', 'sentences', 'variations', 'ofthe', 'visual', 'patterns', 'words', '.', 'approach', 'demonstrates', 'possible', 'get', 'semantically', 'meaningful', 'features', 'images', 'text', 'without', 'using', 'optical', 'character', 'recognition', 'sequential', 'processing', 'pipelines', ',', 'techniques', 'traditional', 'natural', 'language', 'understanding', 'algorithms', 'require', '.', 'validate', 'approach', ',', 'present', 'results', 'two', 'applications', ':', 'text', 'classification', 'dialog', 'modeling', '.', 'using', '2d', 'convolutional', 'neural', 'network', ',', 'able', 'outperform', 'state-of-art', 'accuracy', 'results', 'non-latin', 'alphabet-based', 'text', 'classification', 'achieved', 'promising', 'results', 'eight', 'text', 'classification', 'datasets', '.', 'furthermore', ',', 'approach', 'outperformed', 'memory', 'networks', 'using', 'vocabulary', 'entities', 'fromtask', '4', 'babi', 'dialog', 'dataset', '.']","propose, new, approach, natural, language, understanding, consider, input, text, image, apply, 2d, convolutional, neural, networks, learn, local, global, semantics, sentences, variations, ofthe, visual, patterns, words, ., approach, demonstrates, possible, get, semantically, meaningful, features, images, text, without, using, optical, character, recognition, sequential, processing, pipelines, ,, techniques, traditional, natural, language, understanding, algorithms, require, ., validate, approach, ,, present, results, two, applications, :, text, classification, dialog, modeling, ., using, 2d, convolutional, neural, network, ,, able, outperform, state-of-art, accuracy, results, non-latin, alphabet-based, text, classification, achieved, promising, results, eight, text, classification, datasets, ., furthermore, ,, approach, outperformed, memory, networks, using, vocabulary, entities, fromtask, 4, babi, dialog, dataset, ."
"An Automated Multiple-Choice Question Generation Using Natural Language
  Processing Techniques","Chidinma A. Nwafor, Ikechukwu E. Onyenwe",2021-03-26T22:39:59Z,"  Automatic multiple-choice question generation (MCQG) is a useful yet
challenging task in Natural Language Processing (NLP). It is the task of
automatic generation of correct and relevant questions from textual data.
Despite its usefulness, manually creating sizeable, meaningful and relevant
questions is a time-consuming and challenging task for teachers. In this paper,
we present an NLP-based system for automatic MCQG for Computer-Based Testing
Examination (CBTE).We used NLP technique to extract keywords that are important
words in a given lesson material. To validate that the system is not perverse,
five lesson materials were used to check the effectiveness and efficiency of
the system. The manually extracted keywords by the teacher were compared to the
auto-generated keywords and the result shows that the system was capable of
extracting keywords from lesson materials in setting examinable questions. This
outcome is presented in a user-friendly interface for easy accessibility.
","['automatic', 'multiple-choice', 'question', 'generation', '(', 'mcqg', ')', 'useful', 'yet', 'challenging', 'task', 'natural', 'language', 'processing', '(', 'nlp', ')', '.', 'task', 'automatic', 'generation', 'correct', 'relevant', 'questions', 'textual', 'data', '.', 'despite', 'usefulness', ',', 'manually', 'creating', 'sizeable', ',', 'meaningful', 'relevant', 'questions', 'time-consuming', 'challenging', 'task', 'teachers', '.', 'paper', ',', 'present', 'nlp-based', 'system', 'automatic', 'mcqg', 'computer-based', 'testing', 'examination', '(', 'cbte', ')', '.we', 'used', 'nlp', 'technique', 'extract', 'keywords', 'important', 'words', 'given', 'lesson', 'material', '.', 'validate', 'system', 'perverse', ',', 'five', 'lesson', 'materials', 'used', 'check', 'effectiveness', 'efficiency', 'system', '.', 'manually', 'extracted', 'keywords', 'teacher', 'compared', 'auto-generated', 'keywords', 'result', 'shows', 'system', 'capable', 'extracting', 'keywords', 'lesson', 'materials', 'setting', 'examinable', 'questions', '.', 'outcome', 'presented', 'user-friendly', 'interface', 'easy', 'accessibility', '.']","automatic, multiple-choice, question, generation, (, mcqg, ), useful, yet, challenging, task, natural, language, processing, (, nlp, ), ., task, automatic, generation, correct, relevant, questions, textual, data, ., despite, usefulness, ,, manually, creating, sizeable, ,, meaningful, relevant, questions, time-consuming, challenging, task, teachers, ., paper, ,, present, nlp-based, system, automatic, mcqg, computer-based, testing, examination, (, cbte, ), .we, used, nlp, technique, extract, keywords, important, words, given, lesson, material, ., validate, system, perverse, ,, five, lesson, materials, used, check, effectiveness, efficiency, system, ., manually, extracted, keywords, teacher, compared, auto-generated, keywords, result, shows, system, capable, extracting, keywords, lesson, materials, setting, examinable, questions, ., outcome, presented, user-friendly, interface, easy, accessibility, ."
"Can Multilingual Language Models Transfer to an Unseen Dialect? A Case
  Study on North African Arabizi","Benjamin Muller, Benoit Sagot, Djamé Seddah",2020-05-01T11:29:23Z,"  Building natural language processing systems for non standardized and low
resource languages is a difficult challenge. The recent success of large-scale
multilingual pretrained language models provides new modeling tools to tackle
this. In this work, we study the ability of multilingual language models to
process an unseen dialect. We take user generated North-African Arabic as our
case study, a resource-poor dialectal variety of Arabic with frequent
code-mixing with French and written in Arabizi, a non-standardized
transliteration of Arabic to Latin script. Focusing on two tasks,
part-of-speech tagging and dependency parsing, we show in zero-shot and
unsupervised adaptation scenarios that multilingual language models are able to
transfer to such an unseen dialect, specifically in two extreme cases: (i)
across scripts, using Modern Standard Arabic as a source language, and (ii)
from a distantly related language, unseen during pretraining, namely Maltese.
Our results constitute the first successful transfer experiments on this
dialect, paving thus the way for the development of an NLP ecosystem for
resource-scarce, non-standardized and highly variable vernacular languages.
","['building', 'natural', 'language', 'processing', 'systems', 'non', 'standardized', 'low', 'resource', 'languages', 'difficult', 'challenge', '.', 'recent', 'success', 'large-scale', 'multilingual', 'pretrained', 'language', 'models', 'provides', 'new', 'modeling', 'tools', 'tackle', '.', 'work', ',', 'study', 'ability', 'multilingual', 'language', 'models', 'process', 'unseen', 'dialect', '.', 'take', 'user', 'generated', 'north-african', 'arabic', 'case', 'study', ',', 'resource-poor', 'dialectal', 'variety', 'arabic', 'frequent', 'code-mixing', 'french', 'written', 'arabizi', ',', 'non-standardized', 'transliteration', 'arabic', 'latin', 'script', '.', 'focusing', 'two', 'tasks', ',', 'part-of-speech', 'tagging', 'dependency', 'parsing', ',', 'show', 'zero-shot', 'unsupervised', 'adaptation', 'scenarios', 'multilingual', 'language', 'models', 'able', 'transfer', 'unseen', 'dialect', ',', 'specifically', 'two', 'extreme', 'cases', ':', '(', ')', 'across', 'scripts', ',', 'using', 'modern', 'standard', 'arabic', 'source', 'language', ',', '(', 'ii', ')', 'distantly', 'related', 'language', ',', 'unseen', 'pretraining', ',', 'namely', 'maltese', '.', 'results', 'constitute', 'first', 'successful', 'transfer', 'experiments', 'dialect', ',', 'paving', 'thus', 'way', 'development', 'nlp', 'ecosystem', 'resource-scarce', ',', 'non-standardized', 'highly', 'variable', 'vernacular', 'languages', '.']","building, natural, language, processing, systems, non, standardized, low, resource, languages, difficult, challenge, ., recent, success, large-scale, multilingual, pretrained, language, models, provides, new, modeling, tools, tackle, ., work, ,, study, ability, multilingual, language, models, process, unseen, dialect, ., take, user, generated, north-african, arabic, case, study, ,, resource-poor, dialectal, variety, arabic, frequent, code-mixing, french, written, arabizi, ,, non-standardized, transliteration, arabic, latin, script, ., focusing, two, tasks, ,, part-of-speech, tagging, dependency, parsing, ,, show, zero-shot, unsupervised, adaptation, scenarios, multilingual, language, models, able, transfer, unseen, dialect, ,, specifically, two, extreme, cases, :, (, ), across, scripts, ,, using, modern, standard, arabic, source, language, ,, (, ii, ), distantly, related, language, ,, unseen, pretraining, ,, namely, maltese, ., results, constitute, first, successful, transfer, experiments, dialect, ,, paving, thus, way, development, nlp, ecosystem, resource-scarce, ,, non-standardized, highly, variable, vernacular, languages, ."
ClimateBert: A Pretrained Language Model for Climate-Related Text,"Nicolas Webersinke, Mathias Kraus, Julia Anna Bingler, Markus Leippold",2021-10-22T18:47:34Z,"  Over the recent years, large pretrained language models (LM) have
revolutionized the field of natural language processing (NLP). However, while
pretraining on general language has been shown to work very well for common
language, it has been observed that niche language poses problems. In
particular, climate-related texts include specific language that common LMs can
not represent accurately. We argue that this shortcoming of today's LMs limits
the applicability of modern NLP to the broad field of text processing of
climate-related texts. As a remedy, we propose CLIMATEBERT, a transformer-based
language model that is further pretrained on over 2 million paragraphs of
climate-related texts, crawled from various sources such as common news,
research articles, and climate reporting of companies. We find that CLIMATEBERT
leads to a 48% improvement on a masked language model objective which, in turn,
leads to lowering error rates by 3.57% to 35.71% for various climate-related
downstream tasks like text classification, sentiment analysis, and
fact-checking.
","['recent', 'years', ',', 'large', 'pretrained', 'language', 'models', '(', 'lm', ')', 'revolutionized', 'field', 'natural', 'language', 'processing', '(', 'nlp', ')', '.', 'however', ',', 'pretraining', 'general', 'language', 'shown', 'work', 'well', 'common', 'language', ',', 'observed', 'niche', 'language', 'poses', 'problems', '.', 'particular', ',', 'climate-related', 'texts', 'include', 'specific', 'language', 'common', 'lms', 'represent', 'accurately', '.', 'argue', 'shortcoming', 'today', ""'s"", 'lms', 'limits', 'applicability', 'modern', 'nlp', 'broad', 'field', 'text', 'processing', 'climate-related', 'texts', '.', 'remedy', ',', 'propose', 'climatebert', ',', 'transformer-based', 'language', 'model', 'pretrained', '2', 'million', 'paragraphs', 'climate-related', 'texts', ',', 'crawled', 'various', 'sources', 'common', 'news', ',', 'research', 'articles', ',', 'climate', 'reporting', 'companies', '.', 'find', 'climatebert', 'leads', '48', '%', 'improvement', 'masked', 'language', 'model', 'objective', ',', 'turn', ',', 'leads', 'lowering', 'error', 'rates', '3.57', '%', '35.71', '%', 'various', 'climate-related', 'downstream', 'tasks', 'like', 'text', 'classification', ',', 'sentiment', 'analysis', ',', 'fact-checking', '.']","recent, years, ,, large, pretrained, language, models, (, lm, ), revolutionized, field, natural, language, processing, (, nlp, ), ., however, ,, pretraining, general, language, shown, work, well, common, language, ,, observed, niche, language, poses, problems, ., particular, ,, climate-related, texts, include, specific, language, common, lms, represent, accurately, ., argue, shortcoming, today, 's, lms, limits, applicability, modern, nlp, broad, field, text, processing, climate-related, texts, ., remedy, ,, propose, climatebert, ,, transformer-based, language, model, pretrained, 2, million, paragraphs, climate-related, texts, ,, crawled, various, sources, common, news, ,, research, articles, ,, climate, reporting, companies, ., find, climatebert, leads, 48, %, improvement, masked, language, model, objective, ,, turn, ,, leads, lowering, error, rates, 3.57, %, 35.71, %, various, climate-related, downstream, tasks, like, text, classification, ,, sentiment, analysis, ,, fact-checking, ."
INCLUSIFY: A benchmark and a model for gender-inclusive German,David Pomerenke,2022-12-05T19:37:48Z,"  Gender-inclusive language is important for achieving gender equality in
languages with gender inflections, such as German. While stirring some
controversy, it is increasingly adopted by companies and political
institutions. A handful of tools have been developed to help people use
gender-inclusive language by identifying instances of the generic masculine and
providing suggestions for more inclusive reformulations. In this report, we
define the underlying tasks in terms of natural language processing, and
present a dataset and measures for benchmarking them. We also present a model
that implements these tasks, by combining an inclusive language database with
an elaborate sequence of processing steps via standard pre-trained models. Our
model achieves a recall of 0.89 and a precision of 0.82 in our benchmark for
identifying exclusive language; and one of its top five suggestions is chosen
in real-world texts in 44% of cases. We sketch how the area could be further
advanced by training end-to-end models and using large language models; and we
urge the community to include more gender-inclusive texts in their training
data in order to not present an obstacle to the adoption of gender-inclusive
language. Through these efforts, we hope to contribute to restoring justice in
language and, to a small extent, in reality.
","['gender-inclusive', 'language', 'important', 'achieving', 'gender', 'equality', 'languages', 'gender', 'inflections', ',', 'german', '.', 'stirring', 'controversy', ',', 'increasingly', 'adopted', 'companies', 'political', 'institutions', '.', 'handful', 'tools', 'developed', 'help', 'people', 'use', 'gender-inclusive', 'language', 'identifying', 'instances', 'generic', 'masculine', 'providing', 'suggestions', 'inclusive', 'reformulations', '.', 'report', ',', 'define', 'underlying', 'tasks', 'terms', 'natural', 'language', 'processing', ',', 'present', 'dataset', 'measures', 'benchmarking', '.', 'also', 'present', 'model', 'implements', 'tasks', ',', 'combining', 'inclusive', 'language', 'database', 'elaborate', 'sequence', 'processing', 'steps', 'via', 'standard', 'pre-trained', 'models', '.', 'model', 'achieves', 'recall', '0.89', 'precision', '0.82', 'benchmark', 'identifying', 'exclusive', 'language', ';', 'one', 'top', 'five', 'suggestions', 'chosen', 'real-world', 'texts', '44', '%', 'cases', '.', 'sketch', 'area', 'could', 'advanced', 'training', 'end-to-end', 'models', 'using', 'large', 'language', 'models', ';', 'urge', 'community', 'include', 'gender-inclusive', 'texts', 'training', 'data', 'order', 'present', 'obstacle', 'adoption', 'gender-inclusive', 'language', '.', 'efforts', ',', 'hope', 'contribute', 'restoring', 'justice', 'language', ',', 'small', 'extent', ',', 'reality', '.']","gender-inclusive, language, important, achieving, gender, equality, languages, gender, inflections, ,, german, ., stirring, controversy, ,, increasingly, adopted, companies, political, institutions, ., handful, tools, developed, help, people, use, gender-inclusive, language, identifying, instances, generic, masculine, providing, suggestions, inclusive, reformulations, ., report, ,, define, underlying, tasks, terms, natural, language, processing, ,, present, dataset, measures, benchmarking, ., also, present, model, implements, tasks, ,, combining, inclusive, language, database, elaborate, sequence, processing, steps, via, standard, pre-trained, models, ., model, achieves, recall, 0.89, precision, 0.82, benchmark, identifying, exclusive, language, ;, one, top, five, suggestions, chosen, real-world, texts, 44, %, cases, ., sketch, area, could, advanced, training, end-to-end, models, using, large, language, models, ;, urge, community, include, gender-inclusive, texts, training, data, order, present, obstacle, adoption, gender-inclusive, language, ., efforts, ,, hope, contribute, restoring, justice, language, ,, small, extent, ,, reality, ."
PADL: Language-Directed Physics-Based Character Control,"Jordan Juravsky, Yunrong Guo, Sanja Fidler, Xue Bin Peng",2023-01-31T18:59:22Z,"  Developing systems that can synthesize natural and life-like motions for
simulated characters has long been a focus for computer animation. But in order
for these systems to be useful for downstream applications, they need not only
produce high-quality motions, but must also provide an accessible and versatile
interface through which users can direct a character's behaviors. Natural
language provides a simple-to-use and expressive medium for specifying a user's
intent. Recent breakthroughs in natural language processing (NLP) have
demonstrated effective use of language-based interfaces for applications such
as image generation and program synthesis. In this work, we present PADL, which
leverages recent innovations in NLP in order to take steps towards developing
language-directed controllers for physics-based character animation. PADL
allows users to issue natural language commands for specifying both high-level
tasks and low-level skills that a character should perform. We present an
adversarial imitation learning approach for training policies to map high-level
language commands to low-level controls that enable a character to perform the
desired task and skill specified by a user's commands. Furthermore, we propose
a multi-task aggregation method that leverages a language-based multiple-choice
question-answering approach to determine high-level task objectives from
language commands. We show that our framework can be applied to effectively
direct a simulated humanoid character to perform a diverse array of complex
motor skills.
","['developing', 'systems', 'synthesize', 'natural', 'life-like', 'motions', 'simulated', 'characters', 'long', 'focus', 'computer', 'animation', '.', 'order', 'systems', 'useful', 'downstream', 'applications', ',', 'need', 'produce', 'high-quality', 'motions', ',', 'must', 'also', 'provide', 'accessible', 'versatile', 'interface', 'users', 'direct', 'character', ""'s"", 'behaviors', '.', 'natural', 'language', 'provides', 'simple-to-use', 'expressive', 'medium', 'specifying', 'user', ""'s"", 'intent', '.', 'recent', 'breakthroughs', 'natural', 'language', 'processing', '(', 'nlp', ')', 'demonstrated', 'effective', 'use', 'language-based', 'interfaces', 'applications', 'image', 'generation', 'program', 'synthesis', '.', 'work', ',', 'present', 'padl', ',', 'leverages', 'recent', 'innovations', 'nlp', 'order', 'take', 'steps', 'towards', 'developing', 'language-directed', 'controllers', 'physics-based', 'character', 'animation', '.', 'padl', 'allows', 'users', 'issue', 'natural', 'language', 'commands', 'specifying', 'high-level', 'tasks', 'low-level', 'skills', 'character', 'perform', '.', 'present', 'adversarial', 'imitation', 'learning', 'approach', 'training', 'policies', 'map', 'high-level', 'language', 'commands', 'low-level', 'controls', 'enable', 'character', 'perform', 'desired', 'task', 'skill', 'specified', 'user', ""'s"", 'commands', '.', 'furthermore', ',', 'propose', 'multi-task', 'aggregation', 'method', 'leverages', 'language-based', 'multiple-choice', 'question-answering', 'approach', 'determine', 'high-level', 'task', 'objectives', 'language', 'commands', '.', 'show', 'framework', 'applied', 'effectively', 'direct', 'simulated', 'humanoid', 'character', 'perform', 'diverse', 'array', 'complex', 'motor', 'skills', '.']","developing, systems, synthesize, natural, life-like, motions, simulated, characters, long, focus, computer, animation, ., order, systems, useful, downstream, applications, ,, need, produce, high-quality, motions, ,, must, also, provide, accessible, versatile, interface, users, direct, character, 's, behaviors, ., natural, language, provides, simple-to-use, expressive, medium, specifying, user, 's, intent, ., recent, breakthroughs, natural, language, processing, (, nlp, ), demonstrated, effective, use, language-based, interfaces, applications, image, generation, program, synthesis, ., work, ,, present, padl, ,, leverages, recent, innovations, nlp, order, take, steps, towards, developing, language-directed, controllers, physics-based, character, animation, ., padl, allows, users, issue, natural, language, commands, specifying, high-level, tasks, low-level, skills, character, perform, ., present, adversarial, imitation, learning, approach, training, policies, map, high-level, language, commands, low-level, controls, enable, character, perform, desired, task, skill, specified, user, 's, commands, ., furthermore, ,, propose, multi-task, aggregation, method, leverages, language-based, multiple-choice, question-answering, approach, determine, high-level, task, objectives, language, commands, ., show, framework, applied, effectively, direct, simulated, humanoid, character, perform, diverse, array, complex, motor, skills, ."
"Reinforcement Learning and Bandits for Speech and Language Processing:
  Tutorial, Review and Outlook",Baihan Lin,2022-10-24T21:49:12Z,"  In recent years, reinforcement learning and bandits have transformed a wide
range of real-world applications including healthcare, finance, recommendation
systems, robotics, and last but not least, the speech and natural language
processing. While most speech and language applications of reinforcement
learning algorithms are centered around improving the training of deep neural
networks with its flexible optimization properties, there are still many
grounds to explore to utilize the benefits of reinforcement learning, such as
its reward-driven adaptability, state representations, temporal structures and
generalizability. In this survey, we present an overview of recent advancements
of reinforcement learning and bandits, and discuss how they can be effectively
employed to solve speech and natural language processing problems with models
that are adaptive, interactive and scalable.
","['recent', 'years', ',', 'reinforcement', 'learning', 'bandits', 'transformed', 'wide', 'range', 'real-world', 'applications', 'including', 'healthcare', ',', 'finance', ',', 'recommendation', 'systems', ',', 'robotics', ',', 'last', 'least', ',', 'speech', 'natural', 'language', 'processing', '.', 'speech', 'language', 'applications', 'reinforcement', 'learning', 'algorithms', 'centered', 'around', 'improving', 'training', 'deep', 'neural', 'networks', 'flexible', 'optimization', 'properties', ',', 'still', 'many', 'grounds', 'explore', 'utilize', 'benefits', 'reinforcement', 'learning', ',', 'reward-driven', 'adaptability', ',', 'state', 'representations', ',', 'temporal', 'structures', 'generalizability', '.', 'survey', ',', 'present', 'overview', 'recent', 'advancements', 'reinforcement', 'learning', 'bandits', ',', 'discuss', 'effectively', 'employed', 'solve', 'speech', 'natural', 'language', 'processing', 'problems', 'models', 'adaptive', ',', 'interactive', 'scalable', '.']","recent, years, ,, reinforcement, learning, bandits, transformed, wide, range, real-world, applications, including, healthcare, ,, finance, ,, recommendation, systems, ,, robotics, ,, last, least, ,, speech, natural, language, processing, ., speech, language, applications, reinforcement, learning, algorithms, centered, around, improving, training, deep, neural, networks, flexible, optimization, properties, ,, still, many, grounds, explore, utilize, benefits, reinforcement, learning, ,, reward-driven, adaptability, ,, state, representations, ,, temporal, structures, generalizability, ., survey, ,, present, overview, recent, advancements, reinforcement, learning, bandits, ,, discuss, effectively, employed, solve, speech, natural, language, processing, problems, models, adaptive, ,, interactive, scalable, ."
Quantum Natural Language Processing,"Dominic Widdows, Willie Aboumrad, Dohun Kim, Sayonee Ray, Jonathan Mei",2024-03-28T18:15:07Z,"  Language processing is at the heart of current developments in artificial
intelligence, and quantum computers are becoming available at the same time.
This has led to great interest in quantum natural language processing, and
several early proposals and experiments.
  This paper surveys the state of this area, showing how NLP-related techniques
have been used in quantum language processing. We examine the art of word
embeddings and sequential models, proposing some avenues for future
investigation and discussing the tradeoffs present in these directions. We also
highlight some recent methods to compute attention in transformer models, and
perform grammatical parsing. We also introduce a new quantum design for the
basic task of text encoding (representing a string of characters in memory),
which has not been addressed in detail before.
  Quantum theory has contributed toward quantifying uncertainty and explaining
""What is intelligence?"" In this context, we argue that ""hallucinations"" in
modern artificial intelligence systems are a misunderstanding of the way facts
are conceptualized: language can express many plausible hypotheses, of which
only a few become actual.
","['language', 'processing', 'heart', 'current', 'developments', 'artificial', 'intelligence', ',', 'quantum', 'computers', 'becoming', 'available', 'time', '.', 'led', 'great', 'interest', 'quantum', 'natural', 'language', 'processing', ',', 'several', 'early', 'proposals', 'experiments', '.', 'paper', 'surveys', 'state', 'area', ',', 'showing', 'nlp-related', 'techniques', 'used', 'quantum', 'language', 'processing', '.', 'examine', 'art', 'word', 'embeddings', 'sequential', 'models', ',', 'proposing', 'avenues', 'future', 'investigation', 'discussing', 'tradeoffs', 'present', 'directions', '.', 'also', 'highlight', 'recent', 'methods', 'compute', 'attention', 'transformer', 'models', ',', 'perform', 'grammatical', 'parsing', '.', 'also', 'introduce', 'new', 'quantum', 'design', 'basic', 'task', 'text', 'encoding', '(', 'representing', 'string', 'characters', 'memory', ')', ',', 'addressed', 'detail', '.', 'quantum', 'theory', 'contributed', 'toward', 'quantifying', 'uncertainty', 'explaining', ""''"", 'intelligence', '?', ""''"", 'context', ',', 'argue', '``', 'hallucinations', ""''"", 'modern', 'artificial', 'intelligence', 'systems', 'misunderstanding', 'way', 'facts', 'conceptualized', ':', 'language', 'express', 'many', 'plausible', 'hypotheses', ',', 'become', 'actual', '.']","language, processing, heart, current, developments, artificial, intelligence, ,, quantum, computers, becoming, available, time, ., led, great, interest, quantum, natural, language, processing, ,, several, early, proposals, experiments, ., paper, surveys, state, area, ,, showing, nlp-related, techniques, used, quantum, language, processing, ., examine, art, word, embeddings, sequential, models, ,, proposing, avenues, future, investigation, discussing, tradeoffs, present, directions, ., also, highlight, recent, methods, compute, attention, transformer, models, ,, perform, grammatical, parsing, ., also, introduce, new, quantum, design, basic, task, text, encoding, (, representing, string, characters, memory, ), ,, addressed, detail, ., quantum, theory, contributed, toward, quantifying, uncertainty, explaining, '', intelligence, ?, '', context, ,, argue, ``, hallucinations, '', modern, artificial, intelligence, systems, misunderstanding, way, facts, conceptualized, :, language, express, many, plausible, hypotheses, ,, become, actual, ."
"Evidence from fMRI Supports a Two-Phase Abstraction Process in Language
  Models","Emily Cheng, Richard J. Antonello",2024-09-09T16:33:16Z,"  Research has repeatedly demonstrated that intermediate hidden states
extracted from large language models are able to predict measured brain
response to natural language stimuli. Yet, very little is known about the
representation properties that enable this high prediction performance. Why is
it the intermediate layers, and not the output layers, that are most capable
for this unique and highly general transfer task? In this work, we show that
evidence from language encoding models in fMRI supports the existence of a
two-phase abstraction process within LLMs. We use manifold learning methods to
show that this abstraction process naturally arises over the course of training
a language model and that the first ""composition"" phase of this abstraction
process is compressed into fewer layers as training continues. Finally, we
demonstrate a strong correspondence between layerwise encoding performance and
the intrinsic dimensionality of representations from LLMs. We give initial
evidence that this correspondence primarily derives from the inherent
compositionality of LLMs and not their next-word prediction properties.
","['research', 'repeatedly', 'demonstrated', 'intermediate', 'hidden', 'states', 'extracted', 'large', 'language', 'models', 'able', 'predict', 'measured', 'brain', 'response', 'natural', 'language', 'stimuli', '.', 'yet', ',', 'little', 'known', 'representation', 'properties', 'enable', 'high', 'prediction', 'performance', '.', 'intermediate', 'layers', ',', 'output', 'layers', ',', 'capable', 'unique', 'highly', 'general', 'transfer', 'task', '?', 'work', ',', 'show', 'evidence', 'language', 'encoding', 'models', 'fmri', 'supports', 'existence', 'two-phase', 'abstraction', 'process', 'within', 'llms', '.', 'use', 'manifold', 'learning', 'methods', 'show', 'abstraction', 'process', 'naturally', 'arises', 'course', 'training', 'language', 'model', 'first', '``', 'composition', ""''"", 'phase', 'abstraction', 'process', 'compressed', 'fewer', 'layers', 'training', 'continues', '.', 'finally', ',', 'demonstrate', 'strong', 'correspondence', 'layerwise', 'encoding', 'performance', 'intrinsic', 'dimensionality', 'representations', 'llms', '.', 'give', 'initial', 'evidence', 'correspondence', 'primarily', 'derives', 'inherent', 'compositionality', 'llms', 'next-word', 'prediction', 'properties', '.']","research, repeatedly, demonstrated, intermediate, hidden, states, extracted, large, language, models, able, predict, measured, brain, response, natural, language, stimuli, ., yet, ,, little, known, representation, properties, enable, high, prediction, performance, ., intermediate, layers, ,, output, layers, ,, capable, unique, highly, general, transfer, task, ?, work, ,, show, evidence, language, encoding, models, fmri, supports, existence, two-phase, abstraction, process, within, llms, ., use, manifold, learning, methods, show, abstraction, process, naturally, arises, course, training, language, model, first, ``, composition, '', phase, abstraction, process, compressed, fewer, layers, training, continues, ., finally, ,, demonstrate, strong, correspondence, layerwise, encoding, performance, intrinsic, dimensionality, representations, llms, ., give, initial, evidence, correspondence, primarily, derives, inherent, compositionality, llms, next-word, prediction, properties, ."
Sentiment Analysis Challenges in Persian Language,Mohammad Heydari,2019-07-09T20:46:37Z,"  The rapid growth in data on the internet requires a data mining process to
reach a decision to support insight. The Persian language has strong potential
for deep research in any aspect of natural language processing, especially
sentimental analysis approach. Thousands of websites and blogs updates and
modifies by Persian users around the world that contains millions of Persian
context. This range of application requires a comprehensive structured
framework to extract beneficial information for helping enterprises to enhance
their business and initiate a customer-centric management process by producing
effective recommender systems. Sentimental analysis is an intelligent approach
for extracting useful information from huge amounts of data to help an
enterprise for smart management process. In this road, machine learning and
deep learning techniques will become very helpful but there is the number of
challenges which are face to them. This paper tried to present and assert the
most important challenges of sentimental analysis in the Persian language. This
language is an Indo-European language which spoken by over 110 million people
around the world and is an official language in Iran, Tajikistan, and
Afghanistan. Its also widely used in Uzbekistan, Pakistan and Turkish by order.
","['rapid', 'growth', 'data', 'internet', 'requires', 'data', 'mining', 'process', 'reach', 'decision', 'support', 'insight', '.', 'persian', 'language', 'strong', 'potential', 'deep', 'research', 'aspect', 'natural', 'language', 'processing', ',', 'especially', 'sentimental', 'analysis', 'approach', '.', 'thousands', 'websites', 'blogs', 'updates', 'modifies', 'persian', 'users', 'around', 'world', 'contains', 'millions', 'persian', 'context', '.', 'range', 'application', 'requires', 'comprehensive', 'structured', 'framework', 'extract', 'beneficial', 'information', 'helping', 'enterprises', 'enhance', 'business', 'initiate', 'customer-centric', 'management', 'process', 'producing', 'effective', 'recommender', 'systems', '.', 'sentimental', 'analysis', 'intelligent', 'approach', 'extracting', 'useful', 'information', 'huge', 'amounts', 'data', 'help', 'enterprise', 'smart', 'management', 'process', '.', 'road', ',', 'machine', 'learning', 'deep', 'learning', 'techniques', 'become', 'helpful', 'number', 'challenges', 'face', '.', 'paper', 'tried', 'present', 'assert', 'important', 'challenges', 'sentimental', 'analysis', 'persian', 'language', '.', 'language', 'indo-european', 'language', 'spoken', '110', 'million', 'people', 'around', 'world', 'official', 'language', 'iran', ',', 'tajikistan', ',', 'afghanistan', '.', 'also', 'widely', 'used', 'uzbekistan', ',', 'pakistan', 'turkish', 'order', '.']","rapid, growth, data, internet, requires, data, mining, process, reach, decision, support, insight, ., persian, language, strong, potential, deep, research, aspect, natural, language, processing, ,, especially, sentimental, analysis, approach, ., thousands, websites, blogs, updates, modifies, persian, users, around, world, contains, millions, persian, context, ., range, application, requires, comprehensive, structured, framework, extract, beneficial, information, helping, enterprises, enhance, business, initiate, customer-centric, management, process, producing, effective, recommender, systems, ., sentimental, analysis, intelligent, approach, extracting, useful, information, huge, amounts, data, help, enterprise, smart, management, process, ., road, ,, machine, learning, deep, learning, techniques, become, helpful, number, challenges, face, ., paper, tried, present, assert, important, challenges, sentimental, analysis, persian, language, ., language, indo-european, language, spoken, 110, million, people, around, world, official, language, iran, ,, tajikistan, ,, afghanistan, ., also, widely, used, uzbekistan, ,, pakistan, turkish, order, ."
Machine Translation: A Literature Review,"Ankush Garg, Mayank Agarwal",2018-12-28T19:04:36Z,"  Machine translation (MT) plays an important role in benefiting linguists,
sociologists, computer scientists, etc. by processing natural language to
translate it into some other natural language. And this demand has grown
exponentially over past couple of years, considering the enormous exchange of
information between different regions with different regional languages.
Machine Translation poses numerous challenges, some of which are: a) Not all
words in one language has equivalent word in another language b) Two given
languages may have completely different structures c) Words can have more than
one meaning. Owing to these challenges, along with many others, MT has been
active area of research for more than five decades. Numerous methods have been
proposed in the past which either aim at improving the quality of the
translations generated by them, or study the robustness of these systems by
measuring their performance on many different languages. In this literature
review, we discuss statistical approaches (in particular word-based and
phrase-based) and neural approaches which have gained widespread prominence
owing to their state-of-the-art results across multiple major languages.
","['machine', 'translation', '(', 'mt', ')', 'plays', 'important', 'role', 'benefiting', 'linguists', ',', 'sociologists', ',', 'computer', 'scientists', ',', 'etc', '.', 'processing', 'natural', 'language', 'translate', 'natural', 'language', '.', 'demand', 'grown', 'exponentially', 'past', 'couple', 'years', ',', 'considering', 'enormous', 'exchange', 'information', 'different', 'regions', 'different', 'regional', 'languages', '.', 'machine', 'translation', 'poses', 'numerous', 'challenges', ',', ':', ')', 'words', 'one', 'language', 'equivalent', 'word', 'another', 'language', 'b', ')', 'two', 'given', 'languages', 'may', 'completely', 'different', 'structures', 'c', ')', 'words', 'one', 'meaning', '.', 'owing', 'challenges', ',', 'along', 'many', 'others', ',', 'mt', 'active', 'area', 'research', 'five', 'decades', '.', 'numerous', 'methods', 'proposed', 'past', 'either', 'aim', 'improving', 'quality', 'translations', 'generated', ',', 'study', 'robustness', 'systems', 'measuring', 'performance', 'many', 'different', 'languages', '.', 'literature', 'review', ',', 'discuss', 'statistical', 'approaches', '(', 'particular', 'word-based', 'phrase-based', ')', 'neural', 'approaches', 'gained', 'widespread', 'prominence', 'owing', 'state-of-the-art', 'results', 'across', 'multiple', 'major', 'languages', '.']","machine, translation, (, mt, ), plays, important, role, benefiting, linguists, ,, sociologists, ,, computer, scientists, ,, etc, ., processing, natural, language, translate, natural, language, ., demand, grown, exponentially, past, couple, years, ,, considering, enormous, exchange, information, different, regions, different, regional, languages, ., machine, translation, poses, numerous, challenges, ,, :, ), words, one, language, equivalent, word, another, language, b, ), two, given, languages, may, completely, different, structures, c, ), words, one, meaning, ., owing, challenges, ,, along, many, others, ,, mt, active, area, research, five, decades, ., numerous, methods, proposed, past, either, aim, improving, quality, translations, generated, ,, study, robustness, systems, measuring, performance, many, different, languages, ., literature, review, ,, discuss, statistical, approaches, (, particular, word-based, phrase-based, ), neural, approaches, gained, widespread, prominence, owing, state-of-the-art, results, across, multiple, major, languages, ."
Is Multilingual BERT Fluent in Language Generation?,"Samuel Rönnqvist, Jenna Kanerva, Tapio Salakoski, Filip Ginter",2019-10-09T06:35:59Z,"  The multilingual BERT model is trained on 104 languages and meant to serve as
a universal language model and tool for encoding sentences. We explore how well
the model performs on several languages across several tasks: a diagnostic
classification probing the embeddings for a particular syntactic property, a
cloze task testing the language modelling ability to fill in gaps in a
sentence, and a natural language generation task testing for the ability to
produce coherent text fitting a given context. We find that the currently
available multilingual BERT model is clearly inferior to the monolingual
counterparts, and cannot in many cases serve as a substitute for a well-trained
monolingual model. We find that the English and German models perform well at
generation, whereas the multilingual model is lacking, in particular, for
Nordic languages.
","['multilingual', 'bert', 'model', 'trained', '104', 'languages', 'meant', 'serve', 'universal', 'language', 'model', 'tool', 'encoding', 'sentences', '.', 'explore', 'well', 'model', 'performs', 'several', 'languages', 'across', 'several', 'tasks', ':', 'diagnostic', 'classification', 'probing', 'embeddings', 'particular', 'syntactic', 'property', ',', 'cloze', 'task', 'testing', 'language', 'modelling', 'ability', 'fill', 'gaps', 'sentence', ',', 'natural', 'language', 'generation', 'task', 'testing', 'ability', 'produce', 'coherent', 'text', 'fitting', 'given', 'context', '.', 'find', 'currently', 'available', 'multilingual', 'bert', 'model', 'clearly', 'inferior', 'monolingual', 'counterparts', ',', 'many', 'cases', 'serve', 'substitute', 'well-trained', 'monolingual', 'model', '.', 'find', 'english', 'german', 'models', 'perform', 'well', 'generation', ',', 'whereas', 'multilingual', 'model', 'lacking', ',', 'particular', ',', 'nordic', 'languages', '.']","multilingual, bert, model, trained, 104, languages, meant, serve, universal, language, model, tool, encoding, sentences, ., explore, well, model, performs, several, languages, across, several, tasks, :, diagnostic, classification, probing, embeddings, particular, syntactic, property, ,, cloze, task, testing, language, modelling, ability, fill, gaps, sentence, ,, natural, language, generation, task, testing, ability, produce, coherent, text, fitting, given, context, ., find, currently, available, multilingual, bert, model, clearly, inferior, monolingual, counterparts, ,, many, cases, serve, substitute, well-trained, monolingual, model, ., find, english, german, models, perform, well, generation, ,, whereas, multilingual, model, lacking, ,, particular, ,, nordic, languages, ."
"From English To Foreign Languages: Transferring Pre-trained Language
  Models",Ke Tran,2020-02-18T00:22:54Z,"  Pre-trained models have demonstrated their effectiveness in many downstream
natural language processing (NLP) tasks. The availability of multilingual
pre-trained models enables zero-shot transfer of NLP tasks from high resource
languages to low resource ones. However, recent research in improving
pre-trained models focuses heavily on English. While it is possible to train
the latest neural architectures for other languages from scratch, it is
undesirable due to the required amount of compute. In this work, we tackle the
problem of transferring an existing pre-trained model from English to other
languages under a limited computational budget. With a single GPU, our approach
can obtain a foreign BERT base model within a day and a foreign BERT large
within two days. Furthermore, evaluating our models on six languages, we
demonstrate that our models are better than multilingual BERT on two zero-shot
tasks: natural language inference and dependency parsing.
","['pre-trained', 'models', 'demonstrated', 'effectiveness', 'many', 'downstream', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', '.', 'availability', 'multilingual', 'pre-trained', 'models', 'enables', 'zero-shot', 'transfer', 'nlp', 'tasks', 'high', 'resource', 'languages', 'low', 'resource', 'ones', '.', 'however', ',', 'recent', 'research', 'improving', 'pre-trained', 'models', 'focuses', 'heavily', 'english', '.', 'possible', 'train', 'latest', 'neural', 'architectures', 'languages', 'scratch', ',', 'undesirable', 'due', 'required', 'amount', 'compute', '.', 'work', ',', 'tackle', 'problem', 'transferring', 'existing', 'pre-trained', 'model', 'english', 'languages', 'limited', 'computational', 'budget', '.', 'single', 'gpu', ',', 'approach', 'obtain', 'foreign', 'bert', 'base', 'model', 'within', 'day', 'foreign', 'bert', 'large', 'within', 'two', 'days', '.', 'furthermore', ',', 'evaluating', 'models', 'six', 'languages', ',', 'demonstrate', 'models', 'better', 'multilingual', 'bert', 'two', 'zero-shot', 'tasks', ':', 'natural', 'language', 'inference', 'dependency', 'parsing', '.']","pre-trained, models, demonstrated, effectiveness, many, downstream, natural, language, processing, (, nlp, ), tasks, ., availability, multilingual, pre-trained, models, enables, zero-shot, transfer, nlp, tasks, high, resource, languages, low, resource, ones, ., however, ,, recent, research, improving, pre-trained, models, focuses, heavily, english, ., possible, train, latest, neural, architectures, languages, scratch, ,, undesirable, due, required, amount, compute, ., work, ,, tackle, problem, transferring, existing, pre-trained, model, english, languages, limited, computational, budget, ., single, gpu, ,, approach, obtain, foreign, bert, base, model, within, day, foreign, bert, large, within, two, days, ., furthermore, ,, evaluating, models, six, languages, ,, demonstrate, models, better, multilingual, bert, two, zero-shot, tasks, :, natural, language, inference, dependency, parsing, ."
"XLTime: A Cross-Lingual Knowledge Transfer Framework for Temporal
  Expression Extraction","Yuwei Cao, William Groves, Tanay Kumar Saha, Joel R. Tetreault, Alex Jaimes, Hao Peng, Philip S. Yu",2022-05-03T20:00:42Z,"  Temporal Expression Extraction (TEE) is essential for understanding time in
natural language. It has applications in Natural Language Processing (NLP)
tasks such as question answering, information retrieval, and causal inference.
To date, work in this area has mostly focused on English as there is a scarcity
of labeled data for other languages. We propose XLTime, a novel framework for
multilingual TEE. XLTime works on top of pre-trained language models and
leverages multi-task learning to prompt cross-language knowledge transfer both
from English and within the non-English languages. XLTime alleviates problems
caused by a shortage of data in the target language. We apply XLTime with
different language models and show that it outperforms the previous automatic
SOTA methods on French, Spanish, Portuguese, and Basque, by large margins.
XLTime also closes the gap considerably on the handcrafted HeidelTime method.
","['temporal', 'expression', 'extraction', '(', 'tee', ')', 'essential', 'understanding', 'time', 'natural', 'language', '.', 'applications', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', 'question', 'answering', ',', 'information', 'retrieval', ',', 'causal', 'inference', '.', 'date', ',', 'work', 'area', 'mostly', 'focused', 'english', 'scarcity', 'labeled', 'data', 'languages', '.', 'propose', 'xltime', ',', 'novel', 'framework', 'multilingual', 'tee', '.', 'xltime', 'works', 'top', 'pre-trained', 'language', 'models', 'leverages', 'multi-task', 'learning', 'prompt', 'cross-language', 'knowledge', 'transfer', 'english', 'within', 'non-english', 'languages', '.', 'xltime', 'alleviates', 'problems', 'caused', 'shortage', 'data', 'target', 'language', '.', 'apply', 'xltime', 'different', 'language', 'models', 'show', 'outperforms', 'previous', 'automatic', 'sota', 'methods', 'french', ',', 'spanish', ',', 'portuguese', ',', 'basque', ',', 'large', 'margins', '.', 'xltime', 'also', 'closes', 'gap', 'considerably', 'handcrafted', 'heideltime', 'method', '.']","temporal, expression, extraction, (, tee, ), essential, understanding, time, natural, language, ., applications, natural, language, processing, (, nlp, ), tasks, question, answering, ,, information, retrieval, ,, causal, inference, ., date, ,, work, area, mostly, focused, english, scarcity, labeled, data, languages, ., propose, xltime, ,, novel, framework, multilingual, tee, ., xltime, works, top, pre-trained, language, models, leverages, multi-task, learning, prompt, cross-language, knowledge, transfer, english, within, non-english, languages, ., xltime, alleviates, problems, caused, shortage, data, target, language, ., apply, xltime, different, language, models, show, outperforms, previous, automatic, sota, methods, french, ,, spanish, ,, portuguese, ,, basque, ,, large, margins, ., xltime, also, closes, gap, considerably, handcrafted, heideltime, method, ."
Sequence to sequence pretraining for a less-resourced Slovenian language,"Matej Ulčar, Marko Robnik-Šikonja",2022-07-28T10:08:50Z,"  Large pretrained language models have recently conquered the area of natural
language processing. As an alternative to predominant masked language modelling
introduced in BERT, the T5 model has introduced a more general training
objective, namely sequence to sequence transformation, which includes masked
language model but more naturally fits text generation tasks such as machine
translation, summarization, question answering, text simplification, dialogue
systems, etc. The monolingual variants of T5 models have been limited to
well-resourced languages, while the massively multilingual T5 model supports
101 languages. In contrast, we trained two different sized T5-type sequence to
sequence models for morphologically rich Slovene language with much less
resources and analyzed their behavior on 11 tasks. Concerning classification
tasks, the SloT5 models mostly lag behind the monolingual Slovene SloBERTa
model but are useful for the generative tasks.
","['large', 'pretrained', 'language', 'models', 'recently', 'conquered', 'area', 'natural', 'language', 'processing', '.', 'alternative', 'predominant', 'masked', 'language', 'modelling', 'introduced', 'bert', ',', 't5', 'model', 'introduced', 'general', 'training', 'objective', ',', 'namely', 'sequence', 'sequence', 'transformation', ',', 'includes', 'masked', 'language', 'model', 'naturally', 'fits', 'text', 'generation', 'tasks', 'machine', 'translation', ',', 'summarization', ',', 'question', 'answering', ',', 'text', 'simplification', ',', 'dialogue', 'systems', ',', 'etc', '.', 'monolingual', 'variants', 't5', 'models', 'limited', 'well-resourced', 'languages', ',', 'massively', 'multilingual', 't5', 'model', 'supports', '101', 'languages', '.', 'contrast', ',', 'trained', 'two', 'different', 'sized', 't5-type', 'sequence', 'sequence', 'models', 'morphologically', 'rich', 'slovene', 'language', 'much', 'less', 'resources', 'analyzed', 'behavior', '11', 'tasks', '.', 'concerning', 'classification', 'tasks', ',', 'slot5', 'models', 'mostly', 'lag', 'behind', 'monolingual', 'slovene', 'sloberta', 'model', 'useful', 'generative', 'tasks', '.']","large, pretrained, language, models, recently, conquered, area, natural, language, processing, ., alternative, predominant, masked, language, modelling, introduced, bert, ,, t5, model, introduced, general, training, objective, ,, namely, sequence, sequence, transformation, ,, includes, masked, language, model, naturally, fits, text, generation, tasks, machine, translation, ,, summarization, ,, question, answering, ,, text, simplification, ,, dialogue, systems, ,, etc, ., monolingual, variants, t5, models, limited, well-resourced, languages, ,, massively, multilingual, t5, model, supports, 101, languages, ., contrast, ,, trained, two, different, sized, t5-type, sequence, sequence, models, morphologically, rich, slovene, language, much, less, resources, analyzed, behavior, 11, tasks, ., concerning, classification, tasks, ,, slot5, models, mostly, lag, behind, monolingual, slovene, sloberta, model, useful, generative, tasks, ."
"ERRA: An Embodied Representation and Reasoning Architecture for
  Long-horizon Language-conditioned Manipulation Tasks","Chao Zhao, Shuai Yuan, Chunli Jiang, Junhao Cai, Hongyu Yu, Michael Yu Wang, Qifeng Chen",2023-04-05T06:50:22Z,"  This letter introduces ERRA, an embodied learning architecture that enables
robots to jointly obtain three fundamental capabilities (reasoning, planning,
and interaction) for solving long-horizon language-conditioned manipulation
tasks. ERRA is based on tightly-coupled probabilistic inferences at two
granularity levels. Coarse-resolution inference is formulated as sequence
generation through a large language model, which infers action language from
natural language instruction and environment state. The robot then zooms to the
fine-resolution inference part to perform the concrete action corresponding to
the action language. Fine-resolution inference is constructed as a Markov
decision process, which takes action language and environmental sensing as
observations and outputs the action. The results of action execution in
environments provide feedback for subsequent coarse-resolution reasoning. Such
coarse-to-fine inference allows the robot to decompose and achieve long-horizon
tasks interactively. In extensive experiments, we show that ERRA can complete
various long-horizon manipulation tasks specified by abstract language
instructions. We also demonstrate successful generalization to the novel but
similar natural language instructions.
","['letter', 'introduces', 'erra', ',', 'embodied', 'learning', 'architecture', 'enables', 'robots', 'jointly', 'obtain', 'three', 'fundamental', 'capabilities', '(', 'reasoning', ',', 'planning', ',', 'interaction', ')', 'solving', 'long-horizon', 'language-conditioned', 'manipulation', 'tasks', '.', 'erra', 'based', 'tightly-coupled', 'probabilistic', 'inferences', 'two', 'granularity', 'levels', '.', 'coarse-resolution', 'inference', 'formulated', 'sequence', 'generation', 'large', 'language', 'model', ',', 'infers', 'action', 'language', 'natural', 'language', 'instruction', 'environment', 'state', '.', 'robot', 'zooms', 'fine-resolution', 'inference', 'part', 'perform', 'concrete', 'action', 'corresponding', 'action', 'language', '.', 'fine-resolution', 'inference', 'constructed', 'markov', 'decision', 'process', ',', 'takes', 'action', 'language', 'environmental', 'sensing', 'observations', 'outputs', 'action', '.', 'results', 'action', 'execution', 'environments', 'provide', 'feedback', 'subsequent', 'coarse-resolution', 'reasoning', '.', 'coarse-to-fine', 'inference', 'allows', 'robot', 'decompose', 'achieve', 'long-horizon', 'tasks', 'interactively', '.', 'extensive', 'experiments', ',', 'show', 'erra', 'complete', 'various', 'long-horizon', 'manipulation', 'tasks', 'specified', 'abstract', 'language', 'instructions', '.', 'also', 'demonstrate', 'successful', 'generalization', 'novel', 'similar', 'natural', 'language', 'instructions', '.']","letter, introduces, erra, ,, embodied, learning, architecture, enables, robots, jointly, obtain, three, fundamental, capabilities, (, reasoning, ,, planning, ,, interaction, ), solving, long-horizon, language-conditioned, manipulation, tasks, ., erra, based, tightly-coupled, probabilistic, inferences, two, granularity, levels, ., coarse-resolution, inference, formulated, sequence, generation, large, language, model, ,, infers, action, language, natural, language, instruction, environment, state, ., robot, zooms, fine-resolution, inference, part, perform, concrete, action, corresponding, action, language, ., fine-resolution, inference, constructed, markov, decision, process, ,, takes, action, language, environmental, sensing, observations, outputs, action, ., results, action, execution, environments, provide, feedback, subsequent, coarse-resolution, reasoning, ., coarse-to-fine, inference, allows, robot, decompose, achieve, long-horizon, tasks, interactively, ., extensive, experiments, ,, show, erra, complete, various, long-horizon, manipulation, tasks, specified, abstract, language, instructions, ., also, demonstrate, successful, generalization, novel, similar, natural, language, instructions, ."
"Is ChatGPT a Financial Expert? Evaluating Language Models on Financial
  Natural Language Processing","Yue Guo, Zian Xu, Yi Yang",2023-10-19T11:43:15Z,"  The emergence of Large Language Models (LLMs), such as ChatGPT, has
revolutionized general natural language preprocessing (NLP) tasks. However,
their expertise in the financial domain lacks a comprehensive evaluation. To
assess the ability of LLMs to solve financial NLP tasks, we present FinLMEval,
a framework for Financial Language Model Evaluation, comprising nine datasets
designed to evaluate the performance of language models. This study compares
the performance of encoder-only language models and the decoder-only language
models. Our findings reveal that while some decoder-only LLMs demonstrate
notable performance across most financial tasks via zero-shot prompting, they
generally lag behind the fine-tuned expert models, especially when dealing with
proprietary datasets. We hope this study provides foundation evaluations for
continuing efforts to build more advanced LLMs in the financial domain.
","['emergence', 'large', 'language', 'models', '(', 'llms', ')', ',', 'chatgpt', ',', 'revolutionized', 'general', 'natural', 'language', 'preprocessing', '(', 'nlp', ')', 'tasks', '.', 'however', ',', 'expertise', 'financial', 'domain', 'lacks', 'comprehensive', 'evaluation', '.', 'assess', 'ability', 'llms', 'solve', 'financial', 'nlp', 'tasks', ',', 'present', 'finlmeval', ',', 'framework', 'financial', 'language', 'model', 'evaluation', ',', 'comprising', 'nine', 'datasets', 'designed', 'evaluate', 'performance', 'language', 'models', '.', 'study', 'compares', 'performance', 'encoder-only', 'language', 'models', 'decoder-only', 'language', 'models', '.', 'findings', 'reveal', 'decoder-only', 'llms', 'demonstrate', 'notable', 'performance', 'across', 'financial', 'tasks', 'via', 'zero-shot', 'prompting', ',', 'generally', 'lag', 'behind', 'fine-tuned', 'expert', 'models', ',', 'especially', 'dealing', 'proprietary', 'datasets', '.', 'hope', 'study', 'provides', 'foundation', 'evaluations', 'continuing', 'efforts', 'build', 'advanced', 'llms', 'financial', 'domain', '.']","emergence, large, language, models, (, llms, ), ,, chatgpt, ,, revolutionized, general, natural, language, preprocessing, (, nlp, ), tasks, ., however, ,, expertise, financial, domain, lacks, comprehensive, evaluation, ., assess, ability, llms, solve, financial, nlp, tasks, ,, present, finlmeval, ,, framework, financial, language, model, evaluation, ,, comprising, nine, datasets, designed, evaluate, performance, language, models, ., study, compares, performance, encoder-only, language, models, decoder-only, language, models, ., findings, reveal, decoder-only, llms, demonstrate, notable, performance, across, financial, tasks, via, zero-shot, prompting, ,, generally, lag, behind, fine-tuned, expert, models, ,, especially, dealing, proprietary, datasets, ., hope, study, provides, foundation, evaluations, continuing, efforts, build, advanced, llms, financial, domain, ."
"Revenge of the Fallen? Recurrent Models Match Transformers at Predicting
  Human Language Comprehension Metrics","James A. Michaelov, Catherine Arnett, Benjamin K. Bergen",2024-04-30T01:02:15Z,"  Transformers have generally supplanted recurrent neural networks as the
dominant architecture for both natural language processing tasks and for
modelling the effect of predictability on online human language comprehension.
However, two recently developed recurrent model architectures, RWKV and Mamba,
appear to perform natural language tasks comparably to or better than
transformers of equivalent scale. In this paper, we show that contemporary
recurrent models are now also able to match - and in some cases, exceed - the
performance of comparably sized transformers at modeling online human language
comprehension. This suggests that transformer language models are not uniquely
suited to this task, and opens up new directions for debates about the extent
to which architectural features of language models make them better or worse
models of human language comprehension.
","['transformers', 'generally', 'supplanted', 'recurrent', 'neural', 'networks', 'dominant', 'architecture', 'natural', 'language', 'processing', 'tasks', 'modelling', 'effect', 'predictability', 'online', 'human', 'language', 'comprehension', '.', 'however', ',', 'two', 'recently', 'developed', 'recurrent', 'model', 'architectures', ',', 'rwkv', 'mamba', ',', 'appear', 'perform', 'natural', 'language', 'tasks', 'comparably', 'better', 'transformers', 'equivalent', 'scale', '.', 'paper', ',', 'show', 'contemporary', 'recurrent', 'models', 'also', 'able', 'match', '-', 'cases', ',', 'exceed', '-', 'performance', 'comparably', 'sized', 'transformers', 'modeling', 'online', 'human', 'language', 'comprehension', '.', 'suggests', 'transformer', 'language', 'models', 'uniquely', 'suited', 'task', ',', 'opens', 'new', 'directions', 'debates', 'extent', 'architectural', 'features', 'language', 'models', 'make', 'better', 'worse', 'models', 'human', 'language', 'comprehension', '.']","transformers, generally, supplanted, recurrent, neural, networks, dominant, architecture, natural, language, processing, tasks, modelling, effect, predictability, online, human, language, comprehension, ., however, ,, two, recently, developed, recurrent, model, architectures, ,, rwkv, mamba, ,, appear, perform, natural, language, tasks, comparably, better, transformers, equivalent, scale, ., paper, ,, show, contemporary, recurrent, models, also, able, match, -, cases, ,, exceed, -, performance, comparably, sized, transformers, modeling, online, human, language, comprehension, ., suggests, transformer, language, models, uniquely, suited, task, ,, opens, new, directions, debates, extent, architectural, features, language, models, make, better, worse, models, human, language, comprehension, ."
"A Survey of Embedding Space Alignment Methods for Language and Knowledge
  Graphs","Alexander Kalinowski, Yuan An",2020-10-26T16:08:13Z,"  Neural embedding approaches have become a staple in the fields of computer
vision, natural language processing, and more recently, graph analytics. Given
the pervasive nature of these algorithms, the natural question becomes how to
exploit the embedding spaces to map, or align, embeddings of different data
sources. To this end, we survey the current research landscape on word,
sentence and knowledge graph embedding algorithms. We provide a classification
of the relevant alignment techniques and discuss benchmark datasets used in
this field of research. By gathering these diverse approaches into a singular
survey, we hope to further motivate research into alignment of embedding spaces
of varied data types and sources.
","['neural', 'embedding', 'approaches', 'become', 'staple', 'fields', 'computer', 'vision', ',', 'natural', 'language', 'processing', ',', 'recently', ',', 'graph', 'analytics', '.', 'given', 'pervasive', 'nature', 'algorithms', ',', 'natural', 'question', 'becomes', 'exploit', 'embedding', 'spaces', 'map', ',', 'align', ',', 'embeddings', 'different', 'data', 'sources', '.', 'end', ',', 'survey', 'current', 'research', 'landscape', 'word', ',', 'sentence', 'knowledge', 'graph', 'embedding', 'algorithms', '.', 'provide', 'classification', 'relevant', 'alignment', 'techniques', 'discuss', 'benchmark', 'datasets', 'used', 'field', 'research', '.', 'gathering', 'diverse', 'approaches', 'singular', 'survey', ',', 'hope', 'motivate', 'research', 'alignment', 'embedding', 'spaces', 'varied', 'data', 'types', 'sources', '.']","neural, embedding, approaches, become, staple, fields, computer, vision, ,, natural, language, processing, ,, recently, ,, graph, analytics, ., given, pervasive, nature, algorithms, ,, natural, question, becomes, exploit, embedding, spaces, map, ,, align, ,, embeddings, different, data, sources, ., end, ,, survey, current, research, landscape, word, ,, sentence, knowledge, graph, embedding, algorithms, ., provide, classification, relevant, alignment, techniques, discuss, benchmark, datasets, used, field, research, ., gathering, diverse, approaches, singular, survey, ,, hope, motivate, research, alignment, embedding, spaces, varied, data, types, sources, ."
"Language and Intelligence, Artificial vs. Natural or What Can and What
  Cannot AI Do with NL?",Gyula Klima,2022-08-31T10:11:50Z,"  In this talk, I argue that there are certain pragmatic features of natural
language (that I will call 'productivity' and 'malleability', on top of
syntactical generativity and semantical compositionality), which are not only
hard, but even impossible to capture in an artificial language used by an AI
system, and the reason for this is to be found in certain deep, metaphysical
differences between artificial and natural intelligence, accounting for the
differences in their respective processes of concept-formation.
","['talk', ',', 'argue', 'certain', 'pragmatic', 'features', 'natural', 'language', '(', 'call', ""'productivity"", ""'"", ""'malleability"", ""'"", ',', 'top', 'syntactical', 'generativity', 'semantical', 'compositionality', ')', ',', 'hard', ',', 'even', 'impossible', 'capture', 'artificial', 'language', 'used', 'ai', 'system', ',', 'reason', 'found', 'certain', 'deep', ',', 'metaphysical', 'differences', 'artificial', 'natural', 'intelligence', ',', 'accounting', 'differences', 'respective', 'processes', 'concept-formation', '.']","talk, ,, argue, certain, pragmatic, features, natural, language, (, call, 'productivity, ', 'malleability, ', ,, top, syntactical, generativity, semantical, compositionality, ), ,, hard, ,, even, impossible, capture, artificial, language, used, ai, system, ,, reason, found, certain, deep, ,, metaphysical, differences, artificial, natural, intelligence, ,, accounting, differences, respective, processes, concept-formation, ."
"AfroLM: A Self-Active Learning-based Multilingual Pretrained Language
  Model for 23 African Languages","Bonaventure F. P. Dossou, Atnafu Lambebo Tonja, Oreen Yousuf, Salomey Osei, Abigail Oppong, Iyanuoluwa Shode, Oluwabusayo Olufunke Awoyomi, Chris Chinenye Emezue",2022-11-07T02:15:25Z,"  In recent years, multilingual pre-trained language models have gained
prominence due to their remarkable performance on numerous downstream Natural
Language Processing tasks (NLP). However, pre-training these large multilingual
language models requires a lot of training data, which is not available for
African Languages. Active learning is a semi-supervised learning algorithm, in
which a model consistently and dynamically learns to identify the most
beneficial samples to train itself on, in order to achieve better optimization
and performance on downstream tasks. Furthermore, active learning effectively
and practically addresses real-world data scarcity. Despite all its benefits,
active learning, in the context of NLP and especially multilingual language
models pretraining, has received little consideration. In this paper, we
present AfroLM, a multilingual language model pretrained from scratch on 23
African languages (the largest effort to date) using our novel self-active
learning framework. Pretrained on a dataset significantly (14x) smaller than
existing baselines, AfroLM outperforms many multilingual pretrained language
models (AfriBERTa, XLMR-base, mBERT) on various NLP downstream tasks (NER, text
classification, and sentiment analysis). Additional out-of-domain sentiment
analysis experiments show that \textbf{AfroLM} is able to generalize well
across various domains. We release the code source, and our datasets used in
our framework at https://github.com/bonaventuredossou/MLM_AL.
","['recent', 'years', ',', 'multilingual', 'pre-trained', 'language', 'models', 'gained', 'prominence', 'due', 'remarkable', 'performance', 'numerous', 'downstream', 'natural', 'language', 'processing', 'tasks', '(', 'nlp', ')', '.', 'however', ',', 'pre-training', 'large', 'multilingual', 'language', 'models', 'requires', 'lot', 'training', 'data', ',', 'available', 'african', 'languages', '.', 'active', 'learning', 'semi-supervised', 'learning', 'algorithm', ',', 'model', 'consistently', 'dynamically', 'learns', 'identify', 'beneficial', 'samples', 'train', ',', 'order', 'achieve', 'better', 'optimization', 'performance', 'downstream', 'tasks', '.', 'furthermore', ',', 'active', 'learning', 'effectively', 'practically', 'addresses', 'real-world', 'data', 'scarcity', '.', 'despite', 'benefits', ',', 'active', 'learning', ',', 'context', 'nlp', 'especially', 'multilingual', 'language', 'models', 'pretraining', ',', 'received', 'little', 'consideration', '.', 'paper', ',', 'present', 'afrolm', ',', 'multilingual', 'language', 'model', 'pretrained', 'scratch', '23', 'african', 'languages', '(', 'largest', 'effort', 'date', ')', 'using', 'novel', 'self-active', 'learning', 'framework', '.', 'pretrained', 'dataset', 'significantly', '(', '14x', ')', 'smaller', 'existing', 'baselines', ',', 'afrolm', 'outperforms', 'many', 'multilingual', 'pretrained', 'language', 'models', '(', 'afriberta', ',', 'xlmr-base', ',', 'mbert', ')', 'various', 'nlp', 'downstream', 'tasks', '(', 'ner', ',', 'text', 'classification', ',', 'sentiment', 'analysis', ')', '.', 'additional', 'out-of-domain', 'sentiment', 'analysis', 'experiments', 'show', '\\textbf', '{', 'afrolm', '}', 'able', 'generalize', 'well', 'across', 'various', 'domains', '.', 'release', 'code', 'source', ',', 'datasets', 'used', 'framework', 'https', ':', '//github.com/bonaventuredossou/mlm_al', '.']","recent, years, ,, multilingual, pre-trained, language, models, gained, prominence, due, remarkable, performance, numerous, downstream, natural, language, processing, tasks, (, nlp, ), ., however, ,, pre-training, large, multilingual, language, models, requires, lot, training, data, ,, available, african, languages, ., active, learning, semi-supervised, learning, algorithm, ,, model, consistently, dynamically, learns, identify, beneficial, samples, train, ,, order, achieve, better, optimization, performance, downstream, tasks, ., furthermore, ,, active, learning, effectively, practically, addresses, real-world, data, scarcity, ., despite, benefits, ,, active, learning, ,, context, nlp, especially, multilingual, language, models, pretraining, ,, received, little, consideration, ., paper, ,, present, afrolm, ,, multilingual, language, model, pretrained, scratch, 23, african, languages, (, largest, effort, date, ), using, novel, self-active, learning, framework, ., pretrained, dataset, significantly, (, 14x, ), smaller, existing, baselines, ,, afrolm, outperforms, many, multilingual, pretrained, language, models, (, afriberta, ,, xlmr-base, ,, mbert, ), various, nlp, downstream, tasks, (, ner, ,, text, classification, ,, sentiment, analysis, ), ., additional, out-of-domain, sentiment, analysis, experiments, show, \textbf, {, afrolm, }, able, generalize, well, across, various, domains, ., release, code, source, ,, datasets, used, framework, https, :, //github.com/bonaventuredossou/mlm_al, ."
A Report on the 2020 Sarcasm Detection Shared Task,"Debanjan Ghosh, Avijit Vajpayee, Smaranda Muresan",2020-05-12T14:27:19Z,"  Detecting sarcasm and verbal irony is critical for understanding people's
actual sentiments and beliefs. Thus, the field of sarcasm analysis has become a
popular research problem in natural language processing. As the community
working on computational approaches for sarcasm detection is growing, it is
imperative to conduct benchmarking studies to analyze the current
state-of-the-art, facilitating progress in this area. We report on the shared
task on sarcasm detection we conducted as a part of the 2nd Workshop on
Figurative Language Processing (FigLang 2020) at ACL 2020.
","['detecting', 'sarcasm', 'verbal', 'irony', 'critical', 'understanding', 'people', ""'s"", 'actual', 'sentiments', 'beliefs', '.', 'thus', ',', 'field', 'sarcasm', 'analysis', 'become', 'popular', 'research', 'problem', 'natural', 'language', 'processing', '.', 'community', 'working', 'computational', 'approaches', 'sarcasm', 'detection', 'growing', ',', 'imperative', 'conduct', 'benchmarking', 'studies', 'analyze', 'current', 'state-of-the-art', ',', 'facilitating', 'progress', 'area', '.', 'report', 'shared', 'task', 'sarcasm', 'detection', 'conducted', 'part', '2nd', 'workshop', 'figurative', 'language', 'processing', '(', 'figlang', '2020', ')', 'acl', '2020', '.']","detecting, sarcasm, verbal, irony, critical, understanding, people, 's, actual, sentiments, beliefs, ., thus, ,, field, sarcasm, analysis, become, popular, research, problem, natural, language, processing, ., community, working, computational, approaches, sarcasm, detection, growing, ,, imperative, conduct, benchmarking, studies, analyze, current, state-of-the-art, ,, facilitating, progress, area, ., report, shared, task, sarcasm, detection, conducted, part, 2nd, workshop, figurative, language, processing, (, figlang, 2020, ), acl, 2020, ."
Developmental Negation Processing in Transformer Language Models,"Antonio Laverghetta Jr., John Licato",2022-04-29T14:07:34Z,"  Reasoning using negation is known to be difficult for transformer-based
language models. While previous studies have used the tools of
psycholinguistics to probe a transformer's ability to reason over negation,
none have focused on the types of negation studied in developmental psychology.
We explore how well transformers can process such categories of negation, by
framing the problem as a natural language inference (NLI) task. We curate a set
of diagnostic questions for our target categories from popular NLI datasets and
evaluate how well a suite of models reason over them. We find that models
perform consistently better only on certain categories, suggesting clear
distinctions in how they are processed.
","['reasoning', 'using', 'negation', 'known', 'difficult', 'transformer-based', 'language', 'models', '.', 'previous', 'studies', 'used', 'tools', 'psycholinguistics', 'probe', 'transformer', ""'s"", 'ability', 'reason', 'negation', ',', 'none', 'focused', 'types', 'negation', 'studied', 'developmental', 'psychology', '.', 'explore', 'well', 'transformers', 'process', 'categories', 'negation', ',', 'framing', 'problem', 'natural', 'language', 'inference', '(', 'nli', ')', 'task', '.', 'curate', 'set', 'diagnostic', 'questions', 'target', 'categories', 'popular', 'nli', 'datasets', 'evaluate', 'well', 'suite', 'models', 'reason', '.', 'find', 'models', 'perform', 'consistently', 'better', 'certain', 'categories', ',', 'suggesting', 'clear', 'distinctions', 'processed', '.']","reasoning, using, negation, known, difficult, transformer-based, language, models, ., previous, studies, used, tools, psycholinguistics, probe, transformer, 's, ability, reason, negation, ,, none, focused, types, negation, studied, developmental, psychology, ., explore, well, transformers, process, categories, negation, ,, framing, problem, natural, language, inference, (, nli, ), task, ., curate, set, diagnostic, questions, target, categories, popular, nli, datasets, evaluate, well, suite, models, reason, ., find, models, perform, consistently, better, certain, categories, ,, suggesting, clear, distinctions, processed, ."
"Misinforming LLMs: vulnerabilities, challenges and opportunities","Bo Zhou, Daniel Geißler, Paul Lukowicz",2024-08-02T10:35:49Z,"  Large Language Models (LLMs) have made significant advances in natural
language processing, but their underlying mechanisms are often misunderstood.
Despite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely
on statistical patterns in word embeddings rather than true cognitive
processes. This leads to vulnerabilities such as ""hallucination"" and
misinformation. The paper argues that current LLM architectures are inherently
untrustworthy due to their reliance on correlations of sequential patterns of
word embedding vectors. However, ongoing research into combining generative
transformer-based models with fact bases and logic programming languages may
lead to the development of trustworthy LLMs capable of generating statements
based on given truth and explaining their self-reasoning process.
","['large', 'language', 'models', '(', 'llms', ')', 'made', 'significant', 'advances', 'natural', 'language', 'processing', ',', 'underlying', 'mechanisms', 'often', 'misunderstood', '.', 'despite', 'exhibiting', 'coherent', 'answers', 'apparent', 'reasoning', 'behaviors', ',', 'llms', 'rely', 'statistical', 'patterns', 'word', 'embeddings', 'rather', 'true', 'cognitive', 'processes', '.', 'leads', 'vulnerabilities', '``', 'hallucination', ""''"", 'misinformation', '.', 'paper', 'argues', 'current', 'llm', 'architectures', 'inherently', 'untrustworthy', 'due', 'reliance', 'correlations', 'sequential', 'patterns', 'word', 'embedding', 'vectors', '.', 'however', ',', 'ongoing', 'research', 'combining', 'generative', 'transformer-based', 'models', 'fact', 'bases', 'logic', 'programming', 'languages', 'may', 'lead', 'development', 'trustworthy', 'llms', 'capable', 'generating', 'statements', 'based', 'given', 'truth', 'explaining', 'self-reasoning', 'process', '.']","large, language, models, (, llms, ), made, significant, advances, natural, language, processing, ,, underlying, mechanisms, often, misunderstood, ., despite, exhibiting, coherent, answers, apparent, reasoning, behaviors, ,, llms, rely, statistical, patterns, word, embeddings, rather, true, cognitive, processes, ., leads, vulnerabilities, ``, hallucination, '', misinformation, ., paper, argues, current, llm, architectures, inherently, untrustworthy, due, reliance, correlations, sequential, patterns, word, embedding, vectors, ., however, ,, ongoing, research, combining, generative, transformer-based, models, fact, bases, logic, programming, languages, may, lead, development, trustworthy, llms, capable, generating, statements, based, given, truth, explaining, self-reasoning, process, ."
Prior Polarity Lexical Resources for the Italian Language,"Valeria Borzì, Simone Faro, Arianna Pavone, Sabrina Sansone",2015-07-01T07:29:12Z,"  In this paper we present SABRINA (Sentiment Analysis: a Broad Resource for
Italian Natural language Applications) a manually annotated prior polarity
lexical resource for Italian natural language applications in the field of
opinion mining and sentiment induction. The resource consists in two different
sets, an Italian dictionary of more than 277.000 words tagged with their prior
polarity value, and a set of polarity modifiers, containing more than 200
words, which can be used in combination with non neutral terms of the
dictionary in order to induce the sentiment of Italian compound terms. To the
best of our knowledge this is the first prior polarity manually annotated
resource which has been developed for the Italian natural language.
","['paper', 'present', 'sabrina', '(', 'sentiment', 'analysis', ':', 'broad', 'resource', 'italian', 'natural', 'language', 'applications', ')', 'manually', 'annotated', 'prior', 'polarity', 'lexical', 'resource', 'italian', 'natural', 'language', 'applications', 'field', 'opinion', 'mining', 'sentiment', 'induction', '.', 'resource', 'consists', 'two', 'different', 'sets', ',', 'italian', 'dictionary', '277.000', 'words', 'tagged', 'prior', 'polarity', 'value', ',', 'set', 'polarity', 'modifiers', ',', 'containing', '200', 'words', ',', 'used', 'combination', 'non', 'neutral', 'terms', 'dictionary', 'order', 'induce', 'sentiment', 'italian', 'compound', 'terms', '.', 'best', 'knowledge', 'first', 'prior', 'polarity', 'manually', 'annotated', 'resource', 'developed', 'italian', 'natural', 'language', '.']","paper, present, sabrina, (, sentiment, analysis, :, broad, resource, italian, natural, language, applications, ), manually, annotated, prior, polarity, lexical, resource, italian, natural, language, applications, field, opinion, mining, sentiment, induction, ., resource, consists, two, different, sets, ,, italian, dictionary, 277.000, words, tagged, prior, polarity, value, ,, set, polarity, modifiers, ,, containing, 200, words, ,, used, combination, non, neutral, terms, dictionary, order, induce, sentiment, italian, compound, terms, ., best, knowledge, first, prior, polarity, manually, annotated, resource, developed, italian, natural, language, ."
Baselines and test data for cross-lingual inference,"Željko Agić, Natalie Schluter",2017-04-18T14:12:37Z,"  The recent years have seen a revival of interest in textual entailment,
sparked by i) the emergence of powerful deep neural network learners for
natural language processing and ii) the timely development of large-scale
evaluation datasets such as SNLI. Recast as natural language inference, the
problem now amounts to detecting the relation between pairs of statements: they
either contradict or entail one another, or they are mutually neutral. Current
research in natural language inference is effectively exclusive to English. In
this paper, we propose to advance the research in SNLI-style natural language
inference toward multilingual evaluation. To that end, we provide test data for
four major languages: Arabic, French, Spanish, and Russian. We experiment with
a set of baselines. Our systems are based on cross-lingual word embeddings and
machine translation. While our best system scores an average accuracy of just
over 75%, we focus largely on enabling further research in multilingual
inference.
","['recent', 'years', 'seen', 'revival', 'interest', 'textual', 'entailment', ',', 'sparked', ')', 'emergence', 'powerful', 'deep', 'neural', 'network', 'learners', 'natural', 'language', 'processing', 'ii', ')', 'timely', 'development', 'large-scale', 'evaluation', 'datasets', 'snli', '.', 'recast', 'natural', 'language', 'inference', ',', 'problem', 'amounts', 'detecting', 'relation', 'pairs', 'statements', ':', 'either', 'contradict', 'entail', 'one', 'another', ',', 'mutually', 'neutral', '.', 'current', 'research', 'natural', 'language', 'inference', 'effectively', 'exclusive', 'english', '.', 'paper', ',', 'propose', 'advance', 'research', 'snli-style', 'natural', 'language', 'inference', 'toward', 'multilingual', 'evaluation', '.', 'end', ',', 'provide', 'test', 'data', 'four', 'major', 'languages', ':', 'arabic', ',', 'french', ',', 'spanish', ',', 'russian', '.', 'experiment', 'set', 'baselines', '.', 'systems', 'based', 'cross-lingual', 'word', 'embeddings', 'machine', 'translation', '.', 'best', 'system', 'scores', 'average', 'accuracy', '75', '%', ',', 'focus', 'largely', 'enabling', 'research', 'multilingual', 'inference', '.']","recent, years, seen, revival, interest, textual, entailment, ,, sparked, ), emergence, powerful, deep, neural, network, learners, natural, language, processing, ii, ), timely, development, large-scale, evaluation, datasets, snli, ., recast, natural, language, inference, ,, problem, amounts, detecting, relation, pairs, statements, :, either, contradict, entail, one, another, ,, mutually, neutral, ., current, research, natural, language, inference, effectively, exclusive, english, ., paper, ,, propose, advance, research, snli-style, natural, language, inference, toward, multilingual, evaluation, ., end, ,, provide, test, data, four, major, languages, :, arabic, ,, french, ,, spanish, ,, russian, ., experiment, set, baselines, ., systems, based, cross-lingual, word, embeddings, machine, translation, ., best, system, scores, average, accuracy, 75, %, ,, focus, largely, enabling, research, multilingual, inference, ."
Rigorously Assessing Natural Language Explanations of Neurons,"Jing Huang, Atticus Geiger, Karel D'Oosterlinck, Zhengxuan Wu, Christopher Potts",2023-09-19T04:49:45Z,"  Natural language is an appealing medium for explaining how large language
models process and store information, but evaluating the faithfulness of such
explanations is challenging. To help address this, we develop two modes of
evaluation for natural language explanations that claim individual neurons
represent a concept in a text input. In the observational mode, we evaluate
claims that a neuron $a$ activates on all and only input strings that refer to
a concept picked out by the proposed explanation $E$. In the intervention mode,
we construe $E$ as a claim that the neuron $a$ is a causal mediator of the
concept denoted by $E$. We apply our framework to the GPT-4-generated
explanations of GPT-2 XL neurons of Bills et al. (2023) and show that even the
most confident explanations have high error rates and little to no causal
efficacy. We close the paper by critically assessing whether natural language
is a good choice for explanations and whether neurons are the best level of
analysis.
","['natural', 'language', 'appealing', 'medium', 'explaining', 'large', 'language', 'models', 'process', 'store', 'information', ',', 'evaluating', 'faithfulness', 'explanations', 'challenging', '.', 'help', 'address', ',', 'develop', 'two', 'modes', 'evaluation', 'natural', 'language', 'explanations', 'claim', 'individual', 'neurons', 'represent', 'concept', 'text', 'input', '.', 'observational', 'mode', ',', 'evaluate', 'claims', 'neuron', '$', '$', 'activates', 'input', 'strings', 'refer', 'concept', 'picked', 'proposed', 'explanation', '$', 'e', '$', '.', 'intervention', 'mode', ',', 'construe', '$', 'e', '$', 'claim', 'neuron', '$', '$', 'causal', 'mediator', 'concept', 'denoted', '$', 'e', '$', '.', 'apply', 'framework', 'gpt-4-generated', 'explanations', 'gpt-2', 'xl', 'neurons', 'bills', 'et', 'al', '.', '(', '2023', ')', 'show', 'even', 'confident', 'explanations', 'high', 'error', 'rates', 'little', 'causal', 'efficacy', '.', 'close', 'paper', 'critically', 'assessing', 'whether', 'natural', 'language', 'good', 'choice', 'explanations', 'whether', 'neurons', 'best', 'level', 'analysis', '.']","natural, language, appealing, medium, explaining, large, language, models, process, store, information, ,, evaluating, faithfulness, explanations, challenging, ., help, address, ,, develop, two, modes, evaluation, natural, language, explanations, claim, individual, neurons, represent, concept, text, input, ., observational, mode, ,, evaluate, claims, neuron, $, $, activates, input, strings, refer, concept, picked, proposed, explanation, $, e, $, ., intervention, mode, ,, construe, $, e, $, claim, neuron, $, $, causal, mediator, concept, denoted, $, e, $, ., apply, framework, gpt-4-generated, explanations, gpt-2, xl, neurons, bills, et, al, ., (, 2023, ), show, even, confident, explanations, high, error, rates, little, causal, efficacy, ., close, paper, critically, assessing, whether, natural, language, good, choice, explanations, whether, neurons, best, level, analysis, ."
Natural Language Reinforcement Learning,"Xidong Feng, Ziyu Wan, Mengyue Yang, Ziyan Wang, Girish A. Koushik, Yali Du, Ying Wen, Jun Wang",2024-02-11T11:03:04Z,"  Reinforcement Learning (RL) has shown remarkable abilities in learning
policies for decision-making tasks. However, RL is often hindered by issues
such as low sample efficiency, lack of interpretability, and sparse supervision
signals. To tackle these limitations, we take inspiration from the human
learning process and introduce Natural Language Reinforcement Learning (NLRL),
which innovatively combines RL principles with natural language representation.
Specifically, NLRL redefines RL concepts like task objectives, policy, value
function, Bellman equation, and policy iteration in natural language space. We
present how NLRL can be practically implemented with the latest advancements in
large language models (LLMs) like GPT-4. Initial experiments over tabular MDPs
demonstrate the effectiveness, efficiency, and also interpretability of the
NLRL framework.
","['reinforcement', 'learning', '(', 'rl', ')', 'shown', 'remarkable', 'abilities', 'learning', 'policies', 'decision-making', 'tasks', '.', 'however', ',', 'rl', 'often', 'hindered', 'issues', 'low', 'sample', 'efficiency', ',', 'lack', 'interpretability', ',', 'sparse', 'supervision', 'signals', '.', 'tackle', 'limitations', ',', 'take', 'inspiration', 'human', 'learning', 'process', 'introduce', 'natural', 'language', 'reinforcement', 'learning', '(', 'nlrl', ')', ',', 'innovatively', 'combines', 'rl', 'principles', 'natural', 'language', 'representation', '.', 'specifically', ',', 'nlrl', 'redefines', 'rl', 'concepts', 'like', 'task', 'objectives', ',', 'policy', ',', 'value', 'function', ',', 'bellman', 'equation', ',', 'policy', 'iteration', 'natural', 'language', 'space', '.', 'present', 'nlrl', 'practically', 'implemented', 'latest', 'advancements', 'large', 'language', 'models', '(', 'llms', ')', 'like', 'gpt-4', '.', 'initial', 'experiments', 'tabular', 'mdps', 'demonstrate', 'effectiveness', ',', 'efficiency', ',', 'also', 'interpretability', 'nlrl', 'framework', '.']","reinforcement, learning, (, rl, ), shown, remarkable, abilities, learning, policies, decision-making, tasks, ., however, ,, rl, often, hindered, issues, low, sample, efficiency, ,, lack, interpretability, ,, sparse, supervision, signals, ., tackle, limitations, ,, take, inspiration, human, learning, process, introduce, natural, language, reinforcement, learning, (, nlrl, ), ,, innovatively, combines, rl, principles, natural, language, representation, ., specifically, ,, nlrl, redefines, rl, concepts, like, task, objectives, ,, policy, ,, value, function, ,, bellman, equation, ,, policy, iteration, natural, language, space, ., present, nlrl, practically, implemented, latest, advancements, large, language, models, (, llms, ), like, gpt-4, ., initial, experiments, tabular, mdps, demonstrate, effectiveness, ,, efficiency, ,, also, interpretability, nlrl, framework, ."
"Verification and Refinement of Natural Language Explanations through
  LLM-Symbolic Theorem Proving","Xin Quan, Marco Valentino, Louise A. Dennis, André Freitas",2024-05-02T15:20:01Z,"  Natural language explanations have become a proxy for evaluating explainable
and multi-step Natural Language Inference (NLI) models. However, assessing the
validity of explanations for NLI is challenging as it typically involves the
crowd-sourcing of apposite datasets, a process that is time-consuming and prone
to logical errors. To address existing limitations, this paper investigates the
verification and refinement of natural language explanations through the
integration of Large Language Models (LLMs) and Theorem Provers (TPs).
Specifically, we present a neuro-symbolic framework, named Explanation-Refiner,
that augments a TP with LLMs to generate and formalise explanatory sentences
and suggest potential inference strategies for NLI. In turn, the TP is employed
to provide formal guarantees on the logical validity of the explanations and to
generate feedback for subsequent improvements. We demonstrate how
Explanation-Refiner can be jointly used to evaluate explanatory reasoning,
autoformalisation, and error correction mechanisms of state-of-the-art LLMs as
well as to automatically enhance the quality of human-annotated explanations of
variable complexity in different domains.
","['natural', 'language', 'explanations', 'become', 'proxy', 'evaluating', 'explainable', 'multi-step', 'natural', 'language', 'inference', '(', 'nli', ')', 'models', '.', 'however', ',', 'assessing', 'validity', 'explanations', 'nli', 'challenging', 'typically', 'involves', 'crowd-sourcing', 'apposite', 'datasets', ',', 'process', 'time-consuming', 'prone', 'logical', 'errors', '.', 'address', 'existing', 'limitations', ',', 'paper', 'investigates', 'verification', 'refinement', 'natural', 'language', 'explanations', 'integration', 'large', 'language', 'models', '(', 'llms', ')', 'theorem', 'provers', '(', 'tps', ')', '.', 'specifically', ',', 'present', 'neuro-symbolic', 'framework', ',', 'named', 'explanation-refiner', ',', 'augments', 'tp', 'llms', 'generate', 'formalise', 'explanatory', 'sentences', 'suggest', 'potential', 'inference', 'strategies', 'nli', '.', 'turn', ',', 'tp', 'employed', 'provide', 'formal', 'guarantees', 'logical', 'validity', 'explanations', 'generate', 'feedback', 'subsequent', 'improvements', '.', 'demonstrate', 'explanation-refiner', 'jointly', 'used', 'evaluate', 'explanatory', 'reasoning', ',', 'autoformalisation', ',', 'error', 'correction', 'mechanisms', 'state-of-the-art', 'llms', 'well', 'automatically', 'enhance', 'quality', 'human-annotated', 'explanations', 'variable', 'complexity', 'different', 'domains', '.']","natural, language, explanations, become, proxy, evaluating, explainable, multi-step, natural, language, inference, (, nli, ), models, ., however, ,, assessing, validity, explanations, nli, challenging, typically, involves, crowd-sourcing, apposite, datasets, ,, process, time-consuming, prone, logical, errors, ., address, existing, limitations, ,, paper, investigates, verification, refinement, natural, language, explanations, integration, large, language, models, (, llms, ), theorem, provers, (, tps, ), ., specifically, ,, present, neuro-symbolic, framework, ,, named, explanation-refiner, ,, augments, tp, llms, generate, formalise, explanatory, sentences, suggest, potential, inference, strategies, nli, ., turn, ,, tp, employed, provide, formal, guarantees, logical, validity, explanations, generate, feedback, subsequent, improvements, ., demonstrate, explanation-refiner, jointly, used, evaluate, explanatory, reasoning, ,, autoformalisation, ,, error, correction, mechanisms, state-of-the-art, llms, well, automatically, enhance, quality, human-annotated, explanations, variable, complexity, different, domains, ."
"Natural Language-Oriented Programming (NLOP): Towards Democratizing
  Software Creation",Amin Beheshti,2024-06-08T09:13:54Z,"  As generative Artificial Intelligence (AI) technologies evolve, they offer
unprecedented potential to automate and enhance various tasks, including
coding. Natural Language-Oriented Programming (NLOP), a vision introduced in
this paper, harnesses this potential by allowing developers to articulate
software requirements and logic in their natural language, thereby
democratizing software creation. This approach streamlines the development
process and significantly lowers the barrier to entry for software engineering,
making it feasible for non-experts to contribute effectively to software
projects. By simplifying the transition from concept to code, NLOP can
accelerate development cycles, enhance collaborative efforts, and reduce
misunderstandings in requirement specifications. This paper reviews various
programming models, assesses their contributions and limitations, and
highlights that natural language will be the new programming language. Through
this comparison, we illustrate how NLOP stands to transform the landscape of
software engineering by fostering greater inclusivity and innovation.
","['generative', 'artificial', 'intelligence', '(', 'ai', ')', 'technologies', 'evolve', ',', 'offer', 'unprecedented', 'potential', 'automate', 'enhance', 'various', 'tasks', ',', 'including', 'coding', '.', 'natural', 'language-oriented', 'programming', '(', 'nlop', ')', ',', 'vision', 'introduced', 'paper', ',', 'harnesses', 'potential', 'allowing', 'developers', 'articulate', 'software', 'requirements', 'logic', 'natural', 'language', ',', 'thereby', 'democratizing', 'software', 'creation', '.', 'approach', 'streamlines', 'development', 'process', 'significantly', 'lowers', 'barrier', 'entry', 'software', 'engineering', ',', 'making', 'feasible', 'non-experts', 'contribute', 'effectively', 'software', 'projects', '.', 'simplifying', 'transition', 'concept', 'code', ',', 'nlop', 'accelerate', 'development', 'cycles', ',', 'enhance', 'collaborative', 'efforts', ',', 'reduce', 'misunderstandings', 'requirement', 'specifications', '.', 'paper', 'reviews', 'various', 'programming', 'models', ',', 'assesses', 'contributions', 'limitations', ',', 'highlights', 'natural', 'language', 'new', 'programming', 'language', '.', 'comparison', ',', 'illustrate', 'nlop', 'stands', 'transform', 'landscape', 'software', 'engineering', 'fostering', 'greater', 'inclusivity', 'innovation', '.']","generative, artificial, intelligence, (, ai, ), technologies, evolve, ,, offer, unprecedented, potential, automate, enhance, various, tasks, ,, including, coding, ., natural, language-oriented, programming, (, nlop, ), ,, vision, introduced, paper, ,, harnesses, potential, allowing, developers, articulate, software, requirements, logic, natural, language, ,, thereby, democratizing, software, creation, ., approach, streamlines, development, process, significantly, lowers, barrier, entry, software, engineering, ,, making, feasible, non-experts, contribute, effectively, software, projects, ., simplifying, transition, concept, code, ,, nlop, accelerate, development, cycles, ,, enhance, collaborative, efforts, ,, reduce, misunderstandings, requirement, specifications, ., paper, reviews, various, programming, models, ,, assesses, contributions, limitations, ,, highlights, natural, language, new, programming, language, ., comparison, ,, illustrate, nlop, stands, transform, landscape, software, engineering, fostering, greater, inclusivity, innovation, ."
"Natural Language Generation and Understanding of Big Code for
  AI-Assisted Programming: A Review","Man Fai Wong, Shangxin Guo, Ching Nam Hang, Siu Wai Ho, Chee Wei Tan",2023-07-04T21:26:51Z,"  This paper provides a comprehensive review of the literature concerning the
utilization of Natural Language Processing (NLP) techniques, with a particular
focus on transformer-based large language models (LLMs) trained using Big Code,
within the domain of AI-assisted programming tasks. LLMs, augmented with
software naturalness, have played a crucial role in facilitating AI-assisted
programming applications, including code generation, code completion, code
translation, code refinement, code summarization, defect detection, and clone
detection. Notable examples of such applications include the GitHub Copilot
powered by OpenAI's Codex and DeepMind AlphaCode. This paper presents an
overview of the major LLMs and their applications in downstream tasks related
to AI-assisted programming. Furthermore, it explores the challenges and
opportunities associated with incorporating NLP techniques with software
naturalness in these applications, with a discussion on extending AI-assisted
programming capabilities to Apple's Xcode for mobile software development. This
paper also presents the challenges of and opportunities for incorporating NLP
techniques with software naturalness, empowering developers with advanced
coding assistance and streamlining the software development process.
","['paper', 'provides', 'comprehensive', 'review', 'literature', 'concerning', 'utilization', 'natural', 'language', 'processing', '(', 'nlp', ')', 'techniques', ',', 'particular', 'focus', 'transformer-based', 'large', 'language', 'models', '(', 'llms', ')', 'trained', 'using', 'big', 'code', ',', 'within', 'domain', 'ai-assisted', 'programming', 'tasks', '.', 'llms', ',', 'augmented', 'software', 'naturalness', ',', 'played', 'crucial', 'role', 'facilitating', 'ai-assisted', 'programming', 'applications', ',', 'including', 'code', 'generation', ',', 'code', 'completion', ',', 'code', 'translation', ',', 'code', 'refinement', ',', 'code', 'summarization', ',', 'defect', 'detection', ',', 'clone', 'detection', '.', 'notable', 'examples', 'applications', 'include', 'github', 'copilot', 'powered', 'openai', ""'s"", 'codex', 'deepmind', 'alphacode', '.', 'paper', 'presents', 'overview', 'major', 'llms', 'applications', 'downstream', 'tasks', 'related', 'ai-assisted', 'programming', '.', 'furthermore', ',', 'explores', 'challenges', 'opportunities', 'associated', 'incorporating', 'nlp', 'techniques', 'software', 'naturalness', 'applications', ',', 'discussion', 'extending', 'ai-assisted', 'programming', 'capabilities', 'apple', ""'s"", 'xcode', 'mobile', 'software', 'development', '.', 'paper', 'also', 'presents', 'challenges', 'opportunities', 'incorporating', 'nlp', 'techniques', 'software', 'naturalness', ',', 'empowering', 'developers', 'advanced', 'coding', 'assistance', 'streamlining', 'software', 'development', 'process', '.']","paper, provides, comprehensive, review, literature, concerning, utilization, natural, language, processing, (, nlp, ), techniques, ,, particular, focus, transformer-based, large, language, models, (, llms, ), trained, using, big, code, ,, within, domain, ai-assisted, programming, tasks, ., llms, ,, augmented, software, naturalness, ,, played, crucial, role, facilitating, ai-assisted, programming, applications, ,, including, code, generation, ,, code, completion, ,, code, translation, ,, code, refinement, ,, code, summarization, ,, defect, detection, ,, clone, detection, ., notable, examples, applications, include, github, copilot, powered, openai, 's, codex, deepmind, alphacode, ., paper, presents, overview, major, llms, applications, downstream, tasks, related, ai-assisted, programming, ., furthermore, ,, explores, challenges, opportunities, associated, incorporating, nlp, techniques, software, naturalness, applications, ,, discussion, extending, ai-assisted, programming, capabilities, apple, 's, xcode, mobile, software, development, ., paper, also, presents, challenges, opportunities, incorporating, nlp, techniques, software, naturalness, ,, empowering, developers, advanced, coding, assistance, streamlining, software, development, process, ."
"Bridging Domain Knowledge and Process Discovery Using Large Language
  Models","Ali Norouzifar, Humam Kourani, Marcus Dees, Wil van der Aalst",2024-08-30T14:23:40Z,"  Discovering good process models is essential for different process analysis
tasks such as conformance checking and process improvements. Automated process
discovery methods often overlook valuable domain knowledge. This knowledge,
including insights from domain experts and detailed process documentation,
remains largely untapped during process discovery. This paper leverages Large
Language Models (LLMs) to integrate such knowledge directly into process
discovery. We use rules derived from LLMs to guide model construction, ensuring
alignment with both domain knowledge and actual process executions. By
integrating LLMs, we create a bridge between process knowledge expressed in
natural language and the discovery of robust process models, advancing process
discovery methodologies significantly. To showcase the usability of our
framework, we conducted a case study with the UWV employee insurance agency,
demonstrating its practical benefits and effectiveness.
","['discovering', 'good', 'process', 'models', 'essential', 'different', 'process', 'analysis', 'tasks', 'conformance', 'checking', 'process', 'improvements', '.', 'automated', 'process', 'discovery', 'methods', 'often', 'overlook', 'valuable', 'domain', 'knowledge', '.', 'knowledge', ',', 'including', 'insights', 'domain', 'experts', 'detailed', 'process', 'documentation', ',', 'remains', 'largely', 'untapped', 'process', 'discovery', '.', 'paper', 'leverages', 'large', 'language', 'models', '(', 'llms', ')', 'integrate', 'knowledge', 'directly', 'process', 'discovery', '.', 'use', 'rules', 'derived', 'llms', 'guide', 'model', 'construction', ',', 'ensuring', 'alignment', 'domain', 'knowledge', 'actual', 'process', 'executions', '.', 'integrating', 'llms', ',', 'create', 'bridge', 'process', 'knowledge', 'expressed', 'natural', 'language', 'discovery', 'robust', 'process', 'models', ',', 'advancing', 'process', 'discovery', 'methodologies', 'significantly', '.', 'showcase', 'usability', 'framework', ',', 'conducted', 'case', 'study', 'uwv', 'employee', 'insurance', 'agency', ',', 'demonstrating', 'practical', 'benefits', 'effectiveness', '.']","discovering, good, process, models, essential, different, process, analysis, tasks, conformance, checking, process, improvements, ., automated, process, discovery, methods, often, overlook, valuable, domain, knowledge, ., knowledge, ,, including, insights, domain, experts, detailed, process, documentation, ,, remains, largely, untapped, process, discovery, ., paper, leverages, large, language, models, (, llms, ), integrate, knowledge, directly, process, discovery, ., use, rules, derived, llms, guide, model, construction, ,, ensuring, alignment, domain, knowledge, actual, process, executions, ., integrating, llms, ,, create, bridge, process, knowledge, expressed, natural, language, discovery, robust, process, models, ,, advancing, process, discovery, methodologies, significantly, ., showcase, usability, framework, ,, conducted, case, study, uwv, employee, insurance, agency, ,, demonstrating, practical, benefits, effectiveness, ."
"Generative Pre-trained Transformer: A Comprehensive Review on Enabling
  Technologies, Potential Applications, Emerging Challenges, and Future
  Directions","Gokul Yenduri, Ramalingam M, Chemmalar Selvi G, Supriya Y, Gautam Srivastava, Praveen Kumar Reddy Maddikunta, Deepti Raj G, Rutvij H Jhaveri, Prabadevi B, Weizheng Wang, Athanasios V. Vasilakos, Thippa Reddy Gadekallu",2023-05-11T19:20:38Z,"  The Generative Pre-trained Transformer (GPT) represents a notable
breakthrough in the domain of natural language processing, which is propelling
us toward the development of machines that can understand and communicate using
language in a manner that closely resembles that of humans. GPT is based on the
transformer architecture, a deep neural network designed for natural language
processing tasks. Due to their impressive performance on natural language
processing tasks and ability to effectively converse, GPT have gained
significant popularity among researchers and industrial communities, making
them one of the most widely used and effective models in natural language
processing and related fields, which motivated to conduct this review. This
review provides a detailed overview of the GPT, including its architecture,
working process, training procedures, enabling technologies, and its impact on
various applications. In this review, we also explored the potential challenges
and limitations of a GPT. Furthermore, we discuss potential solutions and
future directions. Overall, this paper aims to provide a comprehensive
understanding of GPT, enabling technologies, their impact on various
applications, emerging challenges, and potential solutions.
","['generative', 'pre-trained', 'transformer', '(', 'gpt', ')', 'represents', 'notable', 'breakthrough', 'domain', 'natural', 'language', 'processing', ',', 'propelling', 'us', 'toward', 'development', 'machines', 'understand', 'communicate', 'using', 'language', 'manner', 'closely', 'resembles', 'humans', '.', 'gpt', 'based', 'transformer', 'architecture', ',', 'deep', 'neural', 'network', 'designed', 'natural', 'language', 'processing', 'tasks', '.', 'due', 'impressive', 'performance', 'natural', 'language', 'processing', 'tasks', 'ability', 'effectively', 'converse', ',', 'gpt', 'gained', 'significant', 'popularity', 'among', 'researchers', 'industrial', 'communities', ',', 'making', 'one', 'widely', 'used', 'effective', 'models', 'natural', 'language', 'processing', 'related', 'fields', ',', 'motivated', 'conduct', 'review', '.', 'review', 'provides', 'detailed', 'overview', 'gpt', ',', 'including', 'architecture', ',', 'working', 'process', ',', 'training', 'procedures', ',', 'enabling', 'technologies', ',', 'impact', 'various', 'applications', '.', 'review', ',', 'also', 'explored', 'potential', 'challenges', 'limitations', 'gpt', '.', 'furthermore', ',', 'discuss', 'potential', 'solutions', 'future', 'directions', '.', 'overall', ',', 'paper', 'aims', 'provide', 'comprehensive', 'understanding', 'gpt', ',', 'enabling', 'technologies', ',', 'impact', 'various', 'applications', ',', 'emerging', 'challenges', ',', 'potential', 'solutions', '.']","generative, pre-trained, transformer, (, gpt, ), represents, notable, breakthrough, domain, natural, language, processing, ,, propelling, us, toward, development, machines, understand, communicate, using, language, manner, closely, resembles, humans, ., gpt, based, transformer, architecture, ,, deep, neural, network, designed, natural, language, processing, tasks, ., due, impressive, performance, natural, language, processing, tasks, ability, effectively, converse, ,, gpt, gained, significant, popularity, among, researchers, industrial, communities, ,, making, one, widely, used, effective, models, natural, language, processing, related, fields, ,, motivated, conduct, review, ., review, provides, detailed, overview, gpt, ,, including, architecture, ,, working, process, ,, training, procedures, ,, enabling, technologies, ,, impact, various, applications, ., review, ,, also, explored, potential, challenges, limitations, gpt, ., furthermore, ,, discuss, potential, solutions, future, directions, ., overall, ,, paper, aims, provide, comprehensive, understanding, gpt, ,, enabling, technologies, ,, impact, various, applications, ,, emerging, challenges, ,, potential, solutions, ."
"Context-Tuning: Learning Contextualized Prompts for Natural Language
  Generation","Tianyi Tang, Junyi Li, Wayne Xin Zhao, Ji-Rong Wen",2022-01-21T12:35:28Z,"  Recently, pretrained language models (PLMs) have had exceptional success in
language generation. To leverage the rich knowledge encoded by PLMs, a simple
yet powerful paradigm is to use prompts in the form of either discrete tokens
or continuous embeddings. In existing studies, these prompting methods are
typically independent of the inputs, lacking sufficient consideration of input
semantics. To address this issue, we propose a novel continuous prompting
approach, called context-tuning, to fine-tuning PLMs for natural language
generation. Firstly, the prompts are derived based on the input text to elicit
useful knowledge from PLMs for generation. We refer to such prompts as
contextualized prompts. Secondly, we use continuous inverse prompting to
improve the process of natural language generation by modeling an inverse
generation process from output to input, making the generated text more
relevant to the inputs. Furthermore, we utilize a lightweight context-tuning
method that fine-tunes only 0.12% of the parameters while maintaining good
performance. Our code is publicly available at
https://github.com/RUCAIBox/Context-Tuning.
","['recently', ',', 'pretrained', 'language', 'models', '(', 'plms', ')', 'exceptional', 'success', 'language', 'generation', '.', 'leverage', 'rich', 'knowledge', 'encoded', 'plms', ',', 'simple', 'yet', 'powerful', 'paradigm', 'use', 'prompts', 'form', 'either', 'discrete', 'tokens', 'continuous', 'embeddings', '.', 'existing', 'studies', ',', 'prompting', 'methods', 'typically', 'independent', 'inputs', ',', 'lacking', 'sufficient', 'consideration', 'input', 'semantics', '.', 'address', 'issue', ',', 'propose', 'novel', 'continuous', 'prompting', 'approach', ',', 'called', 'context-tuning', ',', 'fine-tuning', 'plms', 'natural', 'language', 'generation', '.', 'firstly', ',', 'prompts', 'derived', 'based', 'input', 'text', 'elicit', 'useful', 'knowledge', 'plms', 'generation', '.', 'refer', 'prompts', 'contextualized', 'prompts', '.', 'secondly', ',', 'use', 'continuous', 'inverse', 'prompting', 'improve', 'process', 'natural', 'language', 'generation', 'modeling', 'inverse', 'generation', 'process', 'output', 'input', ',', 'making', 'generated', 'text', 'relevant', 'inputs', '.', 'furthermore', ',', 'utilize', 'lightweight', 'context-tuning', 'method', 'fine-tunes', '0.12', '%', 'parameters', 'maintaining', 'good', 'performance', '.', 'code', 'publicly', 'available', 'https', ':', '//github.com/rucaibox/context-tuning', '.']","recently, ,, pretrained, language, models, (, plms, ), exceptional, success, language, generation, ., leverage, rich, knowledge, encoded, plms, ,, simple, yet, powerful, paradigm, use, prompts, form, either, discrete, tokens, continuous, embeddings, ., existing, studies, ,, prompting, methods, typically, independent, inputs, ,, lacking, sufficient, consideration, input, semantics, ., address, issue, ,, propose, novel, continuous, prompting, approach, ,, called, context-tuning, ,, fine-tuning, plms, natural, language, generation, ., firstly, ,, prompts, derived, based, input, text, elicit, useful, knowledge, plms, generation, ., refer, prompts, contextualized, prompts, ., secondly, ,, use, continuous, inverse, prompting, improve, process, natural, language, generation, modeling, inverse, generation, process, output, input, ,, making, generated, text, relevant, inputs, ., furthermore, ,, utilize, lightweight, context-tuning, method, fine-tunes, 0.12, %, parameters, maintaining, good, performance, ., code, publicly, available, https, :, //github.com/rucaibox/context-tuning, ."
"ChatGPT as Data Augmentation for Compositional Generalization: A Case
  Study in Open Intent Detection","Yihao Fang, Xianzhi Li, Stephen W. Thomas, Xiaodan Zhu",2023-08-25T17:51:23Z,"  Open intent detection, a crucial aspect of natural language understanding,
involves the identification of previously unseen intents in user-generated
text. Despite the progress made in this field, challenges persist in handling
new combinations of language components, which is essential for compositional
generalization. In this paper, we present a case study exploring the use of
ChatGPT as a data augmentation technique to enhance compositional
generalization in open intent detection tasks. We begin by discussing the
limitations of existing benchmarks in evaluating this problem, highlighting the
need for constructing datasets for addressing compositional generalization in
open intent detection tasks. By incorporating synthetic data generated by
ChatGPT into the training process, we demonstrate that our approach can
effectively improve model performance. Rigorous evaluation of multiple
benchmarks reveals that our method outperforms existing techniques and
significantly enhances open intent detection capabilities. Our findings
underscore the potential of large language models like ChatGPT for data
augmentation in natural language understanding tasks.
","['open', 'intent', 'detection', ',', 'crucial', 'aspect', 'natural', 'language', 'understanding', ',', 'involves', 'identification', 'previously', 'unseen', 'intents', 'user-generated', 'text', '.', 'despite', 'progress', 'made', 'field', ',', 'challenges', 'persist', 'handling', 'new', 'combinations', 'language', 'components', ',', 'essential', 'compositional', 'generalization', '.', 'paper', ',', 'present', 'case', 'study', 'exploring', 'use', 'chatgpt', 'data', 'augmentation', 'technique', 'enhance', 'compositional', 'generalization', 'open', 'intent', 'detection', 'tasks', '.', 'begin', 'discussing', 'limitations', 'existing', 'benchmarks', 'evaluating', 'problem', ',', 'highlighting', 'need', 'constructing', 'datasets', 'addressing', 'compositional', 'generalization', 'open', 'intent', 'detection', 'tasks', '.', 'incorporating', 'synthetic', 'data', 'generated', 'chatgpt', 'training', 'process', ',', 'demonstrate', 'approach', 'effectively', 'improve', 'model', 'performance', '.', 'rigorous', 'evaluation', 'multiple', 'benchmarks', 'reveals', 'method', 'outperforms', 'existing', 'techniques', 'significantly', 'enhances', 'open', 'intent', 'detection', 'capabilities', '.', 'findings', 'underscore', 'potential', 'large', 'language', 'models', 'like', 'chatgpt', 'data', 'augmentation', 'natural', 'language', 'understanding', 'tasks', '.']","open, intent, detection, ,, crucial, aspect, natural, language, understanding, ,, involves, identification, previously, unseen, intents, user-generated, text, ., despite, progress, made, field, ,, challenges, persist, handling, new, combinations, language, components, ,, essential, compositional, generalization, ., paper, ,, present, case, study, exploring, use, chatgpt, data, augmentation, technique, enhance, compositional, generalization, open, intent, detection, tasks, ., begin, discussing, limitations, existing, benchmarks, evaluating, problem, ,, highlighting, need, constructing, datasets, addressing, compositional, generalization, open, intent, detection, tasks, ., incorporating, synthetic, data, generated, chatgpt, training, process, ,, demonstrate, approach, effectively, improve, model, performance, ., rigorous, evaluation, multiple, benchmarks, reveals, method, outperforms, existing, techniques, significantly, enhances, open, intent, detection, capabilities, ., findings, underscore, potential, large, language, models, like, chatgpt, data, augmentation, natural, language, understanding, tasks, ."
"Setting up the Data Printer with Improved English to Ukrainian Machine
  Translation","Yurii Paniv, Dmytro Chaplynskyi, Nikita Trynus, Volodymyr Kyrylov",2024-04-23T16:34:34Z,"  To build large language models for Ukrainian we need to expand our corpora
with large amounts of new algorithmic tasks expressed in natural language.
Examples of task performance expressed in English are abundant, so with a
high-quality translation system our community will be enabled to curate
datasets faster. To aid this goal, we introduce a recipe to build a translation
system using supervised finetuning of a large pretrained language model with a
noisy parallel dataset of 3M pairs of Ukrainian and English sentences followed
by a second phase of training using 17K examples selected by k-fold perplexity
filtering on another dataset of higher quality. Our decoder-only model named
Dragoman beats performance of previous state of the art encoder-decoder models
on the FLORES devtest set.
","['build', 'large', 'language', 'models', 'ukrainian', 'need', 'expand', 'corpora', 'large', 'amounts', 'new', 'algorithmic', 'tasks', 'expressed', 'natural', 'language', '.', 'examples', 'task', 'performance', 'expressed', 'english', 'abundant', ',', 'high-quality', 'translation', 'system', 'community', 'enabled', 'curate', 'datasets', 'faster', '.', 'aid', 'goal', ',', 'introduce', 'recipe', 'build', 'translation', 'system', 'using', 'supervised', 'finetuning', 'large', 'pretrained', 'language', 'model', 'noisy', 'parallel', 'dataset', '3m', 'pairs', 'ukrainian', 'english', 'sentences', 'followed', 'second', 'phase', 'training', 'using', '17k', 'examples', 'selected', 'k-fold', 'perplexity', 'filtering', 'another', 'dataset', 'higher', 'quality', '.', 'decoder-only', 'model', 'named', 'dragoman', 'beats', 'performance', 'previous', 'state', 'art', 'encoder-decoder', 'models', 'flores', 'devtest', 'set', '.']","build, large, language, models, ukrainian, need, expand, corpora, large, amounts, new, algorithmic, tasks, expressed, natural, language, ., examples, task, performance, expressed, english, abundant, ,, high-quality, translation, system, community, enabled, curate, datasets, faster, ., aid, goal, ,, introduce, recipe, build, translation, system, using, supervised, finetuning, large, pretrained, language, model, noisy, parallel, dataset, 3m, pairs, ukrainian, english, sentences, followed, second, phase, training, using, 17k, examples, selected, k-fold, perplexity, filtering, another, dataset, higher, quality, ., decoder-only, model, named, dragoman, beats, performance, previous, state, art, encoder-decoder, models, flores, devtest, set, ."
Contextual Text Denoising with Masked Language Models,"Yifu Sun, Haoming Jiang",2019-10-30T18:47:37Z,"  Recently, with the help of deep learning models, significant advances have
been made in different Natural Language Processing (NLP) tasks. Unfortunately,
state-of-the-art models are vulnerable to noisy texts. We propose a new
contextual text denoising algorithm based on the ready-to-use masked language
model. The proposed algorithm does not require retraining of the model and can
be integrated into any NLP system without additional training on paired
cleaning training data. We evaluate our method under synthetic noise and
natural noise and show that the proposed algorithm can use context information
to correct noise text and improve the performance of noisy inputs in several
downstream tasks.
","['recently', ',', 'help', 'deep', 'learning', 'models', ',', 'significant', 'advances', 'made', 'different', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', '.', 'unfortunately', ',', 'state-of-the-art', 'models', 'vulnerable', 'noisy', 'texts', '.', 'propose', 'new', 'contextual', 'text', 'denoising', 'algorithm', 'based', 'ready-to-use', 'masked', 'language', 'model', '.', 'proposed', 'algorithm', 'require', 'retraining', 'model', 'integrated', 'nlp', 'system', 'without', 'additional', 'training', 'paired', 'cleaning', 'training', 'data', '.', 'evaluate', 'method', 'synthetic', 'noise', 'natural', 'noise', 'show', 'proposed', 'algorithm', 'use', 'context', 'information', 'correct', 'noise', 'text', 'improve', 'performance', 'noisy', 'inputs', 'several', 'downstream', 'tasks', '.']","recently, ,, help, deep, learning, models, ,, significant, advances, made, different, natural, language, processing, (, nlp, ), tasks, ., unfortunately, ,, state-of-the-art, models, vulnerable, noisy, texts, ., propose, new, contextual, text, denoising, algorithm, based, ready-to-use, masked, language, model, ., proposed, algorithm, require, retraining, model, integrated, nlp, system, without, additional, training, paired, cleaning, training, data, ., evaluate, method, synthetic, noise, natural, noise, show, proposed, algorithm, use, context, information, correct, noise, text, improve, performance, noisy, inputs, several, downstream, tasks, ."
Spark NLP: Natural Language Understanding at Scale,"Veysel Kocaman, David Talby",2021-01-26T15:11:52Z,"  Spark NLP is a Natural Language Processing (NLP) library built on top of
Apache Spark ML. It provides simple, performant and accurate NLP annotations
for machine learning pipelines that can scale easily in a distributed
environment. Spark NLP comes with 1100 pre trained pipelines and models in more
than 192 languages. It supports nearly all the NLP tasks and modules that can
be used seamlessly in a cluster. Downloaded more than 2.7 million times and
experiencing nine times growth since January 2020, Spark NLP is used by 54% of
healthcare organizations as the worlds most widely used NLP library in the
enterprise.
","['spark', 'nlp', 'natural', 'language', 'processing', '(', 'nlp', ')', 'library', 'built', 'top', 'apache', 'spark', 'ml', '.', 'provides', 'simple', ',', 'performant', 'accurate', 'nlp', 'annotations', 'machine', 'learning', 'pipelines', 'scale', 'easily', 'distributed', 'environment', '.', 'spark', 'nlp', 'comes', '1100', 'pre', 'trained', 'pipelines', 'models', '192', 'languages', '.', 'supports', 'nearly', 'nlp', 'tasks', 'modules', 'used', 'seamlessly', 'cluster', '.', 'downloaded', '2.7', 'million', 'times', 'experiencing', 'nine', 'times', 'growth', 'since', 'january', '2020', ',', 'spark', 'nlp', 'used', '54', '%', 'healthcare', 'organizations', 'worlds', 'widely', 'used', 'nlp', 'library', 'enterprise', '.']","spark, nlp, natural, language, processing, (, nlp, ), library, built, top, apache, spark, ml, ., provides, simple, ,, performant, accurate, nlp, annotations, machine, learning, pipelines, scale, easily, distributed, environment, ., spark, nlp, comes, 1100, pre, trained, pipelines, models, 192, languages, ., supports, nearly, nlp, tasks, modules, used, seamlessly, cluster, ., downloaded, 2.7, million, times, experiencing, nine, times, growth, since, january, 2020, ,, spark, nlp, used, 54, %, healthcare, organizations, worlds, widely, used, nlp, library, enterprise, ."
"BERT: A Review of Applications in Natural Language Processing and
  Understanding",M. V. Koroteev,2021-03-22T15:34:39Z,"  In this review, we describe the application of one of the most popular deep
learning-based language models - BERT. The paper describes the mechanism of
operation of this model, the main areas of its application to the tasks of text
analytics, comparisons with similar models in each task, as well as a
description of some proprietary models. In preparing this review, the data of
several dozen original scientific articles published over the past few years,
which attracted the most attention in the scientific community, were
systematized. This survey will be useful to all students and researchers who
want to get acquainted with the latest advances in the field of natural
language text analysis.
","['review', ',', 'describe', 'application', 'one', 'popular', 'deep', 'learning-based', 'language', 'models', '-', 'bert', '.', 'paper', 'describes', 'mechanism', 'operation', 'model', ',', 'main', 'areas', 'application', 'tasks', 'text', 'analytics', ',', 'comparisons', 'similar', 'models', 'task', ',', 'well', 'description', 'proprietary', 'models', '.', 'preparing', 'review', ',', 'data', 'several', 'dozen', 'original', 'scientific', 'articles', 'published', 'past', 'years', ',', 'attracted', 'attention', 'scientific', 'community', ',', 'systematized', '.', 'survey', 'useful', 'students', 'researchers', 'want', 'get', 'acquainted', 'latest', 'advances', 'field', 'natural', 'language', 'text', 'analysis', '.']","review, ,, describe, application, one, popular, deep, learning-based, language, models, -, bert, ., paper, describes, mechanism, operation, model, ,, main, areas, application, tasks, text, analytics, ,, comparisons, similar, models, task, ,, well, description, proprietary, models, ., preparing, review, ,, data, several, dozen, original, scientific, articles, published, past, years, ,, attracted, attention, scientific, community, ,, systematized, ., survey, useful, students, researchers, want, get, acquainted, latest, advances, field, natural, language, text, analysis, ."
"Utilizing Large Language Models for Natural Interface to Pharmacology
  Databases","Hong Lu, Chuan Li, Yinheng Li, Jie Zhao",2023-07-26T17:50:11Z,"  The drug development process necessitates that pharmacologists undertake
various tasks, such as reviewing literature, formulating hypotheses, designing
experiments, and interpreting results. Each stage requires accessing and
querying vast amounts of information. In this abstract, we introduce a Large
Language Model (LLM)-based Natural Language Interface designed to interact with
structured information stored in databases. Our experiments demonstrate the
feasibility and effectiveness of the proposed framework. This framework can
generalize to query a wide range of pharmaceutical data and knowledge bases.
","['drug', 'development', 'process', 'necessitates', 'pharmacologists', 'undertake', 'various', 'tasks', ',', 'reviewing', 'literature', ',', 'formulating', 'hypotheses', ',', 'designing', 'experiments', ',', 'interpreting', 'results', '.', 'stage', 'requires', 'accessing', 'querying', 'vast', 'amounts', 'information', '.', 'abstract', ',', 'introduce', 'large', 'language', 'model', '(', 'llm', ')', '-based', 'natural', 'language', 'interface', 'designed', 'interact', 'structured', 'information', 'stored', 'databases', '.', 'experiments', 'demonstrate', 'feasibility', 'effectiveness', 'proposed', 'framework', '.', 'framework', 'generalize', 'query', 'wide', 'range', 'pharmaceutical', 'data', 'knowledge', 'bases', '.']","drug, development, process, necessitates, pharmacologists, undertake, various, tasks, ,, reviewing, literature, ,, formulating, hypotheses, ,, designing, experiments, ,, interpreting, results, ., stage, requires, accessing, querying, vast, amounts, information, ., abstract, ,, introduce, large, language, model, (, llm, ), -based, natural, language, interface, designed, interact, structured, information, stored, databases, ., experiments, demonstrate, feasibility, effectiveness, proposed, framework, ., framework, generalize, query, wide, range, pharmaceutical, data, knowledge, bases, ."
Decoding Layer Saliency in Language Transformers,"Elizabeth M. Hou, Gregory Castanon",2023-08-09T20:53:22Z,"  In this paper, we introduce a strategy for identifying textual saliency in
large-scale language models applied to classification tasks. In visual networks
where saliency is more well-studied, saliency is naturally localized through
the convolutional layers of the network; however, the same is not true in
modern transformer-stack networks used to process natural language. We adapt
gradient-based saliency methods for these networks, propose a method for
evaluating the degree of semantic coherence of each layer, and demonstrate
consistent improvement over numerous other methods for textual saliency on
multiple benchmark classification datasets. Our approach requires no additional
training or access to labelled data, and is comparatively very computationally
efficient.
","['paper', ',', 'introduce', 'strategy', 'identifying', 'textual', 'saliency', 'large-scale', 'language', 'models', 'applied', 'classification', 'tasks', '.', 'visual', 'networks', 'saliency', 'well-studied', ',', 'saliency', 'naturally', 'localized', 'convolutional', 'layers', 'network', ';', 'however', ',', 'true', 'modern', 'transformer-stack', 'networks', 'used', 'process', 'natural', 'language', '.', 'adapt', 'gradient-based', 'saliency', 'methods', 'networks', ',', 'propose', 'method', 'evaluating', 'degree', 'semantic', 'coherence', 'layer', ',', 'demonstrate', 'consistent', 'improvement', 'numerous', 'methods', 'textual', 'saliency', 'multiple', 'benchmark', 'classification', 'datasets', '.', 'approach', 'requires', 'additional', 'training', 'access', 'labelled', 'data', ',', 'comparatively', 'computationally', 'efficient', '.']","paper, ,, introduce, strategy, identifying, textual, saliency, large-scale, language, models, applied, classification, tasks, ., visual, networks, saliency, well-studied, ,, saliency, naturally, localized, convolutional, layers, network, ;, however, ,, true, modern, transformer-stack, networks, used, process, natural, language, ., adapt, gradient-based, saliency, methods, networks, ,, propose, method, evaluating, degree, semantic, coherence, layer, ,, demonstrate, consistent, improvement, numerous, methods, textual, saliency, multiple, benchmark, classification, datasets, ., approach, requires, additional, training, access, labelled, data, ,, comparatively, computationally, efficient, ."
Personalized Large Language Models,"Stanisław Woźniak, Bartłomiej Koptyra, Arkadiusz Janz, Przemysław Kazienko, Jan Kocoń",2024-02-14T15:55:30Z,"  Large language models (LLMs) have significantly advanced Natural Language
Processing (NLP) tasks in recent years. However, their universal nature poses
limitations in scenarios requiring personalized responses, such as
recommendation systems and chatbots. This paper investigates methods to
personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on
subjective tasks. Results demonstrate that personalized fine-tuning improves
model reasoning compared to non-personalized models. Experiments on datasets
for emotion recognition and hate speech detection show consistent performance
gains with personalized methods across different LLM architectures. These
findings underscore the importance of personalization for enhancing LLM
capabilities in subjective text perception tasks.
","['large', 'language', 'models', '(', 'llms', ')', 'significantly', 'advanced', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', 'recent', 'years', '.', 'however', ',', 'universal', 'nature', 'poses', 'limitations', 'scenarios', 'requiring', 'personalized', 'responses', ',', 'recommendation', 'systems', 'chatbots', '.', 'paper', 'investigates', 'methods', 'personalize', 'llms', ',', 'comparing', 'fine-tuning', 'zero-shot', 'reasoning', 'approaches', 'subjective', 'tasks', '.', 'results', 'demonstrate', 'personalized', 'fine-tuning', 'improves', 'model', 'reasoning', 'compared', 'non-personalized', 'models', '.', 'experiments', 'datasets', 'emotion', 'recognition', 'hate', 'speech', 'detection', 'show', 'consistent', 'performance', 'gains', 'personalized', 'methods', 'across', 'different', 'llm', 'architectures', '.', 'findings', 'underscore', 'importance', 'personalization', 'enhancing', 'llm', 'capabilities', 'subjective', 'text', 'perception', 'tasks', '.']","large, language, models, (, llms, ), significantly, advanced, natural, language, processing, (, nlp, ), tasks, recent, years, ., however, ,, universal, nature, poses, limitations, scenarios, requiring, personalized, responses, ,, recommendation, systems, chatbots, ., paper, investigates, methods, personalize, llms, ,, comparing, fine-tuning, zero-shot, reasoning, approaches, subjective, tasks, ., results, demonstrate, personalized, fine-tuning, improves, model, reasoning, compared, non-personalized, models, ., experiments, datasets, emotion, recognition, hate, speech, detection, show, consistent, performance, gains, personalized, methods, across, different, llm, architectures, ., findings, underscore, importance, personalization, enhancing, llm, capabilities, subjective, text, perception, tasks, ."
"Interactive Task and Concept Learning from Natural Language Instructions
  and GUI Demonstrations","Toby Jia-Jun Li, Marissa Radensky, Justin Jia, Kirielle Singarajah, Tom M. Mitchell, Brad A. Myers",2019-08-30T18:35:01Z,"  Natural language programming is a promising approach to enable end users to
instruct new tasks for intelligent agents. However, our formative study found
that end users would often use unclear, ambiguous or vague concepts when
naturally instructing tasks in natural language, especially when specifying
conditionals. Existing systems have limited support for letting the user teach
agents new concepts or explaining unclear concepts. In this paper, we describe
a new multi-modal domain-independent approach that combines natural language
programming and programming-by-demonstration to allow users to first naturally
describe tasks and associated conditions at a high level, and then collaborate
with the agent to recursively resolve any ambiguities or vagueness through
conversations and demonstrations. Users can also define new procedures and
concepts by demonstrating and referring to contents within GUIs of existing
mobile apps. We demonstrate this approach in PUMICE, an end-user programmable
agent that implements this approach. A lab study with 10 users showed its
usability.
","['natural', 'language', 'programming', 'promising', 'approach', 'enable', 'end', 'users', 'instruct', 'new', 'tasks', 'intelligent', 'agents', '.', 'however', ',', 'formative', 'study', 'found', 'end', 'users', 'would', 'often', 'use', 'unclear', ',', 'ambiguous', 'vague', 'concepts', 'naturally', 'instructing', 'tasks', 'natural', 'language', ',', 'especially', 'specifying', 'conditionals', '.', 'existing', 'systems', 'limited', 'support', 'letting', 'user', 'teach', 'agents', 'new', 'concepts', 'explaining', 'unclear', 'concepts', '.', 'paper', ',', 'describe', 'new', 'multi-modal', 'domain-independent', 'approach', 'combines', 'natural', 'language', 'programming', 'programming-by-demonstration', 'allow', 'users', 'first', 'naturally', 'describe', 'tasks', 'associated', 'conditions', 'high', 'level', ',', 'collaborate', 'agent', 'recursively', 'resolve', 'ambiguities', 'vagueness', 'conversations', 'demonstrations', '.', 'users', 'also', 'define', 'new', 'procedures', 'concepts', 'demonstrating', 'referring', 'contents', 'within', 'guis', 'existing', 'mobile', 'apps', '.', 'demonstrate', 'approach', 'pumice', ',', 'end-user', 'programmable', 'agent', 'implements', 'approach', '.', 'lab', 'study', '10', 'users', 'showed', 'usability', '.']","natural, language, programming, promising, approach, enable, end, users, instruct, new, tasks, intelligent, agents, ., however, ,, formative, study, found, end, users, would, often, use, unclear, ,, ambiguous, vague, concepts, naturally, instructing, tasks, natural, language, ,, especially, specifying, conditionals, ., existing, systems, limited, support, letting, user, teach, agents, new, concepts, explaining, unclear, concepts, ., paper, ,, describe, new, multi-modal, domain-independent, approach, combines, natural, language, programming, programming-by-demonstration, allow, users, first, naturally, describe, tasks, associated, conditions, high, level, ,, collaborate, agent, recursively, resolve, ambiguities, vagueness, conversations, demonstrations, ., users, also, define, new, procedures, concepts, demonstrating, referring, contents, within, guis, existing, mobile, apps, ., demonstrate, approach, pumice, ,, end-user, programmable, agent, implements, approach, ., lab, study, 10, users, showed, usability, ."
Integrating Approaches to Word Representation,Yuval Pinter,2021-09-10T13:44:15Z,"  The problem of representing the atomic elements of language in modern neural
learning systems is one of the central challenges of the field of natural
language processing. I present a survey of the distributional, compositional,
and relational approaches to addressing this task, and discuss various means of
integrating them into systems, with special emphasis on the word level and the
out-of-vocabulary phenomenon.
","['problem', 'representing', 'atomic', 'elements', 'language', 'modern', 'neural', 'learning', 'systems', 'one', 'central', 'challenges', 'field', 'natural', 'language', 'processing', '.', 'present', 'survey', 'distributional', ',', 'compositional', ',', 'relational', 'approaches', 'addressing', 'task', ',', 'discuss', 'various', 'means', 'integrating', 'systems', ',', 'special', 'emphasis', 'word', 'level', 'out-of-vocabulary', 'phenomenon', '.']","problem, representing, atomic, elements, language, modern, neural, learning, systems, one, central, challenges, field, natural, language, processing, ., present, survey, distributional, ,, compositional, ,, relational, approaches, addressing, task, ,, discuss, various, means, integrating, systems, ,, special, emphasis, word, level, out-of-vocabulary, phenomenon, ."
"Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial
  Text Attacks","Piotr Gaiński, Klaudia Bałazy",2023-02-10T08:50:51Z,"  We propose a novel gradient-based attack against transformer-based language
models that searches for an adversarial example in a continuous space of token
probabilities. Our algorithm mitigates the gap between adversarial loss for
continuous and discrete text representations by performing multi-step
quantization in a quantization-compensation loop. Experiments show that our
method significantly outperforms other approaches on various natural language
processing (NLP) tasks.
","['propose', 'novel', 'gradient-based', 'attack', 'transformer-based', 'language', 'models', 'searches', 'adversarial', 'example', 'continuous', 'space', 'token', 'probabilities', '.', 'algorithm', 'mitigates', 'gap', 'adversarial', 'loss', 'continuous', 'discrete', 'text', 'representations', 'performing', 'multi-step', 'quantization', 'quantization-compensation', 'loop', '.', 'experiments', 'show', 'method', 'significantly', 'outperforms', 'approaches', 'various', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', '.']","propose, novel, gradient-based, attack, transformer-based, language, models, searches, adversarial, example, continuous, space, token, probabilities, ., algorithm, mitigates, gap, adversarial, loss, continuous, discrete, text, representations, performing, multi-step, quantization, quantization-compensation, loop, ., experiments, show, method, significantly, outperforms, approaches, various, natural, language, processing, (, nlp, ), tasks, ."
"Field-testing items using artificial intelligence: Natural language
  processing with transformers",Hotaka Maeda,2023-10-18T01:56:16Z,"  Five thousand variations of the RoBERTa model, an artificially intelligent
""transformer"" that can understand text language, completed an English literacy
exam with 29 multiple-choice questions. Data were used to calculate the
psychometric properties of the items, which showed some degree of agreement to
those obtained from human examinee data.
","['five', 'thousand', 'variations', 'roberta', 'model', ',', 'artificially', 'intelligent', ""''"", 'transformer', ""''"", 'understand', 'text', 'language', ',', 'completed', 'english', 'literacy', 'exam', '29', 'multiple-choice', 'questions', '.', 'data', 'used', 'calculate', 'psychometric', 'properties', 'items', ',', 'showed', 'degree', 'agreement', 'obtained', 'human', 'examinee', 'data', '.']","five, thousand, variations, roberta, model, ,, artificially, intelligent, '', transformer, '', understand, text, language, ,, completed, english, literacy, exam, 29, multiple-choice, questions, ., data, used, calculate, psychometric, properties, items, ,, showed, degree, agreement, obtained, human, examinee, data, ."
Social Media Sentiment Analysis for Cryptocurrency Market Prediction,"Ali Raheman, Anton Kolonin, Igors Fridkins, Ikram Ansari, Mukul Vishwas",2022-04-19T03:27:29Z,"  In this paper, we explore the usability of different natural language
processing models for the sentiment analysis of social media applied to
financial market prediction, using the cryptocurrency domain as a reference. We
study how the different sentiment metrics are correlated with the price
movements of Bitcoin. For this purpose, we explore different methods to
calculate the sentiment metrics from a text finding most of them not very
accurate for this prediction task. We find that one of the models outperforms
more than 20 other public ones and makes it possible to fine-tune it
efficiently given its interpretable nature. Thus we confirm that interpretable
artificial intelligence and natural language processing methods might be more
valuable practically than non-explainable and non-interpretable ones. In the
end, we analyse potential causal connections between the different sentiment
metrics and the price movements.
","['paper', ',', 'explore', 'usability', 'different', 'natural', 'language', 'processing', 'models', 'sentiment', 'analysis', 'social', 'media', 'applied', 'financial', 'market', 'prediction', ',', 'using', 'cryptocurrency', 'domain', 'reference', '.', 'study', 'different', 'sentiment', 'metrics', 'correlated', 'price', 'movements', 'bitcoin', '.', 'purpose', ',', 'explore', 'different', 'methods', 'calculate', 'sentiment', 'metrics', 'text', 'finding', 'accurate', 'prediction', 'task', '.', 'find', 'one', 'models', 'outperforms', '20', 'public', 'ones', 'makes', 'possible', 'fine-tune', 'efficiently', 'given', 'interpretable', 'nature', '.', 'thus', 'confirm', 'interpretable', 'artificial', 'intelligence', 'natural', 'language', 'processing', 'methods', 'might', 'valuable', 'practically', 'non-explainable', 'non-interpretable', 'ones', '.', 'end', ',', 'analyse', 'potential', 'causal', 'connections', 'different', 'sentiment', 'metrics', 'price', 'movements', '.']","paper, ,, explore, usability, different, natural, language, processing, models, sentiment, analysis, social, media, applied, financial, market, prediction, ,, using, cryptocurrency, domain, reference, ., study, different, sentiment, metrics, correlated, price, movements, bitcoin, ., purpose, ,, explore, different, methods, calculate, sentiment, metrics, text, finding, accurate, prediction, task, ., find, one, models, outperforms, 20, public, ones, makes, possible, fine-tune, efficiently, given, interpretable, nature, ., thus, confirm, interpretable, artificial, intelligence, natural, language, processing, methods, might, valuable, practically, non-explainable, non-interpretable, ones, ., end, ,, analyse, potential, causal, connections, different, sentiment, metrics, price, movements, ."
"CADgpt: Harnessing Natural Language Processing for 3D Modelling to
  Enhance Computer-Aided Design Workflows",Timo Kapsalis,2024-01-10T17:32:32Z,"  This paper introduces CADgpt, an innovative plugin integrating Natural
Language Processing (NLP) with Rhino3D for enhancing 3D modelling in
computer-aided design (CAD) environments. Leveraging OpenAI's GPT-4, CADgpt
simplifies the CAD interface, enabling users, particularly beginners, to
perform complex 3D modelling tasks through intuitive natural language commands.
This approach significantly reduces the learning curve associated with
traditional CAD software, fostering a more inclusive and engaging educational
environment. The paper discusses CADgpt's technical architecture, including its
integration within Rhino3D and the adaptation of GPT-4 capabilities for CAD
tasks. It presents case studies demonstrating CADgpt's efficacy in various
design scenarios, highlighting its potential to democratise design education by
making sophisticated design tools accessible to a broader range of students.
The discussion further explores CADgpt's implications for pedagogy and
curriculum development, emphasising its role in enhancing creative exploration
and conceptual thinking in design education.
  Keywords: Natural Language Processing, Computer-Aided Design, 3D Modelling,
Design Automation, Design Education, Architectural Education
","['paper', 'introduces', 'cadgpt', ',', 'innovative', 'plugin', 'integrating', 'natural', 'language', 'processing', '(', 'nlp', ')', 'rhino3d', 'enhancing', '3d', 'modelling', 'computer-aided', 'design', '(', 'cad', ')', 'environments', '.', 'leveraging', 'openai', ""'s"", 'gpt-4', ',', 'cadgpt', 'simplifies', 'cad', 'interface', ',', 'enabling', 'users', ',', 'particularly', 'beginners', ',', 'perform', 'complex', '3d', 'modelling', 'tasks', 'intuitive', 'natural', 'language', 'commands', '.', 'approach', 'significantly', 'reduces', 'learning', 'curve', 'associated', 'traditional', 'cad', 'software', ',', 'fostering', 'inclusive', 'engaging', 'educational', 'environment', '.', 'paper', 'discusses', 'cadgpt', ""'s"", 'technical', 'architecture', ',', 'including', 'integration', 'within', 'rhino3d', 'adaptation', 'gpt-4', 'capabilities', 'cad', 'tasks', '.', 'presents', 'case', 'studies', 'demonstrating', 'cadgpt', ""'s"", 'efficacy', 'various', 'design', 'scenarios', ',', 'highlighting', 'potential', 'democratise', 'design', 'education', 'making', 'sophisticated', 'design', 'tools', 'accessible', 'broader', 'range', 'students', '.', 'discussion', 'explores', 'cadgpt', ""'s"", 'implications', 'pedagogy', 'curriculum', 'development', ',', 'emphasising', 'role', 'enhancing', 'creative', 'exploration', 'conceptual', 'thinking', 'design', 'education', '.', 'keywords', ':', 'natural', 'language', 'processing', ',', 'computer-aided', 'design', ',', '3d', 'modelling', ',', 'design', 'automation', ',', 'design', 'education', ',', 'architectural', 'education']","paper, introduces, cadgpt, ,, innovative, plugin, integrating, natural, language, processing, (, nlp, ), rhino3d, enhancing, 3d, modelling, computer-aided, design, (, cad, ), environments, ., leveraging, openai, 's, gpt-4, ,, cadgpt, simplifies, cad, interface, ,, enabling, users, ,, particularly, beginners, ,, perform, complex, 3d, modelling, tasks, intuitive, natural, language, commands, ., approach, significantly, reduces, learning, curve, associated, traditional, cad, software, ,, fostering, inclusive, engaging, educational, environment, ., paper, discusses, cadgpt, 's, technical, architecture, ,, including, integration, within, rhino3d, adaptation, gpt-4, capabilities, cad, tasks, ., presents, case, studies, demonstrating, cadgpt, 's, efficacy, various, design, scenarios, ,, highlighting, potential, democratise, design, education, making, sophisticated, design, tools, accessible, broader, range, students, ., discussion, explores, cadgpt, 's, implications, pedagogy, curriculum, development, ,, emphasising, role, enhancing, creative, exploration, conceptual, thinking, design, education, ., keywords, :, natural, language, processing, ,, computer-aided, design, ,, 3d, modelling, ,, design, automation, ,, design, education, ,, architectural, education"
A Survey of Code-switched Speech and Language Processing,"Sunayana Sitaram, Khyathi Raghavi Chandu, Sai Krishna Rallabandi, Alan W Black",2019-03-25T14:36:50Z,"  Code-switching, the alternation of languages within a conversation or
utterance, is a common communicative phenomenon that occurs in multilingual
communities across the world. This survey reviews computational approaches for
code-switched Speech and Natural Language Processing. We motivate why
processing code-switched text and speech is essential for building intelligent
agents and systems that interact with users in multilingual communities. As
code-switching data and resources are scarce, we list what is available in
various code-switched language pairs with the language processing tasks they
can be used for. We review code-switching research in various Speech and NLP
applications, including language processing tools and end-to-end systems. We
conclude with future directions and open problems in the field.
","['code-switching', ',', 'alternation', 'languages', 'within', 'conversation', 'utterance', ',', 'common', 'communicative', 'phenomenon', 'occurs', 'multilingual', 'communities', 'across', 'world', '.', 'survey', 'reviews', 'computational', 'approaches', 'code-switched', 'speech', 'natural', 'language', 'processing', '.', 'motivate', 'processing', 'code-switched', 'text', 'speech', 'essential', 'building', 'intelligent', 'agents', 'systems', 'interact', 'users', 'multilingual', 'communities', '.', 'code-switching', 'data', 'resources', 'scarce', ',', 'list', 'available', 'various', 'code-switched', 'language', 'pairs', 'language', 'processing', 'tasks', 'used', '.', 'review', 'code-switching', 'research', 'various', 'speech', 'nlp', 'applications', ',', 'including', 'language', 'processing', 'tools', 'end-to-end', 'systems', '.', 'conclude', 'future', 'directions', 'open', 'problems', 'field', '.']","code-switching, ,, alternation, languages, within, conversation, utterance, ,, common, communicative, phenomenon, occurs, multilingual, communities, across, world, ., survey, reviews, computational, approaches, code-switched, speech, natural, language, processing, ., motivate, processing, code-switched, text, speech, essential, building, intelligent, agents, systems, interact, users, multilingual, communities, ., code-switching, data, resources, scarce, ,, list, available, various, code-switched, language, pairs, language, processing, tasks, used, ., review, code-switching, research, various, speech, nlp, applications, ,, including, language, processing, tools, end-to-end, systems, ., conclude, future, directions, open, problems, field, ."
"Is Attention always needed? A Case Study on Language Identification from
  Speech","Atanu Mandal, Santanu Pal, Indranil Dutta, Mahidas Bhattacharya, Sudip Kumar Naskar",2021-10-05T16:38:57Z,"  Language Identification (LID) is a crucial preliminary process in the field
of Automatic Speech Recognition (ASR) that involves the identification of a
spoken language from audio samples. Contemporary systems that can process
speech in multiple languages require users to expressly designate one or more
languages prior to utilization. The LID task assumes a significant role in
scenarios where ASR systems are unable to comprehend the spoken language in
multilingual settings, leading to unsuccessful speech recognition outcomes. The
present study introduces convolutional recurrent neural network (CRNN) based
LID, designed to operate on the Mel-frequency Cepstral Coefficient (MFCC)
characteristics of audio samples. Furthermore, we replicate certain
state-of-the-art methodologies, specifically the Convolutional Neural Network
(CNN) and Attention-based Convolutional Recurrent Neural Network (CRNN with
attention), and conduct a comparative analysis with our CRNN-based approach. We
conducted comprehensive evaluations on thirteen distinct Indian languages and
our model resulted in over 98\% classification accuracy. The LID model exhibits
high-performance levels ranging from 97% to 100% for languages that are
linguistically similar. The proposed LID model exhibits a high degree of
extensibility to additional languages and demonstrates a strong resistance to
noise, achieving 91.2% accuracy in a noisy setting when applied to a European
Language (EU) dataset.
","['language', 'identification', '(', 'lid', ')', 'crucial', 'preliminary', 'process', 'field', 'automatic', 'speech', 'recognition', '(', 'asr', ')', 'involves', 'identification', 'spoken', 'language', 'audio', 'samples', '.', 'contemporary', 'systems', 'process', 'speech', 'multiple', 'languages', 'require', 'users', 'expressly', 'designate', 'one', 'languages', 'prior', 'utilization', '.', 'lid', 'task', 'assumes', 'significant', 'role', 'scenarios', 'asr', 'systems', 'unable', 'comprehend', 'spoken', 'language', 'multilingual', 'settings', ',', 'leading', 'unsuccessful', 'speech', 'recognition', 'outcomes', '.', 'present', 'study', 'introduces', 'convolutional', 'recurrent', 'neural', 'network', '(', 'crnn', ')', 'based', 'lid', ',', 'designed', 'operate', 'mel-frequency', 'cepstral', 'coefficient', '(', 'mfcc', ')', 'characteristics', 'audio', 'samples', '.', 'furthermore', ',', 'replicate', 'certain', 'state-of-the-art', 'methodologies', ',', 'specifically', 'convolutional', 'neural', 'network', '(', 'cnn', ')', 'attention-based', 'convolutional', 'recurrent', 'neural', 'network', '(', 'crnn', 'attention', ')', ',', 'conduct', 'comparative', 'analysis', 'crnn-based', 'approach', '.', 'conducted', 'comprehensive', 'evaluations', 'thirteen', 'distinct', 'indian', 'languages', 'model', 'resulted', '98\\', '%', 'classification', 'accuracy', '.', 'lid', 'model', 'exhibits', 'high-performance', 'levels', 'ranging', '97', '%', '100', '%', 'languages', 'linguistically', 'similar', '.', 'proposed', 'lid', 'model', 'exhibits', 'high', 'degree', 'extensibility', 'additional', 'languages', 'demonstrates', 'strong', 'resistance', 'noise', ',', 'achieving', '91.2', '%', 'accuracy', 'noisy', 'setting', 'applied', 'european', 'language', '(', 'eu', ')', 'dataset', '.']","language, identification, (, lid, ), crucial, preliminary, process, field, automatic, speech, recognition, (, asr, ), involves, identification, spoken, language, audio, samples, ., contemporary, systems, process, speech, multiple, languages, require, users, expressly, designate, one, languages, prior, utilization, ., lid, task, assumes, significant, role, scenarios, asr, systems, unable, comprehend, spoken, language, multilingual, settings, ,, leading, unsuccessful, speech, recognition, outcomes, ., present, study, introduces, convolutional, recurrent, neural, network, (, crnn, ), based, lid, ,, designed, operate, mel-frequency, cepstral, coefficient, (, mfcc, ), characteristics, audio, samples, ., furthermore, ,, replicate, certain, state-of-the-art, methodologies, ,, specifically, convolutional, neural, network, (, cnn, ), attention-based, convolutional, recurrent, neural, network, (, crnn, attention, ), ,, conduct, comparative, analysis, crnn-based, approach, ., conducted, comprehensive, evaluations, thirteen, distinct, indian, languages, model, resulted, 98\, %, classification, accuracy, ., lid, model, exhibits, high-performance, levels, ranging, 97, %, 100, %, languages, linguistically, similar, ., proposed, lid, model, exhibits, high, degree, extensibility, additional, languages, demonstrates, strong, resistance, noise, ,, achieving, 91.2, %, accuracy, noisy, setting, applied, european, language, (, eu, ), dataset, ."
Tackling Vision Language Tasks Through Learning Inner Monologues,"Diji Yang, Kezhen Chen, Jinmeng Rao, Xiaoyuan Guo, Yawen Zhang, Jie Yang, Yi Zhang",2023-08-19T10:10:49Z,"  Visual language tasks require AI models to comprehend and reason with both
visual and textual content. Driven by the power of Large Language Models
(LLMs), two prominent methods have emerged: (1) the hybrid integration between
LLMs and Vision-Language Models (VLMs), where visual inputs are firstly
converted into language descriptions by VLMs, serving as inputs for LLMs to
generate final answer(s); (2) visual feature alignment in language space, where
visual inputs are encoded as embeddings and projected to LLMs' language space
via further supervised fine-tuning. The first approach provides light training
costs and interpretability but is hard to be optimized in an end-to-end
fashion. The second approach presents decent performance, but feature alignment
usually requires large amounts of training data and lacks interpretability. To
tackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal
Optimization (IMMO), to solve complex vision language problems by simulating
inner monologue processes, a cognitive process in which an individual engages
in silent verbal communication with themselves. We enable LLMs and VLMs to
interact through natural language conversation and propose to use a two-stage
training process to learn how to do the inner monologue (self-asking questions
and answering questions). IMMO is evaluated on two popular tasks and the
results suggest by emulating the cognitive phenomenon of internal dialogue, our
approach can enhance reasoning and explanation abilities, contributing to the
more effective fusion of vision and language models. More importantly, instead
of using predefined human-crafted monologues, IMMO learns this process within
the deep learning models, promising wider applicability to many different AI
problems beyond vision language tasks.
","['visual', 'language', 'tasks', 'require', 'ai', 'models', 'comprehend', 'reason', 'visual', 'textual', 'content', '.', 'driven', 'power', 'large', 'language', 'models', '(', 'llms', ')', ',', 'two', 'prominent', 'methods', 'emerged', ':', '(', '1', ')', 'hybrid', 'integration', 'llms', 'vision-language', 'models', '(', 'vlms', ')', ',', 'visual', 'inputs', 'firstly', 'converted', 'language', 'descriptions', 'vlms', ',', 'serving', 'inputs', 'llms', 'generate', 'final', 'answer', '(', ')', ';', '(', '2', ')', 'visual', 'feature', 'alignment', 'language', 'space', ',', 'visual', 'inputs', 'encoded', 'embeddings', 'projected', 'llms', ""'"", 'language', 'space', 'via', 'supervised', 'fine-tuning', '.', 'first', 'approach', 'provides', 'light', 'training', 'costs', 'interpretability', 'hard', 'optimized', 'end-to-end', 'fashion', '.', 'second', 'approach', 'presents', 'decent', 'performance', ',', 'feature', 'alignment', 'usually', 'requires', 'large', 'amounts', 'training', 'data', 'lacks', 'interpretability', '.', 'tackle', 'dilemma', ',', 'propose', 'novel', 'approach', ',', 'inner', 'monologue', 'multi-modal', 'optimization', '(', 'immo', ')', ',', 'solve', 'complex', 'vision', 'language', 'problems', 'simulating', 'inner', 'monologue', 'processes', ',', 'cognitive', 'process', 'individual', 'engages', 'silent', 'verbal', 'communication', '.', 'enable', 'llms', 'vlms', 'interact', 'natural', 'language', 'conversation', 'propose', 'use', 'two-stage', 'training', 'process', 'learn', 'inner', 'monologue', '(', 'self-asking', 'questions', 'answering', 'questions', ')', '.', 'immo', 'evaluated', 'two', 'popular', 'tasks', 'results', 'suggest', 'emulating', 'cognitive', 'phenomenon', 'internal', 'dialogue', ',', 'approach', 'enhance', 'reasoning', 'explanation', 'abilities', ',', 'contributing', 'effective', 'fusion', 'vision', 'language', 'models', '.', 'importantly', ',', 'instead', 'using', 'predefined', 'human-crafted', 'monologues', ',', 'immo', 'learns', 'process', 'within', 'deep', 'learning', 'models', ',', 'promising', 'wider', 'applicability', 'many', 'different', 'ai', 'problems', 'beyond', 'vision', 'language', 'tasks', '.']","visual, language, tasks, require, ai, models, comprehend, reason, visual, textual, content, ., driven, power, large, language, models, (, llms, ), ,, two, prominent, methods, emerged, :, (, 1, ), hybrid, integration, llms, vision-language, models, (, vlms, ), ,, visual, inputs, firstly, converted, language, descriptions, vlms, ,, serving, inputs, llms, generate, final, answer, (, ), ;, (, 2, ), visual, feature, alignment, language, space, ,, visual, inputs, encoded, embeddings, projected, llms, ', language, space, via, supervised, fine-tuning, ., first, approach, provides, light, training, costs, interpretability, hard, optimized, end-to-end, fashion, ., second, approach, presents, decent, performance, ,, feature, alignment, usually, requires, large, amounts, training, data, lacks, interpretability, ., tackle, dilemma, ,, propose, novel, approach, ,, inner, monologue, multi-modal, optimization, (, immo, ), ,, solve, complex, vision, language, problems, simulating, inner, monologue, processes, ,, cognitive, process, individual, engages, silent, verbal, communication, ., enable, llms, vlms, interact, natural, language, conversation, propose, use, two-stage, training, process, learn, inner, monologue, (, self-asking, questions, answering, questions, ), ., immo, evaluated, two, popular, tasks, results, suggest, emulating, cognitive, phenomenon, internal, dialogue, ,, approach, enhance, reasoning, explanation, abilities, ,, contributing, effective, fusion, vision, language, models, ., importantly, ,, instead, using, predefined, human-crafted, monologues, ,, immo, learns, process, within, deep, learning, models, ,, promising, wider, applicability, many, different, ai, problems, beyond, vision, language, tasks, ."
"Bridging between Cognitive Processing Signals and Linguistic Features
  via a Unified Attentional Network","Yuqi Ren, Deyi Xiong",2021-12-16T12:25:11Z,"  Cognitive processing signals can be used to improve natural language
processing (NLP) tasks. However, it is not clear how these signals correlate
with linguistic information. Bridging between human language processing and
linguistic features has been widely studied in neurolinguistics, usually via
single-variable controlled experiments with highly-controlled stimuli. Such
methods not only compromises the authenticity of natural reading, but also are
time-consuming and expensive. In this paper, we propose a data-driven method to
investigate the relationship between cognitive processing signals and
linguistic features. Specifically, we present a unified attentional framework
that is composed of embedding, attention, encoding and predicting layers to
selectively map cognitive processing signals to linguistic features. We define
the mapping procedure as a bridging task and develop 12 bridging tasks for
lexical, syntactic and semantic features. The proposed framework only requires
cognitive processing signals recorded under natural reading as inputs, and can
be used to detect a wide range of linguistic features with a single cognitive
dataset. Observations from experiment results resonate with previous
neuroscience findings. In addition to this, our experiments also reveal a
number of interesting findings, such as the correlation between contextual
eye-tracking features and tense of sentence.
","['cognitive', 'processing', 'signals', 'used', 'improve', 'natural', 'language', 'processing', '(', 'nlp', ')', 'tasks', '.', 'however', ',', 'clear', 'signals', 'correlate', 'linguistic', 'information', '.', 'bridging', 'human', 'language', 'processing', 'linguistic', 'features', 'widely', 'studied', 'neurolinguistics', ',', 'usually', 'via', 'single-variable', 'controlled', 'experiments', 'highly-controlled', 'stimuli', '.', 'methods', 'compromises', 'authenticity', 'natural', 'reading', ',', 'also', 'time-consuming', 'expensive', '.', 'paper', ',', 'propose', 'data-driven', 'method', 'investigate', 'relationship', 'cognitive', 'processing', 'signals', 'linguistic', 'features', '.', 'specifically', ',', 'present', 'unified', 'attentional', 'framework', 'composed', 'embedding', ',', 'attention', ',', 'encoding', 'predicting', 'layers', 'selectively', 'map', 'cognitive', 'processing', 'signals', 'linguistic', 'features', '.', 'define', 'mapping', 'procedure', 'bridging', 'task', 'develop', '12', 'bridging', 'tasks', 'lexical', ',', 'syntactic', 'semantic', 'features', '.', 'proposed', 'framework', 'requires', 'cognitive', 'processing', 'signals', 'recorded', 'natural', 'reading', 'inputs', ',', 'used', 'detect', 'wide', 'range', 'linguistic', 'features', 'single', 'cognitive', 'dataset', '.', 'observations', 'experiment', 'results', 'resonate', 'previous', 'neuroscience', 'findings', '.', 'addition', ',', 'experiments', 'also', 'reveal', 'number', 'interesting', 'findings', ',', 'correlation', 'contextual', 'eye-tracking', 'features', 'tense', 'sentence', '.']","cognitive, processing, signals, used, improve, natural, language, processing, (, nlp, ), tasks, ., however, ,, clear, signals, correlate, linguistic, information, ., bridging, human, language, processing, linguistic, features, widely, studied, neurolinguistics, ,, usually, via, single-variable, controlled, experiments, highly-controlled, stimuli, ., methods, compromises, authenticity, natural, reading, ,, also, time-consuming, expensive, ., paper, ,, propose, data-driven, method, investigate, relationship, cognitive, processing, signals, linguistic, features, ., specifically, ,, present, unified, attentional, framework, composed, embedding, ,, attention, ,, encoding, predicting, layers, selectively, map, cognitive, processing, signals, linguistic, features, ., define, mapping, procedure, bridging, task, develop, 12, bridging, tasks, lexical, ,, syntactic, semantic, features, ., proposed, framework, requires, cognitive, processing, signals, recorded, natural, reading, inputs, ,, used, detect, wide, range, linguistic, features, single, cognitive, dataset, ., observations, experiment, results, resonate, previous, neuroscience, findings, ., addition, ,, experiments, also, reveal, number, interesting, findings, ,, correlation, contextual, eye-tracking, features, tense, sentence, ."
"Deep Lexical Hypothesis: Identifying personality structure in natural
  language","Andrew Cutler, David M. Condon",2022-03-04T02:06:10Z,"  Recent advances in natural language processing (NLP) have produced general
models that can perform complex tasks such as summarizing long passages and
translating across languages. Here, we introduce a method to extract adjective
similarities from language models as done with survey-based ratings in
traditional psycholexical studies but using millions of times more text in a
natural setting. The correlational structure produced through this method is
highly similar to that of self- and other-ratings of 435 terms reported by
Saucier and Goldberg (1996a). The first three unrotated factors produced using
NLP are congruent with those in survey data, with coefficients of 0.89, 0.79,
and 0.79. This structure is robust to many modeling decisions: adjective set,
including those with 1,710 terms (Goldberg, 1982) and 18,000 terms (Allport &
Odbert, 1936); the query used to extract correlations; and language model.
Notably, Neuroticism and Openness are only weakly and inconsistently recovered.
This is a new source of signal that is closer to the original (semantic) vision
of the Lexical Hypothesis. The method can be applied where surveys cannot: in
dozens of languages simultaneously, with tens of thousands of items, on
historical text, and at extremely large scale for little cost. The code is made
public to facilitate reproduction and fast iteration in new directions of
research.
","['recent', 'advances', 'natural', 'language', 'processing', '(', 'nlp', ')', 'produced', 'general', 'models', 'perform', 'complex', 'tasks', 'summarizing', 'long', 'passages', 'translating', 'across', 'languages', '.', ',', 'introduce', 'method', 'extract', 'adjective', 'similarities', 'language', 'models', 'done', 'survey-based', 'ratings', 'traditional', 'psycholexical', 'studies', 'using', 'millions', 'times', 'text', 'natural', 'setting', '.', 'correlational', 'structure', 'produced', 'method', 'highly', 'similar', 'self-', 'other-ratings', '435', 'terms', 'reported', 'saucier', 'goldberg', '(', '1996a', ')', '.', 'first', 'three', 'unrotated', 'factors', 'produced', 'using', 'nlp', 'congruent', 'survey', 'data', ',', 'coefficients', '0.89', ',', '0.79', ',', '0.79.', 'structure', 'robust', 'many', 'modeling', 'decisions', ':', 'adjective', 'set', ',', 'including', '1,710', 'terms', '(', 'goldberg', ',', '1982', ')', '18,000', 'terms', '(', 'allport', '&', 'odbert', ',', '1936', ')', ';', 'query', 'used', 'extract', 'correlations', ';', 'language', 'model', '.', 'notably', ',', 'neuroticism', 'openness', 'weakly', 'inconsistently', 'recovered', '.', 'new', 'source', 'signal', 'closer', 'original', '(', 'semantic', ')', 'vision', 'lexical', 'hypothesis', '.', 'method', 'applied', 'surveys', ':', 'dozens', 'languages', 'simultaneously', ',', 'tens', 'thousands', 'items', ',', 'historical', 'text', ',', 'extremely', 'large', 'scale', 'little', 'cost', '.', 'code', 'made', 'public', 'facilitate', 'reproduction', 'fast', 'iteration', 'new', 'directions', 'research', '.']","recent, advances, natural, language, processing, (, nlp, ), produced, general, models, perform, complex, tasks, summarizing, long, passages, translating, across, languages, ., ,, introduce, method, extract, adjective, similarities, language, models, done, survey-based, ratings, traditional, psycholexical, studies, using, millions, times, text, natural, setting, ., correlational, structure, produced, method, highly, similar, self-, other-ratings, 435, terms, reported, saucier, goldberg, (, 1996a, ), ., first, three, unrotated, factors, produced, using, nlp, congruent, survey, data, ,, coefficients, 0.89, ,, 0.79, ,, 0.79., structure, robust, many, modeling, decisions, :, adjective, set, ,, including, 1,710, terms, (, goldberg, ,, 1982, ), 18,000, terms, (, allport, &, odbert, ,, 1936, ), ;, query, used, extract, correlations, ;, language, model, ., notably, ,, neuroticism, openness, weakly, inconsistently, recovered, ., new, source, signal, closer, original, (, semantic, ), vision, lexical, hypothesis, ., method, applied, surveys, :, dozens, languages, simultaneously, ,, tens, thousands, items, ,, historical, text, ,, extremely, large, scale, little, cost, ., code, made, public, facilitate, reproduction, fast, iteration, new, directions, research, ."
"Revisiting and Advancing Chinese Natural Language Understanding with
  Accelerated Heterogeneous Knowledge Pre-training","Taolin Zhang, Junwei Dong, Jianing Wang, Chengyu Wang, Ang Wang, Yinghui Liu, Jun Huang, Yong Li, Xiaofeng He",2022-10-11T09:34:21Z,"  Recently, knowledge-enhanced pre-trained language models (KEPLMs) improve
context-aware representations via learning from structured relations in
knowledge graphs, and/or linguistic knowledge from syntactic or dependency
analysis. Unlike English, there is a lack of high-performing open-source
Chinese KEPLMs in the natural language processing (NLP) community to support
various language understanding applications. In this paper, we revisit and
advance the development of Chinese natural language understanding with a series
of novel Chinese KEPLMs released in various parameter sizes, namely CKBERT
(Chinese knowledge-enhanced BERT).Specifically, both relational and linguistic
knowledge is effectively injected into CKBERT based on two novel pre-training
tasks, i.e., linguistic-aware masked language modeling and contrastive
multi-hop relation modeling. Based on the above two pre-training paradigms and
our in-house implemented TorchAccelerator, we have pre-trained base (110M),
large (345M) and huge (1.3B) versions of CKBERT efficiently on GPU clusters.
Experiments demonstrate that CKBERT outperforms strong baselines for Chinese
over various benchmark NLP tasks and in terms of different model sizes.
","['recently', ',', 'knowledge-enhanced', 'pre-trained', 'language', 'models', '(', 'keplms', ')', 'improve', 'context-aware', 'representations', 'via', 'learning', 'structured', 'relations', 'knowledge', 'graphs', ',', 'and/or', 'linguistic', 'knowledge', 'syntactic', 'dependency', 'analysis', '.', 'unlike', 'english', ',', 'lack', 'high-performing', 'open-source', 'chinese', 'keplms', 'natural', 'language', 'processing', '(', 'nlp', ')', 'community', 'support', 'various', 'language', 'understanding', 'applications', '.', 'paper', ',', 'revisit', 'advance', 'development', 'chinese', 'natural', 'language', 'understanding', 'series', 'novel', 'chinese', 'keplms', 'released', 'various', 'parameter', 'sizes', ',', 'namely', 'ckbert', '(', 'chinese', 'knowledge-enhanced', 'bert', ')', '.specifically', ',', 'relational', 'linguistic', 'knowledge', 'effectively', 'injected', 'ckbert', 'based', 'two', 'novel', 'pre-training', 'tasks', ',', 'i.e.', ',', 'linguistic-aware', 'masked', 'language', 'modeling', 'contrastive', 'multi-hop', 'relation', 'modeling', '.', 'based', 'two', 'pre-training', 'paradigms', 'in-house', 'implemented', 'torchaccelerator', ',', 'pre-trained', 'base', '(', '110m', ')', ',', 'large', '(', '345m', ')', 'huge', '(', '1.3b', ')', 'versions', 'ckbert', 'efficiently', 'gpu', 'clusters', '.', 'experiments', 'demonstrate', 'ckbert', 'outperforms', 'strong', 'baselines', 'chinese', 'various', 'benchmark', 'nlp', 'tasks', 'terms', 'different', 'model', 'sizes', '.']","recently, ,, knowledge-enhanced, pre-trained, language, models, (, keplms, ), improve, context-aware, representations, via, learning, structured, relations, knowledge, graphs, ,, and/or, linguistic, knowledge, syntactic, dependency, analysis, ., unlike, english, ,, lack, high-performing, open-source, chinese, keplms, natural, language, processing, (, nlp, ), community, support, various, language, understanding, applications, ., paper, ,, revisit, advance, development, chinese, natural, language, understanding, series, novel, chinese, keplms, released, various, parameter, sizes, ,, namely, ckbert, (, chinese, knowledge-enhanced, bert, ), .specifically, ,, relational, linguistic, knowledge, effectively, injected, ckbert, based, two, novel, pre-training, tasks, ,, i.e., ,, linguistic-aware, masked, language, modeling, contrastive, multi-hop, relation, modeling, ., based, two, pre-training, paradigms, in-house, implemented, torchaccelerator, ,, pre-trained, base, (, 110m, ), ,, large, (, 345m, ), huge, (, 1.3b, ), versions, ckbert, efficiently, gpu, clusters, ., experiments, demonstrate, ckbert, outperforms, strong, baselines, chinese, various, benchmark, nlp, tasks, terms, different, model, sizes, ."
"Universal Syntactic Structures: Modeling Syntax for Various Natural
  Languages","Min K. Kim, Hafu Takero, Sara Fedovik",2023-12-28T20:44:26Z,"  We aim to provide an explanation for how the human brain might connect words
for sentence formation. A novel approach to modeling syntactic representation
is introduced, potentially showing the existence of universal syntactic
structures for all natural languages. As the discovery of DNA's double helix
structure shed light on the inner workings of genetics, we wish to introduce a
basic understanding of how language might work in the human brain. It could be
the brain's way of encoding and decoding knowledge. It also brings some insight
into theories in linguistics, psychology, and cognitive science. After looking
into the logic behind universal syntactic structures and the methodology of the
modeling technique, we attempt to analyze corpora that showcase universality in
the language process of different natural languages such as English and Korean.
Lastly, we discuss the critical period hypothesis, universal grammar, and a few
other assertions on language for the purpose of advancing our understanding of
the human brain.
","['aim', 'provide', 'explanation', 'human', 'brain', 'might', 'connect', 'words', 'sentence', 'formation', '.', 'novel', 'approach', 'modeling', 'syntactic', 'representation', 'introduced', ',', 'potentially', 'showing', 'existence', 'universal', 'syntactic', 'structures', 'natural', 'languages', '.', 'discovery', 'dna', ""'s"", 'double', 'helix', 'structure', 'shed', 'light', 'inner', 'workings', 'genetics', ',', 'wish', 'introduce', 'basic', 'understanding', 'language', 'might', 'work', 'human', 'brain', '.', 'could', 'brain', ""'s"", 'way', 'encoding', 'decoding', 'knowledge', '.', 'also', 'brings', 'insight', 'theories', 'linguistics', ',', 'psychology', ',', 'cognitive', 'science', '.', 'looking', 'logic', 'behind', 'universal', 'syntactic', 'structures', 'methodology', 'modeling', 'technique', ',', 'attempt', 'analyze', 'corpora', 'showcase', 'universality', 'language', 'process', 'different', 'natural', 'languages', 'english', 'korean', '.', 'lastly', ',', 'discuss', 'critical', 'period', 'hypothesis', ',', 'universal', 'grammar', ',', 'assertions', 'language', 'purpose', 'advancing', 'understanding', 'human', 'brain', '.']","aim, provide, explanation, human, brain, might, connect, words, sentence, formation, ., novel, approach, modeling, syntactic, representation, introduced, ,, potentially, showing, existence, universal, syntactic, structures, natural, languages, ., discovery, dna, 's, double, helix, structure, shed, light, inner, workings, genetics, ,, wish, introduce, basic, understanding, language, might, work, human, brain, ., could, brain, 's, way, encoding, decoding, knowledge, ., also, brings, insight, theories, linguistics, ,, psychology, ,, cognitive, science, ., looking, logic, behind, universal, syntactic, structures, methodology, modeling, technique, ,, attempt, analyze, corpora, showcase, universality, language, process, different, natural, languages, english, korean, ., lastly, ,, discuss, critical, period, hypothesis, ,, universal, grammar, ,, assertions, language, purpose, advancing, understanding, human, brain, ."
"Leveraging Prompt-Learning for Structured Information Extraction from
  Crohn's Disease Radiology Reports in a Low-Resource Language","Liam Hazan, Gili Focht, Naama Gavrielov, Roi Reichart, Talar Hagopian, Mary-Louise C. Greer, Ruth Cytter Kuint, Dan Turner, Moti Freiman",2024-05-02T19:11:54Z,"  Automatic conversion of free-text radiology reports into structured data
using Natural Language Processing (NLP) techniques is crucial for analyzing
diseases on a large scale. While effective for tasks in widely spoken languages
like English, generative large language models (LLMs) typically underperform
with less common languages and can pose potential risks to patient privacy.
Fine-tuning local NLP models is hindered by the skewed nature of real-world
medical datasets, where rare findings represent a significant data imbalance.
We introduce SMP-BERT, a novel prompt learning method that leverages the
structured nature of reports to overcome these challenges. In our studies
involving a substantial collection of Crohn's disease radiology reports in
Hebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed
traditional fine-tuning methods in performance, notably in detecting infrequent
conditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more
accurate AI diagnostics available for low-resource languages.
","['automatic', 'conversion', 'free-text', 'radiology', 'reports', 'structured', 'data', 'using', 'natural', 'language', 'processing', '(', 'nlp', ')', 'techniques', 'crucial', 'analyzing', 'diseases', 'large', 'scale', '.', 'effective', 'tasks', 'widely', 'spoken', 'languages', 'like', 'english', ',', 'generative', 'large', 'language', 'models', '(', 'llms', ')', 'typically', 'underperform', 'less', 'common', 'languages', 'pose', 'potential', 'risks', 'patient', 'privacy', '.', 'fine-tuning', 'local', 'nlp', 'models', 'hindered', 'skewed', 'nature', 'real-world', 'medical', 'datasets', ',', 'rare', 'findings', 'represent', 'significant', 'data', 'imbalance', '.', 'introduce', 'smp-bert', ',', 'novel', 'prompt', 'learning', 'method', 'leverages', 'structured', 'nature', 'reports', 'overcome', 'challenges', '.', 'studies', 'involving', 'substantial', 'collection', 'crohn', ""'s"", 'disease', 'radiology', 'reports', 'hebrew', '(', '8,000', 'patients', '10,000', 'reports', ')', ',', 'smp-bert', 'greatly', 'surpassed', 'traditional', 'fine-tuning', 'methods', 'performance', ',', 'notably', 'detecting', 'infrequent', 'conditions', '(', 'auc', ':', '0.99', 'vs', '0.94', ',', 'f1', ':', '0.84', 'vs', '0.34', ')', '.', 'smp-bert', 'empowers', 'accurate', 'ai', 'diagnostics', 'available', 'low-resource', 'languages', '.']","automatic, conversion, free-text, radiology, reports, structured, data, using, natural, language, processing, (, nlp, ), techniques, crucial, analyzing, diseases, large, scale, ., effective, tasks, widely, spoken, languages, like, english, ,, generative, large, language, models, (, llms, ), typically, underperform, less, common, languages, pose, potential, risks, patient, privacy, ., fine-tuning, local, nlp, models, hindered, skewed, nature, real-world, medical, datasets, ,, rare, findings, represent, significant, data, imbalance, ., introduce, smp-bert, ,, novel, prompt, learning, method, leverages, structured, nature, reports, overcome, challenges, ., studies, involving, substantial, collection, crohn, 's, disease, radiology, reports, hebrew, (, 8,000, patients, 10,000, reports, ), ,, smp-bert, greatly, surpassed, traditional, fine-tuning, methods, performance, ,, notably, detecting, infrequent, conditions, (, auc, :, 0.99, vs, 0.94, ,, f1, :, 0.84, vs, 0.34, ), ., smp-bert, empowers, accurate, ai, diagnostics, available, low-resource, languages, ."
"Early Prediction of 30-day ICU Re-admissions Using Natural Language
  Processing and Machine Learning","Zhiheng Li, Xinyue Xing, Bingzhang Lu, Zhixiang Li",2019-10-06T22:54:00Z,"  ICU readmission is associated with longer hospitalization, mortality and
adverse outcomes. An early recognition of ICU re-admission can help prevent
patients from worse situation and lower treatment cost. As the abundance of
Electronics Health Records (EHR), it is popular to design clinical decision
tools with machine learning technique manipulating on healthcare large scale
data. We designed data-driven predictive models to estimate the risk of ICU
readmission. The discharge summary of each hospital admission was carefully
represented by natural language processing techniques. Unified Medical Language
System (UMLS) was further used to standardize inconsistency of discharge
summaries. 5 machine learning classifiers were adopted to construct predictive
models. The best configuration yielded a competitive AUC of 0.748. Our work
suggests that natural language processing of discharge summaries is capable to
send clinicians warning of unplanned 30-day readmission upon discharge.
","['icu', 'readmission', 'associated', 'longer', 'hospitalization', ',', 'mortality', 'adverse', 'outcomes', '.', 'early', 'recognition', 'icu', 're-admission', 'help', 'prevent', 'patients', 'worse', 'situation', 'lower', 'treatment', 'cost', '.', 'abundance', 'electronics', 'health', 'records', '(', 'ehr', ')', ',', 'popular', 'design', 'clinical', 'decision', 'tools', 'machine', 'learning', 'technique', 'manipulating', 'healthcare', 'large', 'scale', 'data', '.', 'designed', 'data-driven', 'predictive', 'models', 'estimate', 'risk', 'icu', 'readmission', '.', 'discharge', 'summary', 'hospital', 'admission', 'carefully', 'represented', 'natural', 'language', 'processing', 'techniques', '.', 'unified', 'medical', 'language', 'system', '(', 'umls', ')', 'used', 'standardize', 'inconsistency', 'discharge', 'summaries', '.', '5', 'machine', 'learning', 'classifiers', 'adopted', 'construct', 'predictive', 'models', '.', 'best', 'configuration', 'yielded', 'competitive', 'auc', '0.748.', 'work', 'suggests', 'natural', 'language', 'processing', 'discharge', 'summaries', 'capable', 'send', 'clinicians', 'warning', 'unplanned', '30-day', 'readmission', 'upon', 'discharge', '.']","icu, readmission, associated, longer, hospitalization, ,, mortality, adverse, outcomes, ., early, recognition, icu, re-admission, help, prevent, patients, worse, situation, lower, treatment, cost, ., abundance, electronics, health, records, (, ehr, ), ,, popular, design, clinical, decision, tools, machine, learning, technique, manipulating, healthcare, large, scale, data, ., designed, data-driven, predictive, models, estimate, risk, icu, readmission, ., discharge, summary, hospital, admission, carefully, represented, natural, language, processing, techniques, ., unified, medical, language, system, (, umls, ), used, standardize, inconsistency, discharge, summaries, ., 5, machine, learning, classifiers, adopted, construct, predictive, models, ., best, configuration, yielded, competitive, auc, 0.748., work, suggests, natural, language, processing, discharge, summaries, capable, send, clinicians, warning, unplanned, 30-day, readmission, upon, discharge, ."
A Survey on Using Gaze Behaviour for Natural Language Processing,"Sandeep Mathias, Diptesh Kanojia, Abhijit Mishra, Pushpak Bhattacharyya",2021-12-21T15:52:56Z,"  Gaze behaviour has been used as a way to gather cognitive information for a
number of years. In this paper, we discuss the use of gaze behaviour in solving
different tasks in natural language processing (NLP) without having to record
it at test time. This is because the collection of gaze behaviour is a costly
task, both in terms of time and money. Hence, in this paper, we focus on
research done to alleviate the need for recording gaze behaviour at run time.
We also mention different eye tracking corpora in multiple languages, which are
currently available and can be used in natural language processing. We conclude
our paper by discussing applications in a domain - education - and how learning
gaze behaviour can help in solving the tasks of complex word identification and
automatic essay grading.
","['gaze', 'behaviour', 'used', 'way', 'gather', 'cognitive', 'information', 'number', 'years', '.', 'paper', ',', 'discuss', 'use', 'gaze', 'behaviour', 'solving', 'different', 'tasks', 'natural', 'language', 'processing', '(', 'nlp', ')', 'without', 'record', 'test', 'time', '.', 'collection', 'gaze', 'behaviour', 'costly', 'task', ',', 'terms', 'time', 'money', '.', 'hence', ',', 'paper', ',', 'focus', 'research', 'done', 'alleviate', 'need', 'recording', 'gaze', 'behaviour', 'run', 'time', '.', 'also', 'mention', 'different', 'eye', 'tracking', 'corpora', 'multiple', 'languages', ',', 'currently', 'available', 'used', 'natural', 'language', 'processing', '.', 'conclude', 'paper', 'discussing', 'applications', 'domain', '-', 'education', '-', 'learning', 'gaze', 'behaviour', 'help', 'solving', 'tasks', 'complex', 'word', 'identification', 'automatic', 'essay', 'grading', '.']","gaze, behaviour, used, way, gather, cognitive, information, number, years, ., paper, ,, discuss, use, gaze, behaviour, solving, different, tasks, natural, language, processing, (, nlp, ), without, record, test, time, ., collection, gaze, behaviour, costly, task, ,, terms, time, money, ., hence, ,, paper, ,, focus, research, done, alleviate, need, recording, gaze, behaviour, run, time, ., also, mention, different, eye, tracking, corpora, multiple, languages, ,, currently, available, used, natural, language, processing, ., conclude, paper, discussing, applications, domain, -, education, -, learning, gaze, behaviour, help, solving, tasks, complex, word, identification, automatic, essay, grading, ."
A Neural-Symbolic Approach to Natural Language Understanding,"Zhixuan Liu, Zihao Wang, Yuan Lin, Hang Li",2022-03-20T14:12:44Z,"  Deep neural networks, empowered by pre-trained language models, have achieved
remarkable results in natural language understanding (NLU) tasks. However,
their performances can drastically deteriorate when logical reasoning is
needed. This is because NLU in principle depends on not only analogical
reasoning, which deep neural networks are good at, but also logical reasoning.
According to the dual-process theory, analogical reasoning and logical
reasoning are respectively carried out by System 1 and System 2 in the human
brain. Inspired by the theory, we present a novel framework for NLU called
Neural-Symbolic Processor (NSP), which performs analogical reasoning based on
neural processing and logical reasoning based on both neural and symbolic
processing. As a case study, we conduct experiments on two NLU tasks, question
answering (QA) and natural language inference (NLI), when numerical reasoning
(a type of logical reasoning) is necessary. The experimental results show that
our method significantly outperforms state-of-the-art methods in both tasks.
","['deep', 'neural', 'networks', ',', 'empowered', 'pre-trained', 'language', 'models', ',', 'achieved', 'remarkable', 'results', 'natural', 'language', 'understanding', '(', 'nlu', ')', 'tasks', '.', 'however', ',', 'performances', 'drastically', 'deteriorate', 'logical', 'reasoning', 'needed', '.', 'nlu', 'principle', 'depends', 'analogical', 'reasoning', ',', 'deep', 'neural', 'networks', 'good', ',', 'also', 'logical', 'reasoning', '.', 'according', 'dual-process', 'theory', ',', 'analogical', 'reasoning', 'logical', 'reasoning', 'respectively', 'carried', 'system', '1', 'system', '2', 'human', 'brain', '.', 'inspired', 'theory', ',', 'present', 'novel', 'framework', 'nlu', 'called', 'neural-symbolic', 'processor', '(', 'nsp', ')', ',', 'performs', 'analogical', 'reasoning', 'based', 'neural', 'processing', 'logical', 'reasoning', 'based', 'neural', 'symbolic', 'processing', '.', 'case', 'study', ',', 'conduct', 'experiments', 'two', 'nlu', 'tasks', ',', 'question', 'answering', '(', 'qa', ')', 'natural', 'language', 'inference', '(', 'nli', ')', ',', 'numerical', 'reasoning', '(', 'type', 'logical', 'reasoning', ')', 'necessary', '.', 'experimental', 'results', 'show', 'method', 'significantly', 'outperforms', 'state-of-the-art', 'methods', 'tasks', '.']","deep, neural, networks, ,, empowered, pre-trained, language, models, ,, achieved, remarkable, results, natural, language, understanding, (, nlu, ), tasks, ., however, ,, performances, drastically, deteriorate, logical, reasoning, needed, ., nlu, principle, depends, analogical, reasoning, ,, deep, neural, networks, good, ,, also, logical, reasoning, ., according, dual-process, theory, ,, analogical, reasoning, logical, reasoning, respectively, carried, system, 1, system, 2, human, brain, ., inspired, theory, ,, present, novel, framework, nlu, called, neural-symbolic, processor, (, nsp, ), ,, performs, analogical, reasoning, based, neural, processing, logical, reasoning, based, neural, symbolic, processing, ., case, study, ,, conduct, experiments, two, nlu, tasks, ,, question, answering, (, qa, ), natural, language, inference, (, nli, ), ,, numerical, reasoning, (, type, logical, reasoning, ), necessary, ., experimental, results, show, method, significantly, outperforms, state-of-the-art, methods, tasks, ."
